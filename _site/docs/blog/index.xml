<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Kwangmin Kim</title>
<link>kmink3225.netlify.app/docs/blog/index.html</link>
<atom:link href="kmink3225.netlify.app/docs/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>blog</description>
<generator>quarto-1.2.313</generator>
<lastBuildDate>Tue, 31 Dec 2999 15:00:00 GMT</lastBuildDate>
<item>
  <title>Blog Content List</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/content_list.html</link>
  <description><![CDATA[ 



<section id="contents" class="level1">
<h1>Contents</h1>
<ul>
<li><a href="../../../docs/blog/posts/DL/guide_map/index.html">Deep Learning</a></li>
<li><a href="../../../docs/blog/posts/ML/guide_map/index.html">Machine Learning</a></li>
<li><a href="../../../docs/blog/posts/Mathmatics/guide_map/index.html">Mathematics</a></li>
<li><a href="../../../docs/blog/posts/statistics/guide_map/index.html">Statistics</a></li>
<li><a href="../../../docs/blog/posts/Engineering/guide_map/index.html">Engineering</a></li>
<li><a href="../../../docs/blog/posts/Patent/guide_map/index.html">Patent</a></li>
<li><a href="../../../docs/blog/posts/Language/guide_map/index.html">Language</a></li>
<li><a href="../../../docs/blog/posts/Surveilance/guide_map/index.html">Surveilance</a></li>
</ul>
</section>
<section id="reference" class="level1">
<h1>Reference</h1>
<ul>
<li>Statistics
<ul>
<li>George Casella &amp; Rogeer L. Berger - Statistcal Inference, 2nd Edition</li>
<li>Dobson and Barnett (2008) An Introduction to Generalized Linear Model. 3rd Ed. Chapman &amp; Hall.</li>
<li>Fitzmaurice, Laird and Ware (2011) Applied Longitudinal Analysis. 2nd Ed. Wiley.</li>
<li>Hosmer, Lemeshow and May (2008) Applied Survival Analysis. 2nd Ed. Wiley.</li>
<li>슬기로운 통계생활 - https://www.youtube.com/<span class="citation" data-cites="statisticsplaybook">@statisticsplaybook</span></li>
<li>슬기로운 통계생활 - https://github.com/statisticsplaybook</li>
<li>Fast Campus, Coursera, Inflearn</li>
<li>그 외 다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Mathematics
<ul>
<li>James Stewart - Calculus Early Transcedentals, 7th Eidition &amp; any James Stewart series</li>
<li>GILBERT STRANG - Introduction to Linear Algebra, 4th Edition.</li>
<li>임장환 - 머신러닝, 인공지능, 컴퓨터 비전 전공자를 위한 최적화 이론</li>
<li>Fast Campus, Coursera, Inflearn</li>
<li>그 외 다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Machine Learning
<ul>
<li>Gareth M. James, Daniela Witten, Trevor Hastie, Robert Tibshirani - An Introduction to Statistical Learning: With Applications in R 2nd Edition</li>
<li>Trevor Hastie, Robert Tibshirani, Jerome H. Friedman - The Elements of Statistical Learning 2nd Edition</li>
<li>Fast Campus, Coursera, Inflearn</li>
<li>그 외 다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Deep Learning
<ul>
<li>Saito Koki - Deep Learning from Scratch 1,2,3 (밑바닥부터 시작하는 딥러닝 1,2,3)</li>
<li>조준우 - 머신러닝·딥러닝에 필요한 기초 수학 with 파이썬</li>
<li>조준우 - https://github.com/metamath1/noviceml</li>
<li>동빈나 - https://www.youtube.com/c/dongbinna</li>
<li>혁펜하임 - https://www.youtube.com/channel/UCcbPAIfCa4q0x7x8yFXmBag</li>
<li>Fast Campus, Coursera, Inflearn</li>
<li>다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Engineering
<ul>
<li>Fast Campus, Coursera, Inflearn</li>
<li>그 외 다수의 Youtube, and Documents from Googling</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>All List</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/content_list.html</guid>
  <pubDate>Tue, 31 Dec 2999 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Statistics</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/statistics/guide_map/index.html</link>
  <description><![CDATA[ 



<p><strong>(Draft)</strong></p>
<section id="contents-list" class="level1">
<h1>Contents List</h1>
<section id="basic" class="level2">
<h2 class="anchored" data-anchor-id="basic">Basic</h2>
<section id="probability-theory" class="level3">
<h3 class="anchored" data-anchor-id="probability-theory">Probability Theory</h3>
<ul>
<li>2023-02-05, Set Theory</li>
<li>2023-02-05, [Basics of Probability Theory - Axiomatic Foundations]</li>
<li>2023-02-05, [Basics of Probability Theory - Calculus of Probabilities]</li>
<li>2023-02-05, <a href="../../../../../docs/blog/posts/statistics/2023-02-05_probability/index.html">Basics of Probability Theory - Probability</a></li>
<li>2023-02-05, <a href="../../../../../docs/blog/posts/statistics/2023-02-05_conditional_probability/index.html">Conditional Probability</a></li>
<li>2023-02-05, [Independence]</li>
<li>2023-02-05, <a href="../../../../../docs/blog/posts/statistics/2023-02-05_bayes_rule/index.html">Bayes’ Rule</a></li>
<li>2023-02-05, Random Variable</li>
<li>1111-11-11, Probability Distribution</li>
</ul>
</section>
<section id="transformations-and-expectations" class="level3">
<h3 class="anchored" data-anchor-id="transformations-and-expectations">Transformations and Expectations</h3>
<ul>
<li>2023-02-21, <a href="../../../../../docs/blog/posts/statistics/2023-02-21_transformation/index.html">Transformation of Random Variables</a></li>
<li>1111-11-11, Expected Value vs Realizaed Value</li>
<li>1111-11-11, Variance</li>
<li>1111-11-11, Covariance and Correlation</li>
<li>2023-02-28, <a href="../../../../../docs/blog/posts/statistics/2023-02-28_mgf/index.html">Moment Generating Function, MGF</a></li>
</ul>
</section>
<section id="exponential-family-distributions" class="level3">
<h3 class="anchored" data-anchor-id="exponential-family-distributions">Exponential Family Distributions</h3>
<ul>
<li>Discrete Random Variable
<ul>
<li>2023-02-27,<a href="../../../../../docs/blog/posts/statistics/2023-02-27_exponential_family/discrete_bernoulli.html">Bernoulli Distribution</a></li>
<li>2023-02-28,<a href="../../../../../docs/blog/posts/statistics/2023-02-27_exponential_family/discrete_binomial.html">Binomial Distribution</a></li>
<li>2023-03-01,<a href="../../../../../docs/blog/posts/statistics/2023-02-27_exponential_family/discrete_poisson.html">Poisson Distribution</a></li>
<li>2023-03-01,<a href="../../../../../docs/blog/posts/statistics/2023-02-27_exponential_family/discrete_geometric.html">Geometric Distribution</a></li>
<li>1111-11-11, Hypergeometric Distribution</li>
</ul></li>
<li>Continuous Random Variable
<ul>
<li>1111-11-11, Normal Distribution</li>
<li>1111-11-11, Exponential Distribution</li>
<li>1111-11-11, Beta Distribution</li>
<li>1111-11-11, Chi-squared Distribution</li>
</ul></li>
<li>1111-11-11,</li>
</ul>
</section>
<section id="multiple-random-variables" class="level3">
<h3 class="anchored" data-anchor-id="multiple-random-variables">Multiple Random Variables</h3>
<ul>
<li>1111-11-11, Joint Distribution and Marginal Distribution</li>
</ul>
</section>
<section id="point-estimation" class="level3">
<h3 class="anchored" data-anchor-id="point-estimation">Point Estimation</h3>
<ul>
<li>1111-11-11, Estimation Methods - Method of Moments</li>
<li>2023-03-29, Estimation Methods - <a href="../../../../../docs/blog/posts/statistics/2023-03-25_MLE/index.html">Maximum Likelihood Estimation &amp; Statistical Bias</a></li>
<li>1111-11-11, Estimation Methods - Bayesian Estimation</li>
<li>1111-11-11, Estimation Methods - The EM Algorithm</li>
<li>1111-11-11, Evaluation Methods of Estimators - Mean Squared Error</li>
<li>1111-11-11, Evaluation Methods of Estimators - Best Unbiased Estimators</li>
<li>1111-11-11, Evaluation Methods of Estimators - Sufficiency and Unbiasedness</li>
<li>1111-11-11, Evaluation Methods of Estimators - Loss Function Optimality</li>
</ul>
</section>
</section>
<section id="hypothesis-testing" class="level2">
<h2 class="anchored" data-anchor-id="hypothesis-testing">Hypothesis Testing</h2>
<ul>
<li>1111-11-11, Hypothesis Testing</li>
<li>1111-11-11, Permutation Test</li>
</ul>
<section id="methods-of-finding-tests" class="level3">
<h3 class="anchored" data-anchor-id="methods-of-finding-tests">Methods of Finding Tests</h3>
<ul>
<li>1111-11-11, Likelihood Ratio Tests</li>
<li>1111-11-11, Bayesian Tests</li>
<li>1111-11-11, Union-Intersection and Intersection-Union Tets</li>
</ul>
</section>
<section id="methods-of-evaluating-tests" class="level3">
<h3 class="anchored" data-anchor-id="methods-of-evaluating-tests">Methods of Evaluating Tests</h3>
<ul>
<li>1111-11-11, Power</li>
<li>1111-11-11, Error Proabilities and the Power Function</li>
<li>1111-11-11, Most Powerful Tests</li>
<li>2022-12-28, <a href="../../../../../docs/blog/posts/statistics/2022-12-08-P-value/index.html">p-values</a></li>
<li>1111-11-11, Loss Function Optimality</li>
<li>1111-11-11, Multiple Testing</li>
<li>1111-11-11, Sample Size Calculation</li>
<li>1111-11-11, A/B Testing</li>
<li>2023-01-07, <a href="../../../../../docs/blog/posts/statistics/2023-01-07-anova/index.html">ANOVA</a>
<ul>
<li>2023-01-27, <a href="../2023-01-27_ANCOVA/">ANCOVA</a></li>
<li>2023-01-27, <a href="../2023-01-27_rmANOVA/">repeated measures ANOVA</a></li>
<li>2023-01-28, <a href="../2023-01-28_MANOVA/">MANOVA</a></li>
</ul></li>
</ul>
</section>
</section>
<section id="categorical-data-analysis" class="level2">
<h2 class="anchored" data-anchor-id="categorical-data-analysis">Categorical Data Analysis</h2>
<ul>
<li>1111-11-11, Introduction</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>2022-12-28,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>2023-01-07,</li>
<li>2023-01-27,</li>
<li>2023-01-27,</li>
<li>2023-01-28,</li>
</ul>
</section>
<section id="regression" class="level2">
<h2 class="anchored" data-anchor-id="regression">Regression</h2>
<ul>
<li>1111-11-11, Least Square and Simple Linear Regression</li>
<li>1111-11-11, Multiple Linear Regression</li>
</ul>
<section id="generalized-linear-models" class="level3">
<h3 class="anchored" data-anchor-id="generalized-linear-models">Generalized Linear Models</h3>
<ul>
<li>1111-11-11, Logistic Regression</li>
<li>1111-11-11, Multinomial Regression</li>
<li>1111-11-11, Poisson Regression</li>
<li>1111-11-11, Poisson Regression</li>
<li>1111-11-11, Poisson Regression</li>
</ul>
</section>
</section>
<section id="longitudinal-data-analysis" class="level2">
<h2 class="anchored" data-anchor-id="longitudinal-data-analysis">Longitudinal Data Analysis</h2>
<ul>
<li>2023-03-23, <a href="../../../../../docs/blog/posts/statistics/LDA/1_intro.html">LDA (1) - Intro</a></li>
<li>2023-03-23, <a href="../../../../../docs/blog/posts/statistics/LDA/2_covariance_model.html">LDA (2) - Concepts &amp; Covariance Models</a></li>
<li>2023-03-25, <a href="../LDA/intro.qmd">LDA (3) - WLS &amp; REML</a></li>
<li>2023-03-25, <a href="../LDA/intro.qmd">LDA (4) - Respiratory Infection Data Example</a></li>
<li>2023-03-28, <a href="../LDA/intro.qmd">LDA (5) - Epileptic Seizures Data Example</a></li>
</ul>
<section id="mixed-models" class="level3">
<h3 class="anchored" data-anchor-id="mixed-models">Mixed Models</h3>
<ul>
<li>1111-11-11, Linear Mixed Models</li>
</ul>
</section>
</section>
<section id="generalized-additive-models" class="level2">
<h2 class="anchored" data-anchor-id="generalized-additive-models">Generalized Additive Models</h2>
</section>
<section id="survival-analysis" class="level2">
<h2 class="anchored" data-anchor-id="survival-analysis">Survival Analysis</h2>
<ul>
<li>1111-11-11, Cox-Hazard Model</li>
</ul>


</section>
</section>

 ]]></description>
  <category>Statistics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/statistics/guide_map/index.html</guid>
  <pubDate>Fri, 30 Apr 2100 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Machine Learning</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/ML/guide_map/index.html</link>
  <description><![CDATA[ 



<p><strong>(Draft)</strong></p>
<section id="contents-list" class="level1">
<h1>Contents List</h1>
<section id="basic" class="level2">
<h2 class="anchored" data-anchor-id="basic">Basic</h2>
<section id="r" class="level3">
<h3 class="anchored" data-anchor-id="r">R</h3>
</section>
<section id="python" class="level3">
<h3 class="anchored" data-anchor-id="python">Python</h3>
<section id="tensor-flow-framework" class="level4">
<h4 class="anchored" data-anchor-id="tensor-flow-framework">Tensor Flow Framework</h4>
<ul>
<li>2023-02-03, <a href="../../../../../docs/blog/posts/ML/2023-02-03_tf_introduction/index.html">Tensor Flow Introduction</a></li>
</ul>
</section>
<section id="pytorch-framework" class="level4">
<h4 class="anchored" data-anchor-id="pytorch-framework">Pytorch Framework</h4>
<ul>
<li>2023-02-03, <a href="../../../../../docs/blog/posts/ML/2023-02-03_pytorch_introduction/index.html">Pytorch Introduction</a></li>
</ul>
</section>
</section>
</section>
<section id="machine-learning-methods" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning-methods">Machine Learning Methods</h2>
<section id="supervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="supervised-learning">Supervised Learning</h3>
<ul>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Logistic Regression]</li>
<li>0000-00=00, [Generative Models]
<ul>
<li>0000-00=00, [Linear Discriminant Analysis]</li>
<li>0000-00=00, [Quadratic Discriminant Analysis]</li>
<li>0000-00=00, [Naive Bayes]</li>
</ul></li>
<li>0000-00=00, [Resampling Methods]</li>
<li>0000-00=00, [Regularization]</li>
<li>0000-00=00, [Smoothing]</li>
<li>0000-00=00, [Tree Based Methods]</li>
<li>0000-00=00, [Support Vector Machine]</li>
<li>0000-00=00, [PCR]</li>
<li>0000-00=00, [PLS]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
</ul>
</section>
<section id="unupervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="unupervised-learning">Unupervised Learning</h3>
<ul>
<li>0000-00=00, [PCA]</li>
<li>0000-00=00, [K means clustering]</li>
<li>0000-00=00, [Hierarchical Clustering]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
</ul>


</section>
</section>
</section>

 ]]></description>
  <category>ML</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/ML/guide_map/index.html</guid>
  <pubDate>Wed, 31 Mar 2100 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Mathematics</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/guide_map/index.html</link>
  <description><![CDATA[ 



<section id="contents" class="level1">
<h1>Contents</h1>
<section id="basic" class="level2">
<h2 class="anchored" data-anchor-id="basic">Basic</h2>
<ul>
<li>2023-03-24, <a href="../../../../../docs/blog/posts/Mathmatics/variables/index.html">Variable types</a></li>
<li>1111-11-11, <a href="../../../../../docs/blog/posts/Mathmatics/function/index.html">Function</a>
<ul>
<li>2023-01-31, <a href="../../../../../docs/blog/posts/Mathmatics/function/univariable_scalar_function.html">Function (1) - Univariable Scalar Function (One to One)</a></li>
<li>2023-01-31, <a href="../../../../../docs/blog/posts/Mathmatics/function/multivariable_scalar_function.html">Function (2) - Multi-variable Scalar Function (Many to One)</a></li>
<li>2023-01-31, <a href="../../../../../docs/blog/posts/Mathmatics/function/univariable_vector_function.html">Function (3) - Univariable Vector Function (One to Many)</a></li>
<li>2023-01-31, <a href="../../../../../docs/blog/posts/Mathmatics/function/mutivariable_vector_function.html">Function (4) - Multi-variable Vector Function (Many to Many)</a></li>
<li>2023-02-18, <a href="../../../../../docs/blog/posts/Mathmatics/function/composite_function.html">Function (5) - Composite Function</a></li>
</ul></li>
<li>2023-02-18, <a href="../../../../../docs/blog/posts/Mathmatics/transformation/index.html">Transformations of Functions</a></li>
<li>1111-11-11, Vector &amp; Matrix</li>
<li>2023-03-15, <a href="../epsilon_delta/">Limit, <img src="https://latex.codecogs.com/png.latex?%5Cepsilon-%5Cdelta"> Method</a></li>
<li>Differentiation
<ul>
<li>2023-02-04, <a href="../../../../../docs/blog/posts/Mathmatics/differentiation/2023-02-04_uni_derivative.html">Derivative (1) - Univariable Scalar Funtion</a></li>
<li>1111-11-11, <a href="../../../../../docs/blog/posts/Mathmatics/differentiation/2023-02-10_composite_partial_derivative.html">Derivative (2) - Chain Rule &amp; Partial Derivative</a></li>
<li>1111-11-11, Derivative (3) - Higher Order Derivative</li>
<li>1111-11-11, Derivative (4) - Mean Value Theorem</li>
<li>1111-11-11, Derivative (5) - Gradient</li>
</ul></li>
<li>2023-03-15, <a href="../../../../../docs/blog/posts/Mathmatics/taylor_series/index.html">Talyer’s Series</a></li>
<li>1111-11-11, Gradient Direction</li>
<li>1111-11-11, Random Variable</li>
<li>1111-11-11, Probability Distribution</li>
<li>1111-11-11, Information Theory - Entropy</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
</ul>
</section>
<section id="linear-algebra" class="level2">
<h2 class="anchored" data-anchor-id="linear-algebra">Linear Algebra</h2>
<ul>
<li>1111-11-11, Vector Space</li>
<li>1111-11-11, Subspace</li>
<li>1111-11-11, Inner Product</li>
<li>1111-11-11, Linear Combination</li>
<li>1111-11-11, Quadratic Form</li>
<li>1111-11-11, Linear Independence</li>
<li>1111-11-11, Basis, Dimension, &amp; Rank</li>
<li>1111-11-11, Outer Product</li>
<li>1111-11-11, Eigen Value &amp; Eigen Vector</li>
<li>1111-11-11, Eigen Decomposition</li>
<li>1111-11-11, Singular Value Decomposition (SVD)</li>
<li>1111-11-11, Gram-Schmidt</li>
<li>1111-11-11, Group</li>
<li>1111-11-11, Orthogonal Matrix</li>
<li>1111-11-11, Rotation &amp; Group</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
</ul>
</section>
<section id="optimization" class="level2">
<h2 class="anchored" data-anchor-id="optimization">Optimization</h2>
<ul>
<li>2023-03-23, <a href="../../../../../docs/blog/posts/Mathmatics/optimization/minimizer.html">Minimizer &amp; Minimum</a></li>
<li>1111-11-11, Convex Set</li>
<li>1111-11-11, Convex Function</li>
<li>1111-11-11, Unconstrained Optimization</li>
<li>1111-11-11, Non-linear Least Square</li>
<li>1111-11-11, Largrange Multiplier Method
<ul>
<li>1111-11-11, Largrange Primal Function</li>
<li>1111-11-11, Largrange Dual Function</li>
<li>1111-11-11, KKT conditions</li>
</ul></li>
<li>1111-11-11, Gradient Descent Optimizers</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
</ul>
</section>
<section id="reference" class="level2">
<h2 class="anchored" data-anchor-id="reference">Reference</h2>
<ul>
<li>Statistics
<ul>
<li>George Casella &amp; Rogeer L. Berger - Statistcal Inference, 2nd Edition</li>
<li>슬기로운 통계생활 - https://www.youtube.com/<span class="citation" data-cites="statisticsplaybook">@statisticsplaybook</span></li>
<li>슬기로운 통계생활 - https://github.com/statisticsplaybook</li>
<li>다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Mathematics
<ul>
<li>James Stewart - Calculus Early Transcedentals, 7th Eidition</li>
<li>any James Stewart series</li>
<li>임장환 - 머신러닝, 인공지능, 컴퓨터 비전 전공자를 위한 최적화 이론</li>
<li>다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Deep Learning
<ul>
<li>조준우 - 머신러닝·딥러닝에 필요한 기초 수학 with 파이썬</li>
<li>조준우 - https://github.com/metamath1/noviceml</li>
<li>동빈나 - https://www.youtube.com/c/dongbinna</li>
<li>혁펜하임 - https://www.youtube.com/channel/UCcbPAIfCa4q0x7x8yFXmBag</li>
<li>다수의 Youtube, and Documents from Googling</li>
</ul></li>
</ul>


</section>
</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/guide_map/index.html</guid>
  <pubDate>Sun, 28 Feb 2100 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Deep Learning</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/DL/guide_map/index.html</link>
  <description><![CDATA[ 



<p><strong>(Draft)</strong></p>
<section id="contents-list" class="level1">
<h1>Contents List</h1>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<ul>
<li>1111-11-11, Artificial Intelligence</li>
<li>1111-11-11, Perceptron</li>
<li>1111-11-11, Artificial Neural Netwroks (ANN)
<ul>
<li>1111-11-11, activation functions</li>
<li>1111-11-11, output layer design</li>
</ul></li>
<li>1111-11-11, loss function</li>
<li>1111-11-11, numerical differentiation</li>
<li>1111-11-11, gradient descent</li>
<li>1111-11-11, backpropagation</li>
<li>1111-11-11, optimizer
<ul>
<li>1111-11-11, stochastic gradient descent</li>
<li>1111-11-11, momentum</li>
<li>1111-11-11, adaGrad</li>
<li>1111-11-11, adam</li>
<li>1111-11-11, weight initalization</li>
</ul></li>
<li>1111-11-11, batch normalization</li>
<li>1111-11-11, dropout</li>
<li>1111-11-11, tuning parameter</li>
<li>1111-11-11, auto-encoder</li>
<li>1111-11-11, stacked auto-encoder</li>
<li>1111-11-11, denoising auto-encoder(DAE)</li>
</ul>
<section id="convolutional-neural-network-cnn" class="level3">
<h3 class="anchored" data-anchor-id="convolutional-neural-network-cnn">Convolutional Neural Network (CNN)</h3>
<ul>
<li>2023-03-10, <a href="../../../../../docs/blog/posts/DL/2023-03-10_cnn/index.html">CNN (1) - Concept</a></li>
<li>2023-03-10, <a href="">CNN (2) - Practice</a></li>
</ul>
</section>
<section id="natural-language-process-nlp" class="level3">
<h3 class="anchored" data-anchor-id="natural-language-process-nlp">Natural Language Process (NLP)</h3>
<ul>
<li>1111-11-11, word2vec</li>
<li>1111-11-11, improved word2vec</li>
</ul>
</section>
<section id="recurrent-neural-network-rnn" class="level3">
<h3 class="anchored" data-anchor-id="recurrent-neural-network-rnn">Recurrent Neural Network (RNN)</h3>
</section>
<section id="gate-recurrent-unit-gru" class="level3">
<h3 class="anchored" data-anchor-id="gate-recurrent-unit-gru">Gate Recurrent Unit (GRU)</h3>
</section>
<section id="long-short-term-memory-lstm" class="level3">
<h3 class="anchored" data-anchor-id="long-short-term-memory-lstm">Long Short-Term Memory (LSTM)</h3>
</section>
<section id="attention-transformer" class="level3">
<h3 class="anchored" data-anchor-id="attention-transformer">Attention (Transformer)</h3>
</section>
<section id="bidirectional-encoder-representations-from-transformers-bert" class="level3">
<h3 class="anchored" data-anchor-id="bidirectional-encoder-representations-from-transformers-bert">Bidirectional Encoder Representations from Transformers (BERT)</h3>
</section>
<section id="generative-pre-training-transformer-gpt" class="level3">
<h3 class="anchored" data-anchor-id="generative-pre-training-transformer-gpt">Generative Pre-training Transformer (GPT)</h3>


</section>
</section>
</section>

 ]]></description>
  <category>DL</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/DL/guide_map/index.html</guid>
  <pubDate>Thu, 31 Dec 2099 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Engineering</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Engineering/guide_map/index.html</link>
  <description><![CDATA[ 



<section id="it-terminology" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="it-terminology"><span class="header-section-number">1</span> IT Terminology</h2>
<ul>
<li>0000-00-00, Terminology</li>
</ul>
</section>
<section id="data-structure" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="data-structure"><span class="header-section-number">2</span> Data Structure</h2>
<ul>
<li>2023-01-17, <a href="../2023-01-17_data_structure_overview/">Overview</a></li>
<li>2023-01-18, <a href="../2023-01-18_array/">Array</a></li>
<li>2023-01-18, <a href="../2023-01-18_linked_list/">Linked List</a></li>
<li>2023-01-18, <a href="../2023-01-18_python_list/">Python List</a></li>
<li>2023-01-19, <a href="../2023-01-19_stack/">Stack</a></li>
<li>2023-01-19, <a href="../2023-01-19_queue/">Queue</a></li>
<li>2023-01-26, <a href="../2023-01-19_deque/">Deque</a></li>
<li>2023-01-26, <a href="../2023-01-20_binary_search_tree/">Binary Search Tree</a></li>
<li>2023-01-20, <a href="../2023-01-20_priority_queue/">Priority Queue</a></li>
<li>2023-01-20, <a href="../2023-01-20_graph/">Graph</a></li>
</ul>
</section>
<section id="conda" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="conda"><span class="header-section-number">3</span> Conda</h2>
</section>
<section id="docker" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="docker"><span class="header-section-number">4</span> Docker</h2>
<ul>
<li>2023-01-30, Docker Install</li>
<li>2023-01-31, Docker Compose</li>
<li>2023-02-01, Docker Container</li>
</ul>
</section>
<section id="dynamic-documentation" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="dynamic-documentation"><span class="header-section-number">5</span> Dynamic Documentation</h2>
<ul>
<li>2023-01-19, <a href="https://quarto.org/docs/get-started/">Quarto</a></li>
<li>2023-01-19, <a href="https://github.com/yihui/xaringan">xaringan[R]</a></li>
<li>2023-01-19, <a href="https://bookdown.org/yihui/bookdown/get-started.html">Bookdown[R]</a></li>
<li>2023-01-19, <a href="https://decile-team-distil.readthedocs.io/en/latest/index.html">DISTL</a></li>
<li>2023-01-26, <a href="https://www.sphinx-doc.org/en/master/">Sphinx[Python]</a></li>
</ul>
</section>
<section id="aws-cloud" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="aws-cloud"><span class="header-section-number">6</span> AWS Cloud</h2>
<p>Coursera Course: AWS Fundamentals</p>
<ul>
<li>2023-03-09, <a href="../../../../../docs/blog/posts/Engineering/2023-03-02_aws/computing_networking.html">Computing and Networking</a></li>
<li>2023-03-12, <a href="../../../../../docs/blog/posts/Engineering/2023-03-02_aws/storage_database.html">Storage and Database</a></li>
</ul>
</section>
<section id="azure-cloud" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="azure-cloud"><span class="header-section-number">7</span> Azure Cloud</h2>
</section>
<section id="data-modeling" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="data-modeling"><span class="header-section-number">8</span> Data Modeling</h2>
</section>
<section id="apache-airflow" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="apache-airflow"><span class="header-section-number">9</span> Apache Airflow</h2>
</section>
<section id="apache-spark" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="apache-spark"><span class="header-section-number">10</span> Apache Spark</h2>
</section>
<section id="front-end" class="level2" data-number="11">
<h2 data-number="11" class="anchored" data-anchor-id="front-end"><span class="header-section-number">11</span> Front End</h2>
</section>
<section id="back-end" class="level2" data-number="12">
<h2 data-number="12" class="anchored" data-anchor-id="back-end"><span class="header-section-number">12</span> Back End</h2>


</section>

 ]]></description>
  <category>Engineering</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Engineering/guide_map/index.html</guid>
  <pubDate>Thu, 31 Dec 2099 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Language</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Language/guide_map/index.html</link>
  <description><![CDATA[ 



<p><strong>(Draft)</strong></p>
<section id="contents-list" class="level1">
<h1>Contents List</h1>
<section id="r" class="level2">
<h2 class="anchored" data-anchor-id="r">R</h2>
<ul>
<li>1111-11-11, tidyverse
<ul>
<li>1111-11-11, dplyr</li>
<li>1111-11-11, ggplot2</li>
<li>1111-11-11, tidyr</li>
<li>1111-11-11, readr</li>
<li>1111-11-11, purrr</li>
<li>1111-11-11, tibble</li>
<li>1111-11-11, stringr</li>
<li>1111-11-11, forcats</li>
</ul></li>
<li>1111-11-11, tidymodels</li>
<li>1111-11-11, R shiny</li>
</ul>
</section>
<section id="python" class="level2">
<h2 class="anchored" data-anchor-id="python">Python</h2>
<ul>
<li>1111-11-11, numpy</li>
<li>1111-11-11, pandas</li>
<li>1111-11-11, matplotlib</li>
<li>1111-11-11, seaborn</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
</ul>
</section>
<section id="sql" class="level2">
<h2 class="anchored" data-anchor-id="sql">SQL</h2>
<section id="sqlite" class="level3">
<h3 class="anchored" data-anchor-id="sqlite">SQLite</h3>
</section>
<section id="oracle-sql" class="level3">
<h3 class="anchored" data-anchor-id="oracle-sql">Oracle SQL</h3>
</section>
<section id="ms-sql" class="level3">
<h3 class="anchored" data-anchor-id="ms-sql">MS-SQL</h3>
</section>
<section id="postgre-sql" class="level3">
<h3 class="anchored" data-anchor-id="postgre-sql">Postgre SQL</h3>
</section>
</section>
<section id="linux" class="level2">
<h2 class="anchored" data-anchor-id="linux">Linux</h2>
</section>
<section id="powershell" class="level2">
<h2 class="anchored" data-anchor-id="powershell">Powershell</h2>
</section>
<section id="c" class="level2">
<h2 class="anchored" data-anchor-id="c">C++</h2>
</section>
<section id="javascript" class="level2">
<h2 class="anchored" data-anchor-id="javascript">Javascript</h2>


</section>
</section>

 ]]></description>
  <category>Language</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Language/guide_map/index.html</guid>
  <pubDate>Thu, 31 Dec 2099 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Patent</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Patent/guide_map/index.html</link>
  <description><![CDATA[ 



<p><strong>(Draft)</strong></p>
<section id="contents-list" class="level1">
<h1>Contents List</h1>
<section id="basic" class="level2">
<h2 class="anchored" data-anchor-id="basic">Basic</h2>


</section>
</section>

 ]]></description>
  <category>Patent</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Patent/guide_map/index.html</guid>
  <pubDate>Thu, 31 Dec 2099 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Validation</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Surveilance/guide_map/index.html</link>
  <description><![CDATA[ 



<section id="sgs" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sgs"><span class="header-section-number">1</span> SGS</h2>
<ul>
<li>0000-00-00, EN62304</li>
</ul>
</section>
<section id="fda" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="fda"><span class="header-section-number">2</span> FDA</h2>
<ul>
<li>2023-01-27, <a href="../../../../../docs/blog/posts/Surveilance/2022-12-10_FDA_sw_general_guidance/index.html">General Principles of SW Validation</a></li>
<li>2023-01-27, <a href="../../../../../docs/blog/posts/Surveilance/2023-01-27_FDA_sw_general_guidance_presentation/index.html">General Principles of SW Validation - Diagram Summary</a></li>
<li>1111-11-11, Guidance for the Content of Premarket Submissions for Software Contained in Medical Devices</li>
</ul>
</section>
<section id="dhf" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="dhf"><span class="header-section-number">3</span> DHF</h2>
</section>
<section id="public-health" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="public-health"><span class="header-section-number">4</span> Public Health</h2>
</section>
<section id="wet-lab" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="wet-lab"><span class="header-section-number">5</span> Wet Lab</h2>
<ul>
<li>0000-00-00, PCR (Polymerase Chain Reaction) Experiment</li>
</ul>


</section>

 ]]></description>
  <category>Surveilance</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Surveilance/guide_map/index.html</guid>
  <pubDate>Sat, 31 Dec 2089 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Basics (2) - Matrix Operations</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/02.basic_matrix.html</link>
  <description><![CDATA[ 



<section id="matrix" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="matrix"><span class="header-section-number">1</span> Matrix</h2>
<p>A matrix is a rectangular array of elements, usually real numbers, arranged in rows and columns. If <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix, it can be represented as: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%20a_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B1n%7D%20%5C%5C%0A%20%20a_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B2n%7D%20%5C%5C%0A%20%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20a_%7Bm1%7D%20&amp;%20a_%7Bm2%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7Bmn%7D%0A%5Cend%7Bbmatrix%7D%0A"> where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of the matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
</section>
<section id="basic-matrix-operations" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="basic-matrix-operations"><span class="header-section-number">2</span> Basic Matrix Operations</h2>
<section id="matrix-with-combinations-of-vectors" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="matrix-with-combinations-of-vectors"><span class="header-section-number">2.1</span> Matrix with Combinations of Vectors</h3>
<p>A matrix with combinations of vectors is a matrix whose columns are linear combinations of given vectors</p>
<p>Suppose we have vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D,%20%5Cmathbf%7Bv_2%7D,%20%5Cldots,%20%5Cmathbf%7Bv_n%7D"> in <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Em">. Then the matrix <img src="https://latex.codecogs.com/png.latex?A"> whose columns are these vectors is given by:</p>
</section>
<section id="matrix-addition" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="matrix-addition"><span class="header-section-number">2.2</span> Matrix addition</h3>
<p>The sum of two matrices of the same size is a matrix of the same size obtained by adding corresponding entries.</p>
<p>Given two <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">, their sum <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BA%7D%20+%20%5Cmathbf%7BB%7D"> is defined by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D=a_%7Bi,j%7D+b_%7Bi,j%7D%E2%80%8B%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%201%20&amp;%202%20%5C%5C%0A%20%203%20&amp;%204%20%5C%5C%0A%20%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20+%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-1%20&amp;%200%20%5C%5C%0A%20%202%20&amp;%20-3%20%5C%5C%0A%20%20-5%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%200%20&amp;%202%20%5C%5C%0A%20%205%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%2010%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="scalar-multiplication" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="scalar-multiplication"><span class="header-section-number">2.3</span> Scalar multiplication</h3>
<p>The product of a scalar and a matrix is a matrix obtained by multiplying each entry of the matrix by the scalar.</p>
<p>Given a scalar <img src="https://latex.codecogs.com/png.latex?k"> and an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, their product <img src="https://latex.codecogs.com/png.latex?k%5Cmathbf%7BA%7D"> is defined by: <img src="https://latex.codecogs.com/png.latex?%0A(k%5Cmathbf%7BA%7D)_%7Bi,j%7D%20=%20k(a_%7Bi,j%7D)%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A2%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A2%20&amp;%204%20%5C%5C%0A6%20&amp;%208%20%5C%5C%0A10%20&amp;%2012%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="matrix-multiplication" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="matrix-multiplication"><span class="header-section-number">2.4</span> Matrix multiplication</h3>
<p>The product of two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> is a matrix obtained by multiplying the rows of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> by the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">.</p>
<p>Given two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> with dimensions <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> and <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20p">, respectively, their product <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BAB%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20p"> matrix defined by: <img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D%20=%20%5Csum_%7Bk=1%7D%5En%20a_%7Bi,k%7Db_%7Bk,j%7D%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20p">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%0A-1%20&amp;%200%20&amp;%202%20%5C%5C%0A2%20&amp;%20-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A3%20&amp;%20-6%20&amp;%204%20%5C%5C%0A5%20&amp;%20-12%20&amp;%2010%20%5C%5C%0A7%20&amp;%20-18%20&amp;%2016%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="matrix-multiplication-with-a-vector" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="matrix-multiplication-with-a-vector"><span class="header-section-number">2.5</span> Matrix Multiplication with a Vector</h3>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> be a <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%201"> column vector. The matrix-vector product <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BAx%7D"> is defined as:</p>
$$ =
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20%5Cdots%20&amp;%20a_%7B1n%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20%5Cdots%20&amp;%20a_%7B2n%7D%20%5C%5C%0A%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0Aa_%7Bm1%7D%20&amp;%20a_%7Bm2%7D%20&amp;%20%5Cdots%20&amp;%20a_%7Bmn%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%0Ax_1%20%5C%5C%20x_2%20%5C%5C%20%5Cvdots%20%5C%5C%20x_n%0A%5Cend%7Bbmatrix%7D">
=
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7Dx_1%20&amp;%20a_%7B12%7Dx_2%20&amp;%20%5Cdots%20&amp;%20a_%7B1n%7Dx_n%20%5C%5C%0Aa_%7B21%7Dx_1%20&amp;%20a_%7B22%7Dx_2%20&amp;%20%5Cdots%20&amp;%20a_%7B2n%7Dx_n%20%5C%5C%0A%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cvdots%20%5C%5C%0Aa_%7Bm1%7Dx_1%20&amp;%20a_%7Bm2%7Dx_2%20&amp;%20%5Cdots%20&amp;%20a_%7Bmn%7Dx_n%0A%0A%5Cend%7Bbmatrix%7D">
<p>$$</p>
<p>In other words, each entry of the resulting column vector is the dot product of the corresponding row of the matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and the column vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">.</p>
<p>For example, let</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20A%20=%0A%5Cbegin%7Bbmatrix%7D%0A2%20&amp;%201%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A1%20&amp;%202%0A%5Cend%7Bbmatrix%7D%20%5Ctext%7B%20&amp;%20%7D%0A%5Cmathbf%20x=%0A%5Cbegin%7Bbmatrix%7D%0A%20%201%5C%5C-1%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>Then we have</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BAx%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A2%20&amp;%201%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A1%20&amp;%202%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%201%5C%5C-1%0A%5Cend%7Bbmatrix%7D%0A=%0A%5Cbegin%7Bbmatrix%7D%0A%20%201%5C%5C-5%5C%5C-1%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="transpose" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="transpose"><span class="header-section-number">2.6</span> Transpose</h3>
<p>The transpose of an <img src="https://latex.codecogs.com/png.latex?m%20x%20n"> matrix A, denoted by <img src="https://latex.codecogs.com/png.latex?A%5ET">, is the <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix obtained by interchanging the rows and columns of A. Formally, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Ba_%7Bij%7D%5D"> is an m x n matrix, then its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET%20=%20%5Bb_%7Bij%7D%5D"> is an <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix where <img src="https://latex.codecogs.com/png.latex?b_%7Bij%7D"> = <img src="https://latex.codecogs.com/png.latex?a_%7Bji%7D"> for all <img src="https://latex.codecogs.com/png.latex?i"> and <img src="https://latex.codecogs.com/png.latex?j">. In other words, the element in the <img src="https://latex.codecogs.com/png.latex?i"> th row and <img src="https://latex.codecogs.com/png.latex?j"> th column of <img src="https://latex.codecogs.com/png.latex?A%5ET"> is equal to the element in the <img src="https://latex.codecogs.com/png.latex?j"> th row and ith column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>Given an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20m"> matrix defined by: $$ <em>{i,j}^T = </em>{j,i}</p>
<p>$$</p>
<ul>
<li>When <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is transposed, diagnoal entries(<img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D">) do not change but off-diagnoal elements(<img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D%20%5C;%20i%20%5Cneq%20j">) change.</li>
<li>A column vector is tranposed into a row vector, and vice versa.</li>
<li>symmetric matrix: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5ET"></li>
</ul>
<p>Example:</p>
<p>Let A be the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%5C%5C%0A4%20&amp;%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"> The transpose of A, denoted by A^T, is the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5ET%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%204%5C%5C%0A2%20&amp;%205%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="linear-equations-matrix" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="linear-equations-matrix"><span class="header-section-number">2.7</span> Linear Equations &amp; Matrix</h3>
<p>Given an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?A"> and an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%201"> vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">, the matrix-vector product <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D"> is a linear combination of the columns of <img src="https://latex.codecogs.com/png.latex?A"> with coefficients given by the entries of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">. The system of linear equations represented by <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%5Cmathbf%7Bb%7D"> has a unique solution if and only if the columns of <img src="https://latex.codecogs.com/png.latex?A"> are linearly independent.</p>
<p>Here’s an example of a system of linear equations represented by a matrix: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A2x_1%20+%203x_2%20&amp;=%208%20%5C%5C%0A4x_1%20+%205x_2%20&amp;=%2013%0A%5Cend%7Balign*%7D%0A"></p>
This can be written as the matrix equation <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%5Cmathbf%7Bb%7D">, where $$ =
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%0A2%20&amp;%203%5C%5C%0A4%20&amp;%205%0A%5Cend%7Bbmatrix%7D">
=
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%0Ax_1%5C%5C%0Ax_2%0A%5Cend%7Bbmatrix%7D">
=
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%0A8%5C%5C%0A13%0A%5Cend%7Bbmatrix%7D">
<p>$$</p>
<p>The solution to this system can be found by computing the inverse of <img src="https://latex.codecogs.com/png.latex?A"> (if it exists) and multiplying both sides of the equation by it:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7Bx%7D%20=%20%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7Bb%7D%0A"></p>
<p>If <img src="https://latex.codecogs.com/png.latex?A"> does not have an inverse, then the system of equations may have either no solutions or infinitely many solutions.</p>
</section>
<section id="determinant" class="level3" data-number="2.8">
<h3 data-number="2.8" class="anchored" data-anchor-id="determinant"><span class="header-section-number">2.8</span> Determinant</h3>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> square matrix. The determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C"> or <img src="https://latex.codecogs.com/png.latex?%5Cdet(%5Cmathbf%7BA%7D)">, is a scalar value calculated as the sum of the products of the elements in any row or column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> with their corresponding cofactors, that is,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D=%5Csum_%7Bj=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column, and <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D"> is the cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">. The cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D">, is given by <img src="https://latex.codecogs.com/png.latex?(-1)%5E%7Bi+j%7D"> times the determinant of the <img src="https://latex.codecogs.com/png.latex?(n-1)%20%5Ctimes%20(n-1)"> matrix obtained by deleting the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>The determinant of an <img src="https://latex.codecogs.com/png.latex?n%20x%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is a scalar value denoted as <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C">. It is defined as the sum of all possible products of n elements taken one from each row and one from each column, where the sign of each product alternates according to the position of the element in the matrix. For example, the determinant of a <img src="https://latex.codecogs.com/png.latex?3%20x%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20="> <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%20a_%7B11%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B32%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A-%20a_%7B12%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A+%20a_%7B13%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%0A%5Cend%7Bvmatrix%7D%0A"></p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?3%20%5Ctimes%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%204%20&amp;%205%20&amp;%206%20%5C%5C%207%20&amp;%208%20&amp;%209%20%5Cend%7Bbmatrix%7D">. We can calculate the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> using any row or column. Let’s use the first column:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%201%0A%5Cbegin%7Bvmatrix%7D%0A5%20&amp;%206%20%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A-%204%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%203%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A+%207%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%205%20%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bvmatrix%7D%20=%200%0A"></p>
<p>Therefore, the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is zero.</p>
</section>
<section id="inverse" class="level3" data-number="2.9">
<h3 data-number="2.9" class="anchored" data-anchor-id="inverse"><span class="header-section-number">2.9</span> Inverse</h3>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?A"> of size <img src="https://latex.codecogs.com/png.latex?n"> is a matrix <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> such that the product of <img src="https://latex.codecogs.com/png.latex?A"> and <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> is the identity matrix <img src="https://latex.codecogs.com/png.latex?I_n">, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I_n">. If such a matrix exists, then <img src="https://latex.codecogs.com/png.latex?A"> is said to be invertible or non-singular.</p>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D"> and is defined as the unique matrix that satisfies the following equation: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BI%7D"> is the identity matrix. Not all matrices have an inverse, and a matrix that has an inverse is called invertible or nonsingular. A matrix that does not have an inverse is called singular.</p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?2%5Ctimes%202"> matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D.%0A"> The inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cfrac%7B1%7D%7B-2%7D%0A%5Cbegin%7Bbmatrix%7D%0A4%20&amp;%20-2%20%5C%5C%0A-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>We can verify that <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BI%7D"> by computing:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%20-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>Let me give another example and A be a <img src="https://latex.codecogs.com/png.latex?3x3"> square matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D">, is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B%5Ctext%7Bdet%7D(%5Cmathbf%7BA%7D)%7D%5Cbegin%7Bbmatrix%7D%0Aa_%7B22%7Da_%7B33%7D-a_%7B23%7Da_%7B32%7D%20&amp;%20a_%7B13%7Da_%7B32%7D-a_%7B12%7Da_%7B33%7D%20&amp;%20a_%7B12%7Da_%7B23%7D-a_%7B13%7Da_%7B22%7D%20%5C%5C%0Aa_%7B23%7Da_%7B31%7D-a_%7B21%7Da_%7B33%7D%20&amp;%20a_%7B11%7Da_%7B33%7D-a_%7B13%7Da_%7B31%7D%20&amp;%20a_%7B13%7Da_%7B21%7D-a_%7B11%7Da_%7B23%7D%20%5C%5C%0Aa_%7B21%7Da_%7B32%7D-a_%7B22%7Da_%7B31%7D%20&amp;%20a_%7B12%7Da_%7B31%7D-a_%7B11%7Da_%7B32%7D%20&amp;%20a_%7B11%7Da_%7B22%7D-a_%7B12%7Da_%7B21%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?det(%5Cmathbf%7BA%7D)"> is the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%20%5C%5C%0A0%20&amp;%201%20&amp;%204%20%5C%5C%0A5%20&amp;%206%20&amp;%200%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, <img src="https://latex.codecogs.com/png.latex?det(A)"> = -57, and the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B-57%7D%5Cbegin%7Bbmatrix%7D%0A-24%20&amp;%2018%20&amp;%205%20%5C%5C%0A20%20&amp;%20-15%20&amp;%20-4%20%5C%5C%0A-3%20&amp;%202%20&amp;%201%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>There are several formulas for finding the inverse of a matrix such as Gauss-Jordan Elimination, Adjoint method, Cramer’s rule, Inverse formula, etc. This topic is going to be handled in the other blogs.</p>
</section>
<section id="rank" class="level3" data-number="2.10">
<h3 data-number="2.10" class="anchored" data-anchor-id="rank"><span class="header-section-number">2.10</span> Rank</h3>
<p>The rank of a matrix is the dimension of the vector space spanned by its columns (or rows). It is denoted by <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Brank%7D(%5Cmathbf%7BA%7D)">.</p>
<p>For example, consider the following matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%20%20%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%20&amp;%203%5C%5C%0A%20%20%20%204%20&amp;%205%20&amp;%206%20%5C%5C%0A%20%20%20%207%20&amp;%208%20&amp;%209%5C%5C%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are linearly dependent since the third column is equal to the sum of the first two columns. Therefore, the dimension of the vector space spanned by the columns is 2, so the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is 2.</p>
</section>
<section id="trace" class="level3" data-number="2.11">
<h3 data-number="2.11" class="anchored" data-anchor-id="trace"><span class="header-section-number">2.11</span> Trace</h3>
<p>The trace of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)">, is defined as the sum of the diagonal elements of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">. In other words, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> matrix, then its trace is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D"> denotes the <img src="https://latex.codecogs.com/png.latex?i"> th diagonal element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%202%20&amp;%203%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%205%20&amp;%202%20%5C%5C%0A%20%201%20&amp;%201%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>Then, the trace of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)%20=%202%20+%205%20+%204%20=%2011"></p>
</section>
<section id="eigenvalues-and-eigenvectors" class="level3" data-number="2.12">
<h3 data-number="2.12" class="anchored" data-anchor-id="eigenvalues-and-eigenvectors"><span class="header-section-number">2.12</span> Eigenvalues and Eigenvectors</h3>
<p>Let A be an <img src="https://latex.codecogs.com/png.latex?n%20%C3%97%20n"> square matrix. A scalar <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is called an eigenvalue of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> if there exists a non-zero vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> such that <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BAv%7D=%5Clambda%5Cmathbf%7Bv%7D%0A"></p>
<p>Such a vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> is called an eigenvector corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda">.</p>
<p>Example:</p>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> be the matrix</p>
<p>To find the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">, we solve the characteristic equation <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%20=%200">, where I is the n × n identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%0A%20%20&amp;=%0A%20%20%20%20%5Cbegin%7Bvmatrix%7D%0A%20%20%20%203%20-%20%5Clambda%20&amp;%201%20%5C%5C%0A%20%20%20%201%20&amp;%203%20-%20%5Clambda%0A%20%20%20%20%5Cend%7Bvmatrix%7D%20%5C%5C%0A%20%20&amp;=%0A%20%20(3%20-%20%5Clambda)(3%20-%20%5Clambda)%20-%201%20%5C%5C%0A%20%20&amp;=%20%5Clambda%5E2%20-%206%5Clambda%20+%208%20=%200%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this quadratic equation gives us the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">: <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202"> and <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">.</p>
<p>To find the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%20%5Cmathbf%7B0%7D">, where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20I"> is the <img src="https://latex.codecogs.com/png.latex?2%20%5Ctimes%202"> identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%0A%20%20%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%20%201%20&amp;%201%20%5C%5C%0A%20%20%20%20%20%201%20&amp;%201%0A%20%20%20%20%5Cend%7Bbmatrix%7D%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20x%20%5C%5C%0A%20%20%20%20y%0A%20%20%5Cend%7Bbmatrix%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%200%20%5C%5C%0A%20%20%20%200%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this system of equations gives us the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D%20=%20%5Cbegin%7Bbmatrix%7D%20-1%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
<p>Similarly, for <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%204%5Cmathbf%20I)%5Cmathbf%7Bv%7D"> = <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D"> to get the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
</section>
<section id="singular-value-and-singluar-vectors" class="level3" data-number="2.13">
<h3 data-number="2.13" class="anchored" data-anchor-id="singular-value-and-singluar-vectors"><span class="header-section-number">2.13</span> Singular value and Singluar Vectors</h3>
<p>The singular value decomposition (SVD) of a matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> is a factorization of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> into the product of three matrices as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20m"> orthogonal matrix, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> rectangular diagonal matrix with non-negative real numbers on the diagonal, and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> orthogonal matrix.</p>
<p>The diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> are called the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Csigma_1,%20%5Csigma_2,%20%5Cldots,%20%5Csigma_r"> (where <img src="https://latex.codecogs.com/png.latex?r"> is the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">), and are arranged in descending order. The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> are called the left and right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, respectively, and are orthonormal vectors.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be a 3 by 2 matrix given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%5C%5C%0A%20%20%20%203%20&amp;%204%5C%5C%0A%20%20%20%205%20&amp;%206%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The SVD of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.23%20&amp;%20-0.53%20&amp;%20-0.81%5C%5C%0A%20%20-0.53%20&amp;%20-0.72%20&amp;%200.45%5C%5C%0A%20%20-0.81%20&amp;%200.45%20&amp;%20-0.38%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%209.53%20&amp;%200%5C%5C%0A%20%200%20&amp;%200.90%5C%5C%0A%20%200%20&amp;%200%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.62%20&amp;%20-0.78%5C%5C%0A%20%20-0.78%20&amp;%200.62%0A%5Cend%7Bbmatrix%7D%5ET%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where the left singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D">, the right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D">, and the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5CSigma%7D">.</p>
<ul>
<li>연립 방정식을 행렬의 곱으로 나타내보기 <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bmatrix%7Dx_1+2y_1=4%5C%5C2x_1+5y_1=9%5Cend%7Bmatrix%7D%20%5Cquad%20%5Cquad%20%5Cquad%20%5Cbegin%7Bmatrix%7Dx_2+2y_2=3%5C%5C2x_2+5y_2=7%5Cend%7Bmatrix%7D"> <img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20%5C%5C%202%20&amp;%205%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20%5C%5C%20y_1%20&amp;%20y_2%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%204%20&amp;%209%20%5C%5C%203%20&amp;%207%20%5Cend%7Bbmatrix%7D"></li>
<li>중요한 사실(….당연한 사실?)
<ul>
<li>곱셈의 왼쪽 행렬의 열 수와, 오른쪽 행렬의 행 수가 같아야 가능함
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20B_%7Bo%20%5Ctimes%20p%7D"> 에서 <img src="https://latex.codecogs.com/png.latex?n%20=%20o"> 여야 곱셈 성립</li>
</ul></li>
<li>곱셈의 결과 행렬의 크기 = 곱셈의 왼쪽 행렬의 행 수 <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> 곱셈의 오른쪽 행렬의 열 수
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20B_%7Bo%20%5Ctimes%20p%7D%20=%20C_%7Bm%20%5Ctimes%20p%7D"></li>
</ul></li>
<li>교환법칙(Commutative property)이 성립하지 않음
<ul>
<li><img src="https://latex.codecogs.com/png.latex?AB%20%5Cneq%20BA"></li>
</ul></li>
</ul></li>
<li>행렬 곱셈의 여러가지 관점
<ul>
<li>내적으로 바라보기 <img src="https://latex.codecogs.com/png.latex?%20A%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20"> <img src="https://latex.codecogs.com/png.latex?%20AB%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%7D%20&amp;%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_1%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_1%5ET%20b_m%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_2%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_2%5ET%20b_m%7D%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_m%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%5ET%20b_m%7D%20%5Cend%7Bbmatrix%7D"></li>
<li>rank-1 matrix의 합 (또 안가르쳐준 개념 먼저 사용중…..-_-) <img src="https://latex.codecogs.com/png.latex?AB%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%7D%20&amp;%20%5Cmathbf%7Ba_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Bb_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Bb_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7Ba_1%20b_1%5ET%7D%20+%20%5Cmathbf%7Ba_2%20b_2%5ET%7D%20+%20%5Ccdots%20+%20%5Cmathbf%7Ba_m%20b_m%5ET%7D"></li>
<li>column space로 바라보기 <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%7D%20&amp;%20%5Cmathbf%7Ba_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20%5C%5C%20x_2%20%5C%5C%20%5Cvdots%20%5C%5C%20x_m%20%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7Ba_1%7D%20x_1%20+%20%5Cmathbf%7Ba_2%7D%20x_2%20+%20%5Ccdots%20+%20%5Cmathbf%7Ba_m%7D%20x_m%20"> (스칼라배의 합)
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20%5C%5C%200%20&amp;%201%20%5Cend%7Bbmatrix%7D"> 는 2차원 좌표평면의 모든 점을, <img src="https://latex.codecogs.com/png.latex?A=%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%200%20%5C%5C%200%20&amp;%201%20&amp;%200%20%5C%5C%200%20&amp;%200%20&amp;%201%20%5Cend%7Bbmatrix%7D">은 3차원 좌표평면의 모든 점 표현 가능</li>
<li><img src="https://latex.codecogs.com/png.latex?AB%20=%20A%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%7D%20&amp;%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20A%20%5Cmathbf%7Bb_1%7D%20&amp;%20A%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20A%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D"></li>
<li>column space: A의 column vector로 만들 수 있는 부분 공간</li>
</ul></li>
<li>row space로 바라보기 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%5ET%7DA%20=%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20&amp;%20%5Ccdots%20&amp;%20x_m%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20=%20x_1%20%5Cmathbf%7Ba_1%5ET%7D%20+%20x_2%20%5Cmathbf%7Ba_2%5ET%7D%20+%20%5Ccdots%20+%20x_m%20%5Cmathbf%7Ba_m%5ET%7D%20"></li>
</ul></li>
</ul>
</section>
</section>
<section id="열공간column-space" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="열공간column-space"><span class="header-section-number">3</span> 열공간(Column Space)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/g0eaDeVRdZk" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>column space: column vector 들이 span 하는 space
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A">의 column space = <img src="https://latex.codecogs.com/png.latex?C(A)"> 또는 <img src="https://latex.codecogs.com/png.latex?range(A)"></li>
</ul></li>
<li>span: vector들의 linear combination 으로 나타낼 수 있는 모든 vector를 모은 집합
<ul>
<li>vector에 따라, 점일수도 선일수도 평면일 수도 있음</li>
<li>vector space를 이 vector들이 span하는 space → column space는 행렬의 열들이 span하는 space</li>
</ul></li>
<li>vector의 선형 결합(linear combination): vector에 스칼라배를 해서 더하는 것
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D"> 과 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D">의 linear combination으로 2차원 좌표평면 나타내기 <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" class="img-fluid"></li>
</ul></li>
</ul>
</section>
<section id="선형-독립linear-independent" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="선형-독립linear-independent"><span class="header-section-number">4</span> 선형 독립(Linear Independent)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/mOOI4-BfjGQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>…and also see</p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/9F4PZ_1orF0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>선형 독립(linearly independent)인 vectors: (선형 결합을 통해) 더 고차원을 span할 수 있게 해줌</li>
<li>orthogonal 하면 independent
<ul>
<li>but independent해도 항상 orthogonal하지는 않음 (Independent &gt; Orthogonal)</li>
</ul></li>
<li>definition: <img src="https://latex.codecogs.com/png.latex?a_1%20%5Cmathbf%7Bv_1%7D%20+%20a_2%20%5Cmathbf%7Bv_2%7D%20+%20a_3%20%5Cmathbf%7Bv_3%7D%20%5Ccdots%20a_n%20%5Cmathbf%7Bv_n%7D%20=%20%5Cmathbf%7B0%7D"> 를 만족하는 <img src="https://latex.codecogs.com/png.latex?a_1,%20a_2,%20a_3,%20%5Ccdots%20a_n"> 이 <img src="https://latex.codecogs.com/png.latex?a_1%20=%20a_2%20=%20a_3%20=%20%5Ccdots%20=%20a_n%20=%200"> 밖에 없을때
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D">는 모든 elements가 <img src="https://latex.codecogs.com/png.latex?0">인 벡터</li>
<li>예: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%202%20%5Cend%7Bbmatrix%7D"> 는 <img src="https://latex.codecogs.com/png.latex?-2%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D%20+%201%20%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%202%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> 이 되므로, linearly independent 하지 않음</li>
<li>independent한 vector 들의 수 = 표현할 수 있는 차원의 dimension</li>
</ul></li>
</ul>
</section>
<section id="기저basis" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="기저basis"><span class="header-section-number">5</span> 기저(basis)</h2>
<ul>
<li>주어진 vector space를 span하는 linearly independent한 vectors</li>
<li>어떤 공간을 이루는 필수적인 구성요소</li>
<li>orthogonal 하면 orthogonal basis</li>
<li>예: 2차원 좌표평면에 대해
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"> : orthogonal basis</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"> : orthogonal 하지 않은 basis</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> : linearly independent 하지 않으므로 basis 아님</li>
</ul></li>
</ul>
</section>
<section id="항등행렬identity-matrix-역행렬inverse-matrix-대각행렬diagonal-matrix-직교행렬orthogonal-matrix" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="항등행렬identity-matrix-역행렬inverse-matrix-대각행렬diagonal-matrix-직교행렬orthogonal-matrix"><span class="header-section-number">6</span> 항등행렬(identity matrix), 역행렬(inverse matrix), 대각행렬(Diagonal Matrix), 직교행렬(orthogonal matrix)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/XqOvyfMUAwA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="identity-matrix항등행렬" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="identity-matrix항등행렬"><span class="header-section-number">6.1</span> Identity matrix(항등행렬)</h3>
<ul>
<li>항등원: 임의의 원소에 대해 연산하면 자기 자신이 나오게 하는 원소 (by namu.wiki)
<ul>
<li>실수에서 곱셈의 항등원은 1</li>
</ul></li>
<li>행렬의 항등원: 항등행렬(<img src="https://latex.codecogs.com/png.latex?I">) <img src="https://latex.codecogs.com/png.latex?I%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%200%20&amp;%201%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%200%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%201%20%5Cend%7Bbmatrix%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20I_%7Bn%20%5Ctimes%20n%20=%20n%7D%20=%20A_%7Bm%20%5Ctimes%20n%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?I_%7Bm%20%5Ctimes%20m%20=%20m%7D%20%5Ctimes%20A_%7Bm%20%5Ctimes%20n%7D%20=%20A_%7Bm%20%5Ctimes%20n%7D"></li>
</ul></li>
</ul>
</section>
<section id="sec-inv" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="sec-inv"><span class="header-section-number">6.2</span> Inverse matrix(역행렬)</h3>
<ul>
<li>역원: 연산 결과 항등원이 나오게 하는 연소
<ul>
<li>실수에서 곱셈의 역원은 지수의 부호가 반대인 역수 (by namu.wiki): <img src="https://latex.codecogs.com/png.latex?a%20%5Ctimes%20a%5E%7B-1%7D%20=%201"></li>
</ul></li>
<li>행렬의 역원: 역행렬(<img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D">) <img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I%20,%20A%5E%7B-1%7D%20%5Ctimes%20A%20=%20I">
<ul>
<li>존재하지 않는 경우도 있음</li>
<li>존재하면 Invertible(nonsingular, nondegenerate) matrix라고 불림
<ul>
<li>존재하지 않으면 singular, degenerate라고 불림</li>
</ul></li>
<li>square matrix(정사각행렬, <img src="https://latex.codecogs.com/png.latex?m%20=%20n">)은 특수한 경우를 제외하면 역행렬이 항상 존재
<ul>
<li>역행렬이 존재하지 않는특수한 경우: (나중에 배울) determinant가 0인 경우</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?m%20%5Cneq%20n">인 행렬의 경우에는 역행렬이 존재하지 않음
<ul>
<li>다만, 경우에 따라 <img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I"> 를 만족하거나(right inverse), <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D%20%5Ctimes%20A%20=%20I">를 만족하는(left inverse)는 <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D">이 존재함</li>
</ul></li>
<li>연립 방정식을 matrix로 나타냈을 때, 역행렬을 이용해서 해를 찾을 수 있음 <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cmathbf%7Bb%7D%20%5CRightarrow%20A%5E%7B-1%7DA%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D%20%5CRightarrow%20I%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D%20%5CRightarrow%20%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D"></li>
</ul></li>
</ul>
</section>
<section id="diagonal-matrix대각행렬" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="diagonal-matrix대각행렬"><span class="header-section-number">6.3</span> Diagonal Matrix(대각행렬)</h3>
<ul>
<li>diagonal element(대각 원소)외의 모든 elements(off-diagonal elements)가 0인 matrix <img src="https://latex.codecogs.com/png.latex?%20D%20=%20Diag(%5Cmathbf%7Ba%7D)%20=%20%5Cbegin%7Bbmatrix%7D%20a_%7B1,1%7D%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%200%20&amp;%20a_%7B2,2%7D%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%200%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%20a_%7Bn,n%7D%20%5Cend%7Bbmatrix%7D">
<ul>
<li>identity matrix는 diagonal matrix</li>
<li>diagnomal matrix는 symmetric matrix 이기도 함</li>
<li>보통은 square matrix에서 주로 사용됨
<ul>
<li>square matrix가 아니면서 diagonal matrix인 경우: rectangular diagonal matrix</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="orthogonal-matrix직교행렬-orthonomal-matrix" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="orthogonal-matrix직교행렬-orthonomal-matrix"><span class="header-section-number">6.4</span> Orthogonal matrix(직교행렬, orthonomal matrix)</h3>
<ul>
<li>행렬의 각 columns들이 orthonomal vectors (서로 수직하면서 unit vectors) <img src="https://latex.codecogs.com/png.latex?A%20A%5ET%20=%20A%5ET%20A%20=%20I"></li>
<li>identity matrix는 orthogonal matrix</li>
<li>square matrix에서만 정의됨</li>
<li>Orthogonal matrix인 <img src="https://latex.codecogs.com/png.latex?A">이면 <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D%20=%20A%5E%7BT%7D">
<ul>
<li>각 columns에서 자기 자신과의 내적 = 1, 다른 column과의 내적 = 0임</li>
</ul></li>
<li>complex matrix(복소수 행렬)에서는 unitary matrix라고 부름</li>
</ul>
</section>
</section>
<section id="계수rank" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="계수rank"><span class="header-section-number">7</span> 계수(Rank)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/HMST0Yc7EXE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>rank: 행렬이 가지는 independent한 columns의 수 = column space의 dimension = row space의 dimension</li>
<li>independent한 column의 수 = independent한 행의 수: <img src="https://latex.codecogs.com/png.latex?rank(A)%20=%20rank(A%5ET)">
<ul>
<li>proof: <a href="https://en.wikipedia.org/wiki/Rank_%28linear_algebra%29#Proofs_that_column_rank_=_row_rank">Wikipedia</a></li>
</ul></li>
<li>예: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%200%20&amp;%200%20&amp;%200%20%5Cend%7Bbmatrix%7D%20%5CRightarrow%20rank=1"> <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%201%20%5C%5C%200%20&amp;%201%20&amp;%201%20%5Cend%7Bbmatrix%7D%20%5CRightarrow%20rank=2"></li>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D"> 의 최대 랭크는 <img src="https://latex.codecogs.com/png.latex?min%5C%7Bm,n%5C%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?rank(A)%20%3C%20min%5C%7Bm,n%5C%7D"> 면 rank-deficient, <img src="https://latex.codecogs.com/png.latex?rank(A)%20=%20min%5C%7Bm,n%5C%7D">면 full (row/column) rank</li>
</ul></li>
</ul>
</section>
<section id="영공간null-space" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="영공간null-space"><span class="header-section-number">8</span> 영공간(Null space)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/Eizc9TSRYMQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%20%5Cmathbf%7B0%7D"> 을 만족하는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">의 집합
<ul>
<li>column space 관점에서 보기: <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20x_1%20%5Cmathbf%7Ba_1%7D%20+%20x_2%20%5Cmathbf%7Ba_2%7D%20+%20%5Ccdots%20+%20x_n%20%5Cmathbf%7Ba_n%7D%20=%20%5Cmathbf%7B0%7D"></li>
<li>null space에 항상 들어가는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%200%20%5C%5C%20%5Cvdots%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> : trivial solution
<ul>
<li>모든 columns이 다 lienarly independent 하면, null space에는 위의 벡터 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D">하나 밖에 없음</li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D"> 가 아닌 vector가 null space에 있으면, 스칼라배(constant <img src="https://latex.codecogs.com/png.latex?c">에 대해 <img src="https://latex.codecogs.com/png.latex?c%20%5Cmathbf%7Bx%7D">) 역시 null space에 포함됨</li>
<li>혼동 주의! null space는 column space의 일부가 아님
<ul>
<li>row vector의 차원이 null space가 존재하는 공간</li>
</ul></li>
<li>rank와 null space의 dimension의 합은 항상 matrix의 column의 수
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D">에 대해, <img src="https://latex.codecogs.com/png.latex?dim(N(A))%20=%20n%20-%20r">
<ul>
<li>모든 columns이 다 lienarly independent 하면 null space는 0차원(점)</li>
</ul></li>
<li>null space는 row space와 수직한 space
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%20%5Cmathbf%7B0%7D"> : 각각 모든 행과 내적해서 0, → 행들의 linear combination과 내적해도 0</li>
<li>rank는 row space의 dimension → row space의 dimension(<img src="https://latex.codecogs.com/png.latex?dim(R(A))">)과 null space의 dimension(<img src="https://latex.codecogs.com/png.latex?dim(N(A))">)의 합이 <img src="https://latex.codecogs.com/png.latex?n"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%5En%7D"> 공간에 표현: <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_10.PNG" class="img-fluid">
<ul>
<li>겹친 점: 영벡터</li>
</ul></li>
</ul></li>
</ul></li>
<li>left null space: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%5ET%7D%20A%20=%20%5Cmathbf%7B0%5ET%7D"> 인 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">
<ul>
<li>위의 성질을 row에 대해 적용
<ul>
<li>m 차원에 놓인 벡터</li>
<li>dimension: <img src="https://latex.codecogs.com/png.latex?dim(N_L(A))%20=%20m%20-%20r"></li>
<li>column space와 수직: <img src="https://latex.codecogs.com/png.latex?dim(N_L(A))%20+dim(C(A))%20=%20m"></li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?R(A)">에 있는 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_r%7D"> 와 <img src="https://latex.codecogs.com/png.latex?N(A)">에 있는 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 대해:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_r%7D">에 <img src="https://latex.codecogs.com/png.latex?A">를 곱하면 column space로 감</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 <img src="https://latex.codecogs.com/png.latex?A">를 곱하면 $</li>
<li><img src="https://latex.codecogs.com/png.latex?A(%5Cmathbf%7Bx_r%7D%20+%5Cmathbf%7Bx_n%7D)%20=%20A%5Cmathbf%7Bx_r%7D%20+%20A%5Cmathbf%7Bx_n%7D%20=%20A%5Cmathbf%7Bx_r%7D%20=%20%5Cmathbf%7Bb%7D"></li>
</ul></li>
</ul>
</section>
<section id="ax-b의-해의-수" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="ax-b의-해의-수"><span class="header-section-number">9</span> Ax = b의 해의 수</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/nNI2TlD598c" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><p>full column rank 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 있으면 해가 하나</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 없으면 해가 없음 <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_11.PNG" class="img-fluid"></li>
</ul></li>
<li><p>full row rank 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">는 항상 column space 안에 있음: 무한의 해를 가짐</li>
<li>임의의 특정한 해(particular solution) <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_p%7D">와 null space의 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 대해, <img src="https://latex.codecogs.com/png.latex?A(%5Cmathbf%7Bx_p%7D%20+%5Cmathbf%7Bx_n%7D)=%5Cmathbf%7Bb%7D">
<ul>
<li>즉, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_p%7D%20+%5Cmathbf%7Bx_n%7D"> 도 해가 됨: complete solution
<ul>
<li>null space는 무한하므로, 해도 무한함</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>full rank 일때(square matrix): 해가 하나 존재 (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D">$)</p></li>
<li><p>rank-deficient 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 있으면 무한한 해를 가짐</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 없으면 해가 없음</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/02.basic_matrix.html</guid>
  <pubDate>Thu, 30 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" medium="image"/>
</item>
<item>
  <title>Basics (2) - Matrix Operations</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/03.linear_equations_matrix.html</link>
  <description><![CDATA[ 



<section id="matrix" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="matrix"><span class="header-section-number">1</span> Matrix</h2>
<p>A matrix is a rectangular array of elements, usually real numbers, arranged in rows and columns. If <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix, it can be represented as: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%20a_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B1n%7D%20%5C%5C%0A%20%20a_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B2n%7D%20%5C%5C%0A%20%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20a_%7Bm1%7D%20&amp;%20a_%7Bm2%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7Bmn%7D%0A%5Cend%7Bbmatrix%7D%0A"> where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of the matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
</section>
<section id="basic-matrix-operations" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="basic-matrix-operations"><span class="header-section-number">2</span> Basic Matrix Operations</h2>
<section id="matrix-addition" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="matrix-addition"><span class="header-section-number">2.1</span> Matrix addition</h3>
<p>The sum of two matrices of the same size is a matrix of the same size obtained by adding corresponding entries.</p>
<p>Given two <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">, their sum <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BA%7D%20+%20%5Cmathbf%7BB%7D"> is defined by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D=a_%7Bi,j%7D+b_%7Bi,j%7D%E2%80%8B%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%201%20&amp;%202%20%5C%5C%0A%20%203%20&amp;%204%20%5C%5C%0A%20%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20+%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-1%20&amp;%200%20%5C%5C%0A%20%202%20&amp;%20-3%20%5C%5C%0A%20%20-5%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%200%20&amp;%202%20%5C%5C%0A%20%205%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%2010%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="scalar-multiplication" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="scalar-multiplication"><span class="header-section-number">2.2</span> Scalar multiplication</h3>
<p>The product of a scalar and a matrix is a matrix obtained by multiplying each entry of the matrix by the scalar.</p>
<p>Given a scalar <img src="https://latex.codecogs.com/png.latex?k"> and an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, their product <img src="https://latex.codecogs.com/png.latex?k%5Cmathbf%7BA%7D"> is defined by: <img src="https://latex.codecogs.com/png.latex?%0A(k%5Cmathbf%7BA%7D)_%7Bi,j%7D%20=%20k(a_%7Bi,j%7D)%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A2%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A2%20&amp;%204%20%5C%5C%0A6%20&amp;%208%20%5C%5C%0A10%20&amp;%2012%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="matrix-multiplication" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="matrix-multiplication"><span class="header-section-number">2.3</span> Matrix multiplication</h3>
<p>The product of two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> is a matrix obtained by multiplying the rows of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> by the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">.</p>
<p>Given two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> with dimensions <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> and <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20p">, respectively, their product <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BAB%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20p"> matrix defined by: <img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D%20=%20%5Csum_%7Bk=1%7D%5En%20a_%7Bi,k%7Db_%7Bk,j%7D%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20p">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%0A-1%20&amp;%200%20&amp;%202%20%5C%5C%0A2%20&amp;%20-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A3%20&amp;%20-6%20&amp;%204%20%5C%5C%0A5%20&amp;%20-12%20&amp;%2010%20%5C%5C%0A7%20&amp;%20-18%20&amp;%2016%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="transpose" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="transpose"><span class="header-section-number">2.4</span> Transpose</h3>
<p>The transpose of an <img src="https://latex.codecogs.com/png.latex?m%20x%20n"> matrix A, denoted by <img src="https://latex.codecogs.com/png.latex?A%5ET">, is the <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix obtained by interchanging the rows and columns of A. Formally, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Ba_%7Bij%7D%5D"> is an m x n matrix, then its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET%20=%20%5Bb_%7Bij%7D%5D"> is an <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix where <img src="https://latex.codecogs.com/png.latex?b_%7Bij%7D"> = <img src="https://latex.codecogs.com/png.latex?a_%7Bji%7D"> for all <img src="https://latex.codecogs.com/png.latex?i"> and <img src="https://latex.codecogs.com/png.latex?j">. In other words, the element in the <img src="https://latex.codecogs.com/png.latex?i"> th row and <img src="https://latex.codecogs.com/png.latex?j"> th column of <img src="https://latex.codecogs.com/png.latex?A%5ET"> is equal to the element in the <img src="https://latex.codecogs.com/png.latex?j"> th row and ith column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>Given an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20m"> matrix defined by: $$ <em>{i,j}^T = </em>{j,i}</p>
<p>$$</p>
<ul>
<li>When <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is transposed, diagnoal entries(<img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D">) do not change but off-diagnoal elements(<img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D%20%5C;%20i%20%5Cneq%20j">) change.</li>
<li>A column vector is tranposed into a row vector, and vice versa.</li>
<li>symmetric matrix: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5ET"></li>
</ul>
<p>Example:</p>
<p>Let A be the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%5C%5C%0A4%20&amp;%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"> The transpose of A, denoted by A^T, is the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5ET%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%204%5C%5C%0A2%20&amp;%205%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="determinant" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="determinant"><span class="header-section-number">2.5</span> Determinant</h3>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> square matrix. The determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C"> or <img src="https://latex.codecogs.com/png.latex?%5Cdet(%5Cmathbf%7BA%7D)">, is a scalar value calculated as the sum of the products of the elements in any row or column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> with their corresponding cofactors, that is,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D=%5Csum_%7Bj=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column, and <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D"> is the cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">. The cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D">, is given by <img src="https://latex.codecogs.com/png.latex?(-1)%5E%7Bi+j%7D"> times the determinant of the <img src="https://latex.codecogs.com/png.latex?(n-1)%20%5Ctimes%20(n-1)"> matrix obtained by deleting the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>The determinant of an <img src="https://latex.codecogs.com/png.latex?n%20x%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is a scalar value denoted as <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C">. It is defined as the sum of all possible products of n elements taken one from each row and one from each column, where the sign of each product alternates according to the position of the element in the matrix. For example, the determinant of a <img src="https://latex.codecogs.com/png.latex?3%20x%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20="> <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%20a_%7B11%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B32%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A-%20a_%7B12%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A+%20a_%7B13%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%0A%5Cend%7Bvmatrix%7D%0A"></p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?3%20%5Ctimes%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%204%20&amp;%205%20&amp;%206%20%5C%5C%207%20&amp;%208%20&amp;%209%20%5Cend%7Bbmatrix%7D">. We can calculate the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> using any row or column. Let’s use the first column:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%201%0A%5Cbegin%7Bvmatrix%7D%0A5%20&amp;%206%20%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A-%204%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%203%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A+%207%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%205%20%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bvmatrix%7D%20=%200%0A"></p>
<p>Therefore, the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is zero.</p>
</section>
<section id="inverse" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="inverse"><span class="header-section-number">2.6</span> Inverse</h3>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?A"> of size <img src="https://latex.codecogs.com/png.latex?n"> is a matrix <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> such that the product of <img src="https://latex.codecogs.com/png.latex?A"> and <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> is the identity matrix <img src="https://latex.codecogs.com/png.latex?I_n">, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I_n">. If such a matrix exists, then <img src="https://latex.codecogs.com/png.latex?A"> is said to be invertible or non-singular.</p>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D"> and is defined as the unique matrix that satisfies the following equation: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BI%7D"> is the identity matrix. Not all matrices have an inverse, and a matrix that has an inverse is called invertible or nonsingular. A matrix that does not have an inverse is called singular.</p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?2%5Ctimes%202"> matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D.%0A"> The inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cfrac%7B1%7D%7B-2%7D%0A%5Cbegin%7Bbmatrix%7D%0A4%20&amp;%20-2%20%5C%5C%0A-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>We can verify that <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BI%7D"> by computing:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%20-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>Let me give another example and A be a <img src="https://latex.codecogs.com/png.latex?3x3"> square matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D">, is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B%5Ctext%7Bdet%7D(%5Cmathbf%7BA%7D)%7D%5Cbegin%7Bbmatrix%7D%0Aa_%7B22%7Da_%7B33%7D-a_%7B23%7Da_%7B32%7D%20&amp;%20a_%7B13%7Da_%7B32%7D-a_%7B12%7Da_%7B33%7D%20&amp;%20a_%7B12%7Da_%7B23%7D-a_%7B13%7Da_%7B22%7D%20%5C%5C%0Aa_%7B23%7Da_%7B31%7D-a_%7B21%7Da_%7B33%7D%20&amp;%20a_%7B11%7Da_%7B33%7D-a_%7B13%7Da_%7B31%7D%20&amp;%20a_%7B13%7Da_%7B21%7D-a_%7B11%7Da_%7B23%7D%20%5C%5C%0Aa_%7B21%7Da_%7B32%7D-a_%7B22%7Da_%7B31%7D%20&amp;%20a_%7B12%7Da_%7B31%7D-a_%7B11%7Da_%7B32%7D%20&amp;%20a_%7B11%7Da_%7B22%7D-a_%7B12%7Da_%7B21%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?det(%5Cmathbf%7BA%7D)"> is the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%20%5C%5C%0A0%20&amp;%201%20&amp;%204%20%5C%5C%0A5%20&amp;%206%20&amp;%200%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, <img src="https://latex.codecogs.com/png.latex?det(A)"> = -57, and the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B-57%7D%5Cbegin%7Bbmatrix%7D%0A-24%20&amp;%2018%20&amp;%205%20%5C%5C%0A20%20&amp;%20-15%20&amp;%20-4%20%5C%5C%0A-3%20&amp;%202%20&amp;%201%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>There are several formulas for finding the inverse of a matrix such as Gauss-Jordan Elimination, Adjoint method, Cramer’s rule, Inverse formula, etc. This topic is going to be handled in the other blogs.</p>
</section>
<section id="rank" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="rank"><span class="header-section-number">2.7</span> Rank</h3>
<p>The rank of a matrix is the dimension of the vector space spanned by its columns (or rows). It is denoted by <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Brank%7D(%5Cmathbf%7BA%7D)">.</p>
<p>For example, consider the following matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%20%20%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%20&amp;%203%5C%5C%0A%20%20%20%204%20&amp;%205%20&amp;%206%20%5C%5C%0A%20%20%20%207%20&amp;%208%20&amp;%209%5C%5C%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are linearly dependent since the third column is equal to the sum of the first two columns. Therefore, the dimension of the vector space spanned by the columns is 2, so the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is 2.</p>
</section>
<section id="trace" class="level3" data-number="2.8">
<h3 data-number="2.8" class="anchored" data-anchor-id="trace"><span class="header-section-number">2.8</span> Trace</h3>
<p>The trace of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)">, is defined as the sum of the diagonal elements of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">. In other words, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> matrix, then its trace is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D"> denotes the <img src="https://latex.codecogs.com/png.latex?i"> th diagonal element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%202%20&amp;%203%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%205%20&amp;%202%20%5C%5C%0A%20%201%20&amp;%201%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>Then, the trace of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)%20=%202%20+%205%20+%204%20=%2011"></p>
</section>
<section id="eigenvalues-and-eigenvectors" class="level3" data-number="2.9">
<h3 data-number="2.9" class="anchored" data-anchor-id="eigenvalues-and-eigenvectors"><span class="header-section-number">2.9</span> Eigenvalues and Eigenvectors</h3>
<p>Let A be an <img src="https://latex.codecogs.com/png.latex?n%20%C3%97%20n"> square matrix. A scalar <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is called an eigenvalue of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> if there exists a non-zero vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> such that <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BAv%7D=%5Clambda%5Cmathbf%7Bv%7D%0A"></p>
<p>Such a vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> is called an eigenvector corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda">.</p>
<p>Example:</p>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> be the matrix</p>
<p>To find the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">, we solve the characteristic equation <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%20=%200">, where I is the n × n identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%0A%20%20&amp;=%0A%20%20%20%20%5Cbegin%7Bvmatrix%7D%0A%20%20%20%203%20-%20%5Clambda%20&amp;%201%20%5C%5C%0A%20%20%20%201%20&amp;%203%20-%20%5Clambda%0A%20%20%20%20%5Cend%7Bvmatrix%7D%20%5C%5C%0A%20%20&amp;=%0A%20%20(3%20-%20%5Clambda)(3%20-%20%5Clambda)%20-%201%20%5C%5C%0A%20%20&amp;=%20%5Clambda%5E2%20-%206%5Clambda%20+%208%20=%200%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this quadratic equation gives us the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">: <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202"> and <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">.</p>
<p>To find the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%20%5Cmathbf%7B0%7D">, where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20I"> is the <img src="https://latex.codecogs.com/png.latex?2%20%5Ctimes%202"> identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%0A%20%20%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%20%201%20&amp;%201%20%5C%5C%0A%20%20%20%20%20%201%20&amp;%201%0A%20%20%20%20%5Cend%7Bbmatrix%7D%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20x%20%5C%5C%0A%20%20%20%20y%0A%20%20%5Cend%7Bbmatrix%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%200%20%5C%5C%0A%20%20%20%200%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this system of equations gives us the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D%20=%20%5Cbegin%7Bbmatrix%7D%20-1%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
<p>Similarly, for <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%204%5Cmathbf%20I)%5Cmathbf%7Bv%7D"> = <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D"> to get the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
</section>
<section id="singular-value-and-singluar-vectors" class="level3" data-number="2.10">
<h3 data-number="2.10" class="anchored" data-anchor-id="singular-value-and-singluar-vectors"><span class="header-section-number">2.10</span> Singular value and Singluar Vectors</h3>
<p>The singular value decomposition (SVD) of a matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> is a factorization of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> into the product of three matrices as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20m"> orthogonal matrix, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> rectangular diagonal matrix with non-negative real numbers on the diagonal, and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> orthogonal matrix.</p>
<p>The diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> are called the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Csigma_1,%20%5Csigma_2,%20%5Cldots,%20%5Csigma_r"> (where <img src="https://latex.codecogs.com/png.latex?r"> is the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">), and are arranged in descending order. The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> are called the left and right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, respectively, and are orthonormal vectors.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be a 3 by 2 matrix given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%5C%5C%0A%20%20%20%203%20&amp;%204%5C%5C%0A%20%20%20%205%20&amp;%206%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The SVD of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.23%20&amp;%20-0.53%20&amp;%20-0.81%5C%5C%0A%20%20-0.53%20&amp;%20-0.72%20&amp;%200.45%5C%5C%0A%20%20-0.81%20&amp;%200.45%20&amp;%20-0.38%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%209.53%20&amp;%200%5C%5C%0A%20%200%20&amp;%200.90%5C%5C%0A%20%200%20&amp;%200%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.62%20&amp;%20-0.78%5C%5C%0A%20%20-0.78%20&amp;%200.62%0A%5Cend%7Bbmatrix%7D%5ET%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where the left singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D">, the right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D">, and the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5CSigma%7D">.</p>
<ul>
<li>연립 방정식을 행렬의 곱으로 나타내보기 <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bmatrix%7Dx_1+2y_1=4%5C%5C2x_1+5y_1=9%5Cend%7Bmatrix%7D%20%5Cquad%20%5Cquad%20%5Cquad%20%5Cbegin%7Bmatrix%7Dx_2+2y_2=3%5C%5C2x_2+5y_2=7%5Cend%7Bmatrix%7D"> <img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20%5C%5C%202%20&amp;%205%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20%5C%5C%20y_1%20&amp;%20y_2%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%204%20&amp;%209%20%5C%5C%203%20&amp;%207%20%5Cend%7Bbmatrix%7D"></li>
<li>중요한 사실(….당연한 사실?)
<ul>
<li>곱셈의 왼쪽 행렬의 열 수와, 오른쪽 행렬의 행 수가 같아야 가능함
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20B_%7Bo%20%5Ctimes%20p%7D"> 에서 <img src="https://latex.codecogs.com/png.latex?n%20=%20o"> 여야 곱셈 성립</li>
</ul></li>
<li>곱셈의 결과 행렬의 크기 = 곱셈의 왼쪽 행렬의 행 수 <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> 곱셈의 오른쪽 행렬의 열 수
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20B_%7Bo%20%5Ctimes%20p%7D%20=%20C_%7Bm%20%5Ctimes%20p%7D"></li>
</ul></li>
<li>교환법칙(Commutative property)이 성립하지 않음
<ul>
<li><img src="https://latex.codecogs.com/png.latex?AB%20%5Cneq%20BA"></li>
</ul></li>
</ul></li>
<li>행렬 곱셈의 여러가지 관점
<ul>
<li>내적으로 바라보기 <img src="https://latex.codecogs.com/png.latex?%20A%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20"> <img src="https://latex.codecogs.com/png.latex?%20AB%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%7D%20&amp;%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_1%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_1%5ET%20b_m%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_2%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_2%5ET%20b_m%7D%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_m%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%5ET%20b_m%7D%20%5Cend%7Bbmatrix%7D"></li>
<li>rank-1 matrix의 합 (또 안가르쳐준 개념 먼저 사용중…..-_-) <img src="https://latex.codecogs.com/png.latex?AB%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%7D%20&amp;%20%5Cmathbf%7Ba_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Bb_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Bb_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7Ba_1%20b_1%5ET%7D%20+%20%5Cmathbf%7Ba_2%20b_2%5ET%7D%20+%20%5Ccdots%20+%20%5Cmathbf%7Ba_m%20b_m%5ET%7D"></li>
<li>column space로 바라보기 <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%7D%20&amp;%20%5Cmathbf%7Ba_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20%5C%5C%20x_2%20%5C%5C%20%5Cvdots%20%5C%5C%20x_m%20%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7Ba_1%7D%20x_1%20+%20%5Cmathbf%7Ba_2%7D%20x_2%20+%20%5Ccdots%20+%20%5Cmathbf%7Ba_m%7D%20x_m%20"> (스칼라배의 합)
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20%5C%5C%200%20&amp;%201%20%5Cend%7Bbmatrix%7D"> 는 2차원 좌표평면의 모든 점을, <img src="https://latex.codecogs.com/png.latex?A=%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%200%20%5C%5C%200%20&amp;%201%20&amp;%200%20%5C%5C%200%20&amp;%200%20&amp;%201%20%5Cend%7Bbmatrix%7D">은 3차원 좌표평면의 모든 점 표현 가능</li>
<li><img src="https://latex.codecogs.com/png.latex?AB%20=%20A%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%7D%20&amp;%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20A%20%5Cmathbf%7Bb_1%7D%20&amp;%20A%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20A%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D"></li>
<li>column space: A의 column vector로 만들 수 있는 부분 공간</li>
</ul></li>
<li>row space로 바라보기 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%5ET%7DA%20=%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20&amp;%20%5Ccdots%20&amp;%20x_m%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20=%20x_1%20%5Cmathbf%7Ba_1%5ET%7D%20+%20x_2%20%5Cmathbf%7Ba_2%5ET%7D%20+%20%5Ccdots%20+%20x_m%20%5Cmathbf%7Ba_m%5ET%7D%20"></li>
</ul></li>
</ul>
</section>
</section>
<section id="열공간column-space" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="열공간column-space"><span class="header-section-number">3</span> 열공간(Column Space)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/g0eaDeVRdZk" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>column space: column vector 들이 span 하는 space
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A">의 column space = <img src="https://latex.codecogs.com/png.latex?C(A)"> 또는 <img src="https://latex.codecogs.com/png.latex?range(A)"></li>
</ul></li>
<li>span: vector들의 linear combination 으로 나타낼 수 있는 모든 vector를 모은 집합
<ul>
<li>vector에 따라, 점일수도 선일수도 평면일 수도 있음</li>
<li>vector space를 이 vector들이 span하는 space → column space는 행렬의 열들이 span하는 space</li>
</ul></li>
<li>vector의 선형 결합(linear combination): vector에 스칼라배를 해서 더하는 것
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D"> 과 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D">의 linear combination으로 2차원 좌표평면 나타내기 <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" class="img-fluid"></li>
</ul></li>
</ul>
</section>
<section id="선형-독립linear-independent" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="선형-독립linear-independent"><span class="header-section-number">4</span> 선형 독립(Linear Independent)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/mOOI4-BfjGQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>…and also see</p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/9F4PZ_1orF0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>선형 독립(linearly independent)인 vectors: (선형 결합을 통해) 더 고차원을 span할 수 있게 해줌</li>
<li>orthogonal 하면 independent
<ul>
<li>but independent해도 항상 orthogonal하지는 않음 (Independent &gt; Orthogonal)</li>
</ul></li>
<li>definition: <img src="https://latex.codecogs.com/png.latex?a_1%20%5Cmathbf%7Bv_1%7D%20+%20a_2%20%5Cmathbf%7Bv_2%7D%20+%20a_3%20%5Cmathbf%7Bv_3%7D%20%5Ccdots%20a_n%20%5Cmathbf%7Bv_n%7D%20=%20%5Cmathbf%7B0%7D"> 를 만족하는 <img src="https://latex.codecogs.com/png.latex?a_1,%20a_2,%20a_3,%20%5Ccdots%20a_n"> 이 <img src="https://latex.codecogs.com/png.latex?a_1%20=%20a_2%20=%20a_3%20=%20%5Ccdots%20=%20a_n%20=%200"> 밖에 없을때
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D">는 모든 elements가 <img src="https://latex.codecogs.com/png.latex?0">인 벡터</li>
<li>예: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%202%20%5Cend%7Bbmatrix%7D"> 는 <img src="https://latex.codecogs.com/png.latex?-2%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D%20+%201%20%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%202%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> 이 되므로, linearly independent 하지 않음</li>
<li>independent한 vector 들의 수 = 표현할 수 있는 차원의 dimension</li>
</ul></li>
</ul>
</section>
<section id="기저basis" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="기저basis"><span class="header-section-number">5</span> 기저(basis)</h2>
<ul>
<li>주어진 vector space를 span하는 linearly independent한 vectors</li>
<li>어떤 공간을 이루는 필수적인 구성요소</li>
<li>orthogonal 하면 orthogonal basis</li>
<li>예: 2차원 좌표평면에 대해
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"> : orthogonal basis</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"> : orthogonal 하지 않은 basis</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> : linearly independent 하지 않으므로 basis 아님</li>
</ul></li>
</ul>
</section>
<section id="항등행렬identity-matrix-역행렬inverse-matrix-대각행렬diagonal-matrix-직교행렬orthogonal-matrix" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="항등행렬identity-matrix-역행렬inverse-matrix-대각행렬diagonal-matrix-직교행렬orthogonal-matrix"><span class="header-section-number">6</span> 항등행렬(identity matrix), 역행렬(inverse matrix), 대각행렬(Diagonal Matrix), 직교행렬(orthogonal matrix)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/XqOvyfMUAwA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="identity-matrix항등행렬" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="identity-matrix항등행렬"><span class="header-section-number">6.1</span> Identity matrix(항등행렬)</h3>
<ul>
<li>항등원: 임의의 원소에 대해 연산하면 자기 자신이 나오게 하는 원소 (by namu.wiki)
<ul>
<li>실수에서 곱셈의 항등원은 1</li>
</ul></li>
<li>행렬의 항등원: 항등행렬(<img src="https://latex.codecogs.com/png.latex?I">) <img src="https://latex.codecogs.com/png.latex?I%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%200%20&amp;%201%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%200%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%201%20%5Cend%7Bbmatrix%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20I_%7Bn%20%5Ctimes%20n%20=%20n%7D%20=%20A_%7Bm%20%5Ctimes%20n%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?I_%7Bm%20%5Ctimes%20m%20=%20m%7D%20%5Ctimes%20A_%7Bm%20%5Ctimes%20n%7D%20=%20A_%7Bm%20%5Ctimes%20n%7D"></li>
</ul></li>
</ul>
</section>
<section id="sec-inv" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="sec-inv"><span class="header-section-number">6.2</span> Inverse matrix(역행렬)</h3>
<ul>
<li>역원: 연산 결과 항등원이 나오게 하는 연소
<ul>
<li>실수에서 곱셈의 역원은 지수의 부호가 반대인 역수 (by namu.wiki): <img src="https://latex.codecogs.com/png.latex?a%20%5Ctimes%20a%5E%7B-1%7D%20=%201"></li>
</ul></li>
<li>행렬의 역원: 역행렬(<img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D">) <img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I%20,%20A%5E%7B-1%7D%20%5Ctimes%20A%20=%20I">
<ul>
<li>존재하지 않는 경우도 있음</li>
<li>존재하면 Invertible(nonsingular, nondegenerate) matrix라고 불림
<ul>
<li>존재하지 않으면 singular, degenerate라고 불림</li>
</ul></li>
<li>square matrix(정사각행렬, <img src="https://latex.codecogs.com/png.latex?m%20=%20n">)은 특수한 경우를 제외하면 역행렬이 항상 존재
<ul>
<li>역행렬이 존재하지 않는특수한 경우: (나중에 배울) determinant가 0인 경우</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?m%20%5Cneq%20n">인 행렬의 경우에는 역행렬이 존재하지 않음
<ul>
<li>다만, 경우에 따라 <img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I"> 를 만족하거나(right inverse), <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D%20%5Ctimes%20A%20=%20I">를 만족하는(left inverse)는 <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D">이 존재함</li>
</ul></li>
<li>연립 방정식을 matrix로 나타냈을 때, 역행렬을 이용해서 해를 찾을 수 있음 <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cmathbf%7Bb%7D%20%5CRightarrow%20A%5E%7B-1%7DA%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D%20%5CRightarrow%20I%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D%20%5CRightarrow%20%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D"></li>
</ul></li>
</ul>
</section>
<section id="diagonal-matrix대각행렬" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="diagonal-matrix대각행렬"><span class="header-section-number">6.3</span> Diagonal Matrix(대각행렬)</h3>
<ul>
<li>diagonal element(대각 원소)외의 모든 elements(off-diagonal elements)가 0인 matrix <img src="https://latex.codecogs.com/png.latex?%20D%20=%20Diag(%5Cmathbf%7Ba%7D)%20=%20%5Cbegin%7Bbmatrix%7D%20a_%7B1,1%7D%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%200%20&amp;%20a_%7B2,2%7D%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%200%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%20a_%7Bn,n%7D%20%5Cend%7Bbmatrix%7D">
<ul>
<li>identity matrix는 diagonal matrix</li>
<li>diagnomal matrix는 symmetric matrix 이기도 함</li>
<li>보통은 square matrix에서 주로 사용됨
<ul>
<li>square matrix가 아니면서 diagonal matrix인 경우: rectangular diagonal matrix</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="orthogonal-matrix직교행렬-orthonomal-matrix" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="orthogonal-matrix직교행렬-orthonomal-matrix"><span class="header-section-number">6.4</span> Orthogonal matrix(직교행렬, orthonomal matrix)</h3>
<ul>
<li>행렬의 각 columns들이 orthonomal vectors (서로 수직하면서 unit vectors) <img src="https://latex.codecogs.com/png.latex?A%20A%5ET%20=%20A%5ET%20A%20=%20I"></li>
<li>identity matrix는 orthogonal matrix</li>
<li>square matrix에서만 정의됨</li>
<li>Orthogonal matrix인 <img src="https://latex.codecogs.com/png.latex?A">이면 <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D%20=%20A%5E%7BT%7D">
<ul>
<li>각 columns에서 자기 자신과의 내적 = 1, 다른 column과의 내적 = 0임</li>
</ul></li>
<li>complex matrix(복소수 행렬)에서는 unitary matrix라고 부름</li>
</ul>
</section>
</section>
<section id="계수rank" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="계수rank"><span class="header-section-number">7</span> 계수(Rank)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/HMST0Yc7EXE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>rank: 행렬이 가지는 independent한 columns의 수 = column space의 dimension = row space의 dimension</li>
<li>independent한 column의 수 = independent한 행의 수: <img src="https://latex.codecogs.com/png.latex?rank(A)%20=%20rank(A%5ET)">
<ul>
<li>proof: <a href="https://en.wikipedia.org/wiki/Rank_%28linear_algebra%29#Proofs_that_column_rank_=_row_rank">Wikipedia</a></li>
</ul></li>
<li>예: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%200%20&amp;%200%20&amp;%200%20%5Cend%7Bbmatrix%7D%20%5CRightarrow%20rank=1"> <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%201%20%5C%5C%200%20&amp;%201%20&amp;%201%20%5Cend%7Bbmatrix%7D%20%5CRightarrow%20rank=2"></li>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D"> 의 최대 랭크는 <img src="https://latex.codecogs.com/png.latex?min%5C%7Bm,n%5C%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?rank(A)%20%3C%20min%5C%7Bm,n%5C%7D"> 면 rank-deficient, <img src="https://latex.codecogs.com/png.latex?rank(A)%20=%20min%5C%7Bm,n%5C%7D">면 full (row/column) rank</li>
</ul></li>
</ul>
</section>
<section id="영공간null-space" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="영공간null-space"><span class="header-section-number">8</span> 영공간(Null space)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/Eizc9TSRYMQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%20%5Cmathbf%7B0%7D"> 을 만족하는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">의 집합
<ul>
<li>column space 관점에서 보기: <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20x_1%20%5Cmathbf%7Ba_1%7D%20+%20x_2%20%5Cmathbf%7Ba_2%7D%20+%20%5Ccdots%20+%20x_n%20%5Cmathbf%7Ba_n%7D%20=%20%5Cmathbf%7B0%7D"></li>
<li>null space에 항상 들어가는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%200%20%5C%5C%20%5Cvdots%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> : trivial solution
<ul>
<li>모든 columns이 다 lienarly independent 하면, null space에는 위의 벡터 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D">하나 밖에 없음</li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D"> 가 아닌 vector가 null space에 있으면, 스칼라배(constant <img src="https://latex.codecogs.com/png.latex?c">에 대해 <img src="https://latex.codecogs.com/png.latex?c%20%5Cmathbf%7Bx%7D">) 역시 null space에 포함됨</li>
<li>혼동 주의! null space는 column space의 일부가 아님
<ul>
<li>row vector의 차원이 null space가 존재하는 공간</li>
</ul></li>
<li>rank와 null space의 dimension의 합은 항상 matrix의 column의 수
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D">에 대해, <img src="https://latex.codecogs.com/png.latex?dim(N(A))%20=%20n%20-%20r">
<ul>
<li>모든 columns이 다 lienarly independent 하면 null space는 0차원(점)</li>
</ul></li>
<li>null space는 row space와 수직한 space
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%20%5Cmathbf%7B0%7D"> : 각각 모든 행과 내적해서 0, → 행들의 linear combination과 내적해도 0</li>
<li>rank는 row space의 dimension → row space의 dimension(<img src="https://latex.codecogs.com/png.latex?dim(R(A))">)과 null space의 dimension(<img src="https://latex.codecogs.com/png.latex?dim(N(A))">)의 합이 <img src="https://latex.codecogs.com/png.latex?n"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%5En%7D"> 공간에 표현: <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_10.PNG" class="img-fluid">
<ul>
<li>겹친 점: 영벡터</li>
</ul></li>
</ul></li>
</ul></li>
<li>left null space: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%5ET%7D%20A%20=%20%5Cmathbf%7B0%5ET%7D"> 인 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">
<ul>
<li>위의 성질을 row에 대해 적용
<ul>
<li>m 차원에 놓인 벡터</li>
<li>dimension: <img src="https://latex.codecogs.com/png.latex?dim(N_L(A))%20=%20m%20-%20r"></li>
<li>column space와 수직: <img src="https://latex.codecogs.com/png.latex?dim(N_L(A))%20+dim(C(A))%20=%20m"></li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?R(A)">에 있는 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_r%7D"> 와 <img src="https://latex.codecogs.com/png.latex?N(A)">에 있는 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 대해:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_r%7D">에 <img src="https://latex.codecogs.com/png.latex?A">를 곱하면 column space로 감</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 <img src="https://latex.codecogs.com/png.latex?A">를 곱하면 $</li>
<li><img src="https://latex.codecogs.com/png.latex?A(%5Cmathbf%7Bx_r%7D%20+%5Cmathbf%7Bx_n%7D)%20=%20A%5Cmathbf%7Bx_r%7D%20+%20A%5Cmathbf%7Bx_n%7D%20=%20A%5Cmathbf%7Bx_r%7D%20=%20%5Cmathbf%7Bb%7D"></li>
</ul></li>
</ul>
</section>
<section id="ax-b의-해의-수" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="ax-b의-해의-수"><span class="header-section-number">9</span> Ax = b의 해의 수</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/nNI2TlD598c" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><p>full column rank 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 있으면 해가 하나</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 없으면 해가 없음 <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_11.PNG" class="img-fluid"></li>
</ul></li>
<li><p>full row rank 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">는 항상 column space 안에 있음: 무한의 해를 가짐</li>
<li>임의의 특정한 해(particular solution) <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_p%7D">와 null space의 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 대해, <img src="https://latex.codecogs.com/png.latex?A(%5Cmathbf%7Bx_p%7D%20+%5Cmathbf%7Bx_n%7D)=%5Cmathbf%7Bb%7D">
<ul>
<li>즉, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_p%7D%20+%5Cmathbf%7Bx_n%7D"> 도 해가 됨: complete solution
<ul>
<li>null space는 무한하므로, 해도 무한함</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>full rank 일때(square matrix): 해가 하나 존재 (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D">$)</p></li>
<li><p>rank-deficient 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 있으면 무한한 해를 가짐</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 없으면 해가 없음</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/03.linear_equations_matrix.html</guid>
  <pubDate>Thu, 30 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" medium="image"/>
</item>
<item>
  <title>Basics (1) - Vector Operations</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/01.basic_vector.html</link>
  <description><![CDATA[ 



<section id="introduction-linear-algebra-to-deep-learning" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction Linear Algebra to Deep Learning</h1>
<p>Deep learning is a pile of neural networks that are made up of layers of interconnected nodes or neurons, and the weights of the connections between them are learned through a process called backpropagation.</p>
<p>Linear algebra is fundamental to deep learning because many of the computations involved in training neural networks can be expressed as linear algebra operations. For example, matrix multiplication is used to compute the output of each layer in a neural network, and the gradients of the loss function with respect to the weights are computed using the chain rule of calculus, which involves matrix multiplication and vector operations.</p>
<p>In addition to matrix multiplication, other linear algebra concepts such as eigenvectors, eigenvalues, and singular value decomposition (SVD) are also important in deep learning. For example, SVD can be used to reduce the dimensionality of a dataset or to compute principal components, which are useful for data visualization and feature extraction.</p>
<p>Linear algebra libraries such as Numpy, Scipy, and PyTorch provide efficient implementations of these operations, which are essential for training large-scale neural networks on GPUs. Without these libraries, implementing deep learning algorithms would be much more difficult and time-consuming.</p>
<p><a href="https://nbviewer.org/github/fastai/numerical-linear-algebra/blob/master/nbs/1.%20Why%20are%20we%20here.ipynb">Reference: Motivation to Learn Linear Algebra</a></p>
<section id="scalar" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="scalar"><span class="header-section-number">1.1</span> Scalar</h2>
<p>A scalar is a single mathematical quantity, usually a real number, which can be represented by a single value. Scalars are typically denoted by lowercase letters, such as <img src="https://latex.codecogs.com/png.latex?a,%20b,%20c,"> and so on.</p>
</section>
<section id="vector" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="vector"><span class="header-section-number">1.2</span> Vector</h2>
<p>A vector <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bv%7D"> is a mathematical object that represents a quantity with both a magnitude and a direction. In <img src="https://latex.codecogs.com/png.latex?n">-dimensional Euclidean space <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5En">, a vector <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bv%7D"> is typically represented as an ordered list of <img src="https://latex.codecogs.com/png.latex?n"> real numbers:</p>
<ul>
<li>the magnitude of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D%20=%5Cbegin%7Bbmatrix%7D%20x%5C%5C%20y%20%5Cend%7Bbmatrix%7D"> is <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Cmathbf%7Bv%7D%7C%7C%20=%20%5Csqrt%7Bx%5E%7B2%7D%20+%20y%5E%7B2%7D%7D"></li>
<li>the direction of it is the angle with the x axis, <img src="https://latex.codecogs.com/png.latex?%5Ctheta=%5Ctan%5E%7B-1%7D(%5Cfrac%7By%7D%7Bx%7D)"></li>
<li>If magnitude and vector are equal, then they are equal vectors</li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctextbf%7Bv%7D=%0A%5Cbegin%7Bbmatrix%7D%0A%20%20v_1%20%5C%5C%0A%20%20v_2%20%5C%5C%0A%20%20%5Cvdots%20%5C%5C%0A%20%20v_n%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?v_1,%20v_2,%20%5Cldots,%20v_n"> are the components of the vector <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bv%7D">.</p>
<section id="plotting-vectors-on-the-coordinate-plane" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="plotting-vectors-on-the-coordinate-plane"><span class="header-section-number">1.2.1</span> Plotting Vectors on the Coordinate Plane</h3>
<p>Example</p>
<p>Map <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%203%5C%5C%202%20%5Cend%7Bbmatrix%7D"> into <img src="https://latex.codecogs.com/png.latex?x=3">, <img src="https://latex.codecogs.com/png.latex?y=2"> on the Coordinate Plane</p>
<div class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/01.basic_vector_files/figure-html/cell-2-output-1.png" width="592" height="416"></p>
</div>
</div>
<p><a href="http://immersivemath.com/ila/ch02_vectors/ch02.html#auto_label_33">Reference: Read This Article with Interactive Visualization - Points and Vectors</a></p>
</section>
</section>
<section id="basic-vector-operations" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="basic-vector-operations"><span class="header-section-number">1.3</span> Basic Vector Operations</h2>
<section id="addition-of-vectors" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="addition-of-vectors"><span class="header-section-number">1.3.1</span> Addition of Vectors</h3>
<p>The addition of two vectors is the process of adding their corresponding components. If <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Ba%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bb%7D"> are two vectors of the same dimension, then their sum <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bc%7D%20=%20%5Ctextbf%7Ba%7D%20+%20%5Ctextbf%7Bb%7D"> is a vector whose <img src="https://latex.codecogs.com/png.latex?i">-th component is the sum of the <img src="https://latex.codecogs.com/png.latex?i">-th components of <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Ba%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bb%7D">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20%5Ctextbf%7Bc%7D&amp;=%5Ctextbf%7Ba%7D+%5Ctextbf%7Bb%7D%5C%5C%0A%20%20c_i%20&amp;=%20a_i%20+%20b_i%0A%5Cend%7Balign*%7D%0A"></p>
<p>For example, if <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Ba%7D%20=%20%5B1,%202,%203%5D"> and <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bb%7D%20=%20%5B4,%205,%206%5D">, then their sum <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bc%7D%20=%20%5B5,%207,%209%5D">.</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_01.PNG" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_02.PNG" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_03.PNG" class="img-fluid"></p>
</div>
</div>
</div>
</section>
<section id="subtraction-of-vectors" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="subtraction-of-vectors"><span class="header-section-number">1.3.2</span> Subtraction of Vectors</h3>
<p>The subtraction of two vectors is the process of subtracting their corresponding components. If <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Ba%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bb%7D"> are two vectors of the same dimension, then their difference <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bc%7D%20=%20%5Ctextbf%7Ba%7D%20-%20%5Ctextbf%7Bb%7D"> is a vector whose <img src="https://latex.codecogs.com/png.latex?i">-th component is the difference between the <img src="https://latex.codecogs.com/png.latex?i">-th components of <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Ba%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bb%7D">. The formal definition is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20%5Ctextbf%7Bc%7D&amp;=%5Ctextbf%7Ba%7D%20-%20%5Ctextbf%7Bb%7D%5C%5C%0A%20%20c_i%20&amp;=%20a_i%20-%20b_i%0A%5Cend%7Balign*%7D%0A"></p>
<p>For example, if <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Ba%7D%20=%20%5B1,%202,%203%5D"> and <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bb%7D%20=%20%5B4,%205,%206%5D">, then their difference <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bc%7D%20=%20%5B-3,%20-3,%20-3%5D">.</p>
</section>
<section id="scalar-multiplication-of-vectors" class="level3" data-number="1.3.3">
<h3 data-number="1.3.3" class="anchored" data-anchor-id="scalar-multiplication-of-vectors"><span class="header-section-number">1.3.3</span> Scalar Multiplication of Vectors</h3>
<p>The scalar multiplication of a vector is the process of multiplying each component of the vector by a scalar. If <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Ba%7D"> is a vector and <img src="https://latex.codecogs.com/png.latex?k"> is a scalar, then the scalar multiple <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bc%7D%20=%20k%5Ctextbf%7Ba%7D"> is a vector whose <img src="https://latex.codecogs.com/png.latex?i">-th component is <img src="https://latex.codecogs.com/png.latex?k"> times the <img src="https://latex.codecogs.com/png.latex?i">-th component of <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Ba%7D">. The formal definition is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20%5Ctextbf%7Bc%7D&amp;=k%5Ctextbf%7Ba%7D%5C%5C%0A%20%20c_i%20&amp;=%20ka_i%0A%5Cend%7Balign*%7D%0A"></p>
<p>For example, if <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Ba%7D%20=%20%5B1,%202,%203%5D"> and <img src="https://latex.codecogs.com/png.latex?k%20=%202">, then their scalar multiple <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bc%7D%20=%20%5B2,%204,%206%5D">.</p>
<p><a href="http://immersivemath.com/ila/ch02_vectors/ch02.html#sec_vec_arithmetic">Reference: Read This Article with Interactive Visualization - Properties of Vector Arithmetic</a></p>
</section>
<section id="inner-product-of-vectors" class="level3" data-number="1.3.4">
<h3 data-number="1.3.4" class="anchored" data-anchor-id="inner-product-of-vectors"><span class="header-section-number">1.3.4</span> Inner Product of Vectors</h3>
<p>The dot product of two vectors is the sum of the products of their corresponding components (a.k.a dot product &amp; scalar product). If <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Ba%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bb%7D"> are two vectors of the same dimension, then their dot product <img src="https://latex.codecogs.com/png.latex?c%20=%20%5Ctextbf%7Ba%7D%20%5Ccdot%20%5Ctextbf%7Bb%7D"> is a scalar given by the formula:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20c&amp;=%5Ctextbf%7Ba%7D%5Ccdot%20%5Ctextbf%7Bb%7D%5C%5C%0A%20%20&amp;=%20%5Csum_%7Bi=1%7D%5E%7Bn%7Da_ib_i%0A%5Cend%7Balign*%7D%0A"></p>
<ul>
<li>Dot product can be used to measure the similarity between two vectors.</li>
<li>For the two vectors, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Ba%7D%20=%20%5Ba_1,%20a_2,%20%5Ccdots%20a_n%5D"> , <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D%20=%20%5Bb_1,%20b_2,%20%5Ccdots%20b_n%5D">, dot product can be defined as <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7Ba%7D%20%5Ccdot%20%5Cmathbf%7Bb%7D%20=%20%5Cmathbf%7Ba%7D%5E%7BT%7D%20%5Cmathbf%7Bb%7D%20=%20%7C%7C%5Cmathbf%7Ba%7D%7C%7C%5Ctext%7B%20%7D%20%7C%7C%5Cmathbf%7Bb%7D%7C%7C%20%5Ccos%20%5Ctheta%0A"></li>
<li>When two vectors are orthogonal, <img src="https://latex.codecogs.com/png.latex?%5Ccos%2090%5E%7B%5Ccirc%7D%20=%200">, the similarity of the two vectors is 0.</li>
<li>In the Euclidean space, dot product is often called inner product (inner product is a generalization of dot product)</li>
</ul>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Inner Product vs Dot Product
</div>
</div>
<div class="callout-body-container callout-body">
<p>In general, an inner product is a mathematical operation that takes two vectors and produces a scalar. It satisfies certain properties, such as being linear in the first argument, conjugate linear in the second argument, and positive-definite. In other words, an inner product is a bilinear form that satisfies the following properties for all vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7By%7D">, and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bz%7D">, and all scalars <img src="https://latex.codecogs.com/png.latex?a"> and <img src="https://latex.codecogs.com/png.latex?b">:</p>
<ul>
<li>“Linear in the first argument” means that for any fixed vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20u">, the function <img src="https://latex.codecogs.com/png.latex?f"> defined by <img src="https://latex.codecogs.com/png.latex?f(%5Cmathbf%20v)%20=%20%5Clangle%5Cmathbf%20u,%20%5Cmathbf%20v%5Crangle"> is a linear function of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20v">, i.e., <img src="https://latex.codecogs.com/png.latex?f(a%5Cmathbf%20x%20+%20b%5Cmathbf%20y)%20=%20af(%5Cmathbf%20x)%20+%20bf(%5Cmathbf%20y)"> for any scalars <img src="https://latex.codecogs.com/png.latex?a">, <img src="https://latex.codecogs.com/png.latex?b">, and vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7By%7D">.
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Clangle%20a%5Cmathbf%7Bx%7D%20+%20b%5Cmathbf%7By%7D,%20%5Cmathbf%7Bz%7D%5Crangle%20=%20a%5Clangle%5Cmathbf%7Bx%7D,%20%5Cmathbf%7Bz%7D%5Crangle%20+%20b%5Clangle%5Cmathbf%7By%7D,%20%5Cmathbf%7Bz%7D%5Crangle">, the inner product is linear with respect to the first argument. If we multiply a vector by a scalar and add it to another vector, the resulting inner product is the same as if we had calculated the inner product of each vector separately and then added them.</li>
</ul></li>
<li>“Conjugate linear in the second argument” means that for any fixed vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20v">, the function <img src="https://latex.codecogs.com/png.latex?g"> defined by <img src="https://latex.codecogs.com/png.latex?g(%5Cmathbf%20u)%20=%20%5Clangle%5Cmathbf%20u,%20%5Cmathbf%20v%5Crangle"> is a conjugate linear function of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20u">, i.e., <img src="https://latex.codecogs.com/png.latex?g(a%20%5Cmathbf%20x%20+%20b%20%5Cmathbf%20y)%20=%20%5Cbar%7Ba%7D%20g(%5Cmathbf%20x)%20+%20%5Cbar%7Bb%7D%20*%20g(%5Cmathbf%20y)"> for any scalars <img src="https://latex.codecogs.com/png.latex?a">, <img src="https://latex.codecogs.com/png.latex?b">, and vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20x">, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20y">, where <img src="https://latex.codecogs.com/png.latex?%5Cbar%7Ba%7D"> denotes the complex conjugate of <img src="https://latex.codecogs.com/png.latex?a">.
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Clangle%20%5Cmathbf%7Bx%7D,%20a%5Cmathbf%7By%7D,%20b%5Cmathbf%7Bz%7D%5Crangle%20=%20a%5Clangle%5Cmathbf%7Bx%7D,%20%5Cmathbf%7By%7D%5Crangle%20+%20b%5Clangle%5Cmathbf%7Bx%7D,%20%5Cmathbf%7Bz%7D%5Crangle">. this property says that the inner product is linear with respect to the second argument, but with complex conjugation. If we multiply a vector by a scalar and add it to another vector, the resulting inner product is the same as if we had calculated the inner product of each vector separately, complex-conjugated the second vector, and then added them.</li>
</ul></li>
<li>“Symmetry” means <img src="https://latex.codecogs.com/png.latex?%5Clangle%20%5Cmathbf%7Bx%7D,%5Cmathbf%7By%7D%5Crangle=%20%5Clangle%20%5Cmathbf%7By%7D,%5Cmathbf%7Bx%7D%5Crangle">
<ul>
<li>the order of the vectors doesn’t matter when calculating the inner product.<br>
</li>
</ul></li>
<li>“Positive-definite” means that for any nonzero vector v, the inner product <img src="https://latex.codecogs.com/png.latex?%5Clangle%5Cmathbf%20u,%20%5Cmathbf%20v%5Crangle"> is a positive real number. In other words, the inner product of a vector with itself is always positive, except when the vector is the zero vector.
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Clangle%20%5Cmathbf%7Bx%7D,%5Cmathbf%7Bx%7D%5Crangle%5Cge%200,%20%5Clangle%20%5Cmathbf%7Bx%7D,%5Cmathbf%7Bx%7D%5Crangle=0"> only if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=0"></li>
</ul></li>
</ul>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Linear Transformation
</div>
</div>
<div class="callout-body-container callout-body">
<p>A function is said to be linear if it satisfies two properties: <strong>additivity</strong> and <strong>homogeneity</strong>.</p>
<ol type="1">
<li>Additivity means that for any two inputs, the output of the function applied to their sum is equal to the sum of the outputs applied to each input separately. In other words, if we have a function <img src="https://latex.codecogs.com/png.latex?f"> and vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20x"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20y">, then</li>
</ol>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(%5Cmathbf%20x%20+%20%5Cmathbf%20y)%20=%20f(%5Cmathbf%20x)%20+%20f(%5Cmathbf%20y)%0A"></p>
<ol start="2" type="1">
<li>Homogeneity means that for any input and scalar <img src="https://latex.codecogs.com/png.latex?c">, the output of the function applied to the input scaled by <img src="https://latex.codecogs.com/png.latex?c"> is equal to the output applied to the unscaled input multiplied by <img src="https://latex.codecogs.com/png.latex?c">. In other words,</li>
</ol>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(c%5Cmathbf%20x)%20=%20c%20f(%5Cmathbf%20x)%0A"> These two properties together are what we mean when we say a function is linear.</p>
<p>Try to compare <img src="https://latex.codecogs.com/png.latex?y=2x"> for liniearity vs <img src="https://latex.codecogs.com/png.latex?y=2x%5E2"> for non-linearity and which one satisfies the linear properties?</p>
</div>
</div>
<p>Let’s consider the standard inner product of two vectors in <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%20R%5E2">, given by <img src="https://latex.codecogs.com/png.latex?%5Clangle%20%5Cmathbf%20x,%20%5Cmathbf%20y%5Crangle"> = <img src="https://latex.codecogs.com/png.latex?x_1y_1%20+%20x_2y_2">, where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20x%20=%20%5Bx_1,%20x_2%5D%5ET"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20y%20=%20%5By_1,%20y_2%5D%5ET">.</p>
<ol type="1">
<li>Linearity in the first argument:</li>
</ol>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clangle%202%20%5Cmathbf%20x%20+%203%5Cmathbf%20y,%20%5Cmathbf%20z%5Crangle%20=%20(2x_1%20+%203y_1)z_1%20+%20(2x_2%20+%203y_2)z_2%20=%202%5Clangle%20%5Cmathbf%20x,%20%5Cmathbf%20z%20%5Crangle%20+%203%5Clangle%20%5Cmathbf%20y,%20%5Cmathbf%20z%20%5Crangle%0A"></p>
<ol start="2" type="1">
<li>Conjugate linearity in the second argument:</li>
</ol>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clangle%20%5Cmathbf%20x,%202%5Cmathbf%20y+3%5Cmathbf%20z%5Crangle%20=%20x_1(2y_1%20+%203z_1)%20+%20x_2(2y_2%20+%203z_2)%20=%202%5Clangle%20%5Cmathbf%20x,%20%5Cmathbf%20y%20%5Crangle%20+%203%5Clangle%20%5Cmathbf%20x,%20%5Cmathbf%20z%20%5Crangle%0A"></p>
<ol start="3" type="1">
<li>Symmetry:</li>
</ol>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clangle%20%5Cmathbf%20x,%5Cmathbf%20y%5Crangle%20=%20x_1y_1%20+%20x_2y_2%20=%20y_1x_1%20+%20y_2x_2%20=%20%5Clangle%20%5Cmathbf%20y,%20%5Cmathbf%20x%20%5Crangle%0A"></p>
<ol start="4" type="1">
<li>Positive-definite:</li>
</ol>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clangle%20%5Cmathbf%20x,%5Cmathbf%20x%5Crangle%20=%20%20x_1%5E2%20+%20x_2%5E2%20%5Cge%200%20=%20%5Clangle%20%5Cmathbf%20x,%20%5Cmathbf%20x%20%5Crangle%20%5Ctext%7B%20only%20if%20%7D%20%5Cmathbf%20x%20=%20%5B0,%200%5D%5ET%0A"></p>
<p>Let’s see another example of two complex vectors for <em>2. Conjugate linearity in the second argument</em>, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D=%5Cbegin%7Bbmatrix%7D%201+i%20%5C%5C%202%20%5Cend%7Bbmatrix%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D=%5Cbegin%7Bbmatrix%7D%203-2i%20%5C%5C%201%20%5Cend%7Bbmatrix%7D">.</p>
<p>Their inner product would be: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Clangle%20%5Cmathbf%7Bu%7D,%20%5Cmathbf%7Bv%7D%20%5Crangle%20&amp;=%20%5Cbegin%7Bbmatrix%7D%201+i%20%5C%5C%202%20%5Cend%7Bbmatrix%7D%5EH%20%5Cbegin%7Bbmatrix%7D%203-2i%20%5C%5C%201%20%5Cend%7Bbmatrix%7D%20%5C%5C%0A&amp;=%20%5Cbegin%7Bbmatrix%7D%201-i%20&amp;%202%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%203-2i%20%5C%5C%201%20%5Cend%7Bbmatrix%7D%20%5C%5C%0A&amp;=%20(1-i)(3-2i)%20+%202(1)%20%5C%5C%0A&amp;=%201%20+%20i%20+%206%20-%204i%20+%202%20%5C%5C%0A&amp;=%209%20-%203i.%0A%5Cend%7Baligned%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?H"> is the Hermitian transpose, also known as the conjugate transpose, which is similar to the transpose operation, but also involves taking the complex conjugate of each element. For a matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">, the Hermitian transpose is denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A%5EH"> or <img src="https://latex.codecogs.com/png.latex?A%5E%5Cdagger"> and is defined as the transpose of the complex conjugate of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">. Mathematically, for a matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> with elements <img src="https://latex.codecogs.com/png.latex?a_%7Bi,j%7D">, the Hermitian transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A%5EH"> is defined as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(%5Cmathbf%20A%5EH)_%7Bi,j%7D%20=%20%5Coverline%7Ba_%7Bj,i%7D%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Coverline%7Ba_%7Bj,i%7D%7D"> denotes the complex conjugate of <img src="https://latex.codecogs.com/png.latex?a_%7Bj,i%7D">.</p>
<p>In the case of a real-valued matrix, the Hermitian transpose reduces to the ordinary transpose, denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A%5ET">.</p>
<p>Now let’s see the conjugate linearity property in the second argument:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Clangle%20%5Cmathbf%7Bu%7D,%20c%20%5Cmathbf%7Bv%7D%20%5Crangle%20&amp;=%20%5Cbegin%7Bbmatrix%7D%201+i%20%5C%5C2%20%5Cend%7Bbmatrix%7D%5EH%20%5Cleft(c%20%5Cbegin%7Bbmatrix%7D%203-2i%20%5C%5C%201%20%5Cend%7Bbmatrix%7D%5Cright)%20%5C%5C%0A&amp;=%20%5Cbegin%7Bbmatrix%7D%201-i%20&amp;%202%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%203c-2ci%20%5C%5C%20c%20%5Cend%7Bbmatrix%7D%20%5C%5C%0A&amp;=%20(1-i)(3c-2ci)%20+%202(c)%20%5C%5C%0A&amp;=%203c%20-%202ci%20+%202c%20-%202ci%20%5C%5C%0A&amp;=%20(3+2)c%20-%204ci%20%5C%5C%0A&amp;=%20c(3+2i)%20-%204i%5Coverline%7Bc%7D.%0A%5Cend%7Baligned%7D%0A"></p>
<p>We can see that the second component of the result is <img src="https://latex.codecogs.com/png.latex?-4i%5Coverline%7Bc%7D">, which is the conjugate of <img src="https://latex.codecogs.com/png.latex?4ic">. Therefore, we can say that the inner product is conjugate linear in the second argument.</p>
<p>A dot product is a specific type of inner product that is defined for Euclidean spaces, which are spaces with a notion of distance or length. The dot product of two vectors is defined as the sum of the products of their corresponding components. In other words, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20a%20=%20%5Ba_1,%20a_2,%20...,%20a_n%5D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20b%20=%20%5Bb_1,%20b_2,%20...,%20b_n%5D"> are two vectors in <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%20R%5En">, then their dot product is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20a%20%5Ccdot%20%5Cmathbf%20b%20=%20a_1b_1%20+%20a_2b_2%20+%20...%20+%20a_nb_n%0A"></p>
<p>The dot product satisfies some of the properties of an inner product, such as being linear in the first argument and symmetric. However, it is not conjugate linear in the second argument, and it is not positive-definite in general.</p>
<p>So, while a dot product is a specific type of inner product, not all inner products are dot products.</p>
</div>
</div>
<p>For example, if <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Ba%7D%20=%20%5B1,%202,%203%5D"> and <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bb%7D%20=%20%5B4,%205,%206%5D">, then their dot product <img src="https://latex.codecogs.com/png.latex?c%20=%201%5Ccdot%204%20+%202%5Ccdot%205%20+%203%5Ccdot%206%20=%2032">.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Norm
</div>
</div>
<div class="callout-body-container callout-body">
<p>The norm of a vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> is a non-negative scalar value that represents <strong>the size or length</strong> of the vector. The norm is denoted by <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Cmathbf%7Bx%7D%7C%7C"> and satisfies the following properties:</p>
<ul>
<li>Non-negativity: <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Cmathbf%7Bx%7D%7C%7C%5Cgeq%200">, with equality if and only if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D">.</li>
<li>Homogeneity: <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Calpha%5Cmathbf%7Bx%7D%7C%7C=%7C%5Calpha%7C%20%5Ctext%7B%20%7D%7C%7C%5Cmathbf%7Bx%7D%7C%7C"> for any scalar <img src="https://latex.codecogs.com/png.latex?%5Calpha">.</li>
<li>Triangle Inequality: <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Cmathbf%7Bx%7D+%5Cmathbf%7By%7D%7C%7C%5Cleq%20%7C%7C%5Cmathbf%7Bx%7D%7C%7C+%7C%7C%5Cmathbf%7By%7D%7C%7C">.</li>
</ul>
<p>Here is an example of finding the Euclidean norm of a vector: Suppose we have a vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cbegin%7Bbmatrix%7D1%20%5C%5C%20-2%20%5C%5C%202%5Cend%7Bbmatrix%7D">. We can find its norm as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%7C%5Cmathbf%20x%7C%7C=%5Csqrt%7B1%5E2+(-2)%5E2+2%5E2%7D=%5Csqrt%7B9%7D=3%0A"></p>
<p>Therefore, the norm of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> is 3.</p>
<p>There are several types of norms:</p>
<ul>
<li><p>Manhattan Norm or Absolute Norm or <img src="https://latex.codecogs.com/png.latex?l_1">-norm <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%7C%7C%5Cmathbf%7Bx%7D%7C%7C_%7Bl_1%7D%20=%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20%7Cx_i%7C%0A%5Cend%7Bequation*%7D%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> is a vector of length <img src="https://latex.codecogs.com/png.latex?n">. Example: For <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20%5B1,%20-2,%203%5D">, <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Cmathbf%7Bx%7D%7C%7C_%7Bl_1%7D%20=%20%7C1%7C%20+%20%7C-2%7C%20+%20%7C3%7C%20=%206">.</p></li>
<li><p>Euclidean Norm or <img src="https://latex.codecogs.com/png.latex?l_2">-norm <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%7C%7C%5Cmathbf%7Bx%7D%7C%7C_%7Bl_2%7D%20=%20%5Csqrt%7B%5Csum_%7Bi=1%7D%5E%7Bn%7D%20x_i%5E2%7D%0A%5Cend%7Bequation*%7D%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> is a vector of length <img src="https://latex.codecogs.com/png.latex?n">. Example: For <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20%5B1,%202,%203%5D">, <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Cmathbf%7Bx%7D%7C%7C_%7Bl_2%7D%20=%20%5Csqrt%7B1%5E2%20+%202%5E2%20+%203%5E2%7D%20=%20%5Csqrt%7B14%7D">.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_05.PNG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption"><img src="https://latex.codecogs.com/png.latex?l_2">-norm</figcaption><p></p>
</figure>
</div>
<ul>
<li>p-norm(<img src="https://latex.codecogs.com/png.latex?l_2">-norm)</li>
</ul>
<p>For <img src="https://latex.codecogs.com/png.latex?p%20%5Cgeq%201">, <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%7C%7C%5Cmathbf%7Bx%7D%7C%7C_p%20=%20(%5Csum_%7Bi=1%7D%5En%20%7Cx_i%7C%5Ep)%5E%7B%5Cfrac%7B1%7D%7Bp%7D%7D%0A%5Cend%7Bequation*%7D%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> is a vector of length <img src="https://latex.codecogs.com/png.latex?n">. Example: For <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20%5B1,%202,%203%5D">, <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Cmathbf%7Bx%7D%7C%7C_%7Bl_p%7D%20=%20%5Csqrt%7B1%5Ep%20+%202%5Ep%20+%203%5Ep%7D">.</p>
<ul>
<li>Maximum Norm <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%7C%7C%5Cmathbf%7Bx%7D%7C%7C_%7B%5Cinfty%7D%20=%20%5Cmax_%7B1%20%5Cleq%20i%20%5Cleq%20n%7D%20%7Cx_i%7C%0A%5Cend%7Bequation*%7D%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> is a vector of length <img src="https://latex.codecogs.com/png.latex?n">. Example: For <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20%5B1,%20-2,%203%5D">, <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Cmathbf%7Bx%7D%7C%7C_%7B%5Cinfty%7D%20=%20%5Cmax%7B(1,%20%7C-2%7C,%203)%7D%20=%203">.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_06.PNG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption"><img src="https://latex.codecogs.com/png.latex?l_1">-norm vs <img src="https://latex.codecogs.com/png.latex?l_2">-norm vs <img src="https://latex.codecogs.com/png.latex?%5Cmax">-norm</figcaption><p></p>
</figure>
</div>
<ul>
<li>Frobenius Norm: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%7C%7C%5Cmathbf%7Ba%7D%7C%7C_%7BF%7D%20=%20%5Csqrt%7B%5Csum_%7Bi=1%7D%5E%7Bm%7D%20%5Csum_%7Bj=1%7D%5E%7Bn%7D%20%7Ca_%7Bij%7D%7C%5E2%7D%0A%5Cend%7Bequation*%7D%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix. Example: For <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20%5C%5C%203%20&amp;%204%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Cmathbf%7BA%7D%7C%7C_%7BF%7D%20=%20%5Csqrt%7B1%5E2%20+%202%5E2%20+%203%5E2%20+%204%5E2%7D%20=%20%5Csqrt%7B30%7D">.</li>
</ul>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Projection
</div>
</div>
<div class="callout-body-container callout-body">
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> be two vectors. The projection of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> onto <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> is defined as the vector:</p>
<p>This vector is the closest vector to <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> that lies on the line spanned by <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D">. <img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bproj%7D_%7B%5Cmathbf%20v%7D%5Cmathbf%20u%20=%5Cfrac%7B%5Cmathbf%20u%20%5Cmathbf%20v%7D%7B%7C%7C%5Cmathbf%20v%7C%7C%5E2%7D%20%5Cmathbf%20v%0A"> <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_04.PNG" class="img-fluid" alt="Projection"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D%20=%20%7C%7C%5Cmathbf%7Bw%7D%7C%7C%5Cmathbf%7Bv%7D%20=%20%7C%7C%5Cmathbf%7Bu%7D%7C%7C%20%5Ccos%20%5Ctheta%20%5Cmathbf%7Bv%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D%5ET%20%5Cmathbf%7Bu%7D%20=%20%7C%7C%5Cmathbf%7Bu%7D%7C%7C%20%7C%7C%5Cmathbf%7Bu%7D%7C%7C%20=%20%7C%7C%5Cmathbf%7Bu%7D%7C%7C%5E2"></li>
<li>the magnitude of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> = <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Cmathbf%7Bu%7D%7C%7C%20=%20%5Csqrt%7B%5Cmathbf%7Bu%7D%5ET%20%5Cmathbf%7Bu%7D%7D"></li>
<li>unit vector: a normalized vector by dividing it by its magnitude, so the magnitude of a unit vector is 1 <img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Cmathbf%7Bu%7D%7D%20=%20%5Cfrac%7B%5Cmathbf%7Bu%7D%7D%7B%7C%7C%5Cmathbf%7Bu%7D%7C%7C%7D%20=%20%5Cfrac%7B%5Cmathbf%7Bu%7D%7D%7B%5Csqrt%7B%5Cmathbf%7Bu%7D%5ET%20%5Cmathbf%7Bu%7D%7D%7D%0A"></li>
<li>Projected vector, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D">
<ul>
<li>the product of <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Cmathbf%7Bu%7D%5ET%20%5Cmathbf%7Bv%7D%7D%7B%7C%7C%5Cmathbf%7Bv%7D%7C%7C%7D"> and a unit vector of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> <img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cmathbf%7Bu%7D%5ET%20%5Cmathbf%7Bv%7D%7D%7B%7C%7C%5Cmathbf%7Bv%7D%7C%7C%7D%20%5Cfrac%7B%5Cmathbf%7Bv%7D%7D%7B%7C%7C%5Cmathbf%7Bv%7D%7C%7C%7D%20=%20%5Cfrac%7B%5Cmathbf%7Bu%7D%5ET%20%5Cmathbf%7Bv%7D%7D%7B%7C%7C%5Cmathbf%7Bv%7D%7C%7C%5E2%7D%5Cmathbf%7Bv%7D%0A"></li>
</ul></li>
</ul>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D%20=%20%5Cbegin%7Bbmatrix%7D2%20%5C%203%5Cend%7Bbmatrix%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D%20=%20%5Cbegin%7Bbmatrix%7D1%20%5C%5C%201%5Cend%7Bbmatrix%7D">. Then, the projection of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> onto <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bproj%7D_%7B%5Cmathbf%20v%7D%5Cmathbf%20u%20=%5Cfrac%7B%5Cmathbf%20u%20%5Cmathbf%20v%7D%7B%7C%7C%5Cmathbf%20v%7C%7C%5E2%7D%20%5Cmathbf%20v%20=%5Cfrac%7B%5Cbegin%7Bbmatrix%7D2%20%5C%5C%203%5Cend%7Bbmatrix%7D%5Cbegin%7Bbmatrix%7D1%20%5C%5C%201%5Cend%7Bbmatrix%7D%7D%7B%5Cbigg%7B%7C%7D%5Cbigg%7B%7C%7D%5Cbegin%7Bbmatrix%7D1%20%5C%5C%201%5Cend%7Bbmatrix%7D%5Cbigg%7B%7C%7D%5Cbigg%7B%7C%7D%5E2%7D=%5Cfrac%7B5%7D%7B2%7D%5Cbegin%7Bbmatrix%7D1%20%5C%5C%201%5Cend%7Bbmatrix%7D=%5Cbegin%7Bbmatrix%7D5%20%5C%5C%202%5Cend%7Bbmatrix%7D%0A"></p>
<p>This vector is the closest vector to <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> that lies on the line spanned by <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D%20=%20%5Cbegin%7Bbmatrix%7D1%20%5C%5C%201%5Cend%7Bbmatrix%7D">.</p>
<p><a href="http://immersivemath.com/ila/ch03_dotproduct/ch03.html#auto_label_107">Reference: Read This Article with Interactive Visualization - Projection</a></p>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Cauchy-Schwarz Inequality
</div>
</div>
<div class="callout-body-container callout-body">
<p>a fundamental result in mathematics that relates to inner products and norms. It states that for any vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> in an inner product space, the following inequality holds: <img src="https://latex.codecogs.com/png.latex?%0A%20%20%7C%5Clangle%20%5Cmathbf%20u,%5Cmathbf%20v%5Crangle%7C%5Cle%20%7C%7C%5Cmathbf%20u%7C%7C%20%7C%7C%5Cmathbf%20v%20%7C%7C%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Clangle%20%5Cmathbf%7Bu%7D,%20%5Cmathbf%7Bv%7D%5Crangle"> denotes the inner product of vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D">, and <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7Bu%7D%7C"> and <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7Bv%7D%7C"> denote their respective norms. In terms of the cosine formula, the Schwarz inequality can be written as: <img src="https://latex.codecogs.com/png.latex?%0A%5Ccos%20%5Ctheta%20%5Cle%201%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> is the angle between vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D">, and <img src="https://latex.codecogs.com/png.latex?%5Ccos%7B%5Ctheta%7D%20=%20%5Cfrac%7B%5Clangle%20%5Cmathbf%7Bu%7D,%20%5Cmathbf%7Bv%7D%5Crangle%7D%7B%7C%5Cmathbf%7Bu%7D%7C%20%7C%5Cmathbf%7Bv%7D%7C%7D">.</p>
<p>Geometrically, the Schwarz inequality states that the magnitude of the projection of one vector onto the other cannot exceed the length of the vector being projected. In other words, it bounds the correlation between two vectors and ensures that their inner product is always less than or equal to the product of their norms.</p>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Triangle Inequality
</div>
</div>
<div class="callout-body-container callout-body">
<p>The triangle inequality states that for any two vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D">, the length of the sum of the vectors is less than or equal to the sum of the lengths of the vectors themselves. In terms of the cosine formula, this can be expressed as: <img src="https://latex.codecogs.com/png.latex?%0A%7C%7C%5Cmathbf%20u%20+%20%5Cmathbf%20v%7C%7C%5E2%20%5Cle%20%7C%7C%5Cmathbf%20u%7C%7C%5E2%20+%202%7C%7C%5Cmathbf%20u%20%7C%7C%7C%7C%5Cmathbf%20v%20%7C%7C%20+%20%7C%7C%5Cmathbf%20v%20%7C%7C%5E2%0A"></p>
<p>equivalently,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%7C%5Cmathbf%20u%20+%20%5Cmathbf%20v%7C%7C%20%5Cle%20%7C%7C%5Cmathbf%20u%7C%7C%20+%20%7C%7C%5Cmathbf%20v%20%7C%7C%0A"></p>
<p>this inequality means that the distance between two points in a space, represented by vectors, is always shorter than or equal to the sum of the distances between the two vectors. In other words, it is impossible to make a straight line from one point to another that is shorter than the distance represented by the two vectors.</p>
<div class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/01.basic_vector_files/figure-html/cell-3-output-1.png" width="592" height="434"></p>
</div>
</div>
</div>
</div>
</section>
<section id="unit-vector" class="level3" data-number="1.3.5">
<h3 data-number="1.3.5" class="anchored" data-anchor-id="unit-vector"><span class="header-section-number">1.3.5</span> Unit Vector</h3>
<p>A unit vector is a vector that has a magnitude of 1. A unit vector can be obtained by dividing a non-zero vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> by its magnitude <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Cmathbf%7Bv%7D%7C%7C">,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%20%20%5Cmathbf%7B%5Chat%7Bv%7D%7D%20=%20%5Cfrac%7B%5Cmathbf%7Bv%7D%7D%7B%7C%7C%5Cmathbf%7Bv%7D%7C%7C%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5Chat%7Bv%7D%7D"> is the unit vector in the direction of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D">.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20%5C%202%20%5Cend%7Bbmatrix%7D"> be a non-zero vector in <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E2">. The magnitude of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> is <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Cmathbf%7Bv%7D%7C%7C%20=%20%5Csqrt%7B1%5E2%20+%202%5E2%7D%20=%20%5Csqrt%7B5%7D">. Therefore, a unit vector in the direction of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7B%5Chat%7Bv%7D%7D%20=%20%5Cfrac%7B%5Cmathbf%7Bv%7D%7D%7B%7C%7C%5Cmathbf%7Bv%7D%7C%7C%7D%20=%20%5Cfrac%7B1%7D%7B%5Csqrt%7B5%7D%7D%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%202%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cfrac%7B1%7D%7B%5Csqrt%7B5%7D%7D%20%5C%5C%20%5Cfrac%7B2%7D%7B%5Csqrt%7B5%7D%7D%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>Thus, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%20%5Cfrac%7B1%7D%7B%5Csqrt%7B5%7D%7D%20%5C%5C%20%5Cfrac%7B2%7D%7B%5Csqrt%7B5%7D%7D%20%5Cend%7Bbmatrix%7D"> is a unit vector in the direction of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D">.</p>
</section>
<section id="cross-product-of-vectors" class="level3" data-number="1.3.6">
<h3 data-number="1.3.6" class="anchored" data-anchor-id="cross-product-of-vectors"><span class="header-section-number">1.3.6</span> Cross Product of Vectors</h3>
<p>The cross product of two vectors is a vector that is perpendicular to both of them. If <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Ba%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bb%7D"> are two vectors in <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E3">, then their cross product <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bc%7D%20=%20%5Ctextbf%7Ba%7D%20%5Ctimes%20%5Ctextbf%7Bb%7D"> is a vector given by the formula</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctextbf%7Bc%7D%20=%20%5Ctextbf%7Ba%7D%20%5Ctimes%20%5Ctextbf%7Bb%7D%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20=%20%7C%7C%5Ctextbf%7Ba%7D%7C%7C%20%7C%7C%5Ctextbf%7Bb%7D%7C%7C%5Csin(%5Ctheta)%20%5Cmathbf%20n%20%20%20%20%20%20%20%20%20%20%20%0A"></p>
<p>where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctheta"> is the angle between <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Ba%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bb%7D"> in the plane containing them (hence, it <img src="https://latex.codecogs.com/png.latex?0%20%5Cle%20%5Ctheta%20%5Cle%20%5Cpi">)</li>
<li><img src="https://latex.codecogs.com/png.latex?%7C%7C%5Ctextbf%7Ba%7D%7C%7C"> and <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Ctextbf%7Bb%7D%7C%7C"> are the magnitudes of vectors <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Ctextbf%7Ba%7D%7C%7C"> and <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Ctextbf%7Bb%7D%7C%7C"></li>
<li>and <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Ctextbf%7Bn%7D%7C%7C"> is a unit vector perpendicular to the plane containing <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Ctextbf%7Ba%7D%7C%7C"> and <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Ctextbf%7Ba%7D%7C%7C">, with direction such that the ordered set (<img src="https://latex.codecogs.com/png.latex?%7C%7C%5Ctextbf%7Ba%7D%7C%7C">, <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Ctextbf%7Bb%7D%7C%7C">, <img src="https://latex.codecogs.com/png.latex?%7C%7C%5Ctextbf%7Bn%7D%7C%7C">) is positively-oriented.</li>
</ul>
<p>If the vectors <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Ba%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bb%7D"> are parallel (that is, <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> between them is either <img src="https://latex.codecogs.com/png.latex?0"> or <img src="https://latex.codecogs.com/png.latex?%5Cpi">), by the above formula, the cross product of <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Ba%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bb%7D"> is the zero vector 0.</p>
<p><a href="https://en.wikipedia.org/wiki/Cross_product">Reference: read the explanations in wiki</a></p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/Cross_product_vector.svg.png" class="img-fluid" alt="By User:Acdx - Self-made, based on Image:Crossproduct.png, Public Domain"> <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/Right_hand_rule_cross_product.svg" class="img-fluid" alt="Right_hand_rule_cross_product"></p>
</div>
</div>
</div>
<p>For example, <img src="https://latex.codecogs.com/png.latex?%0A%5Ctextbf%7Bc%7D%20=%20%5Ctextbf%7Ba%7D%20%5Ctimes%20%5Ctextbf%7Bb%7D%20=%20%5Ba_2b_3%20-%20a_3b_2,%20a_3b_1%20-%20a_1b_3,%20a_1b_2%20-%20a_2b_1%5D%20%20%20%20%20%20%20%20%20%20%20%0A"></p>
<p>If <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Ba%7D%20=%20%5B1,%202,%203%5D"> and <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bb%7D%20=%20%5B4,%205,%206%5D">, then their cross product <img src="https://latex.codecogs.com/png.latex?%5Ctextbf%7Bc%7D%20=%20%5B-3,%206,%20-3%5D">.</p>
</section>
<section id="column-vector-row-vector" class="level3" data-number="1.3.7">
<h3 data-number="1.3.7" class="anchored" data-anchor-id="column-vector-row-vector"><span class="header-section-number">1.3.7</span> Column Vector &amp; Row Vector</h3>
<p>A column vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> with <img src="https://latex.codecogs.com/png.latex?n"> elements is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%201"> matrix, which can be represented as: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7Bu%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0Au_%7B1%7D%20%5C%5C%0Au_%7B2%7D%20%5C%5C%0A%5Cvdots%20%5C%5C%0Au_%7Bm%7D%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>In an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix, the column vectors can be represented as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20U%20%20=%20%5Cbegin%7Bbmatrix%7D%20%20%5Cmathbf%20u_%7B1%7D%20&amp;%5Cmathbf%20u_%7B2%7D%20&amp;%20%5Cdots%20&amp;%5Cmathbf%20u_%7Bn%7D%20%5Cend%7Bbmatrix%7D%20%5C%5C%0A=%0A%5Cbegin%7Bbmatrix%7D%0A%20%20u_%7B11%7D%20&amp;%20u_%7B12%7D%20&amp;%20%5Ccdots%20&amp;%20u_%7B1n%7D%20%5C%5C%0A%20%20u_%7B21%7D%20&amp;%20u_%7B22%7D%20&amp;%20%5Ccdots%20&amp;%20u_%7B2n%7D%20%5C%5C%0A%20%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20u_%7Bm1%7D%20&amp;%20u_%7Bm2%7D%20&amp;%20%5Ccdots%20&amp;%20u_%7Bmn%7D%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?u_i"> is the <img src="https://latex.codecogs.com/png.latex?i">-th element of the column vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D">, <img src="https://latex.codecogs.com/png.latex?n"> is the number of columns, and <img src="https://latex.codecogs.com/png.latex?m"> is the number of rows in the matrices.</p>
<p>A row vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> with <img src="https://latex.codecogs.com/png.latex?m"> elements is a <img src="https://latex.codecogs.com/png.latex?1%20%5Ctimes%20n"> matrix, which can be represented as: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7Bu%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0Au_%7B1%7D%20&amp;%20u_%7B2%7D%20&amp;%20%5Ccdots%20&amp;%20u_%7Bm%7D%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>In an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix, the row vectors can be represented as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20U%20%20=%20%5Cbegin%7Bbmatrix%7D%20%20%5Cmathbf%20u_%7B1%7D%20%5C%5C%5Cmathbf%20u_%7B2%7D%20%5C%5C%20%5Cvdots%20%5C%5C%5Cmathbf%20u_%7Bm%7D%20%5Cend%7Bbmatrix%7D%20%5C%5C%0A=%0A%5Cbegin%7Bbmatrix%7D%0A%20%20u_%7B11%7D%20&amp;%20u_%7B12%7D%20&amp;%20%5Ccdots%20&amp;%20u_%7B1n%7D%20%5C%5C%0A%20%20u_%7B21%7D%20&amp;%20u_%7B22%7D%20&amp;%20%5Ccdots%20&amp;%20u_%7B2n%7D%20%5C%5C%0A%20%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20u_%7Bm1%7D%20&amp;%20u_%7Bm2%7D%20&amp;%20%5Ccdots%20&amp;%20u_%7Bmn%7D%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?u_i"> is the <img src="https://latex.codecogs.com/png.latex?i">-th element of the row vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> and <img src="https://latex.codecogs.com/png.latex?n"> is the number of columns in the matrix.</p>
</section>
<section id="linear-combination-of-vectors" class="level3" data-number="1.3.8">
<h3 data-number="1.3.8" class="anchored" data-anchor-id="linear-combination-of-vectors"><span class="header-section-number">1.3.8</span> Linear Combination of vectors</h3>
<p>A linear combination of vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_1,%5Cmathbf%7Bv%7D_2,%5Cdots,%5Cmathbf%7Bv%7D_n"> in a vector space <img src="https://latex.codecogs.com/png.latex?V"> over a field <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BF%7D"> is a vector of the form: <img src="https://latex.codecogs.com/png.latex?%0Aa_1%5Cmathbf%7Bv_1%7D+a_2%5Cmathbf%7Bv_2%7D+%5Cdots+a_n%5Cmathbf%7Bv_n%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_1,a_2,%5Cdots,a_n%5Cin%5Cmathbb%7BF%7D">.</p>
<p>For example, suppose we have two vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_1=%5Cbegin%7Bbmatrix%7D%201%20%5C%202%20%5C%203%20%5Cend%7Bbmatrix%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_2=%5Cbegin%7Bbmatrix%7D%204%20%5C%205%20%5C%206%20%5Cend%7Bbmatrix%7D"> in <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E3">. Then, a linear combination of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_1"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_2"> is of the form:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aa_1%5Cbegin%7Bbmatrix%7D1%5C%5C2%5C%5C3%5Cend%7Bbmatrix%7D+a_2%5Cbegin%7Bbmatrix%7D4%5C%5C5%5C%5C6%5Cend%7Bbmatrix%7D=%5Cbegin%7Bbmatrix%7Da_1+4a_2%5C%5C2a_1+5a_2%5C%5C3a_1+6a_2%5Cend%7Bbmatrix%7D%0A"></p>
<p>Here, <img src="https://latex.codecogs.com/png.latex?a_1"> and <img src="https://latex.codecogs.com/png.latex?a_2"> are scalar coefficients that determine the resulting linear combination vector.</p>
</section>
<section id="outer-product" class="level3" data-number="1.3.9">
<h3 data-number="1.3.9" class="anchored" data-anchor-id="outer-product"><span class="header-section-number">1.3.9</span> Outer Product</h3>
<p>The outer product of two vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D%20=%20%5Bu_1,%20u_2,%20%5Cdots,%20u_m%5D%5ET"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D%20=%20%5Bv_1,%20v_2,%20%5Cdots,%20v_n%5D%5ET"> is a matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D%20%5Cmathbf%7Bv%7D%5ET"> of size <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n">, defined by:</p>
$$
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Baligned%7D%0A%5Cmathbf%7Bu%7D%20%5Cotimes%20%5Cmathbf%7Bv%7D%20&amp;=%0A%5Cbegin%7Bbmatrix%7D%0Au_1v_1%20&amp;u_1v_2&amp;%20%5Cdots%20&amp;%20u_1v_n%20%5C%5C%0Au_2v_1%20&amp;u_2v_2&amp;%20%5Cdots%20&amp;%20u_2v_n%20%5C%5C%0A%5Cvdots%20&amp;%5Cvdots&amp;%20%5Cddots%20&amp;%20u_1v_n%20%5C%5C%0Au_mv_1%20&amp;u_mv_2&amp;%20%5Cdots%20&amp;%20u_mv_n%20%5C%5C%0A%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Baligned%7D">
<p>$$</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(%5Cmathbf%7Bu%7D%20%5Cotimes%20%5Cmathbf%7Bv%7D)_%7Bi,j%7D%20=%20u_i%20v_j%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D%20=%20%5Bu_1,%20u_2,%20%5Cdots,%20u_m%5D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D%20=%20%5Bv_1,%20v_2,%20%5Cdots,%20v_n%5D">.</p>
<p>The outer product is also called the tensor product, and it is a type of binary operation between two vectors that results in a matrix. It is important in linear algebra and other fields such as physics and engineering.</p>
<p>Here is an example: Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D%20=%20%5B2,%204,%206%5D%5ET"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D%20=%20%5B1,%203%5D%5ET">. The outer product of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> is:</p>
<p>So the outer product of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> is a <img src="https://latex.codecogs.com/png.latex?3%20%5Ctimes%202"> matrix.</p>
<p><a href="../../../../../docs/blog/posts/Mathmatics/linear_algebra/02.basic_matrix.html">What is a matrix? Go to the Next Blog</a></p>


</section>
</section>
</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/01.basic_vector.html</guid>
  <pubDate>Wed, 29 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_01.PNG" medium="image"/>
</item>
<item>
  <title>Maximum Likelihood Estimation, Statistical Bias, and Point Estimation</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/statistics/2023-03-25_MLE/index.html</link>
  <description><![CDATA[ 



<section id="definition" class="level3" data-number="0.1">
<h3 data-number="0.1" class="anchored" data-anchor-id="definition"><span class="header-section-number">0.1</span> Definition</h3>
<p>To talk about MLE (Maximum Likelihood Estimation), we need to recap the concepts and definitions of probability and likelihood. They are related but distinct concepts.</p>
<ul>
<li>probability is a measure of the chance that an event will occur, given some prior knowledge or assumptions.</li>
<li>likelihood is a measure of the plausibility or compatibility of a particular set of model parameters, given the observed data.</li>
</ul>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Chance vs Plausibility (personal opinion)
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>chance is a general term but closer term to statistics, which is used in the situation of the probability or likelihood of an event occurring based on randomness or uncertainty.<br>
</li>
<li>plausibility chance is a term more often used in everyday life, which refers to the degree to which something is believable based on the available evidence or information.</li>
</ul>
</div>
</div>
<div id="def-likelihood" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 </strong></span>Let <img src="https://latex.codecogs.com/png.latex?X_1,%20X_2,%20...,%20X_n"> be a set of iid random variables with pdf or pmf <img src="https://latex.codecogs.com/png.latex?f(x_i%20%7C%20%5Ctheta)">, where <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> is a vector of unknown parameters. Then, <strong>the likelihood function is defined as the joint pdf or pmf of the observed data, given the values of the parameters</strong>:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AL(%5Ctheta%20%7C%20x_1,%20x_2,%20...,%20x_n)%20=%20L(%5Ctheta%20%7C%20%5Cmathbf%20x)%20=%20%5Cprod_%7Bi=1%7D%5En%20f(x_i%20%7C%20%5Ctheta)%0A"></p>
</div>
<p>The likelihood function is a function of the parameters <img src="https://latex.codecogs.com/png.latex?%5Ctheta">. The function measures the probability of observing a set of data, given the values of the parameters of a statistical model in order to estimate the values of the parameters by finding the values that maximize the likelihood function. The likelihood function is often used in the maximum likelihood estimation (MLE) method, where the MLE estimator is the set of parameter values that maximize the likelihood function.</p>
<p>The likelihood function is related to the concept of conditional probability. Given a set of observed data <img src="https://latex.codecogs.com/png.latex?x_1,%20x_2,%20...,%20x_n">, the likelihood function measures the probability of observing these data, assuming a particular set of parameter values. The likelihood function is not a probability distribution, but it can be used to derive a probability distribution for the parameters, known as the posterior distribution, using Bayes’ theorem.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Probability
</div>
</div>
<div class="callout-body-container callout-body">
<p>Probability is a measure of the likelihood or chance that an event will occur, which is used to quantify uncertainty and randomness.<br>
probability is a function that maps a real number mapped from a random variable into <img src="https://latex.codecogs.com/png.latex?%5B0,1%5D">. The probability function, denoted by <img src="https://latex.codecogs.com/png.latex?P">, satisfies the following axioms:</p>
<ul>
<li>Non-negativity: For any event <img src="https://latex.codecogs.com/png.latex?A%20%5Cin%20%5COmega">, <img src="https://latex.codecogs.com/png.latex?P(A)%20%5Cgeq%200">.</li>
<li>Normalization: The probability of the entire sample space is 1, i.e., <img src="https://latex.codecogs.com/png.latex?P(%5COmega)%20=%201">.</li>
<li>Additivity: For any two disjoint events <img src="https://latex.codecogs.com/png.latex?A,%20B%20%5Cin%20%5COmega">, or <img src="https://latex.codecogs.com/png.latex?A%20%5Ccap%20B%20=%20%5Cemptyset">, the probability of their union is equal to the sum of their individual probabilities, i.e., <img src="https://latex.codecogs.com/png.latex?P(A%20%5Ccup%20B)%20=%20P(A)%20+%20P(B)">.</li>
</ul>
</div>
</div>
<section id="probability-vs-likelihood" class="level4" data-number="0.1.1">
<h4 data-number="0.1.1" class="anchored" data-anchor-id="probability-vs-likelihood"><span class="header-section-number">0.1.1</span> Probability vs Likelihood</h4>
<p>Probability and likelihood are related but distinct concepts in statistics.</p>
<ul>
<li>Probability refers to the measure of the likelihood that a particular event will occur, scaled on <img src="https://latex.codecogs.com/png.latex?%5B0,1%5D">. It is calculated based on a known probability distribution (= some prior knowledge or assumptions) before the data is observed.</li>
<li>On the other hand, likelihood refers to the probability of observing a set of data given a particular set of parameter values in a statistical model. It is calculated based on the unknown parameters after the data is observed.</li>
</ul>
<p>The likelihood function is used to estimate the values of the parameters by finding the parameter values that maximize the likelihood function.</p>
<p>For instance of a coin flip, the <strong>probability</strong> of getting heads on a coin flip is 0.5, regardless of whether the coin has been flipped or not (i.e., without data). In contrast, the <strong>likelihood</strong> of observing heads after a coin has been flipped depends on the parameter of interest. We need to find the parameter given data, the results of multiple coin flips.</p>
<p>If we want to estimate the probability of heads, we can use the maximum likelihood estimation (MLE) approach, which involves finding the value of the coin bias that maximizes the likelihood of observing the observed sequence of heads and tails. The likelihood of the data is calculated using the binomial distribution, which gives the probability of observing a certain number of heads, given the number of tosses and the coin bias. In this case, the likelihood function is a function of the coin bias, and the probability of heads is the value of the coin bias that maximizes the likelihood function.</p>
</section>
<section id="relation-between-likelihood-and-pmf-or-pdf" class="level4" data-number="0.1.2">
<h4 data-number="0.1.2" class="anchored" data-anchor-id="relation-between-likelihood-and-pmf-or-pdf"><span class="header-section-number">0.1.2</span> Relation between Likelihood and PMF or PDF</h4>
<p>The likelihood function is closely related to pmf or pdf of the data, which is a function that describes the probability of observing a particular value or range of values for the data, given the model parameters. The pmf or pdf is a function of the data, not the parameters, and is often written as <img src="https://latex.codecogs.com/png.latex?f(x%7C%5Ctheta)">. The likelihood function is proportional to the pdf because is a product of pdfs when <img src="https://latex.codecogs.com/png.latex?X_i"> is independent, but with the data fixed and the parameter values treated as variables.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;">library</span>(tidyverse)</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;"># Probability of getting heads on a fair coin flip</span></span>
<span id="cb1-4">prob <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fl" style="color: #AD0000;">0.5</span></span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;"># likelihood</span></span>
<span id="cb1-7"><span class="do" style="color: #5E5E5E;
font-style: italic;">## Simulate a coin flip with a biased coin</span></span>
<span id="cb1-8"><span class="fu" style="color: #4758AB;">set.seed</span>(<span class="dv" style="color: #AD0000;">123</span>) <span class="co" style="color: #5E5E5E;"># Set random seed for reproducibility</span></span>
<span id="cb1-9">n <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="dv" style="color: #AD0000;">100</span> <span class="co" style="color: #5E5E5E;"># flipping numbers</span></span>
<span id="cb1-10">p <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fl" style="color: #AD0000;">0.2</span> <span class="co" style="color: #5E5E5E;"># Probability of getting heads</span></span>
<span id="cb1-11">x <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">rbinom</span>(n, <span class="at" style="color: #657422;">size =</span> <span class="dv" style="color: #AD0000;">1</span>, <span class="at" style="color: #657422;">prob =</span> p) <span class="co" style="color: #5E5E5E;"># Simulate n coin flips</span></span>
<span id="cb1-12">x<span class="sc" style="color: #5E5E5E;">%&gt;%</span><span class="fu" style="color: #4758AB;">head</span>(<span class="dv" style="color: #AD0000;">10</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> [1] 0 0 0 1 1 0 0 1 0 0</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="do" style="color: #5E5E5E;
font-style: italic;">## Calculate the likelihood of observing the data given the parameter value p</span></span>
<span id="cb3-2">likelihood <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">prod</span>(<span class="fu" style="color: #4758AB;">dbinom</span>(x, <span class="at" style="color: #657422;">size =</span> <span class="dv" style="color: #AD0000;">1</span>, <span class="at" style="color: #657422;">prob =</span> p))</span>
<span id="cb3-3">likelihood<span class="sc" style="color: #5E5E5E;">%&gt;%</span><span class="fu" style="color: #4758AB;">round</span>()</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
</div>
<p>In this example, <code>prob</code> is the assumed probability of getting heads on a fair coin flip. The probability of getting heads on a fair coin flip is 0.5, which is a fixed value that does not depend on any specific data. On the other hand, <code>p</code> is the probability of getting heads for the biased coin that we are simulating. The likelihood of observing a set of coin flips depends on the parameter value, which is unknown (actually, we know that it was <img src="https://latex.codecogs.com/png.latex?p=0.2">), and the observed data. We simulate a set of 100 coin flips with a biased coin that has a probability of 0.2 of getting heads. We then calculate the likelihood of observing this data given the parameter value of 0.2, which is the product of the probability mass function for each flip.</p>
<p>However, in a real-world scenario, we would not know the true value of <code>p</code> and we would need to estimate it based on the observed data. By finding the Maximum Likelihood Estimation (MLE) of p, we are estimating the value of p that is most likely to have generated the observed data. To find MLE of <code>p</code> that maximizes the likelihood function, we can use numerical optimization methods.</p>
<p>As n increases, the product term in the likelihood function <img src="https://latex.codecogs.com/png.latex?%5Cprod_%7Bi=1%7D%5E%7Bn%7D%20f(x_i;%20%5Ctheta)">, where <img src="https://latex.codecogs.com/png.latex?f"> is the pdf or pmf of the distribution being used, can become very small (since it is a product of values less than 1) and may result in numerical underflow (i.e., the product becomes so small that it rounds down to 0 in computer calculations). In practice, we typically take the logarithm of the likelihood function, called the log-likelihood, to avoid this issue:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clog%20L(%5Ctheta%7Cx_1,%20x_2,%20...,%20x_n)%20=%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20%5Clog%20f(x_i;%20%5Ctheta)%0A"></p>
<p>Using the logarithm allows us to convert the product of small probabilities into a sum of log-probabilities, which are typically easier to work with numerically and mathematically. In this case, as n increases, the sum term in the log-likelihood can decrease (since it is a sum of negative values), but the decrease may not be as severe as in the product term of the likelihood function because of the log scale converting very small or large values into larger or smaller values .</p>
<div id="def-MLE" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2 </strong></span>The MLE estimator <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Ctheta%7D"> is the value of the parameter vector that maximizes the likelihood function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Ctheta%7D_%7BMLE%7D%20=%20%5Cunderset%7B%5Ctheta%7D%7B%5Coperatorname%7Bargmax%7D%7D%20L(%5Ctheta%20%7C%20x_1,%20x_2,%20...,%20x_n)%0A"></p>
<p>or equivalently, maximizes the log-likelihood function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Ctheta%7D_%7BMLE%7D%20=%20%5Cunderset%7B%5Ctheta%7D%7B%5Coperatorname%7Bargmax%7D%7D%20%5Clog%20L(%5Ctheta%20%7C%20x_1,%20x_2,%20...,%20x_n)%0A"></p>
</div>
<p>The Maximum Likelihood Estimation (MLE) is a method of estimating the parameters of a statistical model by finding the values of the parameters that maximize the likelihood function. The likelihood function is the probability of observing the data, given the parameters of the model. The MLE estimator is the set of parameter values that maximize the likelihood function. In other words, the MLE is the set of parameter values that make the observed data most probable, given the assumed probability distribution. The likelihood function is typically the product or the sum (depending on whether the observations are assumed to be independent or not) of the probabilities or probability densities of the observations, evaluated at the values of the parameters.</p>
<p>The MLE estimator has desirable statistical properties, such as consistency, efficiency, and asymptotic normality, under certain regularity conditions on the likelihood function and the parameter space. However, it is important to note that the MLE is not always the best estimator for a given problem, and other estimation methods may be more appropriate depending on the specific characteristics of the data and the model.</p>
<p>The likelihood function is the joint probability density (or mass) function of the data, viewed as a function of the parameters, and we find the maximum of this function <strong>by differentiating</strong> it with respect to the parameters and setting the derivative to zero.</p>
</section>
</section>
<section id="sec-mle_ols" class="level3" data-number="0.2">
<h3 data-number="0.2" class="anchored" data-anchor-id="sec-mle_ols"><span class="header-section-number">0.2</span> MLE of OLS</h3>
<p>In a linear regression, the maximum likelihood estimate of the ordinary least squares (OLS) coefficients is equivalent to the least squares estimate. To derive this, we assume that <img src="https://latex.codecogs.com/png.latex?%5Cepsilon_i%20%5Csim%20N(0,%5Csigma%5E2)"> and that the observations are independent. Then, the likelihood function for the data <img src="https://latex.codecogs.com/png.latex?Y%20=%20(Y_1,%20Y_2,%20%5Cdots,%20Y_n)"> is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AL(Y%7C%5Ctheta)%20=L(Y%7C%5Cbeta,%5Csigma%5E2)%20=%20(2%5Cpi%5Csigma%5E2)%5E%7B-%5Cfrac%7Bn%7D%7B2%7D%7D%20e%5E%7B-%5Cfrac%7B1%7D%7B2%5Csigma%5E2%7D%20%5Csum_%7Bi=1%7D%5En%20(Y_i%20-%20X_i%5Cbeta)%5E2%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?X_i"> is the <img src="https://latex.codecogs.com/png.latex?i"> th row of the design matrix <img src="https://latex.codecogs.com/png.latex?X"> and <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> is the vector of regression coefficients.</p>
<p>To find the maximum likelihood estimates of <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> and <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">, we maximize the likelihood function with respect to these parameters. Taking the log of the likelihood function and simplifying, we obtain:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clog%20L(Y%7C%5Ctheta)%20=%20%5Clog%20L(Y%7C%5Cbeta,%5Csigma%5E2)%20=%20-%5Cfrac%7Bn%7D%7B2%7D%20%5Clog%20(2%5Cpi)%20-%20%5Cfrac%7Bn%7D%7B2%7D%20%5Clog(%5Csigma%5E2)%20-%20%5Cfrac%7B1%7D%7B2%5Csigma%5E2%7D%20%5Csum_%7Bi=1%7D%5En%20(Y_i%20-%20X_i%5Cbeta)%5E2%0A"></p>
<p>To maximize this function with respect to <img src="https://latex.codecogs.com/png.latex?%5Cbeta">, we differentiate with respect to <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> and set the derivative to zero, <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Ctheta%7D%20%5Clog%20L(Y%7C%5Ctheta)%20=%200">:</p>
<p>Solving for <img src="https://latex.codecogs.com/png.latex?%5Cbeta">, we obtain:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Ctheta%7D%20%5Clog%20L(Y%7C%5Cbeta,%5Csigma%5E2)%20=%20-%5Cfrac%7B1%7D%7B2%5Csigma%5E2%7D%20%5Csum_%7Bi=1%7D%5En%202X_i(Y_i%20-%20X_i%5Cbeta)%20=%200%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Cbeta%7D%20=%20(X%5ET%20X)%5E%7B-1%7D%20X%5ET%20Y%0A"> , which is the OLS estimate of <img src="https://latex.codecogs.com/png.latex?%5Cbeta">.</p>
<p>Solving for <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">, we differentiate with respect to <img src="https://latex.codecogs.com/png.latex?sigma%5E2"> and set the derivative to zero:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Csigma%5E2%7D%20log%20L(Y%7C%5Cbeta,%5Csigma%5E2)%20=%20-%5Cfrac%7Bn%7D%7B2%5Csigma%5E2%7D%20+%20%5Cfrac%7B1%7D%7B2%5Csigma%5E4%7D%20%5Csum_%7Bi=1%7D%5En%20(Y_i%20-%20X_i%5Cbeta)%5E2%20=%200%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Csigma%7D%5E2%20=%20%5Cfrac%7B%5Csum_%7Bi=1%7D%5En%20(Y_i%20-%20X_i%5Cbeta)%5E2%7D%7Bn%7D%0A"></p>
<p>which is the OLS estimate of <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">.</p>
<p>Therefore, we see that the maximum likelihood estimates of <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> and <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2"> in linear regression with normally distributed errors are equivalent to the OLS estimates of these parameters.</p>
</section>
<section id="statistical-bias" class="level3" data-number="0.3">
<h3 data-number="0.3" class="anchored" data-anchor-id="statistical-bias"><span class="header-section-number">0.3</span> Statistical Bias</h3>
<p>Statistical bias refers to a systematic error or deviation in the results of a statistical analysis that is caused by factors other than chance. A biased estimator is one that consistently produces estimates that are systematically different from the true value of the parameter being estimated.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
There are 5 Types of bias
</div>
</div>
<div class="callout-body-container callout-body">
<p>The above article discusses five types of statistical bias that analysts, data scientists, and other business professionals should be aware of to minimize their effects on the final results.</p>
<ol type="1">
<li>selection bias: data selection methods are not truly random, leading to unequal representation of the population.</li>
<li>bias in assignment: pre-existing differences between groups in an experiment can affect the outcome, a.k.a allocation bias, treatment assignment bias, or exposure assignment bias.</li>
<li>confounders: additional variables not accounted for in the experimental design can impact the results.</li>
<li>self-serving bias: individuals tend to downplay undesirable qualities and overemphasize desirable ones a.k.a cognitive bias. In other words, people tend to take credit for their successes and blame outside factors for their failures.</li>
<li>experimenter expectations: researchers can unconsciously influence the data through verbal or non-verbal cues.</li>
</ol>
<p>Being aware of these biases can lead to better models and more reliable insights for data-backed business decisions.</p>
<p><a href="https://online.hbs.edu/blog/post/types-of-statistical-bias">Source: Article Written by Jenny Gutbezahl</a></p>
</div>
</div>
<p>It is important to detect and correct for bias in statistical analyses, as biased estimates can lead to incorrect conclusions and decisions. One way to correct for bias is to use an unbiased estimator, which is one that has a zero bias, i.e., its expected value is equal to the true value of the parameter being estimated.</p>
<div id="def-bias" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3 </strong></span>An estimator <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Ctheta%7D"> is said to be biased if</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D(%5Chat%7B%5Ctheta%7D)%5Cne%20%5Ctheta%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BE%7D(%5Chat%7B%5Ctheta%7D)"> is the expected value of the estimator <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Ctheta%7D">, and <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> is the true value of the parameter being estimated.</p>
</div>
<p>An estimator is said to be unbiased if <strong>its expected value is equal to the true value of the parameter being estimated</strong>. In other words, an estimator is unbiased if, on average, it gives an estimate that is equal to the true value of the parameter.</p>
<div class="cell" data-evale="false">

</div>


</section>

 ]]></description>
  <category>Statistics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/statistics/2023-03-25_MLE/index.html</guid>
  <pubDate>Tue, 28 Mar 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Tensorflow - Data Input Pipeline</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Language/pipeline.html</link>
  <description><![CDATA[ 



<ul class="nav nav-pills" id="language-tab">
<li class="nav-item">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<section id="input-pipeline" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="input-pipeline"><span class="header-section-number">1</span> Input Pipeline</h2>
<p>Tensorflow 공식 문서 중 Dataset에 대한 기능 및 성능에 대한 비교 자료</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <code>tf.data API</code> makes it possible to handle large amounts of data, read from different data formats, and perform complex transformations. The tf.data API introduces a tf.data.Dataset abstraction that represents a sequence of elements, in which each element consists of one or more components. For example, in an image pipeline, an element might be a single training example, with a pair of tensor components representing the image and its label. <a href="https://www.tensorflow.org/guide/data">Source: https://www.tensorflow.org/guide/data</a></p>
</div>
</div>
<section id="장점" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="장점"><span class="header-section-number">1.1</span> 장점</h3>
<ul>
<li>어떠한 데이터의 형태가 오더라도 Dataset object 자체가 iterative한 interface를 제공해서 for loop 등의 iteration을 이용하여 데이터의 입력 형태가 변경되어도 코드의 일관성을 유지할 수 있음</li>
</ul>
<p>To create an input pipeline, you must start with a data source. For example, to construct a Dataset from data in memory, you can use tf.data.Dataset.from_tensors() or tf.data.Dataset.from_tensor_slices(). Alternatively, if your input data is stored in a file in the recommended TFRecord format, you can use tf.data.TFRecordDataset().</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> tensorflow <span class="im" style="color: #00769E;">as</span> tf</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> pathlib</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-7"></span>
<span id="cb1-8">np.set_printoptions(precision<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>)</span>
<span id="cb1-9"></span>
<span id="cb1-10">dataset <span class="op" style="color: #5E5E5E;">=</span> tf.data.Dataset.from_tensor_slices([<span class="dv" style="color: #AD0000;">8</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">8</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb1-11">dataset</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>&lt;TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)&gt;</code></pre>
</div>
</div>
<p>Once you have a Dataset object, you can transform it into a new Dataset by chaining method calls on the tf.data.Dataset object. For example, you can apply per-element transformations such as Dataset.map, and multi-element transformations such as Dataset.batch. Refer to the documentation for tf.data.Dataset for a complete list of transformations. The Dataset object is a Python iterable. This makes it possible to consume its elements using a for loop:</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="cf" style="color: #003B4F;">for</span> z <span class="kw" style="color: #003B4F;">in</span> dataset:</span>
<span id="cb3-2">    <span class="bu" style="color: null;">print</span>(z.numpy())</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>8
3
0
8
2
1</code></pre>
</div>
</div>
</section>
</section>
<section id="optimize-pipeline-performance" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="optimize-pipeline-performance"><span class="header-section-number">2</span> Optimize pipeline performance</h2>
<ul>
<li>Dataset을 사용은 prefetch 기능과 interleaving 기능에 의한 연산 속도를 향상 시킬수있다.
<ul>
<li>사용할 수 없는 (또는 사용하지 말아야 할) 특별한 이유가 없다면 필수로 사용해야 할 듯</li>
</ul></li>
<li>Pipeline을 쓸 때 연산 처리 속도가 빨리지는 이유 -&gt; cpu architecture 관련
<ul>
<li>X86, ARM 프로세서
<ul>
<li>실행을 위해 D램 올라감 -&gt; cpu에서 하나의 명령이 거치는 step들 fetch(cpu에 로드), decode(해석), execution(수행) -&gt; load (다시 메모리 이동)</li>
<li>각 단계에서 수행 소요 시간 존재</li>
</ul></li>
</ul></li>
<li>파이프라인 구조를 가지면, 한 스텝 수행 시 다음 데이터가 다른 스텝 수행 가능 -&gt; 시간 단축</li>
</ul>
<p><a href="https://www.tensorflow.org/guide/data">Tensor Flow Pipeline</a></p>
<section id="prefetch" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="prefetch"><span class="header-section-number">2.1</span> Prefetch</h3>
<p>앞쪽 데이터 트레이닝 동안 다음 데이터를 미리 읽어옴</p>
</section>
<section id="interleaving" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="interleaving"><span class="header-section-number">2.2</span> Interleaving</h3>
<p>어떤 작업이 끝나기 전에 dependency 없는 다른 작업 수행(async 하게)</p>
</section>
<section id="caching" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="caching"><span class="header-section-number">2.3</span> Caching</h3>
<p>같은 데이터를 반복적으로 사용시 한번 읽은 데이터를 계속 메모리에 가지고 있음</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
floating point 로 인한 error 누적
</div>
</div>
<div class="callout-body-container callout-body">
<p>Tensorflow와 Numpy로 구현한 값에 오차가 발생하는 이유는 Tensorflow를 어떻게 compile 하였느냐에 따른 차이.</p>
<ul>
<li>Floating point (IEEE-754)에서는 값의 표현에 대한 정의만 있고 실제 연산은 processor vendor마다 다르므로 약간의 오차가 있을 수 있으며, 부동소수점 연산기능을 지원하는 명령들 중 어떠한 명령을 사용하도록 compile하였느냐에 따라 계산값에 차이 발생 가능하고 대부분 무시하지만 오차가 누적이 되면 error rate에 영향이 있을 수 있음.</li>
<li>부동소수점의 precision이 낮을수록 overfitting 가능성 저하되어 오히려 학습이 잘될 수도 있으며 모델을 경량화 할 수 있음 <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> bfloat16 type이 생기게 된 이유.</li>
</ul>
</div>
</div>
</section>
</section>
</div>
</div>
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">

</div>
</div>
<section id="go-to-blog-content-list" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="go-to-blog-content-list"><span class="header-section-number">3</span> Go to Blog Content List</h2>
<p><a href="./docs/blog/posts/content_list.qmd">Blog Content List</a></p>


</section>

</div></ul> ]]></description>
  <category>Language</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Language/pipeline.html</guid>
  <pubDate>Thu, 23 Mar 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>LDA (2) - Concept &amp; Covariance Models</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/statistics/LDA/2_covariance_model.html</link>
  <description><![CDATA[ 



<ul class="nav nav-pills" id="language-tab">
<li class="nav-item">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<section id="notations" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="notations"><span class="header-section-number">1</span> Notations</h2>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?y_%7Bij%7D"> : the univariate response (i.e.&nbsp;scalar) for the <img src="https://latex.codecogs.com/png.latex?i"> th subject at the <img src="https://latex.codecogs.com/png.latex?j"> th occasion or measurement
<ul>
<li>later when I use the vector case, I will re-define this notation, but focus on the scalar case for now.</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?x_%7Bij%7D"> : the predictor at time <img src="https://latex.codecogs.com/png.latex?t_%7Bij%7D">, which is either a scalr or vector.
<ul>
<li>a scalar case: <img src="https://latex.codecogs.com/png.latex?x_%7Bij%7D"> where <img src="https://latex.codecogs.com/png.latex?i"> is the <img src="https://latex.codecogs.com/png.latex?i"> th subject, and <img src="https://latex.codecogs.com/png.latex?j"> is the <img src="https://latex.codecogs.com/png.latex?j"> th measurement.</li>
<li>a vector case: <img src="https://latex.codecogs.com/png.latex?x_%7Bijk%7D"> where <img src="https://latex.codecogs.com/png.latex?i"> is the <img src="https://latex.codecogs.com/png.latex?i"> th subject, <img src="https://latex.codecogs.com/png.latex?j"> is the <img src="https://latex.codecogs.com/png.latex?j"> th measurement, and <img src="https://latex.codecogs.com/png.latex?k%20%5Cin%20%5B1,p%5D"> is the <img src="https://latex.codecogs.com/png.latex?k"> th predictor.</li>
<li>sometimes, covariate for different measurements could be the same. In this case, the notation could be written in <img src="https://latex.codecogs.com/png.latex?x_%7Bi%7D">
<ul>
<li>ex) a gender does not change over time in the most cases.</li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?i=1,%20%5Cdots,%20m"> : i is the index for the <img src="https://latex.codecogs.com/png.latex?i"> th subject</li>
<li><img src="https://latex.codecogs.com/png.latex?j=1,%20%5Cdots,%20n_i"> : j is the index for the <img src="https://latex.codecogs.com/png.latex?j"> th measurement of the <img src="https://latex.codecogs.com/png.latex?i"> th subject
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%7Bn_i%7D"> is the number of measurements of the <img src="https://latex.codecogs.com/png.latex?i"> th subject, each <img src="https://latex.codecogs.com/png.latex?%7Bn_i%7D"> does not have to the same.</li>
<li>balanced desgin: <img src="https://latex.codecogs.com/png.latex?%7Bn_i%7D"> is the same.</li>
<li>unbalanced desgin: <img src="https://latex.codecogs.com/png.latex?%7Bn_i%7D"> is different.</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20y_i"> : a vector (not a matrix), <img src="https://latex.codecogs.com/png.latex?(y_%7Bi1%7D,y_%7Bi2%7D,%5Cdots%20,y_%7Bin_i%7D)"> of the <img src="https://latex.codecogs.com/png.latex?i"> th subject</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20Y"> : the reponse matrix</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20X"> : the predictor matrix</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BE%7D(y_%7Bij%7D)"> : <img src="https://latex.codecogs.com/png.latex?%5Cmu_%7Bij%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BE%7D(%5Cmathbf%20y_i)"> : <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20%5Cmu_%7Bi%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BVar%7D(%5Cmathbf%20y_i)"> : <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BVar%7D(%5Cmathbf%20y_i)"> is a variance-covariance matrix of the different measurement for the <img src="https://latex.codecogs.com/png.latex?i"> th subject
<ul>
<li>for now, we do not care of the variance covariance of the different subjects because we assume that the measurements of different subjects are indpendent. <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%5Ctext%7BVar%7D(y_%7Bi1%7D)%20&amp;%20%5Ctext%7BCov%7D(%20y_%7Bi1%7D,%20y_%7Bi2%7D)%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BCov%7D(%20y_%7Bi1%7D,%20y_%7Bin_i%7D)%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%5Ctext%7BVar%7D(%20y_%7Bi2%7D)%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BCov%7D(%20y_%7Bi2%7D,%20y_%7Bin_i%7D)%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;&amp;%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5Cdots%20&amp;%20%5Ctext%7BVar%7D(%20y_%7Bin_i%7D)%0A%5Cend%7Bbmatrix%7D%0A"></li>
</ul></li>
</ul>
</section>
<section id="assumptions" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="assumptions"><span class="header-section-number">2</span> Assumptions</h2>
<ul>
<li>the measurements for the same subject are not independent.</li>
<li>the measurements for the different subject are independent.</li>
<li>some correlation structures of the different measurements.</li>
</ul>
</section>
<section id="for-continuous-responses" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="for-continuous-responses"><span class="header-section-number">3</span> For Continuous Responses</h2>
<ul>
<li>Marginal Models
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BE%7D(y_%7Bij%7D)%20=%20%5Cmathbf%20x_%7Bij%7D%20%5Cmathbf%20%5Cbeta"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BVar%7D(%5Cmathbf%20y_i)=%20%5Cmathbf%20V_i"></li>
<li>to build a marginal model, we just need info on the 3 things
<ul>
<li>the distribution : a multivariate normal distribution</li>
<li>mean and variance-covariance</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbeta"> is fixed. That’s why we call this marginal models ‘fixed effect’</li>
</ul></li>
</ul>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Recall
</div>
</div>
<div class="callout-body-container callout-body">
<p>We find MLE for the linear regression with the 3 things: the normal distribution (iid), <img src="https://latex.codecogs.com/png.latex?%5Cmu"> and <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2"></p>
</div>
</div>
<ul>
<li>Mixed Effects Models
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BE%7D(y_%7Bij%7D%7C%5Cmathbf%20%5Cbeta_i)%20=%20%5Cmathbf%20x_%7Bij%7D%20%5Cmathbf%20%5Cbeta_i"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20%5Cbeta_i%20=%20%5Cmathbf%20%5Cbeta%20(%5Ctext%7Bfixed%20effect%7D)%20+%20%5Cmathbf%20u_i%20(%5Ctext%7Bsubject-specific%20random%20effect%7D)"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20%5Cbeta_i"> is a random coefficient specific for the <img src="https://latex.codecogs.com/png.latex?i"> th subject, That’s why we call this mixed effect models ‘random effect’</li>
<li>subject-specific random effect: differenct subjects have different <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20%5Cbeta_i"></li>
</ul></li>
<li>Transition Models
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BE%7D(y_%7Bij%7D%7Cy_%7Bi,j-1%7D,%5Cdots,y_%7Bi,1%7D,%5Cmathbf%20x_%7Bij%7D)"></li>
<li>Markov Process: the response variable in the previous time point will affect the measurement in the current time point.</li>
</ul></li>
</ul>
<section id="marginal-models" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="marginal-models"><span class="header-section-number">3.1</span> Marginal Models</h3>
<p>Consider an example of a simple linear model (i.e., a univaiable linear model) <img src="https://latex.codecogs.com/png.latex?%0Ay_%7Bij%7D=%5Cbeta_0+%5Cbeta_1t_%7Bij%7D%20+%20%5Cepsilon_%7Bij%7D%0A"></p>
<ul>
<li>mean part: <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BE%7D(y_%7Bij%7D)"></li>
<li>variance part: <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BVar%7D(%5Cmathbf%20y_%7Bi%7D)=%5Ctext%7BVar%7D(%5Cmathbf%20%5Cepsilon_%7Bi%7D)">
<ul>
<li>more often, a correlation matrix is used in LDA because correlation is more interpretable.</li>
</ul></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BCorr%7D(%5Cmathbf%20y_i)%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%20%5Crho_%7B12%7D&amp;%20%5Cdots%20&amp;%20%5Crho_%7B1n_i%7D%20%5C%5C%0A%5Crho_%7B21%7D%20&amp;%201%20&amp;%20%5Cdots%20&amp;%20%5Crho_%7B2n_i%7D%20%5C%5C%0A%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%20%5C%5C%0A%5Crho_%7Bn_i1%7D%20&amp;%20%5Crho_%7Bn_i2%7D&amp;%20%5Cdots%20&amp;%201%0A%5Cend%7Bbmatrix%7D%0A"></p>
<ul>
<li>in this correlation matrix, there are <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bn(n-1)%7D%7B2%7D"> parameters to estimate</li>
<li>in the mean part, there are 2 parameters, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20%5Cbeta"> to estimate Likewise, the number of the estimators depends on the number of the measurements and the covriates.</li>
</ul>
<p>In LDA, since the responses are multiple, we need to look into the correlation characteristics.</p>
</section>
<section id="empirical-observations" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="empirical-observations"><span class="header-section-number">3.2</span> Empirical Observations</h3>
<p>In empirical observations about the nature of the correlation among repeated measures,</p>
<ul>
<li>correlations among the repeated measures are usually positive</li>
<li>correlations tend to decrease with increasing time separation</li>
<li>correlations among repeated measures rarely approach zero</li>
<li>correlations between any pair of repeated meausres regardless of distance in time is constrained by the reliability of the measurement process.
<ul>
<li>if the measurement process is not very reliable or consistent, then even if two measurements are taken close together in time, their correlation will not be very strong. Similarly, if the measurement process is highly reliable or consistent, then two measurements taken far apart in time may still be highly correlated. Reliability refers to the degree to which a measurement process produces consistent and accurate results over time.</li>
</ul></li>
</ul>
</section>
<section id="modeling-covariance-structure" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="modeling-covariance-structure"><span class="header-section-number">3.3</span> Modeling Covariance Structure</h3>
<p>There are 2 types of covariance structure: unbalanced design and balanced design. For now, let’s focus on the balanced design.</p>
<section id="unbalanced-design" class="level4" data-number="3.3.1">
<h4 data-number="3.3.1" class="anchored" data-anchor-id="unbalanced-design"><span class="header-section-number">3.3.1</span> Unbalanced Design</h4>
<ul>
<li>observations for each subject are not made on the same grid</li>
<li>these observations can be made at different time points and different numbers of observations may be made for each subject.</li>
<li>Missing observations falls into this category.</li>
</ul>
</section>
<section id="balanced-design" class="level4" data-number="3.3.2">
<h4 data-number="3.3.2" class="anchored" data-anchor-id="balanced-design"><span class="header-section-number">3.3.2</span> Balanced Design</h4>
<ul>
<li>observations for each subject are made on the same grid and there is no missing data.
<ul>
<li>number and timing of the repeated measurements are the same for all individuals.</li>
</ul></li>
<li>Then, <img src="https://latex.codecogs.com/png.latex?t_%7Bij%7D"> can be denoted as <img src="https://latex.codecogs.com/png.latex?t_j"> where <img src="https://latex.codecogs.com/png.latex?j%20%5Cin%201,%20%5Cdots,%20n"> because the size of the measurements is the same (<img src="https://latex.codecogs.com/png.latex?n_i"> is the same)</li>
<li>The covariance of the response variable <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20Y_%7Bm%5Ctimes%20n%7D"> :</li>
</ul>
$$
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Baligned%7D%0A%20%20%5Ctext%7BCov%7D(%5Cmathbf%20Y)%0A%20%20&amp;=%5Ctext%7BCov%7D(%5Cmathbf%20y_1,%5Cdots,y_m)%20%5C%5C%0A%20%20&amp;=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%5Ctext%7BVar%7D(%5Cmathbf%20y_1)%20&amp;%200%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%200%20&amp;%20%5Ctext%7BVar%7D(%5Cmathbf%20y_2)%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%20%5C%5C%0A%20%20%20%200%20&amp;%200%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BVar%7D(%5Cmathbf%20y_m)%0A%20%20%5Cend%7Bbmatrix%7D%5C%5C%0A%20%20&amp;=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%5Ctext%7BVar%7D(y_%7B11%7D)%20&amp;%20%5Ctext%7BCov%7D(%20y_%7B11%7D,%20y_%7B12%7D)%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BCov%7D(%20y_%7B11%7D,%20y_%7B1n_1%7D)%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%5Ctext%7BVar%7D(%20y_%7B12%7D)%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BCov%7D(%20y_%7B12%7D,%20y_%7B1n_1%7D)%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;&amp;%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5Cdots%20&amp;%20%5Ctext%7BVar%7D(%20y_%7B1n_1%7D)%0A%5Cend%7Bbmatrix%7D%20&amp;%200%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%200%20&amp;%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%5Ctext%7BVar%7D(y_%7B21%7D)%20&amp;%20%5Ctext%7BCov%7D(%20y_%7B21%7D,%20y_%7B22%7D)%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BCov%7D(%20y_%7B21%7D,%20y_%7Bin_2%7D)%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%5Ctext%7BVar%7D(%20y_%7B22%7D)%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BCov%7D(%20y_%7B22%7D,%20y_%7Bin_2%7D)%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;&amp;%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5Cdots%20&amp;%20%5Ctext%7BVar%7D(%20y_%7B2n_2%7D)%0A%5Cend%7Bbmatrix%7D%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%20%5C%5C%0A%20%20%20%200%20&amp;%200%20&amp;%20%5Cdots%20&amp;%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%5Ctext%7BVar%7D(y_%7Bm1%7D)%20&amp;%20%5Ctext%7BCov%7D(%20y_%7Bm1%7D,%20y_%7Bm2%7D)%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BCov%7D(%20y_%7Bm1%7D,%20y_%7Bmn_m%7D)%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%5Ctext%7BVar%7D(%20y_%7Bm2%7D)%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BCov%7D(%20y_%7Bm2%7D,%20y_%7Bmn_m%7D)%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;&amp;%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5Cdots%20&amp;%20%5Ctext%7BVar%7D(%20y_%7Bmn_m%7D)%0A%5Cend%7Bbmatrix%7D%0A%0A%20%20%5Cend%7Bbmatrix%7D%20%5C%5C%0A%20%20&amp;=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%5CSigma_1%20&amp;%200%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%200%20&amp;%20%5CSigma_1%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%20%5C%5C%0A%20%20%20%200%20&amp;%200%20&amp;%20%5Cdots%20&amp;%20%5CSigma_m%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Baligned%7D">
<p>$$</p>
<p>If we assume the covariance matrices for different subjects are the same, we can denote <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BCov%7D(%5Cmathbf%20Y)=%5CSigma">.</p>
</section>
</section>
<section id="covariance-structure-pattern-models" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="covariance-structure-pattern-models"><span class="header-section-number">3.4</span> Covariance Structure Pattern Models</h3>
<section id="compound-symmetry-structure" class="level4" data-number="3.4.1">
<h4 data-number="3.4.1" class="anchored" data-anchor-id="compound-symmetry-structure"><span class="header-section-number">3.4.1</span> Compound symmetry Structure</h4>
<p><img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Ctext%7BCov%7D(%5Cmathbf%20y_i)=%0A%20%20%5Csigma%5E2%20%20%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%20%5Crho%20&amp;%20%5Crho%20&amp;%20%5Cdots%20&amp;%20%5Crho%20%5C%5C%0A%20%20%20%20%5Crho%20&amp;%201%20&amp;%20%5Crho%20&amp;%20%5Cdots%20&amp;%20%5Crho%20%5C%5C%0A%20%20%20%20%5Crho%20&amp;%20%5Crho%20&amp;%201%20&amp;%20%5Cdots%20&amp;%20%5Crho%20%5C%5C%0A%20%20%20%20%5Cvdots%20&amp;%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%20%5C%5C%0A%20%20%20%20%5Crho%20&amp;%20%5Crho%20&amp;%20%5Crho%20&amp;%20%5Cdots%20&amp;%201%0A%20%20%5Cend%7Bbmatrix%7D%0A"></p>
<ul>
<li>compound symmetry is a.k.a <strong>Exchangeable</strong></li>
<li>Assume variance is constant across visits (say <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">)</li>
<li>Assume correlation between any two visits are constant (say <img src="https://latex.codecogs.com/png.latex?%5Crho">).</li>
<li>Parsimonious: there are two parameters in the covariance, <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2"> and <img src="https://latex.codecogs.com/png.latex?%5Crho"> (computational benefit)</li>
<li>Without any contraint on <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">, you will get closed form estimate.</li>
<li>Covariance variance matrix is plugged into likelihood function to estimate 3 kinds of parameters <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">, <img src="https://latex.codecogs.com/png.latex?%5Crho">, and <img src="https://latex.codecogs.com/png.latex?%5Cbeta"></li>
<li>This structure is so parsimonuous that it could be unrealistic: not commonly used</li>
</ul>
</section>
<section id="toeplitz-structure" class="level4" data-number="3.4.2">
<h4 data-number="3.4.2" class="anchored" data-anchor-id="toeplitz-structure"><span class="header-section-number">3.4.2</span> Toeplitz Structure</h4>
<p><img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Ctext%7BCov%7D(%5Cmathbf%20y_i)=%0A%20%20%5Csigma%5E2%20%20%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%20%5Crho_1%20&amp;%20%5Crho_2%20&amp;%20%5Cdots%20&amp;%20%5Crho_%7Bn-1%7D%20%5C%5C%0A%20%20%20%20%5Crho_1%20&amp;%201%20&amp;%20%5Crho_1%20&amp;%20%5Cdots%20&amp;%20%5Crho_%7Bn-2%7D%20%5C%5C%0A%20%20%20%20%5Crho_2%20&amp;%20%5Crho_1%20&amp;%201%20&amp;%20%5Cdots%20&amp;%20%5Crho_%7Bn-3%7D%20%5C%5C%0A%20%20%20%20%5Cvdots%20&amp;%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%20%5C%5C%0A%20%20%20%20%5Crho_%7Bn-1%7D%20&amp;%20%5Crho_%7Bn-2%7D%20&amp;%20%5Crho_%7Bn-3%7D%20&amp;%20%5Cdots%20&amp;%201%0A%20%20%5Cend%7Bbmatrix%7D%0A"></p>
<ul>
<li>Toeplitz structure is more flexible than compound symmetry</li>
<li>Assume variance is constant across visits and <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BCorr%7D(y_%7Bij%7D,%20y_%7Bi,j+k%7D)%20=%20%5Crho_k">.</li>
<li>Assume correlation among responses at adjacent measurements is constant.</li>
<li>Only suitable for measurements made at equal intervals of time between different measurement.</li>
<li>Without any contraint on <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">, you will get closed form estimate.</li>
<li>Toeplitz covariance has free <img src="https://latex.codecogs.com/png.latex?n"> parameters to estimate (<img src="https://latex.codecogs.com/png.latex?1"> for variance and <img src="https://latex.codecogs.com/png.latex?n-1"> correlation parameters)</li>
<li>The larger time differences, the smaller its correlations</li>
</ul>
</section>
<section id="autoregressive-structure" class="level4" data-number="3.4.3">
<h4 data-number="3.4.3" class="anchored" data-anchor-id="autoregressive-structure"><span class="header-section-number">3.4.3</span> Autoregressive Structure</h4>
<p><img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Ctext%7BCov%7D(%5Cmathbf%20y_i)=%0A%20%20%5Csigma%5E2%20%20%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%20%5Crho%5E1%20&amp;%20%5Crho%5E2%20&amp;%20%5Cdots%20&amp;%20%5Crho%5E%7Bn-1%7D%20%5C%5C%0A%20%20%20%20%5Crho%5E1%20&amp;%201%20&amp;%20%5Crho%5E1%20&amp;%20%5Cdots%20&amp;%20%5Crho%5E%7Bn-2%7D%20%5C%5C%0A%20%20%20%20%5Crho%5E2%20&amp;%20%5Crho%5E1%20&amp;%201%20&amp;%20%5Cdots%20&amp;%20%5Crho%5E%7Bn-3%7D%20%5C%5C%0A%20%20%20%20%5Cvdots%20&amp;%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%20%5C%5C%0A%20%20%20%20%5Crho%5E%7Bn-1%7D%20&amp;%20%5Crho%5E%7Bn-2%7D%20&amp;%20%5Crho%5E%7Bn-3%7D%20&amp;%20%5Cdots%20&amp;%201%0A%20%20%5Cend%7Bbmatrix%7D%0A"></p>
<ul>
<li>A special case of toeplitz structure with <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BCorr%7D(y_%7Bij%7D,y_%7Bi,j+k%7D)=%5Crho%5Ek"></li>
<li>simpler than toeplitz, only 2 parameters</li>
<li>Only suitable for measurements made at equal intervals of time between different measurement.</li>
</ul>
</section>
<section id="banded-structure" class="level4" data-number="3.4.4">
<h4 data-number="3.4.4" class="anchored" data-anchor-id="banded-structure"><span class="header-section-number">3.4.4</span> Banded Structure</h4>
<p><img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Ctext%7BCov%7D(%5Cmathbf%20y_i)=%0A%20%20%5Csigma%5E2%20%20%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%20%5Crho%5E1%20&amp;%200%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%20%5Crho%5E1%20&amp;%201%20&amp;%20%5Crho%5E1%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%200%20&amp;%20%5Crho%5E1%20&amp;%201%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%20%5Cvdots%20&amp;%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%20%5C%5C%0A%20%20%20%200%20&amp;%200%20&amp;%200%20&amp;%20%5Cdots%20&amp;%201%0A%20%20%5Cend%7Bbmatrix%7D%0A"></p>
<p>Look at the more general case of the banded structure in <a href="https://en.wikipedia.org/wiki/Band_matrix">Wiki</a>.</p>
<ul>
<li>Assume correlation is 0 beyond some specified interval.</li>
<li>Can be combined with the previous patterns.</li>
<li>Very strong assumption about how quickly the correlation decays to 0 with increasing time separation.</li>
</ul>
</section>
<section id="exponential-structure" class="level4" data-number="3.4.5">
<h4 data-number="3.4.5" class="anchored" data-anchor-id="exponential-structure"><span class="header-section-number">3.4.5</span> Exponential Structure</h4>
<ul>
<li>A generalization of autoregressive pattern</li>
<li>The most general and reasonable structure</li>
<li>Suitable for unevenly spaced measurements, take actual time points (time difference), the larger time difference the smaller correlation</li>
<li>Assumption that the variance of different measurements over time is the same, which can be easily generalized. You can put different variance on the diagonal.</li>
<li>Let <img src="https://latex.codecogs.com/png.latex?%5C%7Bt_%7Bi1%7D,%5Cdots,t_%7Bin_i%7D%5C%7D"> denote the observation times for the <img src="https://latex.codecogs.com/png.latex?i"> th individual. Then, the correlation is <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BCorr%7D(Y_%7Bij%7D%20,Y_%7Bik%7D)%20=%20%5Crho%5E%7B%7Ct_%7Bij%7D-t_%7Bik%7D%7C%7D"></li>
<li>Correlation decreases exponentially with the time separations between them.</li>
</ul>
</section>
</section>
</section>
</div>
</div>
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">

</div>
</div>
<section id="go-to-blog-content-list" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="go-to-blog-content-list"><span class="header-section-number">4</span> Go to Blog Content List</h2>
<p><a href="../../../../../docs/blog/posts/content_list.html">Blog Content List</a></p>


</section>

</div></ul> ]]></description>
  <category>Statistics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/statistics/LDA/2_covariance_model.html</guid>
  <pubDate>Thu, 23 Mar 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Minimizer &amp; Maximizer</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/minimizer.html</link>
  <description><![CDATA[ 



<ul class="nav nav-pills" id="language-tab">
<li class="nav-item">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<p>A minimizer or a maximizer refer to a point in the domain of a function where the function achieves its minimum or maximum value. More formally, let <img src="https://latex.codecogs.com/png.latex?f:%20X%20%E2%86%92%20%5Cmathbb%20R"> be a real-valued function defined on a set <img src="https://latex.codecogs.com/png.latex?X%20%5Csubset%20%5Cmathbb%20R">.</p>
<div id="def-minimum" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 </strong></span><img src="https://latex.codecogs.com/png.latex?f(x%5E*)"> with a point <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X"> is called a <strong>minimum</strong> if <img src="https://latex.codecogs.com/png.latex?f(x%5E*)%20%5Cle%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20X">. <img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_%7Bx%5Cin%20X%7D%7Bf(x)%7D%0A"> , which means a minimum, <img src="https://latex.codecogs.com/png.latex?f(x)">.</p>
</div>
<div id="def-maximum" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2 </strong></span><img src="https://latex.codecogs.com/png.latex?f(x%5E*)"> with a point <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X"> is called a <strong>maximum</strong> if <img src="https://latex.codecogs.com/png.latex?f(x%5E*)%20%5Cge%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20X">. <img src="https://latex.codecogs.com/png.latex?%0A%5Cmax_%7Bx%5Cin%20X%7D%7Bf(x)%7D%0A"> , which means a maximum, <img src="https://latex.codecogs.com/png.latex?f(x)">.</p>
</div>
<div id="def-minimizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3 </strong></span>A point <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X"> is called a <strong>minimizer</strong> of <img src="https://latex.codecogs.com/png.latex?f"> if <img src="https://latex.codecogs.com/png.latex?f(x%5E*)%20%5Cle%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20X">. <img src="https://latex.codecogs.com/png.latex?%0A%5Carg%5Cmin_%7Bx%5Cin%20X%7D%7Bf(x)%7D%0A"> , which means <img src="https://latex.codecogs.com/png.latex?x"> that mainimizes <img src="https://latex.codecogs.com/png.latex?f(x)">.</p>
</div>
<div id="def-maximizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4 </strong></span>A point <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X"> is called a <strong>maximizer</strong> of <img src="https://latex.codecogs.com/png.latex?f"> if <img src="https://latex.codecogs.com/png.latex?f(x%5E*)%20%5Cge%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20X">. <img src="https://latex.codecogs.com/png.latex?%0A%5Carg%5Cmax_%7Bx%5Cin%20X%7D%7Bf(x)%7D%0A"> , which means <img src="https://latex.codecogs.com/png.latex?x"> that maximizes <img src="https://latex.codecogs.com/png.latex?f(x)">.</p>
</div>
<div id="def-global_minimizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 5 </strong></span>A point <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X"> is called a <strong>global mainimizer</strong> of <img src="https://latex.codecogs.com/png.latex?f"> if <img src="https://latex.codecogs.com/png.latex?f(x%5E*)%20%5Cge%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20%5Cmathbb%20R">. <img src="https://latex.codecogs.com/png.latex?%0A%5Carg%5Cmin_%7Bx%5Cin%20%5Cmathbb%20R%7D%7Bf(x)%7D%0A"> , which means <img src="https://latex.codecogs.com/png.latex?x"> that minimizes <img src="https://latex.codecogs.com/png.latex?f(x)">.</p>
</div>
<div id="def-global_maximizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6 </strong></span>A point <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X"> is called a <strong>global maximizer</strong> of <img src="https://latex.codecogs.com/png.latex?f"> if <img src="https://latex.codecogs.com/png.latex?f(x%5E*)%20%5Cge%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20%5Cmathbb%20R">. <img src="https://latex.codecogs.com/png.latex?%0A%5Carg%5Cmax_%7Bx%5Cin%20%5Cmathbb%20R%7D%7Bf(x)%7D%0A"> , which means <img src="https://latex.codecogs.com/png.latex?x"> that maximizes <img src="https://latex.codecogs.com/png.latex?f(x)">.</p>
</div>
<div id="def-strict_global_maximizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 7 </strong></span>A point <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X"> is called a <strong>strict global maximizer</strong> of <img src="https://latex.codecogs.com/png.latex?f"><br>
if <img src="https://latex.codecogs.com/png.latex?f(x%5E*)%20%3E%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20%5Cmathbb%20R">.</p>
</div>
<div id="def-strict_global_miniimizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 8 </strong></span>A point <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X"> is called a <strong>strict global miniimizer</strong> of <img src="https://latex.codecogs.com/png.latex?f"><br>
if <img src="https://latex.codecogs.com/png.latex?f(x%5E*)%20%3C%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20%5Cmathbb%20R">.</p>
</div>
<div id="def-local_minimizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9 </strong></span>A local minimizer of <img src="https://latex.codecogs.com/png.latex?f"> is a point <img src="https://latex.codecogs.com/png.latex?x*%20%5Cin%20X"> such that there exists a radius, <img src="https://latex.codecogs.com/png.latex?%5Cdelta%3E0"> of a neighborhood of <img src="https://latex.codecogs.com/png.latex?x%5E*"> such that <img src="https://latex.codecogs.com/png.latex?f(x*)%20%5Cle%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20(x%5E*-%5Cdelta,x%5E*+%5Cdelta)"> or <img src="https://latex.codecogs.com/png.latex?%7Cx-x%5E*%7C%3C%5Cdelta"> . A local minimizer is at least best possible solution among nearby points.</p>
</div>
<div id="def-local_maximizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 10 </strong></span>A local maximizer of <img src="https://latex.codecogs.com/png.latex?f"> is a point <img src="https://latex.codecogs.com/png.latex?x*%20%5Cin%20X"> such that there exists a radius, <img src="https://latex.codecogs.com/png.latex?%5Cdelta%3E0"> of a neighborhood of <img src="https://latex.codecogs.com/png.latex?x%5E*"> such that <img src="https://latex.codecogs.com/png.latex?f(x*)%20%5Cge%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20(x%5E*-%5Cdelta,x%5E*+%5Cdelta)"> or <img src="https://latex.codecogs.com/png.latex?%7Cx-x%5E*%7C%3C%5Cdelta"> . A local maximizer is at least best possible solution among nearby points.</p>
</div>
<div id="def-strict_local_minimizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 11 </strong></span>A strict local minimizer of <img src="https://latex.codecogs.com/png.latex?f"> is a point <img src="https://latex.codecogs.com/png.latex?x*%20%5Cin%20X"> such that there exists a radius, <img src="https://latex.codecogs.com/png.latex?%5Cdelta%3E0"> of a neighborhood of <img src="https://latex.codecogs.com/png.latex?x%5E*"> such that <img src="https://latex.codecogs.com/png.latex?f(x*)%20%3C%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20(x%5E*-%5Cdelta,x%5E*+%5Cdelta)"> or <img src="https://latex.codecogs.com/png.latex?%7Cx-x%5E*%7C%3C%5Cdelta"> . A local minimizer is at least best possible solution among nearby points.</p>
</div>
<div id="def-strict_local_maximizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 12 </strong></span>A strict local maximizer of <img src="https://latex.codecogs.com/png.latex?f"> is a point <img src="https://latex.codecogs.com/png.latex?x*%20%5Cin%20X"> such that there exists a radius, <img src="https://latex.codecogs.com/png.latex?%5Cdelta%3E0"> of a neighborhood of <img src="https://latex.codecogs.com/png.latex?x%5E*"> such that <img src="https://latex.codecogs.com/png.latex?f(x*)%20%3E%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20(x%5E*-%5Cdelta,x%5E*+%5Cdelta)"> or <img src="https://latex.codecogs.com/png.latex?%7Cx-x%5E*%7C%3C%5Cdelta"> . A local maximizer is at least best possible solution among nearby points.</p>
</div>
<div id="def-critical_point" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13 </strong></span>It is said to be a critical point if <img src="https://latex.codecogs.com/png.latex?f'(x)"> exists and <img src="https://latex.codecogs.com/png.latex?f'(x%5E*)=0"> for <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X">.</p>
</div>
<p>Note that a function may have multiple minimizers, and some functions may not have a minimizer at all. In addition, if a function has multiple minimizers, they may be either global or local minimizers.</p>
<p><strong>Example</strong></p>
<ul>
<li>If <img src="https://latex.codecogs.com/png.latex?f(x)=2(x-3)%5E2+8">, then<br>
the vertex is <img src="https://latex.codecogs.com/png.latex?(2,8)">, the global minimizer is <img src="https://latex.codecogs.com/png.latex?2">, the global minimum is <img src="https://latex.codecogs.com/png.latex?8">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f(x)=x%5E3-3x%5E2+4">, then<br>
<img src="https://latex.codecogs.com/png.latex?f'(x)=3x%5E2-6x=3x(x-2)"> and the critical points are <img src="https://latex.codecogs.com/png.latex?(0,4),%20(2,0)">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f(x)=7x%5E5-35x+4">, then<br>
<img src="https://latex.codecogs.com/png.latex?f'(x)=35x%5E4-35=35(x%5E2+1)(x-1)(x+1)"> critical points are <img src="https://latex.codecogs.com/png.latex?(-1,0),%20(1,32)">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f(x)=%5Cfrac%7B2x%7D%7Bx%5E2+1%7D">, then<br>
<img src="https://latex.codecogs.com/png.latex?f'(x)=%5Cfrac%7B2(1-x)(1+x)%7D%7B(1+x%5E2)%5E2%7D"> the critical points are <img src="https://latex.codecogs.com/png.latex?(-1,-1),%20(1,1)">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f(x)=4x%5E5-%5Cfrac%7B20%7D%7B3%7Dx%5E3+4">, then<br>
<img src="https://latex.codecogs.com/png.latex?f'(x)=20x%5E4-20x%5E2=20(x%5E2)(x-1)(x+1)"> critical points are <img src="https://latex.codecogs.com/png.latex?(-1,%5Cfrac%7B20%7D%7B3%7D),%20(1,%5Cfrac%7B4%7D%7B3%7D)">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f(x)=%5Cfrac%7B(x%5E2-1)%7D%7B(x-2)%7D">, then<br>
<img src="https://latex.codecogs.com/png.latex?f'(x)=%5Cfrac%7B(x%5E2-4x+1)%7D%7B(x-2)%5E2%7D">, critical points are <img src="https://latex.codecogs.com/png.latex?(-1,%5Cfrac%7B20%7D%7B3%7D),%20(1,%5Cfrac%7B4%7D%7B3%7D)">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f(x)=%5Cmathrm%7Be%7D%5E%7B%5Csin%5Cleft(x%5E2+1%5Cright)%7D">, then<br>
<img src="https://latex.codecogs.com/png.latex?f'(x)=2x%5Cmathrm%7Be%7D%5E%7B%5Csin%5Cleft(x%5E2+1%5Cright)%7D%5Ccos%5Cleft(x%5E2+1%5Cright)"> , <img src="https://latex.codecogs.com/png.latex?f''(x)=-2%5Cmathrm%7Be%7D%5E%7B%5Csin%5Cleft(x%5E2+1%5Cright)%7D%5Ccdot%5Cleft(2x%5E2%5Csin%5Cleft(x%5E2+1%5Cright)-2x%5E2%5Ccos%5E2%5Cleft(x%5E2+1%5Cright)-%5Ccos%5Cleft(x%5E2+1%5Cright)%5Cright)">, critical points are <img src="https://latex.codecogs.com/png.latex?(0,e%5E%7B%5Csin(1)%7D),%20(%5Cpm%5Csqrt%7B(2n-1)%5Cfrac%7B%5Cpi%7D%7B2%7D-1%7D%20)"> where <img src="https://latex.codecogs.com/png.latex?n=1,2,%5Cdots">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f(x)=3x%5E4-4x%5E3+1">, then<br>
<img src="https://latex.codecogs.com/png.latex?f'(x)=12x%5E3-12x%5E2=12x%5E2(x-1)"> , <img src="https://latex.codecogs.com/png.latex?f''(x)=36x%5E2-24x=12x(3x-2)">, critical points are <img src="https://latex.codecogs.com/png.latex?(0,1),%20(1,0)">.</li>
</ul>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="kw" style="color: #003B4F;">def</span> f(x):</span>
<span id="cb1-5">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">*</span>(x<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">3</span>)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">8</span></span>
<span id="cb1-6"><span class="kw" style="color: #003B4F;">def</span> f2(x):</span>
<span id="cb1-7">    <span class="cf" style="color: #003B4F;">return</span> x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb1-8"><span class="kw" style="color: #003B4F;">def</span> f3(x):</span>
<span id="cb1-9">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">7</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">5</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">35</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb1-10"><span class="kw" style="color: #003B4F;">def</span> f4(x):</span>
<span id="cb1-11">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">/</span>(x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb1-12"><span class="kw" style="color: #003B4F;">def</span> f5(x):</span>
<span id="cb1-13">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">4</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">5</span><span class="op" style="color: #5E5E5E;">-</span>(<span class="dv" style="color: #AD0000;">20</span><span class="op" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">3</span>)<span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb1-14"><span class="kw" style="color: #003B4F;">def</span> f6(x):</span>
<span id="cb1-15">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">4</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">4</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb1-16"></span>
<span id="cb1-17"><span class="kw" style="color: #003B4F;">def</span> df(x):</span>
<span id="cb1-18">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">4</span><span class="op" style="color: #5E5E5E;">*</span>(x<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">3</span>)</span>
<span id="cb1-19"><span class="kw" style="color: #003B4F;">def</span> df2(x):</span>
<span id="cb1-20">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">6</span><span class="op" style="color: #5E5E5E;">*</span>x</span>
<span id="cb1-21"><span class="kw" style="color: #003B4F;">def</span> df3(x):</span>
<span id="cb1-22">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">35</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">4</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">35</span></span>
<span id="cb1-23"><span class="kw" style="color: #003B4F;">def</span> df4(x):</span>
<span id="cb1-24">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">*</span>(<span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">-</span>x)<span class="op" style="color: #5E5E5E;">*</span>(<span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">+</span>x)<span class="op" style="color: #5E5E5E;">/</span>(<span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">+</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span></span>
<span id="cb1-25"><span class="kw" style="color: #003B4F;">def</span> df5(x):</span>
<span id="cb1-26">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">20</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">4</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">20</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span></span>
<span id="cb1-27"><span class="kw" style="color: #003B4F;">def</span> df6(x):</span>
<span id="cb1-28">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">12</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">*</span>(x<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb1-29"></span>
<span id="cb1-30"><span class="kw" style="color: #003B4F;">def</span> ddf(n):</span>
<span id="cb1-31">    <span class="cf" style="color: #003B4F;">return</span> np.repeat(<span class="dv" style="color: #AD0000;">4</span>,n)</span>
<span id="cb1-32"><span class="kw" style="color: #003B4F;">def</span> ddf2(x):</span>
<span id="cb1-33">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">6</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">6</span></span>
<span id="cb1-34"><span class="kw" style="color: #003B4F;">def</span> ddf3(x):</span>
<span id="cb1-35">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">140</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb1-36"><span class="kw" style="color: #003B4F;">def</span> ddf4(x):</span>
<span id="cb1-37">    <span class="cf" style="color: #003B4F;">return</span> (<span class="dv" style="color: #AD0000;">4</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">*</span>(x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">3</span>))<span class="op" style="color: #5E5E5E;">/</span>(x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb1-38"><span class="kw" style="color: #003B4F;">def</span> ddf5(x):</span>
<span id="cb1-39">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">80</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">40</span><span class="op" style="color: #5E5E5E;">*</span>x</span>
<span id="cb1-40"><span class="kw" style="color: #003B4F;">def</span> ddf6(x):</span>
<span id="cb1-41">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">12</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">*</span>(<span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>)</span></code></pre></div>
</details>
</div>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># Create a range of x values</span></span>
<span id="cb2-2">x <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">8</span>, <span class="dv" style="color: #AD0000;">1000</span>)</span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;"># Plot the function</span></span>
<span id="cb2-5">plt.plot(x, f(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$f(x)=2(x-3)^2+8$'</span>)</span>
<span id="cb2-6">plt.plot(x, df(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$df(x)=4(x-3)$'</span>)</span>
<span id="cb2-7">plt.plot(x, ddf(<span class="bu" style="color: null;">len</span>(x)), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$d^2f(x)=4$'</span>)</span>
<span id="cb2-8">plt.axhline(y<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb2-9">plt.axvline(x<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb2-10"></span>
<span id="cb2-11">plt.legend()</span>
<span id="cb2-12">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/minimizer_files/figure-html/cell-3-output-1.png" width="577" height="411"></p>
</div>
</div>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">x <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">4</span>, <span class="dv" style="color: #AD0000;">1000</span>)</span>
<span id="cb3-2"></span>
<span id="cb3-3">plt.plot(x, f2(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$f(x)=x^3-3x^2+4$'</span>)</span>
<span id="cb3-4">plt.plot(x, df2(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$df(x)=3x^2-6x=3x(x-2)$'</span>)</span>
<span id="cb3-5">plt.plot(x, ddf2(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$d^2f(x)=6x-6=6(x-1)$'</span>)</span>
<span id="cb3-6">plt.axhline(y<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb3-7">plt.axvline(x<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb3-8"></span>
<span id="cb3-9">plt.legend()</span>
<span id="cb3-10">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/minimizer_files/figure-html/cell-4-output-1.png" width="577" height="411"></p>
</div>
</div>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># Create a range of x values</span></span>
<span id="cb4-2">x <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">1.2</span>, <span class="fl" style="color: #AD0000;">1.2</span>, <span class="dv" style="color: #AD0000;">1000</span>)</span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;"># Plot the function</span></span>
<span id="cb4-5">plt.plot(x, f3(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$f(x)=7x^5-35x+4$'</span>)</span>
<span id="cb4-6">plt.plot(x, df3(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$df(x)=35x^4-35=35(x^2+1)(x-1)(x+1)$'</span>)</span>
<span id="cb4-7">plt.plot(x, ddf3(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$d^2f(x)=120x^3$'</span>)</span>
<span id="cb4-8">plt.axhline(y<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb4-9">plt.axvline(x<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb4-10"></span>
<span id="cb4-11">plt.legend()</span>
<span id="cb4-12">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/minimizer_files/figure-html/cell-5-output-1.png" width="586" height="411"></p>
</div>
</div>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">x <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">4</span>, <span class="dv" style="color: #AD0000;">1000</span>)</span>
<span id="cb5-2"></span>
<span id="cb5-3">plt.plot(x, f4(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$\frac</span><span class="sc" style="color: #5E5E5E;">{2x}</span><span class="vs" style="color: #20794D;">{x^2+1}$'</span>)</span>
<span id="cb5-4">plt.plot(x, df4(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$df(x)=\frac{2(1-x)(1+x)}{(1+x^2)^2}$'</span>)</span>
<span id="cb5-5">plt.plot(x, ddf4(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$d^2f(x)=\frac{4x(x^2-3)}{(1+x^2)^3}$'</span>)</span>
<span id="cb5-6">plt.axhline(y<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb5-7">plt.axvline(x<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb5-8"></span>
<span id="cb5-9">plt.legend()</span>
<span id="cb5-10">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/minimizer_files/figure-html/cell-6-output-1.png" width="569" height="411"></p>
</div>
</div>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">x <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">1000</span>)</span>
<span id="cb6-2"></span>
<span id="cb6-3"><span class="co" style="color: #5E5E5E;"># Plot the function</span></span>
<span id="cb6-4">plt.plot(x, f5(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$f(x)=4x^5-\frac</span><span class="sc" style="color: #5E5E5E;">{20}{3}</span><span class="vs" style="color: #20794D;">x^3+4$'</span>)</span>
<span id="cb6-5">plt.plot(x, df5(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$df(x)=20x^4-20x^2=20(x^2)(x-1)(x+1)$'</span>)</span>
<span id="cb6-6">plt.plot(x, ddf5(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$d^2f(x)=80x^3-40x=40x(x-1)(x+1)$'</span>)</span>
<span id="cb6-7"></span>
<span id="cb6-8">plt.axhline(y<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb6-9">plt.axvline(x<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb6-10">plt.axis([<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">20</span>, <span class="dv" style="color: #AD0000;">20</span>])</span>
<span id="cb6-11">plt.legend()</span>
<span id="cb6-12">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/minimizer_files/figure-html/cell-7-output-1.png" width="588" height="416"></p>
</div>
</div>
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/critical_points.PNG" class="img-fluid" alt="https://www.derivative-calculator.net/"><br>
I felt too annoyed to type this latex and make the function…</p>
<div id="thm-theorem" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 </strong></span>For <img src="https://latex.codecogs.com/png.latex?f:X%20%5Crightarrow%20%5Cmathbb%20R">, let <img src="https://latex.codecogs.com/png.latex?f(x)">, <img src="https://latex.codecogs.com/png.latex?f'(x)">, and <img src="https://latex.codecogs.com/png.latex?f''(x)"> be all continuous. For <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X">, <img src="https://latex.codecogs.com/png.latex?f'(x%5E*)=0"></p>
<ol type="1">
<li>If <img src="https://latex.codecogs.com/png.latex?f''(x)%5Cge%200"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20X">, <img src="https://latex.codecogs.com/png.latex?x%5E*"> is a global minimizer</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f''(x)%3E%200"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20X">, <img src="https://latex.codecogs.com/png.latex?x%5E*"> is a strict global minimizer</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f''(x%5E*)%3E%200">, <img src="https://latex.codecogs.com/png.latex?x%5E*"> is a strict local minimizer</li>
</ol>
</div>
<p>the reverse of the stament 1 in Theorem&nbsp;1 is not true.</p>
<p><strong>Counter Example</strong></p>
<p>If <img src="https://latex.codecogs.com/png.latex?f(x)=3x%5E4-4x%5E3+1">, then<br>
<img src="https://latex.codecogs.com/png.latex?f'(x)=12x%5E3-12x%5E2=12x%5E2(x-1)"> , <img src="https://latex.codecogs.com/png.latex?f''(x)=36x%5E2-24x=12x(3x-2)">, critical points are <img src="https://latex.codecogs.com/png.latex?(0,1),%20(1,0)">.</p>
<p><img src="https://latex.codecogs.com/png.latex?x%5E*=1"> is a global minimizer. For <img src="https://latex.codecogs.com/png.latex?x%5Cin%20%5Cmathbb%20R">, <img src="https://latex.codecogs.com/png.latex?f''(x)%5Cge%200"> is not true.</p>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">x <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="fl" style="color: #AD0000;">1.5</span>, <span class="dv" style="color: #AD0000;">1000</span>)</span>
<span id="cb7-2"></span>
<span id="cb7-3"><span class="co" style="color: #5E5E5E;"># Plot the function</span></span>
<span id="cb7-4">plt.plot(x, f6(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$f(x)=3x^4-4x^3+1$'</span>)</span>
<span id="cb7-5">plt.plot(x, df6(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$df(x)=12x^3-12x^2=12x^2(x-1)$'</span>)</span>
<span id="cb7-6">plt.plot(x, ddf6(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$d^2f(x)=36x^2-24x=12x(3x-2)$'</span>)</span>
<span id="cb7-7"></span>
<span id="cb7-8">plt.axhline(y<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb7-9">plt.axvline(x<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb7-10">plt.axis([<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="fl" style="color: #AD0000;">1.5</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">5</span>])</span>
<span id="cb7-11"></span>
<span id="cb7-12">plt.legend()</span>
<span id="cb7-13">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/minimizer_files/figure-html/cell-8-output-1.png" width="580" height="411"></p>
</div>
</div>
</div>
</div>
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">

</div>
</div>
<section id="go-to-blog-content-list" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Go to Blog Content List</h1>
<p><a href="./docs/blog/posts/content_list.qmd">Blog Content List</a></p>


</section>

</div></ul> ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/minimizer.html</guid>
  <pubDate>Wed, 22 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/critical_points.PNG" medium="image"/>
</item>
<item>
  <title>Variable Types</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/variables/index.html</link>
  <description><![CDATA[ 



<ul class="nav nav-pills" id="language-tab">
<li class="nav-item">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<section id="variable-types" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Variable Types</h1>
<p>Variable types can be classified with various perspectives depending on research purpose:</p>
<ul>
<li>From the perspective of a data type, variable types are largely divided into two categories:
<ul>
<li>quantitative variable: a variable containing quantitative data that represents quantity</li>
<li>categorical variable: a variable containing qualitative data that represents groups</li>
</ul></li>
<li>From the standpoint of modeling or experiment designs, variable types are largely divided into 3 categories:
<ul>
<li>independent variable: a variable (cause) that might have an effect on a dependent variabe (result).</li>
<li>dependent variable: a variable (result) that might be influenced by independent variables (cause).</li>
<li>control variable: a variable that is fixed to look into a relation between an independent variable in your interest and dependent variable.</li>
</ul></li>
<li>From the point of mathmatical view, variable types are categorized largely into 4 categories:
<ul>
<li>univariable: each subject gives rise to a single measurement of independent variable termed exploratory variable.</li>
<li>univariate: each subject gives rise to a single measurement of dependent variables termed response.</li>
<li>multivariate: each subject gives rise to a vector of measurements of independent variables termed exploratory variables.</li>
<li>multivariable: each subject gives rise to a vector of measurements of dependent variables termed responses.</li>
</ul></li>
</ul>
<section id="from-the-point-of-data-type" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="from-the-point-of-data-type"><span class="header-section-number">1.1</span> From the Point of Data Type</h2>
<section id="quantitative-variable" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="quantitative-variable"><span class="header-section-number">1.1.1</span> Quantitative Variable</h3>
<p>the values of the quantitative variables with which you can conduct arithematic operations. There are two types of quantitative variables: discrete and continuous.</p>
<section id="discrete-variables" class="level4" data-number="1.1.1.1">
<h4 data-number="1.1.1.1" class="anchored" data-anchor-id="discrete-variables"><span class="header-section-number">1.1.1.1</span> Discrete Variables</h4>
<ul>
<li>As integer, count valuess of individual items.</li>
<li>ex: number of people, number of different events, etc.</li>
</ul>
</section>
<section id="continuous-variables" class="level4" data-number="1.1.1.2">
<h4 data-number="1.1.1.2" class="anchored" data-anchor-id="continuous-variables"><span class="header-section-number">1.1.1.2</span> Continuous Variables</h4>
<ul>
<li>As real number, measurement values of continuous or uncountable values.</li>
<li>ex: height, weight, distance, volume, age, etc.</li>
</ul>
</section>
</section>
<section id="categorical-variables" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="categorical-variables"><span class="header-section-number">1.1.2</span> Categorical Variables</h3>
<p>Categorical variables contain grouping values representing categories rather than quantity. There are three types of categorical variables: binary, nominal, and ordinal variables.</p>
<section id="binary-variables" class="level4" data-number="1.1.2.1">
<h4 data-number="1.1.2.1" class="anchored" data-anchor-id="binary-variables"><span class="header-section-number">1.1.2.1</span> Binary Variables</h4>
<ul>
<li>Binary variables a.k.a dichotomous variables contain two types of values, true or false, 1 or 0<br>
</li>
<li>ex: disease/non-disease, heads/tails in flipping a coin, win/lose in a game</li>
</ul>
</section>
<section id="nominal-variables" class="level4" data-number="1.1.2.2">
<h4 data-number="1.1.2.2" class="anchored" data-anchor-id="nominal-variables"><span class="header-section-number">1.1.2.2</span> Nominal Variables</h4>
<ul>
<li>catogories with no rank or order among them.</li>
<li>ex: gender, races, colors, brands, company names</li>
</ul>
</section>
<section id="ordinal-variables" class="level4" data-number="1.1.2.3">
<h4 data-number="1.1.2.3" class="anchored" data-anchor-id="ordinal-variables"><span class="header-section-number">1.1.2.3</span> Ordinal Variables</h4>
<ul>
<li>catogories ranked in a specific order</li>
<li>ex: ranks in a game, places in a line, rating scale responses in a movie review</li>
</ul>
</section>
</section>
</section>
<section id="from-the-perspective-of-modeling" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="from-the-perspective-of-modeling"><span class="header-section-number">1.2</span> From the Perspective of Modeling</h2>
<p>Experiments or models are usually designed or built to discover what effect one variable has on another.</p>
<section id="independent-variables" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="independent-variables"><span class="header-section-number">1.2.1</span> Independent Variables</h3>
<ul>
<li>Independent variable is a variable you can set to observe an effect on the outcome of an experiment.<br>
</li>
<li>By many people, independent Variables are also commonly called predictors, explanatory variables, treatment variables, features, etc.</li>
</ul>
</section>
<section id="dependent-variables" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="dependent-variables"><span class="header-section-number">1.2.2</span> Dependent variables</h3>
<ul>
<li>Dependent variable is a variable that represents the outcome of the experiment.</li>
<li>By many people, dependent variables are also commonly called outcome variables, response variables, targets, etc.</li>
</ul>
</section>
<section id="control-variables" class="level3" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="control-variables"><span class="header-section-number">1.2.3</span> Control variables</h3>
<ul>
<li>Control variable is a variable that is held fixed throughout the experiment.</li>
<li>Positive control: a variable that is set for showing effect on the dependent variable.</li>
<li>Negative control: a variable that is set for showing no effect on the dependent variable.</li>
<li>Internal control: a variable that is set for showing effect on the dependent variable with a researcher’s certain intention.</li>
</ul>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
FYI
</div>
</div>
<div class="callout-body-container callout-body">
<p>Strictly speaking, the synonyms of independent and dependent variables are all slightly different for the different purpose.</p>
<ul>
<li>In association research, the use of the terms “dependent” and “independent” should be avoided because the research does not focus on causality between one another.<br>
</li>
<li>When the before-and-after relationship is clear, there might be cases where one variable clearly precedes the other
<ul>
<li>for example, rainfall leads to mud, rather than the other way around.</li>
<li>In these cases, you may call the rainfall a predictor and the mud an outcome variable.</li>
</ul></li>
</ul>
</div>
</div>
</section>
</section>
<section id="perspective-of-modeling" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="perspective-of-modeling"><span class="header-section-number">1.3</span> Perspective of Modeling</h2>
<p>There are largely 3 types of variables: confounders, latent variables, and composite variables</p>
<section id="confounders" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="confounders"><span class="header-section-number">1.3.1</span> Confounders</h3>
<ul>
<li>Confounding variables or confounders
<ul>
<li>Confounder is a variable that hides the true effect of another variable in an experiment by confounding the association between independent and dependent variables. This can happen when the 3rd variable has effect on both independent variable and dependent variable but the 3rd variable has not been controlled in your experiment. Confounders run a high risk of introducing a variety of research biases to your analysis result, particularly omitted variable bias.</li>
</ul></li>
<li>ex: When conducting a study on muscle mass increase for dumbbells in a gym, if gender is not included in the research model, gender is a confounder. This is because men and women have different innate muscle mass and baseline for lifting dumbbells.</li>
</ul>
</section>
<section id="latent-variables" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="latent-variables"><span class="header-section-number">1.3.2</span> Latent variables</h3>
<ul>
<li>Latent variable is a variable that can’t be measured directly but indirectly via a proxy.</li>
<li>ex: lactose tolerance of a person cannot be measured directly but indirectly inferred from measurements of a person’s can be inferred from measurements of digestion ability with biochemical metrics in a certain designed experiment.</li>
</ul>
</section>
<section id="composite-variable" class="level3" data-number="1.3.3">
<h3 data-number="1.3.3" class="anchored" data-anchor-id="composite-variable"><span class="header-section-number">1.3.3</span> Composite variable</h3>
<ul>
<li>Composite variable is a variable made by combining multiple variables of your data. These variables are created not when you measure it but when you analyze data,</li>
<li>ex: When your academic performance is measured with math, physics, literature, and writing composition, your numerical academic performance can be measured by combining math with physics, and your language academic performance by combining literature with writing composition.</li>
</ul>
</section>
</section>
<section id="from-the-point-of-mathmatical-view" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="from-the-point-of-mathmatical-view"><span class="header-section-number">1.4</span> From the point of mathmatical view</h2>
<ul>
<li>univariable: each subject gives rise to a single measurement of independent variable termed exploratory variable.</li>
<li>univariate: each subject gives rise to a single measurement of dependent variables termed response.</li>
<li>multivariate: each subject gives rise to a vector of measurements of independent variables termed exploratory variables.</li>
<li>multivariable: each subject gives rise to a vector of measurements of dependent variables termed responses.</li>
</ul>
</section>
</section>
<section id="data-type" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Data Type</h1>
<p>Data types can also be classified with various perspectives depending on research purpose:</p>
<ul>
<li>From the perspective of programming or computer science <a href="https://amplitude.com/blog/data-types">data type</a></li>
</ul>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Data Type</th>
<th>Definition</th>
<th>Examples</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Integer (int)</td>
<td>Numeric data type for numbers without fractions</td>
<td>-707, 0, 707</td>
</tr>
<tr class="even">
<td>Floating Point (float)</td>
<td>Numeric data type for numbers with fractions</td>
<td>707.07, 0.7, 707.00</td>
</tr>
<tr class="odd">
<td>Character (char)</td>
<td>Single letter, digit, punctuation mark, symbol, or blank space</td>
<td>a, 1, !</td>
</tr>
<tr class="even">
<td>String (str or text)</td>
<td>Sequence of characters, digits, or symbols—always treated as text</td>
<td>hello, +1-999-666-3333</td>
</tr>
<tr class="odd">
<td>Boolean (bool)</td>
<td>True or false values</td>
<td>0 (false), 1 (true)</td>
</tr>
<tr class="even">
<td>Enumerated type (enum)</td>
<td>Small set of predefined unique values (elements or enumerators) that can be text-based or numerical</td>
<td>rock (0), jazz (1)</td>
</tr>
<tr class="odd">
<td>Array</td>
<td>List with a number of elements in a specific order—typically of the same type</td>
<td>rock (0), jazz (1), blues (2), pop (3)</td>
</tr>
<tr class="even">
<td>Date</td>
<td>Date in the YYYY-MM-DD format (ISO 8601 syntax)</td>
<td>2021-09-28</td>
</tr>
<tr class="odd">
<td>Time</td>
<td>Time in the hh:mm:ss format for the time of day, time since an event, or time interval between events</td>
<td>12:00:59</td>
</tr>
<tr class="even">
<td>Datetime</td>
<td>Date and time together in the YYYY-MM-DD hh:mm:ss format</td>
<td>2021-09-28 12:00:59</td>
</tr>
<tr class="odd">
<td>Timestamp</td>
<td>Number of seconds that have elapsed since midnight (00:00:00 UTC), 1st January 1970 (Unix time)</td>
<td>1632855600</td>
</tr>
</tbody>
</table>
<ul>
<li>From the perspective of data measurement
<ul>
<li>longitudinal (or repeated) data: Each subject gives rise to a vector of measurements, but these represent the same response measured at a sequence of observation times</li>
<li>cross-sectional data : Outcome variable(s) and covariates that are measured at a single time point</li>
</ul></li>
</ul>
<section id="from-the-perspective-of-data-measurement" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="from-the-perspective-of-data-measurement"><span class="header-section-number">2.1</span> From the perspective of data measurement</h2>
<section id="longitudinal-or-repeated-data" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="longitudinal-or-repeated-data"><span class="header-section-number">2.1.1</span> Longitudinal (or repeated) Data</h3>
</section>
<section id="cross-sectional-data" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="cross-sectional-data"><span class="header-section-number">2.1.2</span> Cross-sectional Data</h3>
</section>
</section>
</section>
<section id="refrences" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Refrences</h1>
<ul>
<li><a href="https://www.scribbr.com/methodology/types-of-variables/">Scribbr</a></li>
</ul>
</section>
</div>
</div>
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">

</div>
</div>
<section id="go-to-content-list" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Go to Content List</h1>
<ul>
<li><a href="./docs/projects/index.qmd">Project Content List</a></li>
<li><a href="./docs/blog/posts/content_list.qmd">Blog Content List</a></li>
</ul>


</section>

</div></ul> ]]></description>
  <category>template</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/variables/index.html</guid>
  <pubDate>Wed, 22 Mar 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Storage and Database</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Engineering/2023-03-02_aws/storage_database.html</link>
  <description><![CDATA[ 



<ul class="nav nav-pills" id="language-tab">
<li class="nav-item">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<section id="storage-on-aws" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="storage-on-aws"><span class="header-section-number">1</span> Storage on AWS</h2>
<section id="storage-types-of-aws" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="storage-types-of-aws"><span class="header-section-number">1.1</span> Storage Types of AWS</h3>
<ul>
<li>Storage Types <img src="kmink3225.netlify.app/images/aws/storage_types.PNG" class="img-fluid" alt="Storage Types: Block Storage vs Object Storage">
<ul>
<li>Block Storage: split into fixed size chunk of data
<ul>
<li>easy to change small parts: change only block/piece of the data</li>
<li>for frequently modified data, or data with a high trasaction rate (like app or system files)</li>
</ul></li>
<li>Object Storage: each file = single unit of data
<ul>
<li>to change even small parts: need to update the entire file</li>
<li>for WORM(write once, read many) model
<ul>
<li>accessed often, but modified rarely (like photo)</li>
</ul></li>
</ul></li>
<li>File Storage: tree-like hierarchy (folders → subfolders)
<ul>
<li>similar to windows file explorer or MacOS Finder</li>
<li>for files shared/managed by multiple host computers
<ul>
<li>user home directories, developmental environments</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="amazon-ec2-instance-storage-and-amazon-elastic-block-store" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="amazon-ec2-instance-storage-and-amazon-elastic-block-store"><span class="header-section-number">2</span> Amazon EC2 Instance Storage and Amazon Elastic Block Store</h2>
<ul>
<li>block storage
<ul>
<li>boot volume for OS or data volume</li>
</ul></li>
<li>block storages for EC2 instances</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="kmink3225.netlify.app/images/aws/amazone EC2 Instance.PNG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">block storages for EC2 instances with EBS</figcaption><p></p>
</figure>
</div>
<ul>
<li>EC2 instance store: internal storage, ephemeral storage
<ul>
<li>directly(physically) attached: fast, quick response</li>
<li>life cycle is tied to the instance: lose data when stop/terminate the instance</li>
</ul></li>
<li>Amazon Elastic Block Store(Amazon EBS): external storage, persistent storage
<ul>
<li>separate from EC2, user-configured size</li>
<li>one-to-one with EC2 instances (can’t be shared/attached to multiple instances): secure communication
<ul>
<li>can be detached → attached to another instance in the same AZ</li>
<li>for multiple attachements: need to use Amazon EBS Multi-Attach</li>
</ul></li>
<li>Types of EBS
<ul>
<li>SSD backed volumes: for random I/O</li>
<li>HDD backed volumes: for sequential I/O</li>
</ul></li>
<li>backing up data: (EBS)Snapshot</li>
</ul></li>
</ul>
</section>
<section id="object-storage-with-amazon-s3" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="object-storage-with-amazon-s3"><span class="header-section-number">3</span> Object Storage with Amazon S3</h2>
<ul>
<li>for employee photos: can’t use amazon EBS
<ul>
<li>can’t be attached to instances when the app scales</li>
<li>has size limitations</li>
</ul></li>
<li>amazon simple storage service(Amazon S3)
<ul>
<li>standalone, don’t mount onto EC2 instances</li>
<li>access data through URL: storage for the internet<br>
</li>
<li>size limit for a single object: 5Tb</li>
<li>flat structure: use unique identifiers(?)</li>
<li>distributed storage: store data across multiple different facilities within one AWS region
<ul>
<li>durable storage system</li>
</ul></li>
</ul></li>
<li>S3 buckets: objects is stored in buckets
<ul>
<li>need to create buckets first</li>
<li>can make folders inside</li>
<li>region specific</li>
<li>name: should be globally unique across AWS accounts, DNS compliant (no special characters, spaces, etc.)<br>
</li>
<li>URL will be constructed using the name → should be reached with HTTP/HTTPS
<ul>
<li>bucket URL → append object key to bucket URL</li>
</ul>
<img src="kmink3225.netlify.app/images/aws/bucket URL.PNG" title="fig:" class="img-fluid" alt="Bucket URL"></li>
</ul></li>
<li>Accesss control
<ul>
<li>default: everything in S3 is private → can give public access<br>
</li>
<li>to make object publically access, need to change bucket settings</li>
</ul></li>
<li>policies&nbsp;
<ul>
<li>IAM policies</li>
<li>S3 bucket policies
<ul>
<li>JSON format (like IAM policies)</li>
<li>only placed on buckets (can apply for another AWS accounts or anonymous users)
<ul>
<li>not for folders/objects</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="databases-on-aws" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="databases-on-aws"><span class="header-section-number">4</span> Databases on AWS</h2>
<ul>
<li><p>Relational database(RDB): data를 table 형태로 저장, 서로 다른 table간 data는 relationship으로 연결됨</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="kmink3225.netlify.app/images/aws/RDB.PNG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">RDB</figcaption><p></p>
</figure>
</div>
<ul>
<li>Table은 row와 column으로 구성</li>
<li>row는 record라고도 부르며 특정 개체에 관련된 모든 정보를 담고 있음</li>
<li>column은 attribute라고도 부르며 개체의 각 속성을 나타냄</li>
</ul></li>
<li><p>Schema: 각 table 별 관계 및 column에 들어갈 data type 등을 정의한 것</p>
<ul>
<li>schema는 한 번 설정하고 나면 변경하기 어려움</li>
<li>예시: MySQL, PostgresQL, Oracle, SQL server, Amazon Aurora</li>
<li>일반적으로 SQL query를 사용해서 data 접근 및 수정</li>
</ul></li>
<li><p>장점</p>
<ul>
<li>Joins: table을 join하여 data간 관계를 쉽게 이해 가능</li>
<li>Reduced redundancy: 일부 attribute만 다른 경우 table을 나누어 중복 정보가 저장되는 것을 방지할 수 있음</li>
<li>Familiarity: 오래된 기술이기 때문에 자료가 많아서 적응하기 쉬움</li>
<li>Accuracy: data의 안정성 및 결과 보장 <a href="https://ko.wikipedia.org/wiki/ACID">참고</a><br>
</li>
</ul></li>
<li><p>사용처</p>
<ul>
<li>Schema가 거의 변경되지 않는 application들</li>
<li>작업 및 data의 안정성이 필요한 분야 전반</li>
<li>Enterprise Resource Planning (ERP) applications</li>
<li>Customer Relationship Management (CRM) applications</li>
<li>Commerce and financial applications</li>
</ul></li>
<li><p>RDB on AWS</p>
<ul>
<li><p>Managed database: EC2 or AWS database service</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="kmink3225.netlify.app/images/aws/EC2 or AWS database service.PNG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">EC2 or AWS database service</figcaption><p></p>
</figure>
</div></li>
</ul></li>
<li><p>Amazon RDS: AWS에서 제공하는 RDB service</p>
<ul>
<li><strong>Commercial:</strong> Oracle, SQL Server</li>
<li><strong>Open Source:</strong> MySQL, PostgreSQL, MariaDB</li>
<li><strong>Cloud Native:</strong> Amazon Aurora&nbsp;<strong>Note:</strong> The cloud native option, Amazon Aurora, is a MySQL and PostgreSQL-compatible database built for the cloud. It is more durable, more available, and provides faster performance than the Amazon RDS version of MySQL and PostgreSQL</li>
</ul></li>
<li><p>DB instance type - 아래 type 내에서 size 별 선택지 존재</p>
<ul>
<li><strong>Standard</strong>, which include general-purpose instances</li>
<li><strong>Memory Optimized</strong>, which are optimized for memory-intensive applications</li>
<li><strong>Burstable Performance</strong>, which provides a baseline performance level, with the ability to burst to full CPU usage.</li>
</ul></li>
<li><p>DB storage - the DB instance uses <strong>Amazon Elastic Block Store (EBS)</strong> volumes as its storage layer</p>
<ul>
<li>용량: 20~65536Gb</li>
<li>General purpose (SSD)</li>
<li>Provisioned IOPS (SSD)</li>
<li>Magnetic storage (not recommended)</li>
</ul></li>
<li><p>DB subnet group</p>
<ul>
<li>DB를 사용하기 위해서 <strong>VPC</strong> 및 <strong>subnet</strong> 설정 필요&nbsp;=&gt; availability zone 내 subnet 지정 필요</li>
<li>DB subnet은 <strong>private</strong>해야 됨 - gateway에 직접 연결 금지 for 보안</li>
<li>보안의 경우 ACL 및 security group으로 통제 가능 - network section 참고</li>
</ul></li>
<li><p>IAM policy</p>
<ul>
<li>DB subnet group은 traffic을 조절</li>
<li>IAM policy는 data와 table에 대한 접근 및 수정 권한을 조절</li>
</ul></li>
<li><p>Backup</p>
<ul>
<li>Automatic
<ul>
<li>default로 설정</li>
<li>log 및 DB instance 자체를 백업</li>
<li>주기: 0~35일&nbsp;<strong>0일의 경우 automatic 백업을 disable, 기존 backup도 삭제됨</strong></li>
<li>방식: point-in-time&nbsp;=&gt; 특정 기간 내 일어난 transaction에 대해서 recovery</li>
</ul></li>
<li>Manual snapshot
<ul>
<li>35일보다 긴 기간에 대해 backup할 때 사용</li>
</ul></li>
<li>Backup recovery: 새 instance를 생성</li>
</ul></li>
<li><p>Redundancy</p>
<ul>
<li>Multi-AZ를 허용할 경우, Amazon RDS가 다른 AZ에 redundant copy 생성</li>
<li>Primary copy: 평소에 사용하는 copy</li>
<li>Standby copy: primary copy에 접근이 불가한 경우 사용하는 copy</li>
<li>두 copy간 싱크로는 자동 유지</li>
<li>DB instance 생성시 DNS를 설정하면 AWS가 이를 인식하여 자동으로 failover 수행</li>
<li>Redundant copy는 subnet에 존재해야 됨</li>
</ul></li>
<li><p><strong>Amazon DynamoDB</strong></p>
<ul>
<li>Fully managed NoSQL database service: provides fast and predictable performance with seamless scalability</li>
<li><strong>Serverless</strong>
<ul>
<li>RDB와 달리 size 제한 없음</li>
<li>자동 scale 조절</li>
<li>SSD에 자동 저장되며 replication 또한 자동 수행</li>
<li>No schema</li>
</ul></li>
</ul></li>
<li><p><strong>저장된 데이터 양과 접근 횟수에 따라 과금</strong></p></li>
<li><p>구성 요소</p>
<ul>
<li>Table: RDB와 유사하게 item의 집합으로 구성</li>
<li>Item: 다른 item과 unique하게 구분가능한 data, 개수 제한 없음, attribute의 조합으로 구성됨, RDB와 달리 <strong>각 item의 attribute 개수가 다를 수 있음</strong>&nbsp;RDB의 row에 대응</li>
<li>Attribute: RDB와 달리 같은 attribute라도 <strong>다양한 type</strong>의 정보를 저장할 수 있음?&nbsp;RDB의 column에 대응</li>
</ul></li>
<li><p><strong>AWS Database Services </strong></p></li>
</ul>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Database Type</th>
<th>Use Cases</th>
<th>AWS Service</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Relational</td>
<td>Traditional applications, ERP, CRM, e-commerce</td>
<td>Amazon RDS, Amazon Aurora, Amazon Redshift</td>
</tr>
<tr class="even">
<td>Key-value</td>
<td>High-traffic web apps, e-commerce systems, gaming applications</td>
<td>Amazon DynamoDB</td>
</tr>
<tr class="odd">
<td>In-memory</td>
<td>Caching, session management, gaming leaderboards, geospatial applications</td>
<td>Amazon ElastiCache for Memcached, Amazon ElastiCache for Redis</td>
</tr>
<tr class="even">
<td>Document</td>
<td>Content management, catalogs, user profiles</td>
<td>Amazon DocumentDB (with MongoDB compatibility)</td>
</tr>
<tr class="odd">
<td>Wide column</td>
<td>High-scale industrial apps for equipment maintenance, fleet management, and route optimization</td>
<td>Amazon Keyspaces (for Apache Cassandra)</td>
</tr>
<tr class="even">
<td>Graph</td>
<td>Fraud detection, social networking, recommendation engines</td>
<td>Amazon Neptune</td>
</tr>
<tr class="odd">
<td>Time series</td>
<td>IoT applications, DevOps, industrial telemetry</td>
<td>Amazon Timestream</td>
</tr>
<tr class="even">
<td>Ledger</td>
<td>Systems of record, supply chain, registrations, banking transactions</td>
<td>Amazon QLDB</td>
</tr>
</tbody>
</table>
<ul>
<li>선택 기준
<ul>
<li>RDB: 데이터 간 관계가 복잡하고 별도 관리가 필요한 경우에 사용&nbsp;복잡도에 의해 overhead가 발생하기 때문</li>
<li>Key-value DB: Large scale, low latency 보장, 단순 데이터 저장 및 조회 목적으로 적합&nbsp;=&gt; RDB에서는 여러 table에 나누어 저장해야 되는 정보를 한 table에 저장 가능</li>
<li>Graph: SNS와 같은 관계형 자료구조에 적합</li>
<li>Ledger: 금융과 같은 안정성, 변경 불가가 필요한 자료를 저장하는 경우에 적합</li>
</ul></li>
</ul>
</section>
</div>
</div>
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">

</div>
</div>
<section id="back-to-content-list" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="back-to-content-list"><span class="header-section-number">5</span> Back to Content List</h2>
<ul>
<li><a href="../../../../../docs/blog/posts/content_list.html">Global Blog Content List</a></li>
</ul>


</section>

</div></ul> ]]></description>
  <category>Engineering</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Engineering/2023-03-02_aws/storage_database.html</guid>
  <pubDate>Fri, 17 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/images/aws/storage_types.PNG" medium="image"/>
</item>
<item>
  <title>Differentiation - Higher Order Derivative</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/differentiation/2023-03-18_higher_order_derivative.html</link>
  <description><![CDATA[ 



<ul class="nav nav-pills" id="language-tab">
<li class="nav-item">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<div id="def-second_derivative" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 </strong></span>미분 가능한 함수 <img src="https://latex.codecogs.com/png.latex?f(x)"> 의 <img src="https://latex.codecogs.com/png.latex?f'(x)"> 가 존재할 때, <img src="https://latex.codecogs.com/png.latex?f'(x)"> 의 도함수 <img src="https://latex.codecogs.com/png.latex?(f'(x))'"> 를 <img src="https://latex.codecogs.com/png.latex?%0Af%5E%7B''%7D(x),%20%5Cfrac%7Bd%5E2f(x)%7D%7Bdx%5E2%7D,%20%5Ctext%7B%20or%20%7D%20%5Cfrac%7Bd%5E2y%7D%7Bdx%5E2%7D%0A"> 라 표기하고 <img src="https://latex.codecogs.com/png.latex?f(x)"> 의 2차 도함수 or second derivative라고 한다.</p>
<p>같은 방법으로, <img src="https://latex.codecogs.com/png.latex?n"> 차 도함수 <img src="https://latex.codecogs.com/png.latex?f%5E%7B(n)%7D(x)"> or <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bd%5Enf(x)%7D%7Bdx%5En%7D"> 가 정의 된다.</p>
</div>
</section>
<section id="example" class="level2">
<h2 class="anchored" data-anchor-id="example">Example</h2>
<p>다음의 <img src="https://latex.codecogs.com/png.latex?n"> 차 도함수</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?f(x)=x%5E%7B%5Calpha%7D%20%5Ctext%7B%20%7D%20(x%3E0,%20%5Calpha%20%5Cne%20-1)"></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20f'(x)&amp;=%5Calpha%20x%5E%7B%5Calpha-1%7D%5C%5C%0A%20%20%20%20f%5E%7B''%7D(x)&amp;=%5Calpha(%5Calpha-1)%20x%5E%7B%5Calpha-2%7D%5C%5C%0A%20%20%20%20&amp;%5Cvdots%5C%5C%0A%20%20%20%20f%5E%7Bn%7D(x)&amp;=%5Calpha(%5Calpha-1)%5Ccdots(%5Calpha-(n-1))%20x%5E%7B%5Calpha-n%7D%0A%5Cend%7Baligned%7D%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?f(x)=ln(1+x)"></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20f'(x)&amp;=%5Cfrac%7B1%7D%7B1+x%7D%5C%5C%0A%20%20%20%20f%5E%7B''%7D(x)&amp;=-%5Cfrac%7B1%7D%7B(1+x)%5E2%7D%5C%5C%0A%20%20%20%20f%5E%7B3%7D(x)&amp;=(-1)%5E2%5Cfrac%7B1%20%5Ccdot%202%20%7D%7B(1+x)%5E3%7D%5C%5C%0A%20%20%20%20&amp;%5Cvdots%5C%5C%0A%20%20%20%20f%5E%7Bn%7D(x)&amp;=(-1)%5E%7Bn-1%7D%5Cfrac%7B(n-1)!%7D%7B(1+x)%5En%7D%5C%5C%0A%5Cend%7Baligned%7D%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?f(x)=%5Csin(x)"></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20f'(x)&amp;=%5Ccos(x)=%5Csin(x+1%5Ccdot%5Cfrac%7B%5Cpi%7D%7B2%7D)%5C%5C%0A%20%20%20%20f%5E%7B2%7D(x)&amp;=(-1)%5Csin(x)=%5Csin(x+2%5Ccdot%5Cfrac%7B%5Cpi%7D%7B2%7D)%5C%5C%0A%20%20%20%20f%5E%7B3%7D(x)&amp;=-%5Ccos(x)=%5Csin(x+3%5Ccdot%5Cfrac%7B%5Cpi%7D%7B2%7D)%5C%5C%0A%20%20%20%20f%5E%7B4%7D(x)&amp;=(-1)%5E2%5Csin(x)=%5Csin(x+4%5Ccdot%5Cfrac%7B%5Cpi%7D%7B2%7D)%5C%5C%0A%20%20%20%20&amp;%5Cvdots%5C%5C%0A%20%20%20%20f%5E%7Bn%7D(x)&amp;=%5Csin(x+n%5Ccdot%5Cfrac%7B%5Cpi%7D%7B2%7D)%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="mean-value-theorem" class="level2">
<h2 class="anchored" data-anchor-id="mean-value-theorem">Mean Value Theorem</h2>
<div id="thm-mvt" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 </strong></span>If A function <img src="https://latex.codecogs.com/png.latex?f(x)"> is differentiable on <img src="https://latex.codecogs.com/png.latex?%5C%5Ba,b%5C%5D">, then there exists <img src="https://latex.codecogs.com/png.latex?c%20%5Cin%20(a,b)"> such that <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20%5Cfrac%7Bf(b)-f(a)%7D%7Bb-a%7D%20=%20f'(c),%20(a%3Cc%3Cb)%0A%5Cend%7Baligned%7D%0A"></p>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="https://commons.wikimedia.org/w/index.php?curid=1039489" class="img-fluid"></p>
<p></p><figcaption class="figure-caption">By 4C - 자작, based on PNG version, CC BY-SA 3.0</figcaption><p></p>
</figure>
</div>
<section id="example-1" class="level3">
<h3 class="anchored" data-anchor-id="example-1">Example</h3>
</section>
</section>
</div>
</div>
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">

</div>
</div>
<section id="blog-guide-map-link" class="level2">
<h2 class="anchored" data-anchor-id="blog-guide-map-link">Blog Guide Map Link</h2>
<ul>
<li><a href="../../../../../docs/blog/posts/statistics/guide_map/index.html">Statistics Blog</a></li>
<li><a href="../../../../../docs/blog/posts/Engineering/guide_map/index.html">Engineering Blog</a></li>
<li><a href="../../../../../docs/blog/posts/DL/guide_map/index.html">Deep Learning Blog</a></li>
<li><a href="../../../../../docs/blog/posts/ML/guide_map/index.html">Machine Learning Blog</a></li>
<li><a href="../Mathmatics/guide_map/index.qmd">Mathematics Blog</a></li>
<li><a href="../../../../../docs/blog/posts/Patent/guide_map/index.html">Patent Blog</a></li>
<li><a href="../../Validation/guide_map/index.qmd">Validation Blog</a></li>
</ul>


</section>

</div></ul> ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/differentiation/2023-03-18_higher_order_derivative.html</guid>
  <pubDate>Fri, 17 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="https://commons.wikimedia.org/w/index.php?curid=1039489" medium="image"/>
</item>
<item>
  <title>Categorical Data Analysis</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/statistics/categorical_data/2023-03-17_introduction/index.html</link>
  <description><![CDATA[ 



<ul class="nav nav-pills" id="language-tab">
<li class="nav-item">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<section id="goal" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="goal"><span class="header-section-number">1</span> Goal</h2>
<ul>
<li>Visualization Methods
<ul>
<li>for EDA: visualize patterns, trends, anomalies in data</li>
<li>for model diagnostic methods: visualize to assess violations of assumptions</li>
<li>for summary methods: visualize to provide an interpretable summary of data</li>
</ul></li>
<li>apply theory to practice
<ul>
<li>conert research questions into statistical hypotheses and models</li>
<li>look into the difference between non-parametric (ex. fisher exact test) vs parametric (ex. <img src="https://latex.codecogs.com/png.latex?%5Cchi%5E2%20test%20for%20independence">) vs model-based methods (ex. logistic regression)</li>
<li>for summary methods: visualize to provide an interpretable summary of data</li>
</ul></li>
</ul>
</section>
<section id="definition-of-categorical-data" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="definition-of-categorical-data"><span class="header-section-number">2</span> Definition of Categorical Data</h2>
<ul>
<li>categorical (or frequency) data consist of a discrete set of categories, which may be ordered or unordered.
<ul>
<li>unordered
<ul>
<li>gener: {male, female, transgender}</li>
<li>marital status: {never married, married, separated, divorced, widowed}</li>
<li>party preference: {NDP, liberal, conservative, green}</li>
<li>treatment improvement: {none, some, marked}</li>
</ul></li>
<li>ordered
<ul>
<li>age group: {0s,10s,20s,30s, …}</li>
<li>number of children: {0, 1 , 2 ,3, …} ## Structures</li>
</ul></li>
</ul></li>
</ul>
<p>Categorical data appears in various forms like:</p>
<ul>
<li><p>tables</p>
<ul>
<li><p>one way</p></li>
<li><p>two way</p></li>
<li><p>three way</p></li>
</ul></li>
<li><p>matrices</p></li>
<li><p>array</p></li>
<li><p>data frames</p>
<ul>
<li><p>case form</p></li>
<li><p>frequency form</p></li>
</ul></li>
<li></li>
</ul>
</section>
</div>
</div>
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">

</div>
</div>



</div></ul> ]]></description>
  <category>template</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/statistics/categorical_data/2023-03-17_introduction/index.html</guid>
  <pubDate>Thu, 16 Mar 2023 15:00:00 GMT</pubDate>
</item>
</channel>
</rss>
