# 데이터 표준화 프레임워크 아키텍쳐

```{mermaid}
graph TB
    subgraph "Input Layer"
        A[최초 표준화 데이터<br/>테이블/컬럼] --> B[DataLoader]
        A1[사용자 논리명 입력<br/>Streamlit UI] --> B
        A2[코드 스니펫<br/>Streamlit UI] --> B
    end
    
    subgraph "Processing Layer"
        B -->|논리명| C[TokenProcessor<br/>토큰 분석]
        C --> |단어|D[Domain NLP Engine<br/>KoBERT<br/>도메인 분류]
        D --> E[AbbreviationManager<br/>규칙 기반 약어 생성]
        
        RAG[RAG System<br/>표준화 규칙 검색<br/>+ GPT-4o 추천]
        NLP[Terminology NLP Engine<br/> Pre-trained Model KoSRoBERTa<br/> 단어/용어 클러스터링]
        
        RAG --> C
        D -->|단어| NLP
    end

    B --> |코드 스니펫| RAG
    B --> |논리명| NLP

    subgraph "Actors"
        DBA[DBA]
        DS[Data Steward]
        SD[개발자/사용자]
    end

    NLP --> DS
    DS --> MD

    subgraph "Metadata Management Layer"
        MD[통합 사전<br/>단어/도메인/코드/용어]
        E --> MD
        MD --> F[RuleAnalyzer<br/>일관성 검증]
        MD --> H[DataCompletenessAnalyzer<br/>완전성 검증]
    end
    
    subgraph "Analysis Layer"
        F --> G[ReportGenerator<br/>종합 분석 보고]
        H --> G
        NLP --> G
        RAG --> REC[논리명 추천]
        E --> ABR[약어 생성]
    end
    
    subgraph "Output Layer"
        G --> UI1[검증 결과 대시보드]
        REC --> UI2[논리명 추천 탭]
        ABR --> UI3[약어 생성 탭]
    end
    
    %% 스타일링
    style A fill:#e1f5fe
    style A1 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style A2 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style RAG fill:#fff8e1,stroke:#ff8f00,stroke-width:3px
    style NLP fill:#e8f5e8,stroke:#388e3c,stroke-width:3px
    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px
    style E fill:#4caf50,stroke:#2e7d32,stroke-width:3px
    style MD fill:#fce4ec,stroke:#ad1457,stroke-width:2px
    style G fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style UI1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style UI2 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style UI3 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px

```

### NLP Engine Domain Classifier

```{mermaid}
graph TB
    subgraph DS ["Data Sources"]
        A["표준화 원칙 PDF<br/>200개 규칙"] --> B["LLM<br/>Claude 4 Sonnet"]
        A1["표준 단어 사전<br/>14그룹 분류"] --> C["Domain Generator<br/>템플릿 기반"]
        A2["기존 도메인 사전<br/>중복 검증용"] --> C
    end

    subgraph TDG ["Training Data Pipeline"]
        B -->|2,868개| D["domain_data.parquet<br/>구조화 데이터"]
        C -->|2,800개| E["generated.parquet<br/>균등 분포"]
        D --> F["Parquet Merger<br/>스키마 통합"]
        E --> F
        F -->|중복 제거| I["training_dataset<br/>5,632개 최종"]
    end

    subgraph ML ["NLP Model Architecture"]
        I --> J["KoBERT Tokenizer<br/>vocab_size=8,002<br/>max_length=32"]
        J --> K["KoBERT Encoder<br/>monologg/kobert<br/>768 hidden_size"]
        K --> L["Pooler Output<br/>[CLS] token"]
        L --> M["Dropout Layer<br/>dropout=0.3"]
        M --> N["Linear Classifier<br/>768 → 14 classes"]
        N --> Q["AdamW Optimizer<br/>lr=2e-5, batch=64"]
    end

    subgraph EVAL ["Model Performance"]
        Q --> R1["Train Acc: 94.18%"]
        Q --> R2["Test Acc: 95.39%"]
        Q --> R3["F1-Score: 0.94"]
    end

    subgraph DEPLOY ["Model Deployment"]
        R1 --> S["kobert_classifier.pth<br/>모델 저장"]
        S --> T["Inference Function<br/>단일 도메인 예측"]
        T --> U["Classification Result<br/>클래스 + 신뢰도"]
        S -.->|구현 예정| V["Streamlit Web App<br/>실시간 분류 인터페이스"]
        V -.-> W["웹 기반 분류 서비스<br/>CSV 업로드 + 시각화"]
    end

    CT["14개 도메인 그룹"]

    %% 연결선 및 데이터 흐름
    N -.->|분류 대상| CT
    I -.->|균등 분포 보장| R2
    C -.->|템플릿 다양성| R3

    %% 스타일링
    classDef dataSource fill:#e1f5fe
    classDef pipeline fill:#f3e5f5
    classDef model fill:#e8f5e8
    classDef eval fill:#fff3e0
    classDef deploy fill:#fce4ec

    class A,A1,A2,B,C dataSource
    class D,E,F,I pipeline
    class J,K,L,M,N,Q model
    class R1,R2,R3 eval
    class S,T,U,V,W deploy
```

### NLP Engine Terminology Clustering

```{mermaid}
graph TB
    subgraph INPUT ["Data Input"]
        A["Excel 메타데이터<br/>용어 사전 작업용_labIDE.xlsx"]
        A1["속성명_수정<br/>컬럼 메타데이터"]
        A2["테이블명_수정<br/>테이블 메타데이터"]
        
        A --> A1
        A --> A2
    end

    subgraph PREP ["Term Preprocessing"]
        B["Term Extraction<br/>한글/영문/물리명 분리"]
        C["Data Cleaning<br/>중복 제거, 빈 값 필터링"]
        D["Term Standardization<br/>5,000+ 용어 정제"]
        
        A1 --> B
        A2 --> B
        B --> C
        C --> D
    end

    subgraph EMBED ["Embedding Generation"]
        E["SentenceTransformer<br/>jhgan/ko-sroberta-multitask"]
        F["Batch Processing<br/>batch_size=32"]
        G["Vector Generation<br/>768-dim embeddings"]
        
        D --> E
        E --> F
        F --> G
    end

    subgraph CLUSTER ["Clustering Pipeline"]
        H["Similarity Calculation<br/>Cosine Similarity Matrix"]
        I["HDBSCAN Clustering<br/>min_cluster_size=2"]
        J["Agglomerative Clustering<br/>Alternative Method"]
        
        G --> H
        H --> I
        H --> J
    end

    subgraph ANALYSIS ["Cluster Analysis"]
        K["Representative Term<br/>Selection Logic"]
        L["Similarity Scoring<br/>Intra-cluster Coherence"]
        M["Term Type Analysis<br/>Korean/English/Physical"]
        N["System Distribution<br/>Cross-system Mapping"]
        
        I --> K
        J --> K
        K --> L
        L --> M
        M --> N
    end

    subgraph OUTPUT ["Results & Visualization"]
        O["Excel Export<br/>4개 시트 결과"]
        P["Cluster Summary<br/>표준화 추천안"]
        Q["Visualization<br/>분포 차트"]
        R["Similar Term Search<br/>Query Interface"]
        
        N --> O
        O --> P
        P --> Q
        Q --> R
    end

    %% 연결선
    G -.->|임베딩 벡터| H
    I -.->|클러스터 라벨| K
    K -.->|대표 용어| P

    %% 스타일링
    classDef inputBox fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    classDef prepBox fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef embedBox fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef clusterBox fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef analysisBox fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    classDef outputBox fill:#e0f2f1,stroke:#00695c,stroke-width:2px

    class A,A1,A2 inputBox
    class B,C,D prepBox
    class E,F,G embedBox
    class H,I,J clusterBox
    class K,L,M,N analysisBox
    class O,P,Q,R outputBox
```


### 통합 NLP 메타데이터 표준화 플랫폼

```{mermaid}
graph TB
    subgraph INPUT ["Data Sources"]
        A1["표준화 원칙 PDF<br/>200개 규칙"]
        A2["표준 단어 사전<br/>14그룹 분류"]
        A3["Excel 메타데이터<br/>용어 사전 작업용"]
        A4["기존 도메인 사전<br/>중복 검증용"]
    end

    subgraph DATAPREP ["Data Preparation"]
        subgraph TRAIN_DATA ["Training Data Generation"]
            B1["LLM Data Generator<br/>Claude 4 Sonnet"]
            B2["Domain Generator<br/>템플릿 기반"]
            B4["Data Merger<br/>스키마 통합"]
            
            A1 --> B1
            A2 --> B2
            A4 --> B2
            B1 --> B4
            B2 --> B4
        end
        
        subgraph REAL_DATA ["Operational Data Processing"]
            B3["Term Extractor<br/>한글/영문/물리명"]
            B5["Data Cleaning<br/>중복 제거, 정제"]
            
            A3 --> B3
            B3 --> B5
        end
    end

    subgraph PROCESSING ["Parallel NLP Processing"]
        subgraph DOMAIN ["Domain Classification Model"]
            C1["Training Dataset<br/>5,632개 생성 도메인"]
            C2["KoBERT Classifier<br/>768→14 classes"]
            C3["Model Training<br/>95.39% 정확도"]
            C4["New Domain Prediction<br/>신규 도메인 분류"]
            
            C1 --> C2 --> C3 --> C4
        end
        
        subgraph CLUSTER ["Advanced Term Clustering"]
            D1["Real Term Dataset<br/>1,000+ 운영 용어"]
            D2["SentenceTransformer<br/>ko-sroberta-multitask"]
            D3["Multi-Method Clustering<br/>HDBSCAN + Agglomerative"]
            D4["Dimensionality Reduction<br/>t-SNE, UMAP, PCA"]
            D5["Advanced Analytics<br/>네트워크 분석 + 품질 메트릭"]
            
            D1 --> D2 --> D3 --> D4 --> D5
        end
    end

    subgraph INTEGRATION ["Results Integration"]
        E1["Domain Classification<br/>신규 용어 그룹 예측"]
        E2["Interactive Visualization<br/> 대시보드 + 네트워크"]
        E3["Quality Metrics<br/>실루엣 점수 + 클러스터 품질"]
        E4["Standardization Engine<br/>통합 표준화 권장안"]
        
        C4 --> E1
        D5 --> E2
        E2 --> E3
        E1 --> E4
        E3 --> E4
    end

    subgraph DEPLOYMENT ["Advanced Visualization & Export"]
        F1["ML Model Storage<br/>kobert_classifier.pth"]
        F2["Interactive Dashboard<br/>Plotly HTML + 워드클라우드"]
        F3["Network Visualization<br/>유사도 네트워크 그래프"]
        F4["Streamlit Web Platform<br/>통합 NLP 분석 도구"]
        F5["Multi-format Export<br/>Excel + HTML + 시각화"]
        
        E1 --> F1
        E2 --> F2
        E2 --> F3
        F1 --> F4
        F2 --> F4
        F3 --> F4
        F4 --> F5
    end

    %% 데이터 흐름
    B4 --> C1
    B5 --> D1
    E1 -.->|분류 모델| E4
    E2 -.->|시각화 분석| E3
    E3 -.->|품질 검증| E4

    %% 스타일링
    classDef inputStyle fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    classDef prepStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef domainStyle fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef clusterStyle fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef integrationStyle fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    classDef deployStyle fill:#e0f2f1,stroke:#00695c,stroke-width:2px

    class A1,A2,A3,A4 inputStyle
    class B1,B2,B3,B4,B5 prepStyle
    class C1,C2,C3,C4 domainStyle
    class D1,D2,D3,D4,D5 clusterStyle
    class E1,E2,E3,E4 integrationStyle
    class F1,F2,F3,F4,F5 deployStyle
```

### 표준화 품질 평가 시스템 아키텍쳐

```{mermaid}
graph TB
    %% Main Entry Point
    Main[DataStandardizationAnalyzer<br/>메인 분석기]
    
    %% Core Processing Classes
    DataLoader[DataLoader<br/>데이터 로더]
    TokenProcessor[TokenProcessor<br/>토큰 처리기]
    AbbreviationManager[AbbreviationManager<br/>약어 관리자]
    RuleAnalyzer[RuleAnalyzer<br/>규칙 분석기]
    
    %% Rule Checker Classes
    subgraph RuleCheckers["규칙 검증기들"]
        
    end
    
    %% Analysis Classes
    CompletenessAnalyzer[CompletenessAnalyzer<br/>완전성 분석기]
    VocabularyAnalyzer[VocabularyAnalyzer<br/>어휘 분석기]
    
    %% Output Classes
    ReportGenerator[ReportGenerator<br/>보고서 생성기]
    TroubleShooting[TroubleShooting<br/>디버깅 도구]
    
    %% Data Structures
    subgraph DataStructures["데이터 구조"]
        EntityInfo[EntityInfo<br/>엔티티 정보]
        RuleViolation[RuleViolation<br/>규칙 위반 정보]
        TokenAnalysis[TokenAnalysis<br/>토큰 분석 결과]
    end
    
    %% Enums
    subgraph Enums["열거형"]
        AbbreviationStrategy[AbbreviationStrategy<br/>약어 생성 전략]
        DuplicateResolutionStrategy[DuplicateResolutionStrategy<br/>중복 해결 전략]
    end
    
    %% External Data
    ExcelFile[(Excel File<br/>논리명 취합 데이터)]
    DomainDict[(Domain Dictionary<br/>도메인 사전)]
    
    %% Output Files
    Results[(분석 결과<br/>Excel/Text Files)]
    GlossaryDict[(용어사전<br/>Glossary Dictionary)]
    
    %% Main Flow
    Main --> DataLoader
    Main --> RuleAnalyzer
    Main --> CompletenessAnalyzer
    Main --> ReportGenerator
    Main --> TroubleShooting
    
    %% Data Loading
    ExcelFile --> DataLoader
    DataLoader --> |테이블/컬럼 데이터| RuleAnalyzer
    
    %% Token Processing Flow
    RuleAnalyzer --> TokenProcessor
    RuleAnalyzer --> AbbreviationManager
    TokenProcessor --> AbbreviationManager
    
    %% Rule Checking
    RuleAnalyzer --> RuleCheckers
    RuleCheckers --> EntityInfo
    RuleCheckers --> RuleViolation
    
    %% Abbreviation Management
    AbbreviationManager --> AbbreviationStrategy
    AbbreviationManager --> DuplicateResolutionStrategy
    AbbreviationManager --> TokenAnalysis
    
    %% Analysis Flow
    RuleAnalyzer --> |분석 결과| ReportGenerator
    DataLoader --> |원본 데이터| CompletenessAnalyzer
    DataLoader --> |논리명 데이터| VocabularyAnalyzer
    
    %% Domain Integration
    DomainDict --> |도메인 매핑| GlossaryDict
    RuleAnalyzer --> |엔티티 정보| GlossaryDict
    
    %% Output Generation
    ReportGenerator --> Results
    CompletenessAnalyzer --> Results
    VocabularyAnalyzer --> Results
    
    %% Debugging
    TroubleShooting --> AbbreviationManager
    TroubleShooting --> TokenProcessor
    
    %% Styling
    classDef mainClass fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    classDef coreClass fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef ruleClass fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    classDef dataClass fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    classDef outputClass fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    
    class Main mainClass
    class DataLoader,TokenProcessor,AbbreviationManager,RuleAnalyzer coreClass
    class BasicRuleChecker,ConsonantRuleChecker,VowelRuleChecker,LengthRuleChecker ruleClass
    class EntityInfo,RuleViolation,TokenAnalysis,AbbreviationStrategy,DuplicateResolutionStrategy dataClass
    class ReportGenerator,CompletenessAnalyzer,VocabularyAnalyzer,TroubleShooting,Results,GlossaryDict outputClass
```


### NLP Classifier 다이어그램 (0805 최신)

```{mermaid}
graph TD
    %% Data Generation
    subgraph DataGen["훈련 데이터 생성"]
        RuleGen[규칙기반 생성기<br/>2,800개 도메인]
        LLMGen[LLM 생성기<br/>2,800개 도메인]
    end
    
    %% Data Processing
    DataMerger[데이터 통합<br/>중복제거]
    TrainingData[통합 훈련셋<br/>~5,600개 도메인<br/>14개 그룹]
    
    %% Model Training
    subgraph ModelTrain["KoBERT 분류기"]
        Tokenizer[KoBERT<br/>Tokenizer]
        Model[KoBERT Encoder<br/>+ Classifier Head]
        Training[모델 훈련<br/>3 epochs]
    end
    
    %% Output
    TrainedModel[훈련된 모델<br/>kobert_domain_classifier.pth]
    Prediction[도메인 분류 예측<br/>신뢰도 포함]
    
    %% Flow
    RuleGen --> DataMerger
    LLMGen --> DataMerger
    DataMerger --> TrainingData
    
    TrainingData --> Tokenizer
    Tokenizer --> Model
    Model --> Training
    Training --> TrainedModel
    
    TrainedModel --> Prediction
    
    %% Domain Groups Box
    DomainGroups[" 14개 도메인 그룹<br/>날짜, 명, 번호, 식별, 코드, 분류, 값,<br/> 수, 율, 내용, 보안, 단위, 집합, 일반단어"]
    
    TrainingData -.-> DomainGroups
    
    %% Styling
    classDef generation fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef processing fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef model fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    classDef output fill:#f1f8e9,stroke:#558b2f,stroke-width:2px
    classDef info fill:#f5f5f5,stroke:#757575,stroke-width:1px
    
    class RuleGen,LLMGen generation
    class DataMerger,TrainingData processing
    class Tokenizer,Model,Training model
    class TrainedModel,Prediction output
    class DomainGroups info
```

```{mermaid}
graph TB
    %% Data Generation Phase
    subgraph DataGeneration["📊 훈련 데이터 생성"]
        %% Rule-based Generation
        subgraph RuleBased["🔧 규칙기반 생성"]
            StandardWordDict[(표준 단어 사전<br/>tokenized_word_initial_pool)]
            DomainDict[(기존 도메인 사전<br/>domain_dictionary)]
            
            DomainGenerator[EnhancedDomainGenerator<br/>규칙기반 도메인 생성기]
            
            StandardWordDict --> DomainGenerator
            DomainDict --> DomainGenerator
            
            DomainGenerator --> RuleGeneratedData[(규칙생성 데이터<br/>2,800개 도메인<br/>14개 그룹)]
        end
        
        %% LLM Generation  
        subgraph LLMBased["🤖 LLM 기반 생성"]
            LLMPrompt[LLM 프롬프트<br/>PCR 실험 특화]
            LLMModel[Large Language Model]
            
            LLMPrompt --> LLMModel
            LLMModel --> DomainDataMD[(domain_data.md<br/>2,800개 도메인<br/>14개 그룹)]
        end
    end
    
    %% Data Processing Phase
    subgraph DataProcessing["🔄 데이터 처리"]
        %% MD to Parquet Conversion
        MDParser[MD→Parquet 변환기<br/>parse_md_to_dataframe]
        DomainDataMD --> MDParser
        MDParser --> LLMParquet[(domain_data.parquet<br/>구조화된 데이터)]
        
        %% Rule-based to Parquet
        RuleGeneratedData --> RuleParquet[(domain_generated_domains_for_training.parquet<br/>규칙기반 구조화 데이터)]
        
        %% Data Merging
        DataMerger[데이터 병합기<br/>merge_domain_data]
        LLMParquet --> DataMerger
        RuleParquet --> DataMerger
        DataMerger --> MergedData[(통합 훈련 데이터<br/>~5,600개 도메인<br/>중복제거 후)]
    end
    
    %% Model Training Phase
    subgraph ModelTraining["🧠 KoBERT 분류기 훈련"]
        %% Data Preparation
        DataLoader[DomainDataset<br/>데이터 로더]
        MergedData --> DataLoader
        
        %% Tokenization
        KoBERTTokenizer[KoBERT Tokenizer<br/>monologg/kobert]
        DataLoader --> KoBERTTokenizer
        
        %% Model Architecture
        subgraph ModelArch["모델 아키텍처"]
            KoBERTModel[KoBERT Encoder<br/>Pre-trained Model]
            DropoutLayer[Dropout Layer<br/>0.3]
            ClassifierHead[Classification Head<br/>Linear Layer]
            
            KoBERTModel --> DropoutLayer
            DropoutLayer --> ClassifierHead
        end
        
        KoBERTTokenizer --> ModelArch
        
        %% Training Components
        Optimizer[AdamW Optimizer<br/>lr=2e-5]
        LossFunction[CrossEntropyLoss]
        TrainingLoop[Training Loop<br/>3 epochs, batch=64]
        
        ModelArch --> TrainingLoop
        Optimizer --> TrainingLoop
        LossFunction --> TrainingLoop
        
        %% Model Output
        TrainingLoop --> TrainedModel[Trained Model<br/>kobert_domain_classifier.pth]
    end
    
    %% Evaluation Phase
    subgraph ModelEvaluation["📈 모델 평가"]
        TestDataset[Test Dataset<br/>20% 분할]
        DetailedEval[상세 평가<br/>detailed_evaluation]
        
        DataLoader --> TestDataset
        TrainedModel --> DetailedEval
        TestDataset --> DetailedEval
        
        DetailedEval --> EvalResults[(평가 결과<br/>정확도, 분류 보고서<br/>혼동 행렬)]
    end
    
    %% Prediction Phase
    subgraph Prediction["🔮 예측 서비스"]
        InputDomain[입력 도메인명<br/>예: 실험시작일자]
        PredictFunction[predict 함수]
        
        TrainedModel --> PredictFunction
        InputDomain --> PredictFunction
        PredictFunction --> PredResult[(예측 결과<br/>도메인 그룹 + 신뢰도)]
    end
    
    %% Data Flow Labels
    DataGeneration -.-> DataProcessing
    DataProcessing -.-> ModelTraining  
    ModelTraining -.-> ModelEvaluation
    ModelTraining -.-> Prediction
    
    %% Domain Groups
    subgraph DomainGroups["📋 14개 도메인 그룹"]
        Groups["날짜, 보안, 코드, 분류, 명, 번호<br/>식별, 내용, 값, 수, 율, 단위<br/>집합, 일반단어"]
    end
    
    %% Key Components Styling
    classDef dataSource fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef ruleEngine fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef llmEngine fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    classDef processing fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef model fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    classDef output fill:#f1f8e9,stroke:#558b2f,stroke-width:2px
    
    class StandardWordDict,DomainDict,DomainDataMD,MergedData dataSource
    class DomainGenerator,MDParser,DataMerger processing
    class LLMModel,LLMPrompt llmEngine
    class KoBERTModel,KoBERTTokenizer,DataLoader,TrainingLoop model
    class TrainedModel,EvalResults,PredResult output
```

### airflow 플로우 다이어그램

```{mermaid}
graph TB
    subgraph "Phase 1: 기본 환경 구축"
        A1["🐳 Docker Compose로<br/>Airflow 설치"] --> A2["🔗 Connection 설정<br/>PostgreSQL, API endpoints"]
        A2 --> A3["📝 기본 DAG 작성<br/>BashOperator 테스트"]
    end
    
    subgraph "Phase 2: 핵심 워크플로우 구현"
        B1["🐍 Python Operator로<br/>NLP 엔진 연동"] --> B2["📡 Xcom으로<br/>데이터 파이프라인 구축"]
        B2 --> B3["🔀 분기 처리로<br/>다양한 입력 타입 대응"]
    end
    
    subgraph "Phase 3: 고급 기능 적용"
        C1["👁️ Sensor로<br/>실시간 처리"] --> C2["⚙️ Custom Operator<br/>개발"]
        C2 --> C3["📊 모니터링 및<br/>알림 설정"]
    end

    subgraph "메인 파이프라인 DAG 흐름"
        D1["📥 DataLoader<br/>데이터 수집"] --> D2{"🔄 입력 타입<br/>분기"}
        
        D2 -->|테이블/컬럼| D3["🔤 TokenProcessor<br/>토큰 분석"]
        D2 -->|사용자 입력| D4["🤖 RAG System<br/>규칙 검색"]
        D2 -->|코드 스니펫| D4
        
        D3 --> D5["🧠 Domain NLP Engine<br/>도메인 분류"]
        D4 --> D6["📚 Terminology NLP<br/>용어 클러스터링"]
        D5 --> D6
        
        D6 --> D7["📖 통합 사전<br/>메타데이터 통합"]
        D7 --> D8["✅ 검증 시스템<br/>품질 검증"]
        D8 --> D9["📊 ReportGenerator<br/>결과 보고서"]
        D9 --> D10["🖥️ 대시보드<br/>업데이트"]
    end

    subgraph "실시간 처리 DAG"
        E1["👁️ FileSensor<br/>새 데이터 감지"] --> E2["⚡ 빠른 처리<br/>파이프라인"]
        E2 --> E3["🔄 즉시 반영<br/>추천 업데이트"]
    end

    A3 --> B1
    B3 --> C1
    C3 --> D1
    D10 --> E1

    %% 스타일링
    style A1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style A2 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style A3 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    
    style B1 fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style B2 fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style B3 fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    
    style C1 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style C2 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style C3 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    
    style D1 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style D2 fill:#ffebee,stroke:#d32f2f,stroke-width:3px
    style D3 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style D4 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style D5 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style D6 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style D7 fill:#fce4ec,stroke:#ad1457,stroke-width:2px
    style D8 fill:#e0f2f1,stroke:#00695c,stroke-width:2px
    style D9 fill:#e0f2f1,stroke:#00695c,stroke-width:2px
    style D10 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    
    style E1 fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    style E2 fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    style E3 fill:#fff3e0,stroke:#ef6c00,stroke-width:2px

```

## 🎯 **Airflow 도입이 필요한 이유**

1. **복잡한 의존관계**: Processing Layer의 여러 NLP 엔진들과 RAG 시스템 간 의존성
2. **정기적 배치 처리**: 메타데이터 갱신, 모델 재훈련, 품질 검증
3. **실시간에 가까운 처리**: 새로운 데이터 입력 시 자동 파이프라인 실행
4. **모니터링 필요성**: 각 컴포넌트별 성능 및 품질 지표 추적

## 🏗️ **Airflow 아키텍처 설계**

### **1. DAG 구조 설계**

```python
# 메인 데이터 처리 DAG
with DAG(
    dag_id="metadata_standardization_pipeline",
    schedule="0 2 * * *",  # 매일 새벽 2시 실행
    start_date=pendulum.datetime(2024, 1, 1, tz="Asia/Seoul"),
    catchup=False,
    tags=["metadata", "standardization", "nlp"]
) as dag:
```

### **2. 핵심 워크플로우 매핑**

| 시스템 컴포넌트 | Airflow 구현 방식 | 사용할 Operator |
|:---|:---|:---|
| **DataLoader** | 데이터 수집 및 전처리 | `PythonOperator`, `PostgresOperator` |
| **TokenProcessor** | 토큰 분석 배치 작업 | `PythonOperator` |
| **Domain NLP Engine** | ML 모델 추론 | `PythonOperator`, `KubernetesPodOperator` |
| **RAG System** | RAG 검색 및 GPT 호출 | `PythonOperator`, `SimpleHttpOperator` |
| **Terminology NLP** | 용어 클러스터링 | `PythonOperator` |
| **통합 사전 관리** | 메타데이터 업데이트 | `PostgresOperator`, `PythonOperator` |
| **검증 시스템** | 품질 검증 배치 | `PythonOperator`, `BranchPythonOperator` |
| **보고서 생성** | 대시보드 데이터 생성 | `PythonOperator`, `EmailOperator` |

## 🔧 **활용할 Airflow 기능들**

### **1. Sensor 활용 (실시간 처리)**
```python
# 새로운 데이터 입력 감지
new_data_sensor = FileSensor(
    task_id='detect_new_standardization_data',
    filepath='/data/input/new_data.flag',
    fs_conn_id='data_fs',
    poke_interval=30,  # 30초마다 체크
    mode='reschedule'
)
```

### **2. 분기 처리 (BranchPythonOperator)**
```python
def decide_processing_path(**context):
    # 데이터 유형에 따른 처리 분기
    data_type = context['ti'].xcom_pull(key='data_type')
    if data_type == 'table_column':
        return 'token_processing_task'
    elif data_type == 'user_input':
        return 'nlp_processing_task'
    else:
        return 'rag_processing_task'

branch_task = BranchPythonOperator(
    task_id='decide_processing_path',
    python_callable=decide_processing_path
)
```

### **3. Xcom을 통한 데이터 공유**
```python
# TokenProcessor 결과를 다음 단계로 전달
@task
def token_analysis(**context):
    tokens = process_tokens(context['ti'].xcom_pull(key='input_data'))
    return {'tokens': tokens, 'domain_hints': extract_domain_hints(tokens)}

@task  
def domain_classification(**context):
    token_data = context['ti'].xcom_pull(task_ids='token_analysis')
    domains = classify_domains(token_data['tokens'])
    return domains
```

### **4. Task Groups으로 모듈화**
```python
with TaskGroup("nlp_processing_group") as nlp_group:
    token_task = PythonOperator(
        task_id='token_processing',
        python_callable=process_tokens
    )
    
    domain_task = PythonOperator(
        task_id='domain_classification', 
        python_callable=classify_domains
    )
    
    terminology_task = PythonOperator(
        task_id='terminology_clustering',
        python_callable=cluster_terminology
    )
    
    token_task >> [domain_task, terminology_task]
```

### **5. Connection & Hook (외부 시스템 연동)**
```python
# PostgreSQL 메타데이터 DB 연동
postgres_hook = PostgresHook(postgres_conn_id='metadata_db')

# RAG 시스템 API 연동  
@task
def call_rag_system(**context):
    http_hook = SimpleHttpHook(http_conn_id='rag_api')
    response = http_hook.run(
        endpoint='/search',
        data={'query': context['ti'].xcom_pull(key='search_query')},
        headers={'Content-Type': 'application/json'}
    )
    return response.json()
```

### **6. 모니터링 및 알림 설정**
```python
# SLA 설정으로 성능 모니터링
dag_defaults = {
    'sla': timedelta(hours=2),  # 2시간 내 완료
    'email_on_failure': True,
    'email_on_retry': False,
    'email': ['data-team@company.com'],
    'retries': 2,
    'retry_delay': timedelta(minutes=10)
}

# 품질 검증 실패 시 알림
quality_check_task = PythonOperator(
    task_id='data_quality_check',
    python_callable=check_data_quality,
    on_failure_callback=send_quality_alert
)
```

## 📅 **DAG 구성 예시**

### **메인 파이프라인 DAG**
```python
# 1. 데이터 수집
data_loader >> 

# 2. 병렬 처리
[token_processor, rag_processor] >>

# 3. NLP 엔진들
[domain_nlp, terminology_nlp] >>

# 4. 결과 통합
metadata_integration >>

# 5. 검증
[rule_analyzer, completeness_analyzer] >>

# 6. 보고서 생성
report_generator >>

# 7. 대시보드 업데이트
dashboard_update
```

### **실시간 처리 DAG**
```python
# Sensor로 새 입력 감지
new_input_sensor >>

# 빠른 처리 파이프라인
[quick_token_analysis, rag_recommendation] >>

# 결과 즉시 반영
update_recommendations
```

## 🛠️ **구현 순서**

### **Phase 1: 기본 환경 구축**
1. **Docker Compose로 Airflow 설치** (`02.env_setting.qmd` 참고)
2. **Connection 설정** - PostgreSQL, API endpoints (`09.connection_hook.qmd`)
3. **기본 DAG 작성** (`03.operator_basic.qmd`)

### **Phase 2: 핵심 워크플로우 구현**
1. **Python Operator로 NLP 엔진 연동** (`04.python_operator.qmd`)
2. **Xcom으로 데이터 파이프라인 구축** (`06.data_share.qmd`)
3. **분기 처리로 다양한 입력 타입 대응** (`07.task_handling.qmd`)

### **Phase 3: 고급 기능 적용**
1. **Sensor로 실시간 처리** (`10.sensor.qmd`)
2. **Custom Operator 개발** (`08.more_operators.qmd`)
3. **모니터링 및 알림 설정** (`11.airflow_functions.qmd`)

## 🎯 **기대 효과**

1. **자동화**: 수동 개입 없이 전체 파이프라인 실행
2. **신뢰성**: 실패 시 재시도, 알림으로 안정성 확보
3. **확장성**: 새로운 NLP 모델이나 검증 로직 쉽게 추가
4. **모니터링**: 각 단계별 성능 및 품질 지표 실시간 추적
5. **일관성**: 표준화된 워크플로우로 데이터 품질 보장

이렇게 Airflow를 도입하면 복잡한 메타데이터 표준화 시스템을 효율적으로 관리하고 자동화할 수 있습니다!

## 전체 시스템 아키텍처

### Ver5.1

```{mermaid}
graph TB
    subgraph "Data Input Layer"
        A[최초 표준화 데이터<br/>테이블/컬럼 명세서] --> B[DataLoader]
        A1[Streamlit UI<br/>사용자 입력 데이터] --> B
        A2[코드 스니펫<br/>변수명/컬럼명] --> B
    end
    
    subgraph "Processing Layer"
        B -.-> |논리명| C[TokenProcessor<br/>토큰 분석]
        B -.-> |공통코드| MD3[CodeTable<br/>코드 테이블]
        B -.-> |코드 스니펫| LLM    
        C --> D[DomainClassifier<br/>도메인 그룹 분류]
        D --> E[AbbreviationManager<br/>약어 생성]
        E --> MD1[WordDictionary<br/>표준 단어 사전]
        D --> MD2[DomainDictionary<br/>도메인 사전]
        

        subgraph "RAG"
            subgraph "RAG Knowledge Base"
                KB1[표준화 규칙 문서<br/>PDF/DOCX]
                KB2[네이밍 컨벤션<br/>가이드라인]
                KB3[도메인 용어 사전<br/>기존 용어 DB]
                KB4[코드 패턴 예시<br/>변수명 매핑]
                
                KB1 --> EMB[OpenAI Embeddings<br/>text-embedding-3-small]
                KB2 --> EMB
                KB3 --> EMB
                KB4 --> EMB
                EMB --> FAISS[Vector Store<br/>벡터 검색 엔진]
            end

            subgraph "RAG Enhancement Module"
                RAG1[RAG Retriever<br/>관련 규칙 검색]
                RAG3[Context Matcher<br/>유사 패턴 검색]
                LLM[GPT-4o<br/>코드 to 논리명 추천]
            end
        end
    

        subgraph "Metadata Management Layer"
            MD1[WordDictionary<br/>표준 단어 사전]
            MD2[DomainDictionary<br/>도메인 사전]
            MD3[CodeTable<br/>코드 테이블]
            MD4[TerminologyDictionary<br/>용어 사전]
            MD1 --> MD4         
            MD2 --> MD4         
            MD3 --> MD4         
        end
        
        E --> ABR[생성된 약어]
        MD4 --> H[DataCompletenessAnalyzer<br/>완전성 검증]
        MD4 --> F[RuleAnalyzer<br/>일관성 규칙 검증]
        ABR --> F
        RAG1 --> LLM
        LLM --> C
    
        subgraph "NLP Domain Model"
            DG[DomainGenerator<br/>도메인 데이터 생성]
            DC[Domain Model Training<br/>Bi-LSTM + Attention]
            D[DomainClassifier<br/>도메인 그룹 분류]
            DG --> DC
        end
        
        subgraph "NLP Terminology Model"
            NLP1[SBERT Model<br/>문장 임베딩]
            NLP2[ALBERT Model<br/>문맥 이해]
            NLP3[Similarity Calculator<br/>코사인 유사도]
            NLP4[Clustering Engine<br/>K-means/DBSCAN]
            ST1[SimilarTermClassifier<br/>유사 용어 분류]
            ST2[TermClusteringAnalyzer<br/>용어 클러스터링]
            
            NLP1 --> NLP3
            NLP2 --> NLP3
            NLP3 --> NLP4
            NLP1 -.->|임베딩| ST1
            NLP2 -.->|문맥 분석| ST1
            NLP4 -.->|클러스터링| ST2
        end

        
    end

    subgraph "Analysis Layer"
        F --> G[ReportGenerator<br/>분석 결과 보고]
        F --> I[VocabularyAnalyzer<br/>단어 분석]
        D --> J[DomainGroupAnalyzer<br/>도메인 그룹 통계]
        F --> K[TroubleShooting<br/>디버깅]
        H --> G
        ST1 --> G
        ST2 --> G
        RAG3 --> G
    end
    
    subgraph "Output Layer"
        G --> L[명명 규칙 분석 내역]
        I --> N[단어 통계 분석 결과]
        J --> O[도메인 그룹 분류 결과<br/>표준화 권장사항]
        K --> P[오류 진단]
        LLM --> REC[논리명 추천 결과]
        ABR --> ABR_OUT[약어 생성 결과]
    end
    
    subgraph "Streamlit Interface"
        STR1[약어 생성 탭<br/>논리명 to 약어]
        STR2[논리명 추천 탭<br/>코드 to 논리명]
        STR3[검증 결과 탭<br/>품질 분석]
        
        L --> STR3
        N --> STR3
        O --> STR3
        P --> STR3
        REC --> STR2
        ABR_OUT --> STR1
    end
    
    %% 모듈 간 연결
    FAISS --> RAG1
    FAISS --> RAG3
    RAG3 --> LLM
    

    LLM --> E
    DC -.->|학습된 모델| D
    MD4 --> NLP1
    MD4 --> NLP2
    
    %% 스타일링
    style A fill:#e1f5fe
    style A1 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style A2 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style KB1 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style KB2 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style KB3 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style KB4 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style EMB fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style FAISS fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style RAG1 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style RAG2 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style RAG3 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style LLM fill:#ffebee,stroke:#c62828,stroke-width:3px
    style E fill:#4caf50,stroke:#2e7d32,stroke-width:3px
    style ABR fill:#4caf50,stroke:#2e7d32,stroke-width:2px
    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px
    style STR1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style STR2 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style STR3 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style REC fill:#ffebee,stroke:#c62828,stroke-width:2px
    style ABR_OUT fill:#4caf50,stroke:#2e7d32,stroke-width:2px
```

### Ver5.0

```{mermaid}
graph TB
    subgraph "Data Input Layer"
        A[최초 표준화 데이터<br/>테이블/컬럼 명세서] --> B[DataLoader]
        A1[Streamlit UI<br/>사용자 입력 데이터] --> B
        A2[코드 스니펫<br/>변수명/컬럼명] --> B
    end
    
    subgraph "Processing Layer"
        
        subgraph "RAG Knowledge Base"
            KB1[표준화 규칙 문서<br/>PDF/DOCX]
            KB2[네이밍 컨벤션<br/>가이드라인]
            KB3[도메인 용어 사전<br/>기존 용어 DB]
            KB4[코드 패턴 예시<br/>변수명 매핑]
            
            KB1 --> EMB[OpenAI Embeddings<br/>text-embedding-3-small]
            KB2 --> EMB
            KB3 --> EMB
            KB4 --> EMB
            EMB --> FAISS[Vector Store<br/>벡터 검색 엔진]
        end

        subgraph "RAG Enhancement Module"
            RAG1[RAG Retriever<br/>관련 규칙 검색]
            RAG2[Code Analyzer<br/>코드 to 논리명 추천]
            RAG3[Context Matcher<br/>유사 패턴 검색]
            LLM[GPT-4o<br/>논리명 추천 전용]
            
            FAISS --> RAG1
            FAISS --> RAG2
            FAISS --> RAG3
            RAG2 --> LLM
            RAG3 --> LLM
        end
        
        subgraph "Metadata Management Layer"
            MD1[WordDictionary<br/>표준 단어 사전]
            MD2[DomainDictionary<br/>도메인 사전]
            MD3[CodeTable<br/>코드 테이블]
            MD4[TerminologyDictionary<br/>용어 사전]
            MD1 --> MD4         
            MD2 --> MD4         
            MD3 --> MD4         
        end

        subgraph "NLP Domain Model"
            DG[DomainGenerator<br/>도메인 데이터 생성]
            DC[Domain Model Training<br/>Bi-LSTM + Attention]
            D[DomainClassifier<br/>도메인 그룹 분류]
            DG --> DC
            DC -.->|학습된 모델| D
        end
        
        subgraph "NLP Terminology Model"
            NLP1[SBERT Model<br/>문장 임베딩]
            NLP2[ALBERT Model<br/>문맥 이해]
            NLP3[Similarity Calculator<br/>코사인 유사도]
            NLP4[Clustering Engine<br/>K-means/DBSCAN]
            ST1[SimilarTermClassifier<br/>유사 용어 분류]
            ST2[TermClusteringAnalyzer<br/>용어 클러스터링]
            
            NLP1 --> NLP3
            NLP2 --> NLP3
            NLP3 --> NLP4
            NLP1 -.->|임베딩| ST1
            NLP2 -.->|문맥 분석| ST1
            NLP4 -.->|클러스터링| ST2
        end

        B --> |논리명| C[TokenProcessor<br/>토큰 분석]
        B --> |코드|RAG2
        C --> D
        D --> E[AbbreviationManager<br/>약어 생성]
        RAG1 --> 
        
        LLM --> E
        E --> MD1[WordDictionary<br/>표준 단어 사전]
        D --> MD2[DomainDictionary<br/>도메인 사전]
        B --> MD3[CodeTable<br/>코드 테이블]
        
        
        
        MD4 --> NLP1
        MD4 --> NLP2
        
        E --> ABR[생성된 약어]

        
        
        
        MD4 --> H[DataCompletenessAnalyzer<br/>완전성 검증]
        MD4 --> F[RuleAnalyzer<br/>일관성 규칙 검증]
        ABR --> F
    end
    
    subgraph "Analysis Layer"
        F --> G[ReportGenerator<br/>분석 결과 보고]
        F --> I[VocabularyAnalyzer<br/>단어 분석]
        D --> J[DomainGroupAnalyzer<br/>도메인 그룹 통계]
        F --> K[TroubleShooting<br/>디버깅]
        H --> G
        ST1 --> G
        ST2 --> G
        RAG3 --> G
    end
    
    subgraph "Output Layer"
        G --> L[명명 규칙 분석 내역]
        I --> N[단어 통계 분석 결과]
        J --> O[도메인 그룹 분류 결과<br/>표준화 권장사항]
        K --> P[오류 진단]
        LLM --> REC[논리명 추천 결과]
        ABR --> ABR_OUT[약어 생성 결과]
    end
    
    subgraph "Streamlit Interface"
        STR1[약어 생성 탭<br/>논리명 to 약어]
        STR2[논리명 추천 탭<br/>코드 to 논리명]
        STR3[검증 결과 탭<br/>품질 분석]
        
        L --> STR3
        N --> STR3
        O --> STR3
        P --> STR3
        REC --> STR2
        ABR_OUT --> STR1
        REC --> STR1
    end
    
    %% 스타일링
    style A fill:#e1f5fe
    style A1 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style A2 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style KB1 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style KB2 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style KB3 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style KB4 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style EMB fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style FAISS fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style RAG1 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style RAG2 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style RAG3 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style LLM fill:#ffebee,stroke:#c62828,stroke-width:3px
    style E fill:#4caf50,stroke:#2e7d32,stroke-width:3px
    style ABR fill:#4caf50,stroke:#2e7d32,stroke-width:2px
    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px
    style STR1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style STR2 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style STR3 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style REC fill:#ffebee,stroke:#c62828,stroke-width:2px
    style ABR_OUT fill:#4caf50,stroke:#2e7d32,stroke-width:2px
```

### Ver4.0

```{mermaid}
graph TB
    subgraph "Data Input Layer"
        A[최초 표준화 데이터<br/>테이블/컬럼 명세서] --> B[DataLoader]
        A1[Streamlit UI<br/>사용자 입력 데이터] --> B
    end
    
    subgraph "Processing Layer"
        B --> C[TokenProcessor<br/>토큰 분석]
        C --> D[DomainClassifier<br/>도메인 그룹 분류]
        D --> E[AbbreviationManager<br/>약어 생성]
        
        E -->  MD1[WordDictionary<br/>표준 단어 사전]
        D --> MD2[DomainDictionary<br/>도메인 사전]
        B --> MD3[CodeTable<br/>코드 테이블]
        
        subgraph "Metadata Management Layer"
            MD1[WordDictionary<br/>표준 단어 사전]
            MD2[DomainDictionary<br/>도메인 사전]
            MD3[CodeTable<br/>코드 테이블]
            MD4[TerminologyDictionary<br/>용어 사전]
            MD1 --> MD4         
            MD2 --> MD4         
            MD3 --> MD4         
        end
        
        MD4 --> NLP1
        MD4 --> NLP2

        
        subgraph "NLP Domain Model"
            DG[DomainGenerator<br/>도메인 데이터 생성]
            DC[Domain Model Training<br/>Bi-LSTM + Attention]
            DG --> DC
            DC -.->|학습된 모델| D
        end
        
        subgraph "NLP Terminology Model"
            NLP1[SBERT Model<br/>문장 임베딩]
            NLP2[ALBERT Model<br/>문맥 이해]
            NLP3[Similarity Calculator<br/>코사인 유사도]
            NLP4[Clustering Engine<br/>K-means/DBSCAN]
            ST1[SimilarTermClassifier<br/>유사 용어 분류]
            ST2[TermClusteringAnalyzer<br/>용어 클러스터링]
            
            NLP1 --> NLP3
            NLP2 --> NLP3
            NLP3 --> NLP4
            NLP1 -.->|임베딩| ST1
            NLP2 -.->|문맥 분석| ST1
            NLP4 -.->|클러스터링| ST2

        end
        
    
        MD4 --> H[DataCompletenessAnalyzer<br/>완전성 검증]
        MD4 --> F[RuleAnalyzer<br/>일관성 규칙 검증]
    end
    
    subgraph "Analysis Layer"
        F --> G[ReportGenerator<br/>분석 결과 보고]
        F --> I[VocabularyAnalyzer<br/>단어 분석]
        D --> J[DomainGroupAnalyzer<br/>도메인 그룹 통계]
        F --> K[TroubleShooting<br/>디버깅]
        H --> G
        ST1 --> G
        ST2 --> G
    end
    
    subgraph "Output Layer"
        G --> L[명명 규칙 분석 내역]
        I --> N[단어 통계 분석 결과]
        J --> O[도메인 그룹 분류 결과<br/>표준화 권장사항]
        K --> P[오류 진단]
        

    end
    
    subgraph "Presentation Layer"
        L --> STR[Streamlit 실시간 반영]
        N --> STR[Streamlit 실시간 반영]
        O --> STR[Streamlit 실시간 반영]
        P --> STR[Streamlit 실시간 반영]
    end
    
    %% 스타일링
    style A fill:#e1f5fe
    style A1 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px
    style DG fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style DC fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style J fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style MD1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style MD2 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style MD3 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style MD4 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style ST1 fill:#e8eaf6,stroke:#5c6bc0,stroke-width:2px
    style ST2 fill:#e8eaf6,stroke:#5c6bc0,stroke-width:2px
    style L fill:#e8f5e8
    style N fill:#e8f5e8
    style O fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style P fill:#e8f5e8

```



### Ver3.0

```{mermaid}

graph TB
    subgraph "Data Input Layer"
        A[최초 표준화 데이터<br/>테이블/컬럼 명세서] --> B[DataLoader]
        A1[Streamlit UI<br/>사용자 입력 데이터] --> B
    end
    
    subgraph "Processing Layer"
        B --> C[TokenProcessor<br/>토큰 분석]
        C --> D[DomainClassifier<br/>도메인 그룹 분류]
        D --> E[AbbreviationManager<br/>약어 생성]
        
        E -->  MD1[WordDictionary<br/>표준 단어 사전]
        D --> MD2[DomainDictionary<br/>도메인 사전]
        B --> MD3[CodeTable<br/>코드 테이블]
        
        subgraph "Metadata Management Layer"
            MD1[WordDictionary<br/>표준 단어 사전]
            MD2[DomainDictionary<br/>도메인 사전]
            MD3[CodeTable<br/>코드 테이블]
            MD4[TerminologyDictionary<br/>용어 사전]
            MD1 --> MD4         
            MD2 --> MD4         
            MD3 --> MD4         
        end
        
        MD4[TerminologyDictionary<br/>용어 사전] --> H[DataCompletenessAnalyzer<br/>완전성 검증]
        MD4[TerminologyDictionary<br/>용어 사전] --> F[RuleAnalyzer<br/>일관성 규칙 검증]
        
        subgraph "NLP Model Lifecycle"
            DG[DomainGenerator<br/>도메인 데이터 생성]
            DC[Domain Model Training<br/>Bi-LSTM + Attention]
            DG --> DC
            DC -.->|학습된 모델| D
        end
    end
    
    subgraph "Analysis Layer"
        F --> G[ReportGenerator<br/>분석 결과 보고]
        F --> I[VocabularyAnalyzer<br/>단어 분석]
        D --> J[DomainGroupAnalyzer<br/>도메인 그룹 통계]
        F --> K[TroubleShooting<br/>디버깅]
        H --> G[ReportGenerator<br/>분석 결과 보고]
    end
    
    subgraph "Output Layer"
        G --> L[명명 규칙 분석 내역]
        
        I --> N[단어 통계 분석 결과]
        J --> O[도메인 그룹 분류 결과<br/>표준화 권장사항]
        K --> P[오류 진단]
    end
    
    %% 스타일링
    style A fill:#e1f5fe
    style A1 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px
    style DG fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style DC fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style J fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style MD1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style MD2 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style MD3 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style MD4 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style L fill:#e8f5e8
    style M fill:#fff3e0
    style N fill:#e8f5e8
    style O fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style P fill:#e8f5e8
```

### Ver2.0

```{mermaid}
graph TB
    subgraph "Data Input Layer"
        A[Excel 파일<br/>테이블/컬럼 명세서] --> B[DataLoader]
        A1[Streamlit UI<br/>사용자 입력 용어] --> B
    end
    
    subgraph "Processing Layer"
        B --> C[TokenProcessor<br/>토큰 분석]
        C --> D[DomainClassifier<br/>도메인 그룹 분류]
        D --> E[AbbreviationManager<br/>약어 생성]
        E --> F[RuleAnalyzer<br/>일관성 규칙 검증]
        
        subgraph "NLP Model Lifecycle"
            DG[DomainGenerator<br/>도메인 데이터 생성]
            DC[Domain Model Training<br/>Bi-LSTM + Attention]
            DG --> DC
            DC -.->|학습된 모델| D
        end
    end
    
    subgraph "Analysis Layer"
        F --> G[ReportGenerator<br/>분석 결과 보고]
        B --> H[DataCompletenessAnalyzer<br/>완전성 분석]
        F --> I[VocabularyAnalyzer<br/>단어 분석]
        D --> J[DomainGroupAnalyzer<br/>도메인 그룹 통계]
        F --> K[TroubleShooting<br/>디버깅]
    end
    
    subgraph "Output Layer"
        G --> L[명명 규칙 분석 내역]
        H --> M[데이터 품질 완전성 분석 결과]
        I --> N[단어 통계 분석 결과]
        J --> O[도메인 그룹 분류 결과<br/>표준화 권장사항]
        K --> P[오류 진단]
    end
    
    %% 스타일링
    style A fill:#e1f5fe
    style A1 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px
    style DG fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style DC fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style J fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style L fill:#e8f5e8
    style M fill:#fff3e0
    style N fill:#e8f5e8
    style O fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style P fill:#e8f5e8

```

### Ver1.0
```{mermaid}
graph TB
    subgraph "Data Input Layer"
        A[Excel 파일<br/>테이블/컬럼 명세서] --> B[DataLoader]
    end
    
    subgraph "Processing Layer"
        B --> C[TokenProcessor<br/>토큰 분석]
        C --> D[AbbreviationManager<br/>약어 생성]
        D --> E[RuleAnalyzer<br/>일관성 규칙 검증]
    end
    
    subgraph "Analysis Layer"
        E --> F[ReportGenerator<br/>분석 결과 보고]
        B --> G[DataCompletenessAnalyzer<br/>완전성 분석]
        E --> H[VocabularyAnalyzer<br/>단어 분석]
        E --> I[TroubleShooting<br/>디버깅]
    end
    
    subgraph "Output Layer"
        F --> J[명명 규칙 분석 내역]
        G --> K[데이터 품질 완전성 분석 결과]
        H --> L[단어 통계 분석 결과]
        I --> M[오류 진단]
    end
    
    style A fill:#e1f5fe
    style J fill:#e8f5e8
    style K fill:#fff3e0
    style L fill:#e8f5e8
    style M fill:#e8f5e8
```

## DataLoader 클래스 상세 플로우

```{mermaid}
flowchart TD
    Start([시작]) --> Init[DataLoader 초기화]
    Init --> FontSetup{폰트 설정}
    FontSetup -->|성공| LoadData[Excel 데이터 로딩]
    FontSetup -->|실패| ContinueLoad[경고 후 계속 진행]
    ContinueLoad --> LoadData
    
    LoadData --> ValidateFile{파일 존재 확인}
    ValidateFile -->|파일 없음| Error1[오류: 파일 없음]
    ValidateFile -->|파일 있음| ReadSheets[시트별 데이터 읽기]
    
    ReadSheets --> Sheet1[수정 테이블 명세서<br/>Sheet 2]
    ReadSheets --> Sheet2[수정 컬럼 명세서<br/>Sheet 3]
    ReadSheets --> Sheet3[원본 테이블 명세서<br/>Sheet 4]
    ReadSheets --> Sheet4[원본 컬럼 명세서<br/>Sheet 5]
    
    Sheet1 --> PrepareData[테이블 데이터 전처리]
    Sheet2 --> PrepareData
    Sheet3 --> PrepareData
    Sheet4 --> PrepareData
    
    PrepareData --> ExtractColumns[필요 컬럼 추출]
    ExtractColumns --> JoinData[테이블-컬럼 데이터 조인]
    
    JoinData --> RawJoin[원본 데이터 조인<br/>tabl_phys_name 기준]
    JoinData --> ModJoin[수정 데이터 조인<br/>tabl_phys_name 기준]
    
    RawJoin --> Summary[데이터 요약 출력]
    ModJoin --> Summary
    Summary --> Success([완료])
    
    Error1 --> End([종료])
    
    style Start fill:#c8e6c9
    style Success fill:#c8e6c9
    style Error1 fill:#ffcdd2
    style End fill:#ffcdd2
```

## 토큰 처리 및 약어 생성 플로우

```{mermaid}
flowchart TD
    Input[논리명 입력] --> Tokenize[TokenProcessor<br/>토큰화]
    
    Tokenize --> CleanText[특수문자 제거]
    CleanText --> SplitTokens[공백/밑줄 기준 분리]
    SplitTokens --> RemoveStopWords[불용어 제거]
    
    RemoveStopWords --> ProcessTokens{각 토큰 처리}
    
    ProcessTokens --> CheckLength{토큰 길이 확인}
    CheckLength -->|4글자 이하| KeepOriginal[원본 유지]
    CheckLength -->|4글자 초과| CheckCommon{통용 약어 확인}
    
    CheckCommon -->|통용 약어 있음| UseCommon[통용 약어 사용]
    CheckCommon -->|통용 약어 없음| GenerateNew[새 약어 생성]
    
    GenerateNew --> ExtractConsonants[자음 추출]
    ExtractConsonants --> FilterConsecutive[연속 자음 제거]
    FilterConsecutive --> CheckConsonantLength{자음 길이 확인}
    
    CheckConsonantLength -->|4글자 이상| TakeFirst4[첫 4개 자음 사용]
    CheckConsonantLength -->|4글자 미만| AddVowels[모음 추가]
    
    TakeFirst4 --> CheckDuplicate{중복 확인}
    AddVowels --> CheckDuplicate
    
    CheckDuplicate -->|중복 없음| RegisterAbbr[약어 등록]
    CheckDuplicate -->|중복 있음| ResolveDuplicate[중복 해결]
    
    ResolveDuplicate --> AddRemainingConsonants[남은 자음 추가]
    AddRemainingConsonants --> StillDuplicate{여전히 중복?}
    StillDuplicate -->|예| AddVowelsByPosition[위치별 모음 추가]
    StillDuplicate -->|아니오| RegisterAbbr
    
    AddVowelsByPosition --> FinalCheck{여전히 중복?}
    FinalCheck -->|예| AddSequentialNumber[순차 번호 추가]
    FinalCheck -->|아니오| RegisterAbbr
    
    AddSequentialNumber --> RegisterAbbr
    RegisterAbbr --> KeepOriginal
    UseCommon --> KeepOriginal
    KeepOriginal --> CombineTokens[토큰 결합]
    
    CombineTokens --> FinalAbbr[최종 약어 생성]
    
    style Input fill:#e3f2fd
    style FinalAbbr fill:#e8f5e8
    style CheckDuplicate fill:#fff3e0
    style ResolveDuplicate fill:#fff3e0
```

## 규칙 검증 시스템

```{mermaid}
flowchart TD
    Start[분석 시작] --> ValidateInput[입력 데이터 검증]
    ValidateInput --> ProcessRows[행별 처리]
    
    ProcessRows --> ExtractEntity[엔티티 정보 추출]
    ExtractEntity --> TokenizeLogical[논리명 토큰화]
    TokenizeLogical --> CheckRules[일관성 규칙 검증]
    
    CheckRules --> BasicRules[기본 규칙 검증<br/>- 불용어 사용 금지<br/>- 통용 약어 사용<br/>- 소문자 사용]
    CheckRules --> LengthRules[길이 규칙 검증<br/>- 4글자 이하 원본 유지<br/>- 4글자 구성 원칙]
    CheckRules --> ConsonantRules[자음 규칙 검증<br/>- 자음 우선순위<br/>- 연속 자음 처리]
    CheckRules --> VowelRules[모음 규칙 검증<br/>- 모음 위치 처리<br/>- 4글자 미만 보완]
    
    BasicRules --> CollectViolations[위반 사항 수집]
    LengthRules --> CollectViolations
    ConsonantRules --> CollectViolations
    VowelRules --> CollectViolations
    
    CollectViolations --> GenerateReport[처리 결과 생성]
    GenerateReport --> Summary[요약 통계]
    GenerateReport --> SystemAnalysis[시스템별 분석]
    GenerateReport --> ViolationDetails[위반 상세 분석]
    
    Summary --> Dashboard[결과 출력]
    SystemAnalysis --> Dashboard
    ViolationDetails --> Dashboard
    
    style Start fill:#c8e6c9
    style Dashboard fill:#c8e6c9
    style CollectViolations fill:#ffecb3
```

```{mermaid}
flowchart TD
    A[DataFrame 입력] --> B[입력 데이터 검증]
    B --> C[행별 순회 시작]
    C --> D[엔티티 정보 추출]
    D --> E[논리명 토큰화]
    E --> F[물리명 토큰화]
    F --> G[표준 약어 생성]
    G --> H[토큰별 규칙 검증 시작]
    
    H --> I[규칙 검증기 순회]
    I --> J[1. ConsonantRuleChecker]
    J --> K[2. VowelRuleChecker]
    K --> L[3. LengthRuleChecker]
    L --> M[4. BasicRuleChecker]
    
    M --> N[위반 사항 수집]
    N --> O[위반 규칙 번호 정리]
    O --> P[결과 딕셔너리 생성]
    P --> Q{더 많은 토큰?}
    Q -->|Yes| H
    Q -->|No| R{더 많은 행?}
    R -->|Yes| C
    R -->|No| S[최종 DataFrame 생성]
    S --> T[통계 정보 생성]
    T --> U[결과 반환]
    
    style A fill:#e3f2fd
    style J fill:#fff3e0
    style K fill:#fff3e0
    style L fill:#fff3e0
    style M fill:#fff3e0
    style U fill:#e8f5e8
```

### 4.1. RuleAnalyzer 규칙 검증기 처리 순서

```{mermaid}
graph LR
    A[토큰 입력] --> B[ConsonantRuleChecker]
    B --> |규칙 3,4,5,6,7,8,9,10,11| C[VowelRuleChecker]
    C --> |규칙 2| D[LengthRuleChecker]
    D --> |규칙 13| E[BasicRuleChecker]
    E --> |규칙 1,12,14| F[위반사항 통합]
    
    style B fill:#ffeb3b
    style C fill:#ff9800
    style D fill:#2196f3
    style E fill:#9c27b0
    style F fill:#4caf50
```

### 개별 규칙 검증기 상세 로직

```{mermaid}
flowchart TD
    subgraph "ConsonantRuleChecker"
        A1[자음 우선순위 검증] --> A2[연속 자음 검사]
        A2 --> A3[자음 조합 규칙]
        A3 --> A4[위반사항 반환]
    end
    
    subgraph "VowelRuleChecker"
        B1[모음 포함 규칙] --> B2[자음 개수 기반 모음 필요성]
        B2 --> B3[위반사항 반환]
    end
    
    subgraph "LengthRuleChecker"
        C1[토큰 길이 검증] --> C2[약어 길이 규칙]
        C2 --> C3[위반사항 반환]
    end
    
    subgraph "BasicRuleChecker"
        D1[불용어 검사] --> D2[기본 약어 규칙]
        D2 --> D3[소문자 사용 규칙]
        D3 --> D4[위반사항 반환]
    end
    
    style A1 fill:#ffcdd2
    style B1 fill:#f8bbd9
    style C1 fill:#c5cae9
    style D1 fill:#dcedc1
```



## 비즈니스 가치 및 ROI

```{mermaid}
mindmap
  root((데이터 표준화<br/>토큰 분석기))
    비즈니스 가치
      데이터 품질 향상
        일관된 명명 규칙
        표준화된 약어 체계
        오류 감소
      운영 효율성
        자동화된 검증
        빠른 문제 식별
        개발 생산성 향상
      규정 준수
        표준 가이드라인 준수
        감사 대응 용이
        문서화 자동화
    기술적 혜택
      확장성
        모듈화된 구조
        플러그인 방식 규칙 추가
        다양한 데이터 소스 지원
      유지보수성
        명확한 책임 분리
        테스트 가능한 구조
        디버깅 도구 제공
      성능
        배치 처리 지원
        메모리 효율적 처리
        병렬 처리 가능
```

## 6. 구현 우선순위 및 로드맵

```{mermaid}
gantt
    title 데이터 표준화 시스템 구현 로드맵
    dateFormat  YYYY-MM-DD
    section Phase 1: 기초 구축
    DataLoader 구현           :done, phase1a, 2024-01-01, 2024-01-15
    TokenProcessor 구현       :done, phase1b, 2024-01-16, 2024-01-30
    AbbreviationManager 구현  :done, phase1c, 2024-01-31, 2024-02-15
    
    section Phase 2: 규칙 엔진
    RuleAnalyzer 구현         :active, phase2a, 2024-02-16, 2024-03-01
    규칙 검증기 구현          :phase2b, 2024-03-02, 2024-03-15
    
    section Phase 3: 분석 및 보고
    ReportGenerator 구현      :phase3a, 2024-03-16, 2024-03-30
    VocabularyAnalyzer 구현   :phase3b, 2024-03-31, 2024-04-15
    
    section Phase 4: 운영 지원
    TroubleShooting 구현      :phase4a, 2024-04-16, 2024-04-30
    성능 최적화              :phase4b, 2024-05-01, 2024-05-15
    문서화 및 교육           :phase4c, 2024-05-16, 2024-05-30
```

## 시스템 메트릭 및 KPI

```{mermaid}
graph LR
    subgraph "품질 지표"
        A[규칙 준수율<br/>95% 이상]
        B[자동 검증률<br/>100%]
        C[오류 감소율<br/>80% 이상]
    end
    
    subgraph "효율성 지표"
        D[처리 시간<br/>< 5분/1000건]
        E[메모리 사용량<br/>< 1GB]
        F[CPU 사용률<br/>< 50%]
    end
    
    subgraph "비즈니스 지표"
        G[개발 생산성<br/>30% 향상]
        H[데이터 품질<br/>점수 향상]
        I[운영 비용<br/>20% 절감]
    end
    
    A --> G
    B --> H
    C --> I
    D --> G
    E --> I
    F --> I
    
    style A fill:#e8f5e8
    style B fill:#e8f5e8
    style C fill:#e8f5e8
    style D fill:#e3f2fd
    style E fill:#e3f2fd
    style F fill:#e3f2fd
    style G fill:#fff3e0
    style H fill:#fff3e0
    style I fill:#fff3e0
```

## 리스크 관리 및 대응 방안

```{mermaid}
flowchart TD
    subgraph "기술적 리스크"
        TR1[성능 저하]
        TR2[메모리 부족]
        TR3[규칙 충돌]
    end
    
    subgraph "운영적 리스크"
        OR1[사용자 교육 부족]
        OR2[데이터 품질 문제]
        OR3[시스템 장애]
    end
    
    subgraph "대응 방안"
        TR1 --> M1[배치 처리 최적화]
        TR2 --> M2[스트리밍 처리 도입]
        TR3 --> M3[규칙 우선순위 정의]
        
        OR1 --> M4[교육 프로그램 개발]
        OR2 --> M5[데이터 품질 검증 강화]
        OR3 --> M6[모니터링 시스템 구축]
    end
    
    M1 --> Success[성공적 운영]
    M2 --> Success
    M3 --> Success
    M4 --> Success
    M5 --> Success
    M6 --> Success
    
    style Success fill:#c8e6c9
    style TR1 fill:#ffcdd2
    style TR2 fill:#ffcdd2
    style TR3 fill:#ffcdd2
    style OR1 fill:#ffe0b2
    style OR2 fill:#ffe0b2
    style OR3 fill:#ffe0b2
```

---

## 요약

이 데이터 표준화 토큰 분석기는 다음과 같은 핵심 가치를 제공합니다:

1. **자동화된 데이터 품질 관리**: 수동 검증에서 자동화된 시스템으로 전환
2. **표준화된 명명 규칙**: 일관된 데이터베이스 명명 체계 구축
3. **운영 효율성 향상**: 개발자 생산성 증대 및 오류 감소
4. **확장 가능한 아키텍처**: 새로운 규칙 및 요구사항 대응 용이
5. **포괄적인 분석 기능**: 상세한 보고서 및 트러블슈팅 지원

이 시스템을 통해 조직은 데이터 거버넌스를 강화하고, 개발 프로세스를 개선하며, 장기적으로 유지보수 비용을 절감할 수 있습니다. 

## DataCompletenessAnalyzer 상세 플로우

```{mermaid}
flowchart TD
    Start[완전성 분석 시작] --> ValidateInput[입력 데이터 검증]
    ValidateInput --> ProcessData[데이터 처리]
    
    ProcessData --> TableAnalysis[테이블 완전성 분석<br/>- 논리명_국문<br/>- 논리명_영문<br/>- 물리명]
    ProcessData --> ColumnAnalysis[컬럼 완전성 분석<br/>- 논리명_국문<br/>- 논리명_영문<br/>- 물리명<br/>- 설명]
    
    TableAnalysis --> CalculateCompleteness[완전성 비율 계산]
    ColumnAnalysis --> CalculateCompleteness
    
    CalculateCompleteness --> GenerateReport[완전성 보고서 생성]
    GenerateReport --> TableSummary[테이블 완전성 요약]
    GenerateReport --> ColumnSummary[컬럼 완전성 요약]
    GenerateReport --> OverallSummary[전체 요약 통계]
    
    TableSummary --> Results[분석 결과 출력]
    ColumnSummary --> Results
    OverallSummary --> Results
    
    style Start fill:#c8e6c9
    style Results fill:#c8e6c9
    style TableAnalysis fill:#e3f2fd
    style ColumnAnalysis fill:#e8f5e8
    style CalculateCompleteness fill:#fff3e0
```


## Domain Generator


```{mermaid}
flowchart TD
    A[시작] --> B["초기화<br/>• 13개 도메인 그룹 정의<br/>• 기존 도메인 로드<br/>• 생성 규칙 설정"]
    
    B --> C["각 그룹별 도메인 생성<br/>가중치 기반 개수 할당"]
    
    C --> D["도메인 생성 루프<br/>템플릿 + 주제어 + 수식어 조합"]
    
    D --> E{중복 검사}
    E -->|중복| F{최대 시도 초과?}
    E -->|신규| G[도메인 추가]
    
    F -->|Yes| H[다음 그룹]
    F -->|No| D
    
    G --> I{목표 개수 달성?}
    I -->|No| D
    I -->|Yes| H
    
    H --> J{모든 그룹 완료?}
    J -->|No| C
    J -->|Yes| K["품질 분석 및 저장<br/>• 중복/길이/분포 확인<br/>• Excel 파일 저장"]
    
    K --> L[완료]
    
    %% 스타일링
    classDef startEnd fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000000
    classDef process fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000000
    classDef decision fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000000
    classDef generation fill:#e8f5e8,stroke:#388e3c,stroke-width:2px,color:#000000
    
    class A,L startEnd
    class B,K process
    class E,F,I,J decision
    class C,D,G,H generation

```




## Domain Classifier

### English

```{mermaid}
flowchart TD
    A[시작] --> B["데이터 준비<br/>• 영어 논리명 24개<br/>• 라벨 인코딩<br/>• NLTK 토큰화<br/>• Train/Test 분할"]
    
    B --> C["모델 구축<br/>BiLSTM + Recency-weighted Attention"]
    
    C --> D["학습 루프<br/>Forward → Loss → Backward"]
    
    D --> E{20 에포크<br/>완료?}
    E -->|No| D
    E -->|Yes| F["모델 저장 및 예측 테스트<br/>• OOV 처리<br/>• 어텐션 가중치 출력"]
    
    F --> G[완료]
    
    %% 스타일링
    classDef startEnd fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000000
    classDef process fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000000
    classDef model fill:#e8f5e8,stroke:#388e3c,stroke-width:2px,color:#000000
    classDef training fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000000
    classDef decision fill:#ffebee,stroke:#c62828,stroke-width:2px,color:#000000
    
    class A,G startEnd
    class B,F process
    class C model
    class D training
    class E decision

```

### Koreans
```{mermaid}
flowchart TD
    A[시작] --> B1
    
    subgraph B ["데이터 로드 및 전처리"]
        B1[Excel 파일 읽기] --> B2[문자 어휘 사전 구축]
        B2 --> B3[라벨 인코딩]
        B3 --> B4[Train/Val/Test 분할]
    end
    
    B4 --> C["모델 구축<br/>Embedding → Bi-LSTM → Attention → Dense"]
    
    C --> D["학습 루프<br/>Forward Pass → Loss 계산 → Backward Pass"]
    
    D --> E{성능 개선?}
    E -->|Yes| F[모델 저장]
    E -->|No| G[조기 종료 카운터 증가]
    
    F --> H{학습 종료?}
    G --> H
    H -->|계속| D
    H -->|완료| I1
    
    subgraph I ["모델 평가"]
        I1[테스트 정확도] --> I2[혼동 행렬]
        I2 --> I3[분류 리포트]
    end
    
    I3 --> J[예측 테스트 및 저장]
    J --> K[완료]
    
    classDef startEnd fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000000
    classDef process fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000000
    classDef decision fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000000
    classDef evaluation fill:#e8f5e8,stroke:#388e3c,stroke-width:2px,color:#000000
    
    class A,K startEnd
    class B,C,D process
    class E,H decision
    class F,G,I,J evaluation

```



### Domain Class Integreation

```{mermaid}
flowchart TB
    A[시작] --> B[시스템 선택]
    
    subgraph DG ["1. Domain Generator"]
        direction LR
        C["초기화<br/>• 13개 도메인 그룹 정의<br/>• 기존 도메인 로드<br/>• 생성 규칙 설정"]
        D["도메인 생성<br/>템플릿 + 주제어 + 수식어"]
        E{중복 검사}
        F["품질 분석 및 저장<br/>Excel 파일 출력"]
        
        C --> D --> E --> F
    end
    
    subgraph DC ["2. 도메인 분류기"]
        direction LR
        G["도메인 데이터 로드<br/>생성된 도메인 사용"]
        H["전처리<br/>문자/단어 어휘 사전 구축"]
        I["모델 구축<br/>Bi-LSTM + Attention"]
        J["학습 및 평가"]
        K["도메인 분류 모델<br/>(한글/영어 모두 지원)"]
        
        G --> H --> I --> J --> K
    end
    
    subgraph APP ["3. 응용 시스템"]
        direction LR
        L["사용자 입력<br/>(한글/영어 도메인)"]
        M["도메인 분류 실행"]
        N["결과 출력 및<br/>표준화 적용"]
        
        L --> M --> N
    end
    
    %% 연결 관계
    B --> C
    F -.->|생성된 데이터| G
    K -.->|학습된 모델| M
    
    %% 스타일링
    classDef startEnd fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000000
    classDef generator fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000000
    classDef korean fill:#e8f5e8,stroke:#388e3c,stroke-width:2px,color:#000000
    classDef rag fill:#e1f5fe,stroke:#0277bd,stroke-width:2px,color:#000000
    classDef application fill:#ffebee,stroke:#c62828,stroke-width:2px,color:#000000
    classDef decision fill:#fce4ec,stroke:#ad1457,stroke-width:2px,color:#000000
    
    class A,B startEnd
    class C,D,E,F generator
    class G,H,I,J,K korean
    class L,M,N,O,P rag
    class Q,S,T,U1,U,V application
    class R decision
```

## Streamlit Presentation


```{mermaid}
flowchart TD
    A[사용자 입력] --> B{입력 유형}
    
    B -->|논리명| C[약어 생성 탭]
    B -->|코드| D[논리명 추천 탭]
    B -->|검증 요청| E[검증 결과 탭]
    
    C --> F[RAG 검색 + LLM 처리]
    D --> F
    E --> G[규칙 기반 검증]
    
    F --> H[약어/논리명 생성]
    G --> I[품질 점수 계산]
    
    H --> J[결과 화면]
    I --> J
    
    J --> K[사용자 피드백]
    K --> L[학습 데이터 업데이트]
    
    style A fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style B fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style C fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style D fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style E fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style J fill:#ffebee,stroke:#c62828,stroke-width:2px
```

### 핵심 기능별 처리 흐름

```{mermaid}
flowchart TD
    START[시작] --> INPUT[사용자 입력]
    
    INPUT --> FUNC1[ 논리명 기반 <br>약어 생성 기능]
    INPUT --> FUNC2[코드 기반 <br>논리명 추천 기능]
    INPUT --> FUNC3[규칙 기반 <br>검증 기능]
    
    FUNC1 --> PROCESS1[논리명 분석<br/>+ RAG 검색]
    FUNC2 --> PROCESS2[코드 분석<br/>+ 패턴 매칭]
    FUNC3 --> PROCESS3[규칙 검증<br/>+ 품질 측정]
    
    PROCESS1 --> RESULT1[약어 + 설명]
    PROCESS2 --> RESULT2[논리명 목록]
    PROCESS3 --> RESULT3[검증 점수]
    
    RESULT1 --> OUTPUT[결과 출력]
    RESULT2 --> OUTPUT
    RESULT3 --> OUTPUT
    
    OUTPUT --> FEEDBACK[사용자 피드백]
    FEEDBACK --> LEARN[시스템 학습]
    
    style START fill:#c8e6c9,stroke:#388e3c,stroke-width:2px
    style INPUT fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style OUTPUT fill:#ffebee,stroke:#c62828,stroke-width:2px
    style LEARN fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
```



### 시스템 구성요소

```{mermaid}
flowchart LR
    subgraph "사용자 인터페이스"
        UI[Streamlit 앱]
        TAB1[약어 생성]
        TAB2[논리명 추천]
        TAB3[검증 결과]
    end
    
    subgraph "AI 처리"
        RAG[RAG 시스템]
        LLM[GPT-4o]
        EMB[임베딩 검색]
    end
    
    subgraph "데이터 처리"
        TOKEN[토큰 분석]
        DOMAIN[도메인 분류]
        RULE[규칙 검증]
    end
    
    UI --> TAB1
    UI --> TAB2
    UI --> TAB3
    
    TAB1 --> RAG
    TAB2 --> RAG
    TAB3 --> RULE
    
    RAG --> LLM
    RAG --> EMB
    
    LLM --> TOKEN
    TOKEN --> DOMAIN
    DOMAIN --> RULE
    
    style UI fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style RAG fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style LLM fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style TOKEN fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
```

### 용어 표준화 RAG 시스템 전체 아키텍처

```{mermaid}
flowchart TB
    subgraph "Data Sources"
        DS1[표준화 규칙 문서<br/>PDF/DOCX]
        DS2[기존 용어 사전<br/>Excel/CSV]
        DS3[도메인 분류 데이터<br/>학습 데이터]
        DS4[코드/변수명<br/>사용자 입력]
    end
    
    subgraph "RAG Knowledge Base"
        KB1[문서 벡터 저장소<br/>FAISS]
        KB2[용어 패턴 임베딩<br/>OpenAI Embeddings]
        KB3[도메인 규칙 인덱스<br/>Semantic Search]
    end
    
    subgraph "LLM Processing"
        LLM1[규칙 기반 약어 생성<br/>GPT-4o]
        LLM2[코드 기반 논리명 추천<br/>Context-aware]
        LLM3[일관성 검증 및 개선<br/>Multi-turn Chat]
    end
    
    subgraph "Streamlit Interface"
        UI1[약어 생성 탭<br/>논리명 to 물리명]
        UI2[논리명 추천 탭<br/>코드 to 논리명]
        UI3[검증 결과 탭<br/>품질 평가]
        UI4[히스토리 관리<br/>사용자 피드백]
    end
    
    subgraph "Core Processing"
        CP1[TokenProcessor<br/>토큰 분석]
        CP2[DomainClassifier<br/>Bi-LSTM 분류]
        CP3[AbbreviationManager<br/>약어 생성 엔진]
        CP4[RuleAnalyzer<br/>규칙 검증]
    end
    
    subgraph "Quality Assurance"
        QA1[RAGAS 평가<br/>답변 품질 측정]
        QA2[일관성 체크<br/>기존 용어 대비]
        QA3[피드백 루프<br/>학습 개선]
    end
    
    %% 데이터 흐름
    DS1 --> KB1
    DS2 --> KB2
    DS3 --> KB3
    DS4 --> UI2
    
    %% RAG 검색 흐름
    KB1 --> LLM1
    KB2 --> LLM2
    KB3 --> LLM3
    
    %% UI 상호작용
    UI1 --> CP1
    UI2 --> CP2
    UI3 --> CP4
    UI4 --> QA3
    
    %% 처리 흐름
    CP1 --> CP3
    CP2 --> CP3
    CP3 --> CP4
    CP4 --> QA1
    
    %% LLM 통합
    LLM1 --> CP3
    LLM2 --> CP1
    LLM3 --> CP4
    
    %% 품질 보증
    QA1 --> QA2
    QA2 --> QA3
    QA3 --> KB1
    
    %% 결과 출력
    CP4 --> UI3
    QA1 --> UI3
    QA2 --> UI4
    
    %% 스타일링
    style DS1 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style DS2 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style DS3 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style DS4 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    
    style KB1 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style KB2 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style KB3 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    
    style LLM1 fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style LLM2 fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style LLM3 fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    
    style UI1 fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style UI2 fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style UI3 fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style UI4 fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    
    style QA1 fill:#ffebee,stroke:#c62828,stroke-width:2px
    style QA2 fill:#ffebee,stroke:#c62828,stroke-width:2px
    style QA3 fill:#ffebee,stroke:#c62828,stroke-width:2px
```

### 사용자 시나리오별 플로우

#### 시나리오 1: 영어 논리명 → 약어 생성

```{mermaid}
sequenceDiagram
    participant U as 사용자
    participant ST as Streamlit UI
    participant RAG as RAG 시스템
    participant LLM as GPT-4o
    participant DB as 검증 엔진
    
    U->>ST: 영어 논리명 입력
    ST->>RAG: 유사 용어 검색
    RAG->>LLM: 규칙 문서 + 유사 패턴 제공
    LLM->>DB: 약어 생성 요청
    DB->>DB: 규칙 검증 수행
    DB->>ST: 약어 + 준수율 반환
    ST->>U: 결과 표시 + 시각화
    
    Note over U,DB: 실시간 스트리밍 처리
    Note over RAG,LLM: 컨텍스트 기반 추천
```

#### 시나리오 2: 코드 → 논리명 추천

```{mermaid}
sequenceDiagram
    participant U as 사용자
    participant ST as Streamlit UI
    participant CA as 코드 분석기
    participant RAG as RAG 시스템
    participant LLM as GPT-4o
    
    U->>ST: 코드 스니펫 입력
    ST->>CA: 변수명 추출
    CA->>RAG: 패턴 매칭 검색
    RAG->>LLM: 컨텍스트 + 규칙 제공
    LLM->>ST: 논리명 추천 목록
    ST->>U: 신뢰도별 추천 표시
    
    Note over CA,RAG: AST 파싱 + 벡터 검색
    Note over LLM,ST: 멀티턴 대화 지원
```

### 핵심 기술 스택 통합 구조

```{mermaid}
graph LR
    subgraph "Frontend"
        A[Streamlit UI]
        B[실시간 스트리밍]
        C[채팅 인터페이스]
    end
    
    subgraph "Backend Processing"
        D[LangChain LCEL]
        E[RAG 파이프라인]
        F[멀티턴 대화]
    end
    
    subgraph "AI/ML Models"
        G[OpenAI GPT-4o]
        H[FAISS 벡터 DB]
        I[Bi-LSTM 분류기]
    end
    
    subgraph "Data Layer"
        J[문서 로더]
        K[임베딩 처리]
        L[검증 엔진]
    end
    
    subgraph "Quality Assurance"
        M[RAGAS 평가]
        N[피드백 루프]
        O[성능 모니터링]
    end
    
    %% 연결 관계
    A --> D
    B --> E
    C --> F
    
    D --> G
    E --> H
    F --> I
    
    G --> J
    H --> K
    I --> L
    
    J --> M
    K --> N
    L --> O
    
    %% 피드백 루프
    M --> E
    N --> D
    O --> A
    
    %% 스타일링
    style A fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style G fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style J fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style M fill:#ffebee,stroke:#c62828,stroke-width:2px
```

### 기대 효과 및 ROI

```{mermaid}
pie title 업무 효율성 향상
    "자동화된 약어 생성" : 40
    "일관성 검증 자동화" : 25
    "코드 기반 추천" : 20
    "품질 관리 시스템" : 15
```

```{mermaid}
graph LR
    subgraph "정량적 효과"
        A["처리 시간<br/>90% 단축"]
        B["오류율<br/>80% 감소"]
        C["일관성<br/>95% 향상"]
    end
    
    subgraph "정성적 효과"
        D["개발자 만족도<br/>향상"]
        E["표준화 정착<br/>문화 조성"]
        F["데이터 품질<br/>체계화"]
    end
    
    A --> D
    B --> E
    C --> F
    
    style A fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style B fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style C fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style D fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style E fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style F fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
```


# LLFS Study


```{mermaid}

flowchart TB
    subgraph DC ["Data Collection"]
        MCBS[Multi Centered Blood Sampling]
        MS[Mass Spectrometry]
        DT[Data Collection <br> & Engineering]
        
        MCBS --> MS
        MS --> DT
    end
    
    subgraph QC ["Quality Control"]
        IAD[Identify Anomaly Data]
        IMV[Identify Missing Values]

    end
    
    subgraph AN ["Analytics"]
        EDA[EDA]
        DM[Data Mining]
        SA[Statistical Analysis]
        ML[Machine Learning]
        DN[Clinical Domain Knowledge]
        
        EDA --> DM
        DM --> SA
        SA --> ML
        ML --> DN
    end
    
    subgraph RC ["Reporting and Conclusion"]
        SWF[Sharing with Coworkers &<br> Writing a Manuscript]
    end
    
    %% 클러스터 간 연결
    DT --> IAD
    IMV --> EDA
    DN --> SWF
    
    %% 스타일링
    style DC fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style QC fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style AN fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style RC fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    
    style MCBS fill:#e1f5fe
    style MS fill:#e1f5fe
    style DT fill:#e1f5fe
    style IAD fill:#fff8e1
    style IMV fill:#fff8e1
    style EDA fill:#e8f5e8
    style DM fill:#e8f5e8
    style SA fill:#e8f5e8
    style ML fill:#e8f5e8
    style SWF fill:#fce4ec
```
