---
title: Variables
subtitle: Variable Types in Statistics
description: |
  
categories:
  - Statistics
author: Kwangmin Kim
date: 11/07/2023
draft: False
format: 
  html:
    page-layout: full
    code-fold: true
---

<ul class="nav nav-pills" id="language-tab" role="tablist">
  <li class="nav-item" role="presentation">
    <button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" role="tab" aria-controls="Korean" aria-selected="true">Korean</button>
  </li>
  <li class="nav-item" role="presentation">
    <button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" role="tab" aria-controls="knitr" aria-selected="false">English</button>
  </li>

<div class="tab-content" id="language-tabcontent">

<div class="tab-pane fade  show active" id="Korean" role="tabpanel" aria-labelledby="Korean-tab">

# Variable

## Concept

* 어떤 현상이나 사물의 의미를 추상적인 용어를 사용하여 관념적으로 구성한 것
* ex) 성 (gender)

## Concept of Variable

* 한 연속선상에서 둘 이상의 값을 가지는 개념
* ex) 성별(sex)

## Constant

* 결코 변하지 않는 단 하나의 값
* ex) 남자, 여자


# Variable Types

## 독립변수

* 독립변수 (independent variable) 는 조사하고자 하는 사건이나 상황을 독립적으로 발생시키는 원인이 되는 변수로서 *원인변수*, *설명변수*, *예측변수* 라고도 부름
* if s + v, s + v 에서 if s + v 에서 독립 변수의 정보를 추출해낼 수 있다. 
* 예를 들어, 사람이 운동을 하면 근육량이 늘어 난다. 
* 여기서 *사람이 운동을 하면* 부분에서 독립 변수를 뽑아낸다면 운동의 유무가 독립변수가 될 수 있다. 근육량의 변화는 운동의 유무에 따라 결정되는 원인 부분이기 때문이다.

## 종속변수

* 종속변수 (dependent variable) 는 다른 변수에 영향을 받는 변수
* 다른 변수에 영향을 미칠 수 없는 변수
* 인과 관계에서 결과(effect)를 나타냄
* 결과변수, 피설명변서, 피예측변수, 반응변수, 가설적 변수라고도 부른다.
* if s + v, s + v 에서 s + v 에서 독립 변수의 정보를 추출해낼 수 있다. 
* 예를 들어, 사람이 운동을 하면 근육량이 늘어난다. 
* 여기서 *근육량이 늘어난다.* 부분에서 종속 변수가 뽑힌다. 근육량이 종속변수가 될 수 있다. 근육량은 운동의 유무에 따라 그 효과가 영향을 받는 결과 부분이기 때문이다.

## 매개변수

* 매개변수 (intervening variable)는 두 변수는 서로 직접적인 관계가 없는데 두 변수가 간접적으로 관계를 갖는 것처럼 보이도록 하는 변수
* 독립변수와 종속변수 사이에 개입하여 두 변수를 연결하는 변수
* 매개변수는 독립변수의 결과변수인 동시에 종속변수의 원인이 되는 변수
* 독립변수 $\righttarrow$ 매개변수 $\righttarrow$ 종속변수
  * 여기서 독립변수와 종속변수는 직접적인 관계가 없지만, 매개 변수에 의해 마치 관계를 갖는 것처럼 보임
* 예를 들어, 여가 문화 요인의 매개효과를 고려한 장애인의 경제상태가 삶의 만족도에 미치는 영향
  * 독립변수: 경제 상태
  * 종속변수: 삶의 만족도
  * 매개변수: 여가 문화
  * 경제 상태는 여가 문화의 독립 변수로서 돈이 많으면 여가 문화를 즐길 수 있는 비용을 지불할 수 있는 원인이 된다.
  * 여가 문화는 삶의 만족도의 독립 변수로서 여가 문화를 즐김으로 인해 본인이 원하는 취미 활동을 향유함으로써 삶의 만족도가 증가하는 원인이 된다.

## 조절변수

* 조절변수 (moderating variable) 는 독립변수가 종속변수에 원인이 되며 영향을 미치는 영향력의 강도, 세기 , 방향을 조절하는 변수
* 독립변수 $\righttarrow$ 조절변수 $\righttarrow$ 종속변수
* 예를 들어, 따돌림 피해자 학생에 대한 교사의 지지도에 따라 집단따돌림이 자존감에 미치는 영향
  * 교사가 피해자 학생에게 무관심하다면 피해자 학생에 대한 학교폭력이 가중되면서 자존감이 더 하락할 것.
* 예를 들어, 자녀유무에 따라 부부간 의사소통이 이혼에 미치는 영향
  * 부부간 의사소통이 없다면 이혼가능성이 올라간다는 전제가 있고 자녀가 있다면 이혼 가능성이 낮아 질 수 있음

## 외생변수

* 외생변수 (extraneous variable)는 독립변수 외에 종속변수에 영향을 주는 변수로서 원래 관계가 없는 변수를 관계가 있는 것처럼 만들어 종속 변수에 대한 가짜 독립변수가 만들어진다 (가식적 관계 또는 허위관계)
* 외생변수를 통제하면 관계가 있는 것으로 나타났던 독립변수와 종속변수의 관계가 사라짐
* 외새변수는 반드시 통제해줘야 함
* 구조 방정식에서 독립 변수의 개념, 다른 변수에 영향을 주는 변수. 즉 기존에 원인인 것처럼 보이던 가짜 독립 변수가 아니라 실제 원인인 외생변수가 종속변수에 대한 진짜 독립변수. 
* 독립변수 $\leftarrow$ 외생변수 $\righttarrow$ 종속변수
* 예를 들어, 무릎이 쑤시면 비가 온다.
  * 기압이 낮으면 무릎의 통증을 유발하고 동시에 비가 내리는 원인이 된다. 기압의 존재를 찾아내지 못하면 마치 무릎의 통증이 비를 내리게 하는 원인인 것 처럼 인식한다.
  * 대기압이 낮으면 비구름이 고기압에서 저기압으로 이동하면서 비를 내리게 하고 동시에 대기압이 낮을때 상대적으로 체내의 내부 기압이 높아져 팽창하여 관절이 부딪히게 된다.

## 내생변수

* 내생변수 (intraneous variable)는 다른 변수로부터 영향을 받는 변수로서 모형 안에서 그 값이 결정되는 변수 
* 구조 방정식에서 종속변수에 해당.
## 억압변수
## 통제변수

### Significance

실험 결과가 우연히 생성된 것보다 더 극단적인 경우를 통계적으로 유의하다고 한다. (결과가 귀무 가설 하의 분포와 다른 분포에서 나올 수 있다고 생각해 보십시오.)

### p-value

'p-값'의 p는 '확률'을 나타냅니다. p-값은 실험에서 관찰된 결과가 귀무 가설 하에서 발생할 수 있는 극단적인 결과를 얻을 확률의 합계입니다. 즉, p-값은 실험 결과가 우연히 얻어질 확률입니다.

### Alpha

우연한 결과가 통계적으로 유의미하다고 하기 위해 실험의 실제 결과를 넘어서야 하는 극단적이거나 드문 결과의 확률 임계값입니다.

### Type 1 error

귀무가설이 참인데 실수로 귀무가설을 기각하는 오류

### Type 2 error

대립가설이 참인데 실수로 귀무가설을 기각하지 못하는 오류

## p-value: Good vs Bad?

### Goodness

p-값은 테스트 결과의 유의성을 측정할 때 효율적이고 효과적인 통계 지표입니다. 회귀 분석을 수행했다고 가정해 봅시다. 그런 다음 회귀 모델의 결과로 베타 계수와 표준 오차를 얻을 수 있습니다.

|              | high Standard Error    |     low Standard Error |
|--------------|:-----------------------|-----------------------:|
| high $\beta$ | Unclear Interpretation |                     OK |
| low $\beta$  | OK                     | Unclear Interpretation |

: Number of Cases of How You Interpret Regresssion Result

위의 표는 회귀 모델의 결과를 해석할 수 있는 경우의 수를 보여줍니다. 각 계수 $\beta$ 에 대해 4개의 경우가 있습니다. 

1.  **high $\beta$ and high Standard Error** mean that 해당 변수가 강한 영향을 미치나 그 영향이 변동될 수 있음을 의미하므로 회귀 모델에서 도출된 $\beta$ 계수는 유의하지 않을 가능성이 높습니다. 그 효과가 통계적으로 유의미한지 확신할 수 없습니다.
2.  **high $\beta$ and low Standard Error** mean that the corresponding variable has a strong effect, and its variation is small, so the $\beta$ coefficient resulted from your regression model is likely to be significant.
3.  **low $\beta$ and high Standard Error** mean that the corresponding variable has a weak effect on your reponse variable, its effect has a high variation. So, we can clearly interprete the variable with the $\beta$ as a variable that is not significantly associated with your response variable.
4.  **low $\beta$ and high Standard Error** mean that the corresponding variable has a weak effect on your reponse variable, but its effect has a low variation. So, it is difficult to conclude that the variable is significant.

The p-value could be used to provide a clearer interpretation of the unclear situation (i.e. (high $\beta$, high Standard Error), (low $\beta$, high Standard Error) ) by looking at the ratio of the estimated value of a parameter(= $\beta$) to its standard error on the distribution under the null hypothesis. By general convention, the cut-off of p-value indicating statistical signficance is 0.05.

### Badness

Despite the goodness of p-value, it is controversial to make a decision based solely on the p-value. As mentioned above, p-value is the probability that the result of your experiment is due to chance. In addition, looking into $\frac{\beta}{\frac{s.e}{\sqrt{n}}}$, the p-value gets smaller as the sample size becomes larger and larger. **It should be avoided that something is proved just because a low p-value is calucated**.

Even if a result is statistically significant, that does not necessarily mean it has real significance. A small difference that has no practical meaning can be statistically significant if the sample size is large enough. It is because large samples ensure that meaningless effects can become big enough to possibly exclude chance due to simple math.

The American Statistical Association (ASA) has released a statement of six principles for researchers and journal editors on p-values:\
[Source: ASA Statement on Statistical Significance and p-values](https://www.amstat.org/asa/files/pdfs/p-valuestatement.pdf)

1.  P-values can indicate how incompatible the data are with a specified statistical model.
2.  P-values do not measure the probability that the studied hypothesis is true, or the probability that the data produced by random chance alone.
3.  Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.
4.  Proper inference requires full reporting and transparency.
5.  A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.
6.  By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.

## How to use p-vlaues?

Personally, I make use of p-values as a tool in data science to just check whether a model result or a set of variables that appears interesting and useful is in the range of normal variability by chance in the exploratory data analysis(EDA) or data mining step.

If you want to get a statistical significance level through p-values, other methodologies could help increase the accuracy of real significance such as permuted p-values, q-values, and penalization on multiple comparison tests


</div>

<div class="tab-pane fade" id="English" role="tabpanel" aria-labelledby="English-tab">

### Significance

It is said to be statistically significant if a result of your experiment is more extreme than one that is produced by chance. (Try thinking that your result could have come from a different distribution from the one under the null hypothesis.)

### p-value

p of 'p-value' stands for 'probability'. The p-value is the summation of the probabilities of obtaining results as extreme as the observed results from your experiments could occur under the null hypothesis. In other words, p-value is the probability that the result of your experiment is obtained by chance.

### Alpha

The probability threshold of the extreme or rarer results that chance results must be beyond actual results of your experiments in order to be said to be statistically significant.

### Type 1 error

concluding $H_o$ or the null hypothesis is true by mistake.

### Type 2 error

concluding $H_a$ or the alternative hypothesis is true by mistake.

## p-value: Good vs Bad?

### Goodness

p-value is an efficient and effective statistical index when to measure the significance of your test result. Let's make an assumption that you have conducted a regression analysis. Then, you can get beta coefficients and their standard errors as results of your regression model.

|              | high Standard Error    |     low Standard Error |
|--------------|:-----------------------|-----------------------:|
| high $\beta$ | Unclear Interpretation |                     OK |
| low $\beta$  | OK                     | Unclear Interpretation |

: Number of Cases of How You Interpret Regresssion Result

The above table shows the number of cases you can interprete the results of your regression model. There are 4 cases for each coefficient $\beta$.

1.  **high $\beta$ and high Standard Error** mean that the corresponding variable has a strong effect but its effect may be fluctuated, so the $\beta$ coefficient resulted from your regression model is likely to be not significant. We are not sure that its effect is statistically significant.
2.  **high $\beta$ and low Standard Error** mean that the corresponding variable has a strong effect, and its variation is small, so the $\beta$ coefficient resulted from your regression model is likely to be significant.
3.  **low $\beta$ and high Standard Error** mean that the corresponding variable has a weak effect on your reponse variable, its effect has a high variation. So, we can clearly interprete the variable with the $\beta$ as a variable that is not significantly associated with your response variable.
4.  **low $\beta$ and high Standard Error** mean that the corresponding variable has a weak effect on your reponse variable, but its effect has a low variation. So, it is difficult to conclude that the variable is significant.

The p-value could be used to provide a clearer interpretation of the unclear situation (i.e. (high $\beta$, high Standard Error), (low $\beta$, high Standard Error) ) by looking at the ratio of the estimated value of a parameter(= $\beta$) to its standard error on the distribution under the null hypothesis. By general convention, the cut-off of p-value indicating statistical signficance is 0.05.

### Badness

Despite the goodness of p-value, it is controversial to make a decision based solely on the p-value. As mentioned above, p-value is the probability that the result of your experiment is due to chance. In addition, looking into $\frac{\beta}{\frac{s.e}{\sqrt{n}}}$, the p-value gets smaller as the sample size becomes larger and larger. **It should be avoided that something is proved just because a low p-value is calucated**.

Even if a result is statistically significant, that does not necessarily mean it has real significance. A small difference that has no practical meaning can be statistically significant if the sample size is large enough. It is because large samples ensure that meaningless effects can become big enough to possibly exclude chance due to simple math.

The American Statistical Association (ASA) has released a statement of six principles for researchers and journal editors on p-values:\
[Source: ASA Statement on Statistical Significance and p-values](https://www.amstat.org/asa/files/pdfs/p-valuestatement.pdf)

1.  P-values can indicate how incompatible the data are with a specified statistical model.
2.  P-values do not measure the probability that the studied hypothesis is true, or the probability that the data produced by random chance alone.
3.  Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.
4.  Proper inference requires full reporting and transparency.
5.  A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.
6.  By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.

## How to use p-vlaues?

Personally, I make use of p-values as a tool in data science to just check whether a model result or a set of variables that appears interesting and useful is in the range of normal variability by chance in the exploratory data analysis(EDA) or data mining step.

If you want to get a statistical significance level through p-values, other methodologies could help increase the accuracy of real significance such as permuted p-values, q-values, and penalization on multiple comparison tests

</div>

## Blog Guide Map Link

* [Statistics Blog](../guide_map/index.qmd)
* [Engineering Blog](../../Engineering/guide_map/index.qmd)
* [Deep Learning Blog](../../DL/guide_map/index.qmd)
* [Machine Learning Blog](../../ML/guide_map/index.qmd)
* [Mathematics Blog](../../Mathmatics/guide_map/index.qmd)
* [Patent Blog](../../Patent/guide_map/index.qmd)
* [Validation Blog](../../Validation/guide_map/index.qmd)
