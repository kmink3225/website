<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Kwangmin Kim</title>
<link>kmink3225.netlify.app/docs/blog/index.html</link>
<atom:link href="kmink3225.netlify.app/docs/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>A great sample blog</description>
<generator>quarto-1.1.189</generator>
<lastBuildDate>Tue, 27 Dec 2022 15:00:00 GMT</lastBuildDate>
<item>
  <title>FDA Software Validation Guidance Presentation</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/2022-12-10-FDA/FDA_SW_validation_diagram.html</link>
  <description><![CDATA[ 



<section id="notice" class="level2">
<h2 class="anchored" data-anchor-id="notice">Notice</h2>
<ul>
<li>I am so sorry not for providing a compfortab visualization. Although I have tried to use <em>revealjs</em> provided in the guide section in the <em>Quarto</em> website, I am still clumsy at handling it. I will update this article as I get proficient at <em>revealjs</em> using <em>Quarto</em>.</li>
<li>The FDA validation guidance document is a bit difficult to understand because its explanations provide abstract, general, and present broad cocepts. For this reason, I compiled and made a summary of the document with many diagrams. However, some diagrams are too small to see. Please, <strong>scroll up your mouse wheel with the ‘Ctrl’ key on your keyboard pressed to zoom in on the small text in the diagrams</strong>.</li>
<li>(Writing in Progress) It is hard to say that this version of summary is suitable for representing and covering the original document. Some of the content of this document has been excluded for personal use (less than 10% of it have been excluded).</li>
</ul>
<section id="last-update" class="level3">
<h3 class="anchored" data-anchor-id="last-update">Last Update</h3>
<ul>
<li>2022-12-28, <a href="../../../../docs/blog/posts/2022-12-10-FDA/index.html">the summary of the document</a></li>
</ul>
</section>
</section>
<section id="definition-of-software-validation" class="level2">
<h2 class="anchored" data-anchor-id="definition-of-software-validation">Definition of Software Validation</h2>
<p>Software Validation is <strong>a requirement of the Quality System regulation</strong>, which was published in the Federal Register on October 7, 1996 and took effect on June 1, 1997.<br>
(See Title 21 Code of Federal Regulations (CFR) Part 820, and 61 Federal Register (FR) 52602, respectively.)</p>
<section id="some-terminology" class="level3">
<h3 class="anchored" data-anchor-id="some-terminology">Some Terminology</h3>
<p>The medical device Quality System regulation (21 CFR 820.3(k)) defines</p>
<ul>
<li>“establish” = “define, document, and implement”</li>
<li>“establish” = “established”</li>
<li>Confusing terminology: requirements, specification, verification, and validation.</li>
</ul>
</section>
<section id="objective-of-sw-validation-is-to-ensure" class="level3">
<h3 class="anchored" data-anchor-id="objective-of-sw-validation-is-to-ensure">Objective of SW validation is to ensure</h3>
<ul>
<li>accuracy</li>
<li>reliability</li>
<li>consistent intended performance, and</li>
<li>the ability to discern invalid or altered records.</li>
</ul>
</section>
</section>
<section id="quality-system-regulation" class="level2">
<h2 class="anchored" data-anchor-id="quality-system-regulation">Quality System Regulation</h2>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-1">flowchart TB
    subgraph Quality_System_Regulation
        direction LR
        subgraph Requirement
            direction TB
            user_requirements
        end
        subgraph Specification
           direction TB
           document_user_requirements 
        end 
        subgraph Verification
           direction TB
           verify_spacified_requirements
        end
        subgraph Validation
           direction TB
           Confirmation_by_Examinations
           Provision_of_objective_3evidences
        end
        Requirement--&gt; Specification --&gt; Verification --&gt; Validation                    
    end
    subgraph First_Detail
        direction TB
        subgraph User_Requirement
            direction TB
            any_need_for_customer---
            any_need_for_system---
            any_need_for_software
        end
            subgraph Document_User_Requirement
            direction TB
            define_means_for_requirements---
          define_criteria_for_requirements
        end         
        subgraph Verify_Spacified_Requirement
            direction TB
            Objective_Evidence---&gt;|needs|Software_Testing
        end
        subgraph SW_Validation
            direction TB
            subgraph Confirmation_by_Examination
            direction TB
                subgraph Examination_List_of_SW_LifeCycle
                    direction TB
                    comprehensiveness_of_software_testing---
                    inspection_verification_test---
                    analysis_verification_test---
                    other_varification_tests    
                end 
            end             
            subgraph Provision_of_Objective_3evidences
                direction TB
                Software_specifications_conformity---
                Consistent_SW_Implementation---
                Correctness_Completeness_Traceability
            end
        end
        Requirement---User_Requirement
        Specification---Document_User_Requirement
        Verification---Verify_Spacified_Requirement
        Confirmation_by_Examinations---Confirmation_by_Examination
        Provision_of_objective_3evidences---Provision_of_Objective_3evidences             
    end
</pre>
<div id="mermaid-tooltip-1" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="verification" class="level2">
<h2 class="anchored" data-anchor-id="verification">Verification</h2>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-2">flowchart LR
    subgraph Objective_Evidence
        direction LR
        subgraph Design_Outputs_of_SW_life_cycle_for_Specified_Requirements
            direction TB
            Consistency---
            Completeness---
            Correctness---
            Documentation
        end       
        subgraph Software_Testing
            direction LR
            subgraph Testing_Environments
                direction TB
                satisfaction_for_input_requirements
                satisfaction_for_input_requirements---Simulated_Use_Environment
                subgraph User_Site_Testing
                    direction TB                            
                    Installation_Qualification---
                    Operational_Qualification---
                    Performance_Qualification
                end
            end
            satisfaction_for_input_requirements---User_Site_Testing
            subgraph Testing_Activities
                direction TB
                static_analyses---
                dynamic_analyses---
                code_and_document_inspections---
                walkthroughs
            end 
        Testing_Environments--&gt;Testing_Activities
        end
    Design_Outputs_of_SW_life_cycle_for_Specified_Requirements--&gt;Software_Testing--&gt;Testing_Activities
end    

</pre>
<div id="mermaid-tooltip-2" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
<ul>
<li>Installation_Qualification (IQ): documentation of correct installations according to requirements, specifications, vendor’s recommendations, and the FDA’s guidance for all hardware, software, equipment and systems.</li>
<li>Operational_Qualification (OQ): establishment of confidence that the software shows constant performances according to specified requirements.</li>
<li>Performance_Qualification (PQ): confirmation of the performance in the intended use according to the specified requirements for functionality and safety throughout the SW life cycle.</li>
</ul>
</section>
<section id="validation" class="level2">
<h2 class="anchored" data-anchor-id="validation">Validation</h2>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-3">flowchart LR
    subgraph Validation
    direction LR
        subgraph Confirmation_by_Examination
            direction TB
            subgraph Examination_List_at_each_stage_of_SW_Life_Cycle
                direction TB
                comprehensiveness_of_software_testing---
                inspection_verification_test---
                analysis_verification_test---
                other_varification_tests    
            end 
        end
        subgraph Provision_of_objective_3evidences
            direction TB
            subgraph Software_specifications_conform_to
                direction TB
                user_needs 
                intended_uses
            end
            subgraph Consistent_SW_Implementation
                direction TB
                particular_requirements
            end
            subgraph Correctness_Completeness_Traceability
                direction TB
                correct_complete_implementation_by_all_SW_requirements---
                traceable_to_system_requirements
            end
            Software_specifications_conform_to---
            Consistent_SW_Implementation---
            Correctness_Completeness_Traceability
        end
        Confirmation_by_Examination--&gt;
        Provision_of_objective_3evidences
    end



</pre>
<div id="mermaid-tooltip-3" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="benefits-and-difficulty-of-sw-vv" class="level2">
<h2 class="anchored" data-anchor-id="benefits-and-difficulty-of-sw-vv">Benefits and Difficulty of SW V&amp;V</h2>
<section id="benefits-of-sw-vv" class="level4">
<h4 class="anchored" data-anchor-id="benefits-of-sw-vv">Benefits of SW V&amp;V</h4>
<ul>
<li>Increase the usability and reliability of the device,</li>
<li>Resulting in decreased failure rates, fewer recalls and corrective actions, less risk to patients and users, and reduced liability to device manufacturers.</li>
<li>Reduce long term costs by making V&amp;V easier and less costly to reliably modify software and revalidate software changes.</li>
</ul>
</section>
<section id="difficulty-in-sw-vv" class="level4">
<h4 class="anchored" data-anchor-id="difficulty-in-sw-vv">Difficulty in SW V&amp;V</h4>
<ul>
<li>a developer cannot test forever, and
<ul>
<li>it is difficult to know how much evidence is enough.</li>
<li>a matter of developing a <strong>level of confidence</strong> that the device meets all requirements</li>
</ul></li>
<li>Considerations for an acceptable level of confidence</li>
<li>measures and estimates such as defects found in specifications documents</li>
<li>testing coverage, and other techniques are all used before shipping the product.</li>
<li>a level of confidence varies depending upon the safety risk (hazard) of a SW or device</li>
</ul>
</section>
</section>
<section id="sw-development-as-part-of-system-design" class="level2">
<h2 class="anchored" data-anchor-id="sw-development-as-part-of-system-design">SW Development as Part of System Design</h2>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-4">flowchart LR
    subgraph Design_Review
        direction LR
        purpose_design_review---
        design_review_types---
        design_review_requirements---
        design_review_outputs
    end
</pre>
<div id="mermaid-tooltip-4" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
<p>Software validation must be considered within the context of the overall design validation for the system. A documented requirements specification represents</p>
<ul>
<li>user’s needs</li>
<li>intended uses from which the product is developed.</li>
</ul>
<p><strong>A primary goal of SW validation is to demonstrate that all completed SW products comply with all documented requirements</strong>.</p>
</section>
<section id="design-review" class="level2">
<h2 class="anchored" data-anchor-id="design-review">Design Review</h2>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-5">flowchart LR
    subgraph Design_Review
        direction LR
        subgraph Purpose_Design_Review
            direction TB
            documented_structured_comprehensive_systematic_examinations---
            adequacy_of_design_requirements---
            capability_of_design_for_requirements---
            identification_of_problem   
        end
        subgraph Design_Reivew_Types
            direction TB
            subgraph Formal_Design_Review
                direction TB
                3rd_parties_outside_development_team
            end
            subgraph Informal_Design_Review
                direction TB
                within_development_team
            end
        Formal_Design_Review---Informal_Design_Review    
        end
        subgraph Design_Review_Requirements
            direction TB
               necessary_at_least_one_formal_design_review---
               optinal_informal_design_review---
               recommended_multiple_design_reviews
        end
        subgraph Formal_Design_Review_Outputs
            direction TB
            more_than_10_outputs
        end
        Purpose_Design_Review--&gt; Design_Reivew_Types--&gt; Design_Review_Requirements
        Design_Review_Requirements--&gt;Formal_Design_Review_Outputs
    end

</pre>
<div id="mermaid-tooltip-5" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="validation-principles" class="level2">
<h2 class="anchored" data-anchor-id="validation-principles">Validation Principles</h2>
<section id="overview" class="level3">
<h3 class="anchored" data-anchor-id="overview">Overview</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-6">flowchart LR
  subgraph Validation_Principles
        direction LR
        subgraph Validation_Starting_Point
            direction TB
            during_design_planning---
            during_development_planning---
            all_results_should_be_supported_by_evidence_collected_from_planning_SW_lifecylce
        end
        subgraph Validation_Conditions
            direction TB
            Requirements---Estabilishment_Confidence---SW_Lifecycle
        end

        subgraph Validation_Planning
            direction TB
            Specify_Areas
            subgraph Validation_Coverage
                direction TB
            end
            subgraph Validation_Process_Establishment
                direction TB
            end
        Specify_Areas---Validation_Coverage---Validation_Process_Establishment
        end

        subgraph After_Self_Validation
            direction TB
            subgraph Validation_After_SW_Change
        direction TB
        end

        subgraph Independence_of_Review
        direction TB

        end
        Validation_After_SW_Change---Independence_of_Review
        end
            Validation_Starting_Point--&gt;Validation_Conditions--&gt;Validation_Planning--&gt;
After_Self_Validation
    end
</pre>
<div id="mermaid-tooltip-6" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="conditions" class="level3">
<h3 class="anchored" data-anchor-id="conditions">Conditions</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-7">flowchart LR

subgraph Validation_Conditions
    direction LR
    subgraph SW_Requirments
        direction TB
        subgraph Documented_SW_Requirments_Specification
            direction TB
            Baseline_Provision_for_V&amp;V---
            establishment_of_software_requirements_specification
        end
    end
    subgraph Estabilishment_Confidence
        direction TB
            mixture_of_methods_techinques---
            preventing_SW_errors---
            detecting_SW_errors                 
    end
    subgraph SW_Lifecycle
        direction TB
        validation_must_be_conducted_within_established_environment_across_lifecycle---
        lifecycle_contains_SW_engineering_tasks_and_documentation---
        V&amp;V_tasks_must_reflect_intended_use
    end
end
SW_Requirments---Estabilishment_Confidence---SW_Lifecycle
</pre>
<div id="mermaid-tooltip-7" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="planning" class="level3">
<h3 class="anchored" data-anchor-id="planning">Planning</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-8">flowchart LR
    subgraph Validation_Planning
        direction LR
        define_what_to_accomplish
        subgraph Specify_Areas
            direction TB
            scope---
            approach---
            resources---
            schedules_activities---
            types_activitieis---
            extent_of_activities---
            tasks---
            work_items
        end
            define_what_to_accomplish--&gt;Specify_Areas
        subgraph Validation_Coverage
               direction TB
            depending_on_SW_complexity_of_SW_design---
            depending_on_safety_risk_for_specified_intended_use---
            select_activities_tasks_work_items_for_complexity_safety_risk
        end
        subgraph Validation_Process_Establishment
            direction TB
            establish_how_to_conduct--&gt;
            identify_sequence_of_specific_actions--&gt;
            identify_specific_activitieis--&gt;
            identify_specific_tasks--&gt;
            identify_specific_work_items
        end
    Specify_Areas--&gt;Validation_Coverage--&gt;Validation_Process_Establishment
    end
</pre>
<div id="mermaid-tooltip-8" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="after-sw-change" class="level3">
<h3 class="anchored" data-anchor-id="after-sw-change">After SW Change</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-9">flowchart LR

subgraph After_Self_Validation
    direction LR
    subgraph Validation_After_SW_Change
        direction TB
        determine_extent_of_change_on_entire_SW_system--&gt;
        determine_impact_of_change_on_entire_SW_system--&gt;
        conduct_SW_regression_testing_on_unchanged_but_vulnerable_modules
    end
    subgraph Independence_of_Review
        direction TB
        follow_basic_quality_assurance_precept_of_independence_of_review---
        avoid_self_validation---
        should_conduct_contracted_3rd_party_independent_V&amp;V---
        or_conduct_blind_test_with_internal_staff
    end
    Validation_After_SW_Change---Independence_of_Review
end
    
</pre>
<div id="mermaid-tooltip-9" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="sw-lifecycle" class="level3">
<h3 class="anchored" data-anchor-id="sw-lifecycle">SW Lifecycle</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-10">flowchart LR
subgraph SW_Lifecycle
    direction TB
    validation_must_be_conducted_within_the_established_environment_across_lifecycle---
    lifecycle_contains_SW_engineering_tasks_and_documentation---
    V&amp;V_tasks_must_reflect_intended_use
end

subgraph SW_Lifecycle_Activities
    direction TB
    subgraph should_establish_lifecycle_model
        direction TB
        subgraph SW_Lifecycle_Model_List_Defined_in_FDA
            direction TB
            waterfall---
            spiral---
            rapid_prototyping---
            incremental_development---
            etc
        end     
    end
    subgraph should_cover_SW_birth_to_retirement
        direction TB
        subgraph Lifecycle_Activities
            direction TB
            Quality_Plan--&gt;
            System_Requirements_Definition--&gt;
            Detailed_Software_Requirements_Specification--&gt;
            Software_Design_Specification--&gt;
            Construction_or_Coding--&gt;
            Testing--&gt;
            Installation--&gt;
            Operation_and_Support--&gt;
            Maintenance--&gt;
            Retirement
        end
    end
    should_establish_lifecycle_model--&gt;should_cover_SW_birth_to_retirement
    should_cover_SW_birth_to_retirement--&gt;Lifecycle_Activities
end
subgraph SW_Lifecycle_Tasks
    direction TB
    should_define_and_document_risk_related_tasks---
    should_define_and_document_which_tasks_are_appropriate_in_vice_versa---
    Quality_Planning---
    Quality_Planning_Tasks---
    Inclusion_Task_List_for_Plan---
    Identification_Task_List_for_Plan---
    Configuration_Management---
    Control---
    Management---
    Procedures---
    ensure_proper_communications_and_documentation---
    Task_Requirements
end
SW_Lifecycle--&gt;SW_Lifecycle_Activities--&gt;SW_Lifecycle_Tasks
    
</pre>
<div id="mermaid-tooltip-10" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
</section>
<section id="sw-lifecycle-tasks" class="level2">
<h2 class="anchored" data-anchor-id="sw-lifecycle-tasks">SW Lifecycle Tasks</h2>
<section id="overview-1" class="level3">
<h3 class="anchored" data-anchor-id="overview-1">Overview</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-11"> 
flowchart TB

subgraph SW_Lifecycle_Tasks
    direction LR
    subgraph Define_and_Document_List
        direction TB
        risk_related_tasks---
        whether_or_not_tasks_are_appropriate
    end
    
    subgraph Quality_Planning
        direction TB
        subgraph Quality_Planning_Tasks
            direction TB
        
        end
        subgraph Inclusion_List_for_Plan
            direction TB
            
        end
        subgraph Identification_List_for_Plan
            direction TB
            
        end
    Quality_Planning_Tasks--&gt;Inclusion_List_for_Plan--&gt;Identification_List_for_Plan
    end
    
    subgraph Configuration_Management
        direction TB
        subgraph Control
            direction TB
            
        end
        subgraph Management
            direction TB
        end
        subgraph Procedures
            direction TB
        end
        ensure_proper_communications_and_documentation
        Control--&gt;Management--&gt;Procedures--&gt;ensure_proper_communications_and_documentation 
    end
    subgraph Task_Requirements
        direction TB
        identification---
        analysis---
        predetermined_documentation_about_device_its_intended_use---
        Requirements_Specification_List---
        Verfification_List_by_Evaluation---
        Requirements_Tasks    
    end
Define_and_Document_List--&gt;Quality_Planning--&gt;Configuration_Management--&gt;Task_Requirements
end     
</pre>
<div id="mermaid-tooltip-11" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="quality-planning" class="level3">
<h3 class="anchored" data-anchor-id="quality-planning">Quality Planning</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-12">flowchart TB
subgraph Quality_Planning
    direction LR
    subgraph Quality_Planning_Tasks
        direction TB
        Risk_Hazard_Management_Plan---
        Configuration_Management_Plan---
        Software_Quality_Assurance_Plan---
        Software_Verification_and_Validation_Plan---
        Verification_and_Validation_Tasks---
        Acceptance_Criteria---
        Schedule_and_Resource_Allocation_for_V&amp;V_activities---
        Reporting_Requirements---
        Formal_Design_Review_Requirements---
        Other_Technical_Review_Requirements---
        Problem_Reporting_and_Resolution_Procedures---
        Other_Support_Activities
    end
    subgraph Inclusion_List_for_Plan
        direction TB
        specific_tasks_for_each_life_cycle_activity---
        Enumeration_of_important_quality_factors--- 
        like_reliability_maintainability_usability---
        Methods_and_procedures_for_each_task---
        Task_acceptance_criteria---
        Criteria_for_defining_and_documenting_outputs_for_input_requirements---
        Inputs_for_each_task---
        Outputs_from_each_task---
        Roles_resources_and_responsibilities_for_each_task---
        Risks_and_assumptions---
        Documentation_of_user_needs    
    end
    subgraph Identification_List_for_Plan
        direction TB
        personnel---
        facility_and_equipment_resources_for_each_task---
        role_that_risk_hazard_management        
    end
Quality_Planning_Tasks--&gt;Inclusion_List_for_Plan--&gt;Identification_List_for_Plan
end
</pre>
<div id="mermaid-tooltip-12" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="configuration-management" class="level3">
<h3 class="anchored" data-anchor-id="configuration-management">Configuration Management</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-13">flowchart LR
subgraph Configuration_Management
    direction LR
    subgraph Control
        direction TB
        control_multiple_parallel_development_activities---
        ensure_positive_and_correct_correspondence_of---
        specifications_documents---
        source_code---
        object_code---
        test_suites---
        ensure_accurate_identification_of_approved_versions---
        ensure_access_to_approved_versions---
        create_procedures_for_reporting---
        create_procedures_for_resolving_SW_anomalies                            
    end
    subgraph Management
        direction TB
        identify_reports---
        specify_contents---
        specify_format---
        specify_responsible_organizational_elements_for_each_report
    end
    subgraph Procedures
        direction TB
        necessary_for_review_of_SW_development_results---
        necessary_for_approval_of_SW_development_results
    end
    ensure_proper_communications_and_documentation
    Control--&gt;Management--&gt;Procedures--&gt;ensure_proper_communications_and_documentation 
end
</pre>
<div id="mermaid-tooltip-13" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="task-requirements" class="level3">
<h3 class="anchored" data-anchor-id="task-requirements">Task Requirements</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>

</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-14">flowchart TB
    subgraph Task_Requirements
        direction LR
        subgraph group
            direction TB
            identification---
            analysis---
            predetermined_documentation_about_device_its_intended_use
        end
        
        subgraph Requirements_Specification_List
            direction TB
            All_software_system_inputs---
            All_software_system_outputs---
            All_functions_that_software_system_will_perform---
            All_performance_requirements_that_software_will_meet---
            requirement_example_data_throughput_reliability_timing---
            definition_of_all_external_and_user_interfaces---
            any_internal_software_to_system_interfaces---
            How_users_will_interact_with_system---
            What_constitutes_error---
            how_errors_should_be_handled---
            Required_response_times---
            Intended_operating_environment_for_software---
            All_acceptable_ranges_limits_defaults_specific_values---
            All_safety_related_requirements_that_will_be_implemented_in_SW---
            All_safety_related_specifications_that_will_be_implemented_in_SW---
            All_safety_related_features_that_will_be_implemented_in_SW---
            All_safety_related_functions_that_will_be_implemented_in_SW---
            clearly_identify_potential_hazards---
            risk_evaluation_for_accuracy---
            risk_evaluation_for_completeness---
            risk_evaluation_for_consistency---
            risk_evaluation_for_testability---
            risk_evaluation_for_correctness---
            risk_evaluation_for_clarity
        end
        subgraph Verfification_List_by_Evaluation
            direction TB
            no_internal_inconsistencies_among_requirements---
            All_of_performance_requirements_for_system---
            Complete_correct_Fault_tolerance_safety_security_requirements---
            Accurate_Complete_Allocation_of_software_functions---
            Appropriate_Software_requirements_for_system_hazards---
            mesurable_requirements---
            objectively_verifiable_requirements---
            traceable_requirements
        end
        subgraph Requirements_Tasks
            direction TB
            Preliminary_Risk_Analysis---
            Traceability_Analysis---
            ex_Software_Requirements_to_System_Requirements_vice_versa---
            ex_Software_Requirements_to_Risk_Analysis---
            Description_of_User_Characteristics---
            Listing_of_Characteristics_and_Limitations_of_Memory---
            Software_Requirements_Evaluation---
            Software_User_Interface_Requirements_Analysis---
            System_Test_Plan_Generation---
            Acceptance_Test_Plan_Generation---
            Ambiguity_Review_or_Analysis
        end
    group--&gt;Requirements_Specification_List 
    Verfification_List_by_Evaluation--&gt;Requirements_Tasks
    end
</pre>
<div id="mermaid-tooltip-14" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="design-overview" class="level3">
<h3 class="anchored" data-anchor-id="design-overview">Design Overview</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-15">flowchart TB
    subgraph Deign_Task
        direction LR
    subgraph Design_Consideration_List
        direction TB
        subgraph Description
                    direction TB
                end
        subgraph Human_Factors_Engineering
          direction TB
    
        end
        subgraph Safety_Usability_Issues_Conisderation
            direction TB

            end
        Description---Human_Factors_Engineering---Safety_Usability_Issues_Conisderation
    end
    subgraph Design_Specificiation
        direction TB
        subgraph Performing_List
            direction TB
        end
        subgraph Design_Specification_Inclusion_List
            direction TB
        end
        subgraph Evaludations_Criteria_of_Design
            direction TB
        end
    Performing_List---Design_Specification_Inclusion_List---Evaludations_Criteria_of_Design 
    end
    subgraph Design_Activity_and_Task_List
        direction TB
        subgraph Final_Design_activity
            direction TB
        end
        subgraph Specific_Design_Tasks
            direction TB
        end
        subgraph Coding_Activity
            direction TB
            subgraph traceability_analysis
                direction TB
            end
            subgraph Coding_Tasks
                direction TB
            end
        traceability_analysis--&gt;Coding_Tasks
        end
        Final_Design_activity---Specific_Design_Tasks---Coding_Activity
    end
    Design_Consideration_List---Design_Specificiation---Design_Activity_and_Task_List

    end
</pre>
<div id="mermaid-tooltip-15" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="design-consideration" class="level3">
<h3 class="anchored" data-anchor-id="design-consideration">Design Consideration</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-16">flowchart TB
subgraph Design_Consideration_List
    direction LR
        subgraph Requirement_Specification
            direction TB
            logical_representation---
            physical_representation
        end
    subgraph Description
            direction TB
            what_to_do---
            how_to_do                   
        end
    subgraph Human_Factors_Engineering
      direction TB
            entire_design_and_development_process---
            device_design_requirements---
            analyses---
            tests
    end
    subgraph Safety_Usability_Issues_Conisderation
        direction TB
                flowcharts--- 
                state_diagrams--- 
                prototyping_tools---
                test_plans
        end
        Requirement_Specification---Description---Human_Factors_Engineering---Safety_Usability_Issues_Conisderation
    end
</pre>
<div id="mermaid-tooltip-16" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="design-specification" class="level3">
<h3 class="anchored" data-anchor-id="design-specification">Design Specification</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-17">flowchart TB
subgraph Design_Specificiation
        direction LR
        subgraph Conceptual_Specification
            direction TB
            requirements_specification---
            predetermined_criteria---
            Software_risk_analysis---
            Development_procedures---
            coding_guidelines
        end
        subgraph Performing_List
            direction TB
            task---
            function_analyses---
            risk_analyses---
            prototype_tests_and_reviews---
            full_usability_tests
        end
        subgraph Design_Specification_Inclusion_List
            direction TB
            SW_requirements_specification---
            predetermined_criteria_for_SW_acceptance---
            SW_risk_analysis---
            Development_procedure_list---
            coding_guidance---
            Systems_documentation---
            Hardware_to_be_used---
            Parameters_to_be_measured---
            Logical_structure---
            Control_logic---
            logical_processing_steps_aka_algorithms---
            Data_structures_diagram---
            data_flow_diagrams---
            Definitions_of_variables---
            description_of_where_they_are_used---
            Error_alarm_and_warning_messages---
            Supporting_software---
            internal_modules_Communication_links---
            supporting_sw_links---
            link_with_hardware---
            link_with_user---
            physical_Security_measures---
            logical_security_measures
        end
        subgraph Evaludations_Criteria_of_Design
            direction TB
            complete--- 
            correct---
            consistent--- 
            unambiguous--- 
            feasible---
            maintainable---
            analyses_of_control_flow---
            data_flow--- 
            complexity--- 
            timing--- 
            sizing--- 
            memory_allocation---
            module_architecture---
            traceability_analysis_of_modules--- 
            criticality_analysis
        end
    Conceptual_Specification---Performing_List---Design_Specification_Inclusion_List---Evaludations_Criteria_of_Design  
    end
</pre>
<div id="mermaid-tooltip-17" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="design-activity-and-task" class="level3">
<h3 class="anchored" data-anchor-id="design-activity-and-task">Design Activity and Task</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>

</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-18">flowchart TB
subgraph Design_Activity_and_Task_List
        direction LR
        subgraph Final_Design_activity
            direction TB
            Formal_Design_Review_Before_Design_Implementation---
            correct_consistent_complete_accurate_testable
        end
        subgraph Specific_Design_Tasks
            direction TB
            Updated_Software_Risk_Analysis---
            Traceability_Analysis---
            Software_Design_Evaluation---
            Design_Communication_Link_Analysis---
            Module_Test_Plan_Generation---
            Integration_Test_Plan_Generation---
            module_Test_Design_Generation---
            integration_Test_Design_Generation---
            system_Test_Design_Generation---
            acceptance_Test_Design_Generation   
        end
        subgraph Coding_Activity
            direction TB
            subgraph traceability_analysis
                direction TB
                each_element_implementation---
                each_module_implementation_to_element_and_risk_analysis---
                each_functions_implemented_to_element_and_risk_analysis---
                Tests_for_modules_to_element_and_risk_analysis--- 
                Tests_for_functions_to_element_and_risk_analysis---
                Tests_for_modules_to_source_code---
                Tests_for_functions_to_source_code
            end
            subgraph Coding_Tasks
                direction TB
                Traceability_Analyses---
                Source_Code_to_Design_Specification_and_vice_versa---
                Test_Cases_to_Source_Code_and_to_Design_Specification---
                Source_Code_and_Source_Code_Documentation_Evaluation---
                Source_Code_Interface_Analysis---
                Test_Procedure_and_Test_Case_Generation 
            end
        traceability_analysis--&gt;Coding_Tasks
        end
        Final_Design_activity---Specific_Design_Tasks---Coding_Activity
    end

</pre>
<div id="mermaid-tooltip-18" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
</section>
<section id="testing_task" class="level2">
<h2 class="anchored" data-anchor-id="testing_task">Testing_Task</h2>
<section id="overview-2" class="level3">
<h3 class="anchored" data-anchor-id="overview-2">Overview</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-19">flowchart TB
    subgraph Testing_Task
        direction LR
        subgraph Consideration_Before_Testing_Tasks
            direction TB
            subgraph Test_Plans
                direction TB
            end
            subgraph Conditions
                direction TB
            end
            subgraph Start_test_planning_as_early_as_possible
                direction TB
            end
            subgraph Testing_Tenets_Inclusion_List
                direction TB
            end
        Test_Plans---Conditions---Start_test_planning_as_early_as_possible---Testing_Tenets_Inclusion_List
        end
        subgraph Code_Based_Testing
            direction TB
            subgraph white_box_testing
                direction TB
            end
            subgraph Evaluation_of_level_of_white_box_testing
                direction TB
            end
            subgraph Coverage_Metrics_of_White_Box_Testing
                direction TB
            end
        white_box_testing---Evaluation_of_level_of_white_box_testing---Coverage_Metrics_of_White_Box_Testing
        end
        subgraph Alternatives_to_White_Box_Testing
            direction TB
            subgraph Types_of_Functional_Software_Testing_Increasing_Cost
                direction TB
            end
            subgraph Weakness_of_functional_and_white_box_testings
                direction TB
            end
            subgraph Advanced_software_testing_methods
                direction TB
            end
            subgraph Change_in_SW
                direction TB    
            end
        Types_of_Functional_Software_Testing_Increasing_Cost---Weakness_of_functional_and_white_box_testings---
        Advanced_software_testing_methods---Change_in_SW
        end
        

        subgraph Development_Testing
            direction TB
            subgraph unit_level_testing
                direction TB    
            end
            subgraph integration_level_testing
                direction TB
            end
            subgraph system_level_testing
                direction TB
            end
            subgraph Error_Detected
                direction TB        
            end
        unit_level_testing--&gt;integration_level_testing--&gt;system_level_testing--&gt;Error_Detected
        end

        subgraph Testing_Tasks
            direction TB
        end
        subgraph User_Site_Testing
            direction TB
            subgraph Quality_System_Rregulation
                direction TB
            end
            subgraph Understand_Terminology
                direction TB
            end
            subgraph Testing
                direction TB
            end
            Quality_System_Rregulation---Understand_Terminology---Testing
        end
Consideration_Before_Testing_Tasks---Code_Based_Testing---Alternatives_to_White_Box_Testing
Development_Testing---Testing_Tasks---User_Site_Testing
    end
</pre>
<div id="mermaid-tooltip-19" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="consideration_before_testing_tasks" class="level3">
<h3 class="anchored" data-anchor-id="consideration_before_testing_tasks">Consideration_Before_Testing_Tasks</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>

</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-20">flowchart TB
    subgraph Testing_Task
        direction LR
        subgraph Consideration_Before_Testing_Tasks
            direction LR
            subgraph Test_Plans
                direction TB
                should_identify_control_measures_like_traceability_analysis---
                ensure_that_intended_coverage_is_achieved---
                ensure_that_proper_documentation_is_prepared---
                conduct_tests_not_by_SW_developers_but_in_other_sites
            end
            subgraph Conditions
                direction TB
                use_defined_inputs---
                documented_outcomes---
                gonnabe_time_consuming_activity---
                gonnabe_difficult_activity---
                gonnabe_imperfect_activity---
                testing_all_program_functionality---
                does_not_mean_100_prcnt_correction_perfection---
                make_detailed_objective_evaluation---
                requires_sophisticated_definition_specificiation---
                all_test_procedures_data_results_are_documented---
                all_test_procedures_data_results_are_suitable_for_review---
                all_test_procedures_data_results_are_suitable_for_objective_decision_making---
                all_test_procedures_data_results_are_suitable_for_subsequent_regression_testing
            end
            subgraph Start_test_planning_as_early_as_possible
                direction TB
                make_test_plans---
                make_test_cases---
                plan_schedules---
                plan_environments---
                plan_resources_of_personnel_tools---
                plan_methodologies---
                plan_inputs_procedures_outputs_expected_results---
                plan_documentation---
                plan_reporting_criteria
            end
            subgraph Testing_Tenets_Inclusion_List
                direction TB
                expected_test_outcome_is_predefined---
                good_test_case_has_high_probability_of_exposing_errors---
                successful_test_is_one_that_finds_errors---
                There_is_independence_from_coding---
                Both_application_for_user_and_SW_for_programming_expertise_are_employed---
                Testers_use_different_tools_from_coders---
                Examining_only_the_usual_case_is_insufficient---
                Test_documentation_permits_its_reuse---
                Test_documentation_permits_independent_confirmation_---
                of_pass/fail_test_outcome_during_subsequent_review
            end
        Test_Plans---Conditions---Start_test_planning_as_early_as_possible---Testing_Tenets_Inclusion_List
        end

end
</pre>
<div id="mermaid-tooltip-20" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="code_based_testing" class="level3">
<h3 class="anchored" data-anchor-id="code_based_testing">Code_Based_Testing</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-21">flowchart TB
    subgraph Testing_Task
        direction LR
            subgraph Code_Based_Testing
                direction LR
                subgraph white_box_testing
                    direction TB
                    identify_dead_code_never_executed---
                    conduct_unit_test---
                    conduct_other_level_tests
                end
                subgraph Evaluation_of_level_of_white_box_testing
                    direction TB
                    use_coverage_metrics---
                    metrics_of_completeness_of_test_selection_criteria---
                    coverage_should_be_commensurate_with_level_of_SW_risk---
                    coverage_means_100_prcnt_coverage
                end
                subgraph Coverage_Metrics_of_White_Box_Testing
                    direction TB
                    Statement_Coverage---
                    Decision_or_Branch_Coverage---
                    Condition_Coverage---
                    Multi_Condition_Coverage
                    Loop_Coverage---
                    Path_Coverage---
                    Data_Flow_Coverage
                end
            white_box_testing---Evaluation_of_level_of_white_box_testing---Coverage_Metrics_of_White_Box_Testing
            end
end
</pre>
<div id="mermaid-tooltip-21" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
</section>
<section id="testing_task-1" class="level2">
<h2 class="anchored" data-anchor-id="testing_task-1">Testing_Task</h2>
<section id="solution_to_white_box_testing" class="level3">
<h3 class="anchored" data-anchor-id="solution_to_white_box_testing">Solution_to_White_Box_Testing</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>

</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-22"> 
flowchart TB
    subgraph Testing_Task
        direction LR
        subgraph Alternatives_to_White_Box_Testing
            direction LR
            subgraph Types_of_Testing_Increasing_Cost
                direction TB
                    Normal_Case---
                    Output_Forcing---
                    Robustness---
                    Combinations_of_Inputs
            end
            subgraph Weakness_of_functional_and_white_box_testings
                direction TB
                difficulty_in_linking_---
                tests_completion_criteria_to_SW_reliability
            end
            subgraph Advanced_software_testing_methods
                direction TB
                statistical_testing---
                provide_further_assurance_of_reliability---
                generate_randomly_test_data_from_defined_distributions---
                distribution_defined_by_expected_use---
                distribution_defined_by_hazardous_use---
                distribution_defined_by_malicious_use---
                large_test_data_cover_particular_areas_or_concerns---
                statistical_testing_provides_high_structural_coverage---
                statistical_testing_requires_stable_system---
                structural_and_functional_testing_are_prerequisites_for_statistical_testing
            end
            subgraph Change_in_SW
                direction TB
                conduct_regression_analysis_and_testing---
                should_demonstrate_correct_implementation---
                should_demonstrate_no_adverse_impact_on_other_modules   
            end
            subgraph Testing_Tasks
                direction TB
                Test_Planning---
                Structural_Test_Case_Identification---
                Functional_Test_Case_Identification---
                Traceability_Analysis_Testing---
                Unit_Tests_to_Detailed_Design---
                Integration_Tests_to_High_Level_Design---
                System_Tests_to_Software_Requirements---
                Unit_Test_Execution---
                Integration_Test_Execution---
                Functional_Test_Execution---
                System_Test_Execution---
                Acceptance_Test_Execution---
                Test_Results_Evaluation---
                Error_Evaluation_Resolution---
                Final_Test_Report
            end
        Types_of_Testing_Increasing_Cost---Weakness_of_functional_and_white_box_testings---
        Advanced_software_testing_methods---Change_in_SW---Testing_Tasks
        end
end
</pre>
<div id="mermaid-tooltip-22" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="development_testing" class="level3">
<h3 class="anchored" data-anchor-id="development_testing">Development_Testing</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-23">flowchart TB
    subgraph Testing_Task
        direction LR
        subgraph Development_Testing
            direction LR
            subgraph unit_level_testing
                direction TB    
                focus_on_early_examination_of_sub_program_functionality---
                ensure_functionality_invisible_at_system_level_examined---
                ensure_quality_software_units_furnished_for_integration
            end
            subgraph integration_level_testing
                direction TB
                focuses_on_transfer_of_data---
                focuses_on_control_across_program's_internal_and_external_interfaces
            end
            subgraph system_level_testing
                direction TB
                demonstrate_all_specified_functionality_exists---
                demonstrate_SW_is_trustworthy---
                verifies_as_built_program's_functionality_and_performance_on_requirements---
                addresses_functional_concerns_and_intended_uses---
                like_Performance_issues---
                like_Responses_to_stress_conditions---
                like_Operation_of_internal_and_external_security_features---
                like_Effectiveness_of_recovery_procedures---
                like_disaster_recovery---
                like_Usability---
                like_Compatibility_with_other_SW---
                like_Behavior_in_each_of_the_defined_hardware_configurations---
                like_Accuracy_of_documentation
            end
            subgraph Error_Detected
                direction TB        
                should_be_logged---
                should_be_classified---
                should_be_reviewed---
                should_be_resolved_before_SW_release
            end
        unit_level_testing--&gt;integration_level_testing--&gt;system_level_testing--&gt;Error_Detected
        end
end
</pre>
<div id="mermaid-tooltip-23" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
</section>
<section id="user_site_testing" class="level2">
<h2 class="anchored" data-anchor-id="user_site_testing">User_Site_Testing</h2>
<section id="overview-3" class="level3">
<h3 class="anchored" data-anchor-id="overview-3">Overview</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-24">flowchart TB
    subgraph Testing_Task
        direction LR
        subgraph User_Site_Testing
            direction LR
            subgraph Quality_System_Rregulation
                direction TB
                installation---
                inspection_procedures---
                testing_appropriateness---
                documentation_of_inspection---
                testing_to_demonstrate_proper_installation
            end
            subgraph Understand_Terminology
                direction TB
                beta_test---
                site_validation---
                user_acceptance_test---
                installation_verification---
                installation_testing
            end
            subgraph Testing
                direction TB
                subgraph Requirements
                    direction TB
                    either_actual_or_simulated_use---
                    verification_of_intended_functionality---
                    constant_contact_FDA_center
                    subgraph Follow_Predefiened_Plan
                        direction TB
    
                    end
                    subgraph Documented_Evidence
                        direction TB
        
                    end
                  subgraph Evaluation_of_System_Ability
                        direction TB
        
                    end
                  subgraph Evaluation_of_User_Ability
                        direction TB
        
                    end 
                    subgraph Evaluation_of_Operator_Ability
                        direction TB
        
                    end
                constant_contact_FDA_center--&gt;Follow_Predefiened_Plan--&gt;Documented_Evidence--&gt;
            Evaluation_of_System_Ability--&gt;Evaluation_of_User_Ability--&gt;Evaluation_of_Operator_Ability    
                end 
                        
            
            subgraph User_Site_Testing_Task
                direction TB
                Acceptance_Test_Execution2---
                Test_Results_Evaluation2---
                Error_Evaluation_Resolution2---
                Final_Test_Report2  
            end
        Requirements--&gt;User_Site_Testing_Task
        end
        Quality_System_Rregulation--&gt;    Understand_Terminology--&gt;Testing--&gt;User_Site_Testing_Task
        end
end
</pre>
<div id="mermaid-tooltip-24" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="testing" class="level3">
<h3 class="anchored" data-anchor-id="testing">Testing</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-25">flowchart TB
            subgraph Testing
                direction LR
                subgraph Requirements
                    direction LR
                    subgraph Follow_Predefiened_Plan
                        direction TB
                        either_actual_or_simulated_use---
                        verification_of_intended_functionality---
                        constant_contact_FDA_center---
                        formal_summary_of_testing---
                        record_of_formal_acceptance
                    end
                    subgraph Documented_Evidence
                        direction TB
                        testing_plan_of_full_range_of_operating_conditions---
                        testing_plan_to_detect_any_latent_faults---
                        all_testing_procedures---
                        test_input_data---
                        test_results---
                        hardware_installation_and_configuration---
                        software_installation_and_configuration---
                        exercising_measure_of_all_system_components---
                        versions_of_all_system_components           
                    end
                    subgraph Evaluation
                        direction TB
                      subgraph Evaluation_of_System_Ability
                            direction TB
                            high_volume_of_data---
                            heavy_loads_or_stresses---
                            security
                            subgraph fault_testing
                                direction TB
                                avoidance---
                                detection---
                                tolerance---
                                recovery
                            end
                        security---fault_testing---
                        error_message---
                        implementation_of_safety_requirements
                        end
                      subgraph Evaluation_of_User_Ability
                            direction TB
                            ability_to_understand_system---
                            ability_to_interface_with_system
                        end 
                        subgraph Evaluation_of_Operator_Ability
                            direction TB
                            ability_to_perform_intended_functions---
                            ability_to_respond_in_alarms---
                            ability_to_respond_in_warnings---
                            ability_to_respond_in_error_messages
                        end

                    end
            Follow_Predefiened_Plan--&gt;Documented_Evidence--&gt;
            Evaluation_of_System_Ability--&gt;Evaluation_of_User_Ability--&gt;Evaluation_of_Operator_Ability    
            end     
            subgraph User_Site_Testing_Task
                direction TB
                Acceptance_Test_Execution2---
                Test_Results_Evaluation2---
                Error_Evaluation_Resolution2---
                Final_Test_Report2  
            end
        Requirements--&gt;User_Site_Testing_Task
        end
    
</pre>
<div id="mermaid-tooltip-25" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
</section>
<section id="maintenance-and-software-changes" class="level2">
<h2 class="anchored" data-anchor-id="maintenance-and-software-changes">Maintenance and Software Changes</h2>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-26">flowchart LR
    subgraph Hardware_VS_Software
        direction LR
        subgraph HW_maintenance_Inclusion
            direction TB
            preventive_hardware_maintenance_actions--- 
            component_replacement---
            corrective_changes
        end
        subgraph SW_maintenance_Inclusion
            direction TB
            corrective---
            perfective---
            adaptive_maintenance---
            not_include_preventive_maintenance_actions---
            not_include_software_component_replacement
        end
    end
    subgraph Maintenance_Type
        direction TB
        Corrective_maintenance---
        Perfective_maintenance---
        Adaptive_maintenance---
        Sufficient_regression_analysis---
        Sufficient_regression_testing
    end
    subgraph Factors_of_Validation_for_SW_change
        direction TB
        type_of_change---
        development_products_affected---
        impact_of_those_products_on_operation
    end
    subgraph Factors_of_Limitting_Validation_Effort
        direction TB
        documentation_of_design_structure---
        documentation_of_interrelationships_of_modules---
        documentation_of_interrelationships_of_interfaces---
        test_documentation---
    test_cases---
        results_of_previous_verification_and_validation_testing
    end
    subgraph Maintenance_tasks
        direction TB
        Software_Validation_Plan_Revision---
        Anomaly_Evaluation---
        Problem_Identification_and_Resolution_Tracking---
        Proposed_Change_Assessment---
        Task_Iteration---
        Documentation_Updating
    end
Hardware_VS_Software--&gt;Maintenance_Type--&gt;Factors_of_Validation_for_SW_change--&gt;
Factors_of_Limitting_Validation_Effort--&gt;Maintenance_tasks

</pre>
<div id="mermaid-tooltip-26" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="validation-of-quality-system-software" class="level2">
<h2 class="anchored" data-anchor-id="validation-of-quality-system-software">Validation of Quality System Software</h2>
<section id="overview-4" class="level3">
<h3 class="anchored" data-anchor-id="overview-4">Overview</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-27">flowchart LR
    subgraph Use_of_Computers_and_automated_equipment
        direction TB
        medical_device_design---
        laboratory_testing_and_analysis---
        product_inspection_and_acceptance---
        production_and_process_control---
        environmental_controls---
        packaging---
        labeling---
        traceability---
        document_control---
        complaint_management---
        programmable_logic_controllers---
        digital_function_controllers---
        statistical_process_control---
        supervisory_control_and_data_acquisition---
        robotics---
        human_machine_interfaces---
        input_output_devices---
        computer_operating_systems
    end
    subgraph Factors_in_Validation
        direction TB
        subgraph Validation_Factors_of_Quality_System
            direction TB
            subgraph 21_CFR_Part_11_Requirements
                direction TB
            end
        end
        subgraph Validation_Supporting_Factors
            direction TB
        end
        subgraph Factors_of_Validation_Evidence_Level
            direction TB
        end
        subgraph Factors_of_Easing_Validation_Effort
            direction TB
            planning---
            documented_requirments---
            risk_analysis   
        end
    Validation_Factors_of_Quality_System--&gt;Validation_Supporting_Factors--&gt;Factors_of_Validation_Evidence_Level--&gt;
Factors_of_Easing_Validation_Effort
    end
    subgraph Documented_User_Requirements
        direction TB
        intended_use_of_software_or_automated_equipment---
      level_of_dependency_on_software_or_equipment
    end
    subgraph List_That_Must_Be_Defined_by_User
        direction TB
        
    end
    subgraph Documentation_List
        direction TB
        documented_protocol---
        documented_validation_results
        subgraph Documented_Test_Cases
            direction TB
        
        end
        documented_validation_results---Documented_Test_Cases
    end

    subgraph Manufaturer's_Responsbility
        direction TB
        
    end
Use_of_Computers_and_automated_equipment---Factors_in_Validation---Documented_User_Requirements---
List_That_Must_Be_Defined_by_User---Documentation_List---Manufaturer's_Responsbility
</pre>
<div id="mermaid-tooltip-27" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="factors-in-validation" class="level3">
<h3 class="anchored" data-anchor-id="factors-in-validation">Factors in Validation</h3>
<div class="cell" data-fig-width="8">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-28">flowchart LR
    subgraph Factors_in_Validation
        direction LR
        subgraph Validation_Factors_of_Quality_System
            direction TB
            subgraph 21_CFR_Part_11_Requirements
                direction TB
                electronic_records_regulation---
                electronic_signatures_regulation---
                regulations_establishment---
                security---
                data_integrity---
                validation_requirements 
            end
        end
        subgraph Validation_Supporting_Factors
            direction TB
            verifications_of_outputs_from_each_stage--- 
            verifications_of_outputs_throught_SW_life_cycle---
            checking_for_proper_operation_in_intended_use_environment
        end
        subgraph Factors_of_Validation_Evidence_Level
            direction TB
            risk_posed_by_automated_operation---
            complexity_of_process_software---
            degree_of_dependence_on_automated_process
        end
        subgraph Factors_of_Easing_Validation_Effort
            direction TB
            planning---
            documented_requirments---
            risk_analysis   
        end
    Validation_Factors_of_Quality_System--&gt;Validation_Supporting_Factors--&gt;Factors_of_Validation_Evidence_Level--&gt;
Factors_of_Easing_Validation_Effort
    end

</pre>
<div id="mermaid-tooltip-28" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>Public Health</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/2022-12-10-FDA/FDA_SW_validation_diagram.html</guid>
  <pubDate>Tue, 27 Dec 2022 15:00:00 GMT</pubDate>
</item>
<item>
  <title>p-values</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/2022-12-08-P-value/index.html</link>
  <description><![CDATA[ 



<section id="significance" class="level3">
<h3 class="anchored" data-anchor-id="significance">Significance</h3>
<p>It is said to be statistically significant if a result of your experiment is more extreme than one that is produced by chance. (Try thinking that your result could have come from a different distribution from the one under the null hypothesis.)</p>
</section>
<section id="p-value" class="level3">
<h3 class="anchored" data-anchor-id="p-value">p-value</h3>
<p>p of ‘p-value’ stands for ‘probability’. The p-value is the summation of the probabilities of obtaining results as extreme as the observed results from your experiments could occur under the null hypothesis. In other words, p-value is the probability that the result of your experiment is obtained by chance.</p>
</section>
<section id="alpha" class="level3">
<h3 class="anchored" data-anchor-id="alpha">Alpha</h3>
<p>The probability threshold of the extreme or rarer results that chance results must be beyond actual results of your experiments in order to be said to be statistically significant.</p>
</section>
<section id="type-1-error" class="level3">
<h3 class="anchored" data-anchor-id="type-1-error">Type 1 error</h3>
<p>concluding <img src="https://latex.codecogs.com/png.latex?H_o"> or the null hypothesis is true by mistake.</p>
</section>
<section id="type-2-error" class="level3">
<h3 class="anchored" data-anchor-id="type-2-error">Type 2 error</h3>
<p>concluding <img src="https://latex.codecogs.com/png.latex?H_a"> or the alternative hypothesis is true by mistake.</p>
</section>
<section id="p-value-good-vs-bad" class="level2">
<h2 class="anchored" data-anchor-id="p-value-good-vs-bad">p-value: Good vs Bad?</h2>
<section id="goodness" class="level3">
<h3 class="anchored" data-anchor-id="goodness">Goodness</h3>
<p>p-value is an efficient and effective statistical index when to measure the significance of your test result. Let’s make an assumption that you have conducted a regression analysis. Then, you can get beta coefficients and their standard errors as results of your regression model.</p>
<table class="table">
<caption>Number of Cases of How You Interpret Regresssion Result</caption>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">high Standard Error</th>
<th style="text-align: right;">low Standard Error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>high <img src="https://latex.codecogs.com/png.latex?%5Cbeta"></td>
<td style="text-align: left;">Unclear Interpretation</td>
<td style="text-align: right;">OK</td>
</tr>
<tr class="even">
<td>low <img src="https://latex.codecogs.com/png.latex?%5Cbeta"></td>
<td style="text-align: left;">OK</td>
<td style="text-align: right;">Unclear Interpretation</td>
</tr>
</tbody>
</table>
<p>The above table shows the number of cases you can interprete the results of your regression model. There are 4 cases for each coefficient <img src="https://latex.codecogs.com/png.latex?%5Cbeta">.</p>
<ol type="1">
<li><strong>high <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> and high Standard Error</strong> mean that the corresponding variable has a strong effect but its effect may be fluctuated, so the <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> coefficient resulted from your regression model is likely to be not significant. We are not sure that its effect is statistically significant.</li>
<li><strong>high <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> and low Standard Error</strong> mean that the corresponding variable has a strong effect, and its variation is small, so the <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> coefficient resulted from your regression model is likely to be significant.</li>
<li><strong>low <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> and high Standard Error</strong> mean that the corresponding variable has a weak effect on your reponse variable, its effect has a high variation. So, we can clearly interprete the variable with the <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> as a variable that is not significantly associated with your response variable.</li>
<li><strong>low <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> and high Standard Error</strong> mean that the corresponding variable has a weak effect on your reponse variable, but its effect has a low variation. So, it is difficult to conclude that the variable is significant.</li>
</ol>
<p>The p-value could be used to provide a clearer interpretation of the unclear situation (i.e.&nbsp;(high <img src="https://latex.codecogs.com/png.latex?%5Cbeta">, high Standard Error), (low <img src="https://latex.codecogs.com/png.latex?%5Cbeta">, high Standard Error) ) by looking at the ratio of the estimated value of a parameter(= <img src="https://latex.codecogs.com/png.latex?%5Cbeta">) to its standard error on the distribution under the null hypothesis. By general convention, the cut-off of p-value indicating statistical signficance is 0.05.</p>
</section>
<section id="badness" class="level3">
<h3 class="anchored" data-anchor-id="badness">Badness</h3>
<p>Despite the goodness of p-value, it is controversial to make a decision based solely on the p-value. As mentioned above, p-value is the probability that the result of your experiment is due to chance. In addition, looking into <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Cbeta%7D%7B%5Cfrac%7Bs.e%7D%7B%5Csqrt%7Bn%7D%7D%7D">, the p-value gets smaller as the sample size becomes larger and larger. <strong>It should be avoided that something is proved just because a low p-value is calucated</strong>.</p>
<p>Even if a result is statistically significant, that does not necessarily mean it has real significance. A small difference that has no practical meaning can be statistically significant if the sample size is large enough. It is because large samples ensure that meaningless effects can become big enough to possibly exclude chance due to simple math.</p>
<p>The American Statistical Association (ASA) has released a statement of six principles for researchers and journal editors on p-values:<br>
<a href="https://www.amstat.org/asa/files/pdfs/p-valuestatement.pdf">Source: ASA Statement on Statistical Significance and p-values</a></p>
<ol type="1">
<li>P-values can indicate how incompatible the data are with a specified statistical model.</li>
<li>P-values do not measure the probability that the studied hypothesis is true, or the probability that the data produced by random chance alone.</li>
<li>Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.</li>
<li>Proper inference requires full reporting and transparency.</li>
<li>A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.</li>
<li>By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.</li>
</ol>
</section>
</section>
<section id="how-to-use-p-vlaues" class="level2">
<h2 class="anchored" data-anchor-id="how-to-use-p-vlaues">How to use p-vlaues?</h2>
<p>Personally, I make use of p-values as a tool in data science to just check whether a model result or a set of variables that appears interesting and useful is in the range of normal variability by chance in the exploratory data analysis(EDA) or data mining step.</p>
<p>If you want to get a statistical significance level through p-values, other methodologies could help increase the accuracy of real significance such as permuted p-values, q-values, and penalization on multiple comparison tests</p>


</section>

 ]]></description>
  <category>Statistics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/2022-12-08-P-value/index.html</guid>
  <pubDate>Wed, 14 Dec 2022 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/docs/blog/posts/2022-12-08-P-value/coding.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>FDA Software Validation Guidance Summary</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/2022-12-10-FDA/index.html</link>
  <description><![CDATA[ 



<section id="information-on-the-document" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Information on the Document</h1>
<section id="notice" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="notice"><span class="header-section-number">1.1</span> Notice</h2>
<ul>
<li>I am so sorry not for providing a compfortab visualization. Although I have tried to use <em>revealjs</em> provided in the guide section in the <em>Quarto</em> website, I am still clumsy at handling it. I will update this article as I get proficient at <em>revealjs</em> using <em>Quarto</em>.</li>
<li>The FDA validation guidance document is a bit difficult to understand because its explanations provides abstract, general, and present broad cocepts. For this reason, I compiled and made a summary of the document with many diagrams. However, some diagrams are too small to see. Please, <strong>scroll up your mouse wheel with the ‘Ctrl’ key on your keyboard pressed to zoom in on the small text in the diagrams</strong>.</li>
<li>(Writing in Progress) It is hard to say that this version of summary is suitable for representing and covering the original document. Some of the content of this document has been excluded for personal use (less than 10% of it have been excluded).</li>
</ul>
<section id="last-update" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="last-update"><span class="header-section-number">1.1.1</span> Last Update</h3>
<ul>
<li>2022-12-28, <a href="sw_validation_ver1.pdf">download this article as PDF</a></li>
<li>2022-12-28, <a href="../../../../docs/blog/posts/2022-12-10-FDA/FDA_SW_validation_diagram.html">summary with diagrams</a></li>
</ul>
</section>
<section id="source" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="source"><span class="header-section-number">1.1.2</span> Source</h3>
<p><a href="https://www.fda.gov/regulatory-information/search-fda-guidance-documents/general-principles-software-validation">FDA: General Principles of Software Validation</a></p>
</section>
<section id="rationale" class="level3" data-number="1.1.3">
<h3 data-number="1.1.3" class="anchored" data-anchor-id="rationale"><span class="header-section-number">1.1.3</span> Rationale</h3>
<p>FDA has reported the following analysis:</p>
<ul>
<li>242 of 3140 (7.7%) medical device recalls between 1992 and 1998 are attributable to software failures.</li>
<li>192 of the 242 (79.3%) failures were caused by software defects that were introduced when changes were made to the software after its initial production and distribution.</li>
<li>The software validation check is a principal means of avoiding such defects and resultant recalls.</li>
</ul>
</section>
<section id="main-institutions" class="level3" data-number="1.1.4">
<h3 data-number="1.1.4" class="anchored" data-anchor-id="main-institutions"><span class="header-section-number">1.1.4</span> Main Institutions</h3>
<ul>
<li>Center for Devices and Radiological Health (CDRH)</li>
<li>U.S. Department Of Health and Human Services</li>
<li>Food and Drug Administration</li>
<li>Center for Biologics Evaluation and Research</li>
</ul>
</section>
</section>
</section>
<section id="document-summary" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Document Summary</h1>
<section id="purpose" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="purpose"><span class="header-section-number">2.1</span> Purpose</h2>
<p>The purpose is to make a sketch of general validation principle of the validation of medical device software or software used to design or develop.</p>
</section>
<section id="scope" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="scope"><span class="header-section-number">2.2</span> Scope</h2>
<p>The scope of this guidance is broad. The important activities for the software validation include at least:</p>
<ul>
<li>planning,</li>
<li>verfication,</li>
<li>testing,</li>
<li>traceability, and</li>
<li>configuration management.</li>
</ul>
<p>All of the activities above should be</p>
<ul>
<li>integrated</li>
<li>be able to describe software life cycle management and</li>
<li>be able to describe software risk management.</li>
</ul>
<p>The software validation and verification activities should be focused into the entire software life cycle. (It does not necessarily mean that the activies must follow any technical models.)</p>
<p>The guidance is applicable to any software related to a regulated medical device and anyone who is employed in a bio or medical industry.</p>
<section id="the-least-burdensome-approach" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="the-least-burdensome-approach"><span class="header-section-number">2.2.1</span> The Least Burdensome Approach</h3>
<p>The guidance reflects that <em>the minimum list of the relavant scientific and legal requirements</em> that you must comply with.</p>
</section>
<section id="regulatory-requirements-for-software-validation" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="regulatory-requirements-for-software-validation"><span class="header-section-number">2.2.2</span> Regulatory Requirements for Software Validation</h3>
<ul>
<li>Software validation: a requirement of <strong>the Quality System regulation</strong>, which was published in the Federal Register on October 7, 1996 and took effect on June 1, 1997. (See Title 21 Code of Federal Regulations (CFR) Part 820, and 61 Federal Register (FR) 52602, respectively.)</li>
<li>Specific requirements for validation of device software are found in 21 CFR §820.30(g). Other design controls, such as planning, input, verification, and reviews, are required for medical device software. (See 21 CFR §820.30.)</li>
<li>computer systems used to create, modify, and maintain electronic records and to manage electronic signatures are also subject to the validation requirements. (See 21 CFR §11.10(a).)</li>
</ul>
<section id="objective" class="level4" data-number="2.2.2.1">
<h4 data-number="2.2.2.1" class="anchored" data-anchor-id="objective"><span class="header-section-number">2.2.2.1</span> Objective</h4>
<p>The objective of software validation is to ensure:</p>
<ul>
<li>accuracy</li>
<li>reliability</li>
<li>consistent intended performance, and</li>
<li>the ability to discern invalid or altered records.</li>
</ul>
</section>
<section id="what-to-validate" class="level4" data-number="2.2.2.2">
<h4 data-number="2.2.2.2" class="anchored" data-anchor-id="what-to-validate"><span class="header-section-number">2.2.2.2</span> What to validate</h4>
<p><strong>Any software</strong> used to automate device design, testing, component acceptance, manufacturing, labeling, packaging, distribution, complaint handling, or to automate any other aspect of the quality system, including any off-the-shelf software.</p>
</section>
</section>
<section id="quality-system-regulation-vs-pre-market-submissions" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="quality-system-regulation-vs-pre-market-submissions"><span class="header-section-number">2.2.3</span> Quality System Regulation vs Pre-market Submissions</h3>
<p>This document <strong>does not address</strong> any specific requirements <strong>but</strong> general ones. Specific issues should be addressed to</p>
<ul>
<li>the Office of Device Evaluation (ODE),</li>
<li>Center for Devices and Radiological Health (CDRH)</li>
<li>the Office of Blood Research and Review,</li>
<li>Center for Biologics Evaluation and Research (CBER). See the references in Appendix A for applicable FDA guidance documents for pre-market submissions.</li>
</ul>
</section>
</section>
<section id="context-for-software-validation" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="context-for-software-validation"><span class="header-section-number">2.3</span> Context for Software Validation</h2>
<ul>
<li>Validation elements that FDA expects to do for the Quality System regulation, using the principles and tasks are listed in Sections 4 and 5.</li>
<li>Additional specific information is available from many of the references listed in Appendix A</li>
</ul>
<section id="definition-and-terminology" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="definition-and-terminology"><span class="header-section-number">2.3.1</span> Definition and Terminology</h3>
<p>The medical device Quality System regulation (21 CFR 820.3(k)) defines</p>
<ul>
<li>“establish” = “define, document, and implement”</li>
<li>“establish” = “established”</li>
<li>Confusing terminology between the medical device Quality System regulation and the software industry:
<ul>
<li>requirements,</li>
<li>specification,</li>
<li>verification, and</li>
<li>validation.</li>
</ul></li>
</ul>
<section id="requirements-and-specifications" class="level4" data-number="2.3.1.1">
<h4 data-number="2.3.1.1" class="anchored" data-anchor-id="requirements-and-specifications"><span class="header-section-number">2.3.1.1</span> Requirements and Specifications</h4>
<p>The Quality System regulation states</p>
<ol type="1">
<li>that design input requirements must be documented and</li>
<li>that specified requirements must be verified</li>
</ol>
<p>But, the regulation does not further clarify the distinction between the terms “requirement” and “specification.”</p>
<ul>
<li>Requirement
<ul>
<li>can be any need or expectation for a system or for its software.</li>
<li>reflects the stated or implied needs of the customer: requirements may be
<ul>
<li>market-based,</li>
<li>contractual,</li>
<li>statutory, or</li>
<li>an organization’s internal requirements.</li>
</ul></li>
<li>various examples of requirements
<ul>
<li>design, functional, implementation, interface, performance, or physical requirements</li>
</ul></li>
<li>Software requirements derived from the system requirements for those aspects of system functionality</li>
<li>Software requirements are typically stated in functional terms and are defined, refined, and updated as a development project progresses.</li>
<li>Success in accurately and completely documenting software requirements is a crucial factor in successful validation of the resulting software.</li>
</ul></li>
<li>Specification
<ul>
<li>defined as “a document that states requirements.” (See 21 CFR §820.3(y).)</li>
<li>It may refer to or include drawings, patterns, or other relevant documents</li>
<li>It usually indicates the means and the criteria whereby conformity with the requirement can be checked.</li>
<li>Various examples of written specifications
<ul>
<li>system requirements specification,</li>
<li>software requirements specification,</li>
<li>software design specification,</li>
<li>software test specification,</li>
<li>software integration specification, etc.</li>
</ul></li>
<li>All of these documents are design outputs for which various forms of verification are necessary.</li>
</ul></li>
</ul>
</section>
<section id="verifiaction-and-validation" class="level4" data-number="2.3.1.2">
<h4 data-number="2.3.1.2" class="anchored" data-anchor-id="verifiaction-and-validation"><span class="header-section-number">2.3.1.2</span> Verifiaction and Validation</h4>
<p>The Quality System regulation is harmonized with ISO 8402:1994, which treats “verification” and “validation” as separate and distinct terms.</p>
<ul>
<li>Software verification
<ul>
<li>It provides objective evidence that the design outputs of a particular phase of the software development life cycle meet all of the specified requirements for that phase.</li>
<li>It looks for
<ul>
<li>consistency,</li>
<li>completeness, and</li>
<li>correctness of the software and its supporting documentation</li>
</ul></li>
<li><strong>Software testing</strong>
<ul>
<li>verification activities intended to confirm that software development output meets its input requirements.</li>
</ul></li>
<li>Types of verification activities include
<ul>
<li>various static and dynamic analyses,</li>
<li>code and document inspections,</li>
<li>walkthroughs, and other techniques.</li>
</ul></li>
</ul></li>
<li>Software Validation
<ul>
<li>Confirmation by examination and provision of the following objective evidence:</li>
<li>Evidence 1: software specifications conform to <strong>user needs and intended uses</strong>, and</li>
<li>Evidnece 2: the particular requirements implemented through software can be consistently fulfilled.</li>
<li>Evidnece 3: all software requirements have been implemented <strong>correctly and completely and are traceable</strong> to system requirements.</li>
<li>A conclusion that software is validated is highly dependent upon <strong>comprehensive</strong> software testing, inspections, analyses, and other verification tasks performed <strong>at each stage of the software development life cycle</strong>.</li>
<li><strong>Testing</strong> of device software functionality in a <strong>simulated* use environment</strong>, and <strong>user site testing</strong> are typically included as components of an overall design validation program for a software automated device.</li>
</ul></li>
<li>Difficulty in Software verification and validation
<ul>
<li>a developer cannot test forever, and</li>
<li>it is difficult to know how much evidence is enough.</li>
<li>In large measure, software validation is a matter of developing a <strong>“level of confidence”</strong> that the device meets all requirements and user expectations for the software automated functions and features of the device.</li>
<li>Considerations for an acceptable level of confidence
<ul>
<li>measures such as defects found in specifications documents,</li>
<li>estimates of defects remaining,</li>
<li>testing coverage, and other techniques are all used to develop before shipping the product.</li>
<li>However, a level of confidence varies depending upon the safety risk (hazard) posed by the automated functions of the device. (Info on safety risk is found in Section 4 and in the international standards ISO/IEC 14971-1 and IEC 60601-1-4 referenced in Appendix A).</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="iqoqpq" class="level4" data-number="2.3.1.3">
<h4 data-number="2.3.1.3" class="anchored" data-anchor-id="iqoqpq"><span class="header-section-number">2.3.1.3</span> IQ/OQ/PQ</h4>
<p>IQ/OQ/PQ are the terminology related to user site software validation</p>
<ul>
<li>Installation qualification (IQ)</li>
<li>Operational qualification (OQ)</li>
<li>Performance qualification (PQ).</li>
</ul>
<p>Definitions of these terms may be found in FDA’s Guideline on General Principles of Process Validation, dated May 11, 1987, and in FDA’s Glossary of Computerized System and Software Development Terminology, dated August 1995. Both FDA personnel and device manufacturers need to be aware of these differences in terminology as they ask for and provide information regarding software validation.</p>
</section>
</section>
<section id="software-development-as-part-of-system-design" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="software-development-as-part-of-system-design"><span class="header-section-number">2.3.2</span> Software Development as Part of System Design</h3>
<p>Software validation must be considered within the context of the overall design validation for the system. A documented requirements specification represents</p>
<ul>
<li>the user’s needs</li>
<li>intended uses from which the product is developed.</li>
</ul>
<p>A primary goal of software validation is to then demonstrate that all completed software products comply with all documented software and system requirements.</p>
</section>
<section id="software-is-different-from-hardware" class="level3" data-number="2.3.3">
<h3 data-number="2.3.3" class="anchored" data-anchor-id="software-is-different-from-hardware"><span class="header-section-number">2.3.3</span> Software Is Different from Hardware</h3>
<p>Software engineering needs an even greater level of managerial scrutiny and control than does hardware engineering.</p>
</section>
<section id="benefits-of-software-validation" class="level3" data-number="2.3.4">
<h3 data-number="2.3.4" class="anchored" data-anchor-id="benefits-of-software-validation"><span class="header-section-number">2.3.4</span> Benefits of Software Validation</h3>
<ul>
<li>Increase the usability and reliability of the device,</li>
<li>Resulting in decreased failure rates, fewer recalls and corrective actions, less risk to patients and users, and reduced liability to device manufacturers.</li>
<li>Software validation can also reduce long term costs by making it easier and less costly to reliably modify software and revalidate software changes.</li>
</ul>
</section>
<section id="design-review" class="level3" data-number="2.3.5">
<h3 data-number="2.3.5" class="anchored" data-anchor-id="design-review"><span class="header-section-number">2.3.5</span> Design Review</h3>
<p>Design reviews are documented, comprehensive, and systematic examinations of a design to evaluate</p>
<ul>
<li>the adequacy of the design requirements,</li>
<li>the capability of the design to meet these requirements, and</li>
<li>to identify problems.</li>
</ul>
<p>Design review is a primary tool for managing and evaluating development projects.</p>
<ul>
<li>It is strongly recommended that it should be formal design because it is more structured than the informal one.</li>
<li>It includes participation from others outside the development team.</li>
<li>It may review reference or include results from other formal and informal reviews.</li>
<li>Design reviews should include
<ul>
<li>examination of development plans,</li>
<li>requirements specifications,</li>
<li>design specifications,</li>
<li>testing plans and procedures,</li>
<li>all other documents and activities associated with the project,</li>
<li>verification results from each stage of the defined life cycle, and</li>
<li>validation results for the overall device.</li>
</ul></li>
<li>The Quality System regulation requires that at least one formal design review be conducted during the device design process. <strong>However, it is recommended that multiple design reviews be conducted</strong>
<ul>
<li>(e.g., at the end of each software life cycle activity, in preparation for proceeding to the next activity).</li>
</ul></li>
<li>Formal design reviews documented should include:
<ul>
<li>the appropriate tasks and expected results, outputs, or products been established for each software life cycle activity</li>
<li>correctness, completeness, consistency, and accuracy</li>
<li>satisfaction for the standards, practices, and conventions of that activity</li>
<li>establishment of a proper basis for initiating tasks for the next software life cycle activity</li>
</ul></li>
</ul>
</section>
</section>
<section id="principles-of-software-validation" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="principles-of-software-validation"><span class="header-section-number">2.4</span> Principles of Software Validation</h2>
<section id="requirements" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="requirements"><span class="header-section-number">2.4.1</span> Requirements</h3>
<p>A documented software requirements specification provides a baseline for both validation and verification. <strong>The software validation process must include an established software requirements specification</strong> (Ref: 21 CFR 820.3(z) and (aa) and 820.30(f) and (g)).</p>
</section>
<section id="defect-prevention" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="defect-prevention"><span class="header-section-number">2.4.2</span> Defect Prevention</h3>
<p>In order to establish that confidence, software developers should use a mixture of methods and techniques to prevent software errors and to detect software errors that do occur.</p>
</section>
<section id="time-and-effort" class="level3" data-number="2.4.3">
<h3 data-number="2.4.3" class="anchored" data-anchor-id="time-and-effort"><span class="header-section-number">2.4.3</span> Time and Effort</h3>
<p>Preparation for software validation should begin early, i.e., <strong>during design and development planning and design input</strong>. The final conclusion that the software is validated should be <strong>based on evidence</strong> collected from planned efforts conducted throughout the software lifecycle.</p>
</section>
<section id="software-life-cycle" class="level3" data-number="2.4.4">
<h3 data-number="2.4.4" class="anchored" data-anchor-id="software-life-cycle"><span class="header-section-number">2.4.4</span> Software Life Cycle</h3>
<ul>
<li>Software validation takes place within the environment of an established software life cycle.</li>
<li>The software life cycle contains <strong>software engineering tasks and documentation</strong> necessary to support the software validation effort.</li>
<li>specific verification and validation tasks need to be appropriate for the intended use of the software</li>
</ul>
</section>
<section id="plans" class="level3" data-number="2.4.5">
<h3 data-number="2.4.5" class="anchored" data-anchor-id="plans"><span class="header-section-number">2.4.5</span> Plans</h3>
<ul>
<li>The software validation process is defined and controlled through the use of a plan.</li>
<li>The software validation plan defines “what” is to be accomplished through the software validation effort.</li>
<li>Software validation plans specify areas such as
<ul>
<li>scope,</li>
<li>approach,</li>
<li>resources,</li>
<li>schedules and the types and extent of activities,</li>
<li>tasks, and</li>
<li>work items.</li>
</ul></li>
</ul>
</section>
<section id="procedures" class="level3" data-number="2.4.6">
<h3 data-number="2.4.6" class="anchored" data-anchor-id="procedures"><span class="header-section-number">2.4.6</span> Procedures</h3>
<p>The software validation process is executed through the use of procedures. These procedures establish “how” to conduct the software validation effort. The procedures should identify the specific actions or sequence of actions that must be taken to complete individual validation activities, tasks, and work items.</p>
</section>
<section id="software-validation-after-a-change" class="level3" data-number="2.4.7">
<h3 data-number="2.4.7" class="anchored" data-anchor-id="software-validation-after-a-change"><span class="header-section-number">2.4.7</span> Software Validation After a Change</h3>
<ul>
<li>Due to the complexity of software, a small local change may have a significant global system impact.</li>
<li>If a change exists in the software, the whole validation status of the software needs to be re-established.</li>
<li>need to determine the extent and impact of that change on the entire software system.</li>
<li>the software developer should then conduct an appropriate level of software regression testing to show that unchanged but vulnerable portions of the system have not been adversely affected.</li>
</ul>
</section>
<section id="validation-coverage" class="level3" data-number="2.4.8">
<h3 data-number="2.4.8" class="anchored" data-anchor-id="validation-coverage"><span class="header-section-number">2.4.8</span> Validation Coverage</h3>
<ul>
<li>Validation coverage should be based on the software’s complexity and safety risk.</li>
<li>The selection of validation activities, tasks, and work items should be commensurate with the complexity of the software design and the risk associated with the use of the software for the specified intended use.</li>
</ul>
</section>
<section id="independence-of-review" class="level3" data-number="2.4.9">
<h3 data-number="2.4.9" class="anchored" data-anchor-id="independence-of-review"><span class="header-section-number">2.4.9</span> Independence of Review</h3>
<ul>
<li>Validation activities should be based on the basic quality assurance precept of “independence of review.”</li>
<li>Self-validation is extremely difficult.</li>
<li>When possible, an independent evaluation is always better (like a contracted third-party independent verification and validation)</li>
<li>Another approach is to assign internal staff members that are not involved in a particular design or its implementation, but who have sufficient knowledge to evaluate the project and conduct the verification and validation activities.</li>
</ul>
</section>
<section id="flexibility-and-responsibility" class="level3" data-number="2.4.10">
<h3 data-number="2.4.10" class="anchored" data-anchor-id="flexibility-and-responsibility"><span class="header-section-number">2.4.10</span> Flexibility and Responsibility</h3>
<p>The device manufacturer has flexibility in choosing how to apply these validation principles, but retains ultimate responsibility for demonstrating that the software has been validated. FDA regulated medical device applications include software that:</p>
<ul>
<li>Is a component, part, or accessory of a medical device;
<ul>
<li>components: e.g., application software, operating systems, compilers, debuggers, configuration management tools, and many more</li>
</ul></li>
<li>Is itself a medical device; or</li>
<li>Is used in manufacturing, design and development, or other parts of the quality system.</li>
<li>No matter how complex and disperse the software is, the manufacturer is in charge of responsibility for software validation.</li>
</ul>
</section>
</section>
<section id="activities-and-tasks" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="activities-and-tasks"><span class="header-section-number">2.5</span> Activities and Tasks</h2>
<p>Software validation is accomplished through <strong>a series of activities and tasks</strong> that are planned and executed at various stages of the software development life cycle. These tasks may be</p>
<ul>
<li>one time occurrences</li>
<li>iterated many times</li>
</ul>
<section id="software-life-cycle-activities" class="level3" data-number="2.5.1">
<h3 data-number="2.5.1" class="anchored" data-anchor-id="software-life-cycle-activities"><span class="header-section-number">2.5.1</span> Software Life Cycle Activities</h3>
<ul>
<li>Software developers should establish a software life cycle model that is appropriate for their product and organization.</li>
<li>The selected software life cycle model should cover the software from its birth to its retirement.</li>
<li>Activities in a typical software life cycle model:
<ul>
<li>Quality Planning</li>
<li>System Requirements Definition</li>
<li>Detailed Software Requirements Specification</li>
<li>Software Design Specification</li>
<li>Construction or Coding</li>
<li>Testing</li>
<li>Installation</li>
<li>Operation and Support</li>
<li>Maintenance</li>
<li>Retirement</li>
</ul></li>
<li>Verification, testing, and other tasks that support software validation occur during each of these activities.</li>
<li>Several software life cycle models defined in FDA’s Glossary of Computerized System and Software Development</li>
</ul>
<p>Terminology dated August 1995:</p>
<ul>
<li>waterfall</li>
<li>spiral</li>
<li>rapid prototyping</li>
<li>incremental development, etc.</li>
</ul>
</section>
<section id="typical-tasks-supporting-validation" class="level3" data-number="2.5.2">
<h3 data-number="2.5.2" class="anchored" data-anchor-id="typical-tasks-supporting-validation"><span class="header-section-number">2.5.2</span> Typical Tasks Supporting Validation</h3>
<p>the software developer should at least consider each of the risk-related tasks and should define and document which tasks are or are not appropriate for their specific application.</p>
<section id="quality-planning" class="level4" data-number="2.5.2.1">
<h4 data-number="2.5.2.1" class="anchored" data-anchor-id="quality-planning"><span class="header-section-number">2.5.2.1</span> Quality Planning</h4>
<p>Design and development planning should culminate in a plan that identifies</p>
<ul>
<li>necessary tasks,</li>
<li>procedures for anomaly reporting and resolution,</li>
<li>necessary resources, and</li>
<li>management review requirements including formal design reviews.</li>
</ul>
<p>The plan should include:</p>
<ul>
<li>The specific tasks for each life cycle activity;</li>
<li>Enumeration of important quality factors (e.g., reliability, maintainability, and usability);</li>
<li>Methods and procedures for each task;</li>
<li>Task acceptance criteria;</li>
<li>Criteria for defining and documenting outputs in terms that will allow evaluation of their conformance to input requirements;</li>
<li>Inputs for each task;</li>
<li>Outputs from each task;</li>
<li>Roles, resources, and responsibilities for each task;</li>
<li>Risks and assumptions; and</li>
<li>Documentation of user needs.</li>
</ul>
<p>The plan should identify</p>
<ul>
<li>the personnel,</li>
<li>the facility and equipment resources for each task, and</li>
<li>the role that risk (hazard) management will play.</li>
</ul>
<p>A configuration management plan should be developed that will guide and control multiple parallel development activities and ensure proper communications and documentation.</p>
<p>Controls are necessary to ensure positive and correct correspondence among all approved versions of the specifications documents, source code, object code, and test suites that comprise a software system. The controls also should ensure accurate identification of, and access to, the currently approved versions.</p>
<p>Procedures should be created for reporting and resolving software anomalies found through validation or other activities.</p>
<p>Management should identify the reports and specify the contents, format, and responsible organizational elements for each report. Procedures also are necessary for the review and approval of software development results, including the responsible organizational elements for such reviews and approvals.</p>
<p>Typical Tasks – Quality Planning</p>
<ul>
<li>Risk (Hazard) Management Plan</li>
<li>Configuration Management Plan</li>
<li>Software Quality Assurance Plan
<ul>
<li>Software Verification and Validation Plan
<ul>
<li>Verification and Validation Tasks, and Acceptance Criteria</li>
<li>Schedule and Resource Allocation (for software verification and validation activities)</li>
<li>Reporting Requirements</li>
</ul></li>
<li>Formal Design Review Requirements</li>
<li>Other Technical Review Requirements</li>
</ul></li>
<li>Problem Reporting and Resolution Procedures</li>
<li>Other Support Activities</li>
</ul>
</section>
<section id="requirements-1" class="level4" data-number="2.5.2.2">
<h4 data-number="2.5.2.2" class="anchored" data-anchor-id="requirements-1"><span class="header-section-number">2.5.2.2</span> Requirements</h4>
<p>Requirements development includes the</p>
<ul>
<li>identification,</li>
<li>analysis, and</li>
<li>documentation of information about the device and its intended use.</li>
</ul>
<p>Areas of special importance include allocation of system functions to</p>
<ul>
<li>hardware/software,</li>
<li>operating conditions,</li>
<li>user characteristics,</li>
<li>potential hazards, and</li>
<li>anticipated tasks.</li>
</ul>
<p>In addition, the requirements should state clearly the intended use of the software. It is not possible to validate software without predetermined and documented software requirements. Typical software requirements specify the following:</p>
<ul>
<li>All software system inputs;</li>
<li>All software system outputs;</li>
<li>All functions that the software system will perform;</li>
<li>All performance requirements that the software will meet, (e.g., data throughput, reliability, and timing);</li>
<li>The definition of all external and user interfaces, as well as any internal software-to-system interfaces;</li>
<li>How users will interact with the system;</li>
<li>What constitutes an error and how errors should be handled;</li>
<li>Required response times;</li>
<li>The intended operating environment for the software, if this is a design constraint (e.g., hardware platform, operating system);</li>
<li>All ranges, limits, defaults, and specific values that the software will accept; and</li>
<li>All safety related requirements, specifications, features, or functions that will be implemented in software.</li>
</ul>
<p>Software requirement specifications should identify clearly the potential hazards that can result from a software failure in the system as well as any safety requirements to be implemented in software.</p>
<p>The consequences of software failure should be evaluated, along with means of mitigating such failures (e.g., hardware mitigation, defensive programming, etc.).</p>
<p>The Quality System regulation requires a mechanism for addressing incomplete, ambiguous, or conflicting requirements. (See 21 CFR 820.30(c).) Each requirement (e.g., hardware, software, user, operator interface, and safety) identified in the software requirements specification should be evaluated for accuracy, completeness, consistency, testability, correctness, and clarity.</p>
<p>For example, software requirements should be evaluated to verify that:</p>
<ul>
<li>There are no internal inconsistencies among requirements;</li>
<li>All of the performance requirements for the system have been spelled out;</li>
<li>Fault tolerance, safety, and security requirements are complete and correct;</li>
<li>Allocation of software functions is accurate and complete;</li>
<li>Software requirements are appropriate for the system hazards; and</li>
<li>All requirements are expressed in terms that are measurable or objectively verifiable.</li>
</ul>
<p>A software requirements traceability analysis should be conducted to trace software requirements to (and from) system requirements and to risk analysis results. In addition to any other analyses and documentation used to verify software requirements, a formal design review is recommended to confirm that requirements are fully specified and appropriate before extensive software design efforts begin. Requirements can be approved and released incrementally, but care should be taken that interactions and interfaces among software (and hardware) requirements are properly reviewed, analyzed, and controlled.</p>
<p>Typical Tasks – Requirements</p>
<ul>
<li>Preliminary Risk Analysis</li>
<li>Traceability Analysis
<ul>
<li>Software Requirements to System Requirements (and vice versa)</li>
<li>Software Requirements to Risk Analysis</li>
</ul></li>
<li>Description of User Characteristics</li>
<li>Listing of Characteristics and Limitations of Primary and Secondary Memory</li>
<li>Software Requirements Evaluation</li>
<li>Software User Interface Requirements Analysis</li>
<li>System Test Plan Generation</li>
<li>Acceptance Test Plan Generation</li>
<li>Ambiguity Review or Analysis</li>
</ul>
</section>
<section id="design" class="level4" data-number="2.5.2.3">
<h4 data-number="2.5.2.3" class="anchored" data-anchor-id="design"><span class="header-section-number">2.5.2.3</span> Design</h4>
<p>In the design process, the software requirements specification is translated into a logical and physical representation of the software to be implemented. The software design specification is a description of what the software should do and how it should do it. The design specification may contain both a high level summary of the design and detailed design information. Human factors engineering should be woven into</p>
<ul>
<li>the entire design and development process,</li>
<li>the device design requirements,</li>
<li>analyses, and</li>
<li>tests.</li>
</ul>
<p>Device safety and usability issues should be considered when developing</p>
<ul>
<li>flowcharts,</li>
<li>state diagrams,</li>
<li>prototyping tools, and</li>
<li>test plans.</li>
</ul>
<p>Also, task and function analyses, risk analyses, prototype tests and reviews, and full usability tests should be performed. Participants from the user population should be included when applying these methodologies.</p>
<p>The software design specification should include:</p>
<ul>
<li>Software requirements specification, including predetermined criteria for acceptance of the software;</li>
<li>Software risk analysis;</li>
<li>Development procedures and coding guidelines (or other programming procedures);</li>
<li>Systems documentation (e.g., a narrative or a context diagram) that describes the systems context in which the program is intended to function, including the relationship of hardware, software, and the physical environment;</li>
<li>Hardware to be used;</li>
<li>Parameters to be measured or recorded;</li>
<li>Logical structure (including control logic) and logical processing steps (e.g., algorithms);</li>
<li>Data structures and data flow diagrams;</li>
<li>Definitions of variables (control and data) and description of where they are used;</li>
<li>Error, alarm, and warning messages;</li>
<li>Supporting software (e.g., operating systems, drivers, other application software);</li>
<li>Communication links (links among internal modules of the software, links with the supporting software, links with the hardware, and links with the user);</li>
<li>Security measures (both physical and logical security); and</li>
<li>Any additional constraints not identified in the above elements.</li>
</ul>
<p>The first four of the elements noted above usually are separate pre-existing documents that are included by reference in the software design specification. Software requirements specification was discussed in the preceding section, as was software risk analysis.</p>
<p>Software design evaluations criteria:</p>
<ul>
<li>complete,</li>
<li>correct,</li>
<li>consistent,</li>
<li>unambiguous,</li>
<li>feasible,</li>
<li>maintainable,</li>
<li>analyses of control flow,</li>
<li>data flow,</li>
<li>complexity,</li>
<li>timing,</li>
<li>sizing,</li>
<li>memory allocation,</li>
<li>criticality analysis, and many other aspects of the design</li>
</ul>
<p>Appropriate consideration of software architecture (e.g., modular structure) during design can reduce the magnitude of future validation efforts when software changes are needed.</p>
<p>A traceability analysis should be conducted to verify that the software design implements all of the software requirements. As a technique for identifying where requirements are not sufficient, the traceability analysis should also verify that all aspects of the design are traceable to software requirements.</p>
<p>An analysis of communication links should be conducted to evaluate the proposed design with respect to hardware, user, and related software requirements. At the end of the software design activity, a Formal Design Review should be conducted to verify that the design is correct, consistent, complete, accurate, and testable, before moving to implement the design.</p>
<p>Several versions of both the software requirement specification and the software design specification should be maintained. All approved versions should be archived and controlled in accordance with established configuration management procedures.</p>
<p>Typical Tasks – Design</p>
<ul>
<li>Updated Software Risk Analysis</li>
<li>Traceability Analysis - Design Specification to Software Requirements (and vice versa)</li>
<li>Software Design Evaluation</li>
<li>Design Communication Link Analysis</li>
<li>Module Test Plan Generation</li>
<li>Integration Test Plan Generation</li>
<li>Test Design Generation (module, integration, system, and acceptance)</li>
</ul>
</section>
<section id="construction-or-coding" class="level4" data-number="2.5.2.4">
<h4 data-number="2.5.2.4" class="anchored" data-anchor-id="construction-or-coding"><span class="header-section-number">2.5.2.4</span> Construction or Coding</h4>
<p>Software may be constructed either by coding. Coding is the software activity where the detailed design specification is implemented as source code. It is the last stage in decomposition of the software requirements where module specifications are translated into a programming language.</p>
<p>Coding usually involves the use of a high-level programming language, but may also entail the use of assembly language (or microcode) for time-critical operations.</p>
<p>A source code traceability analysis is an important tool to verify that all code is linked to established specifications and established test procedures. A source code traceability analysis should be conducted and documented to verify that:</p>
<ul>
<li>Each element of the software design specification has been implemented in code;</li>
<li>Modules and functions implemented in code can be traced back to an element in the software design specification and to the risk analysis;</li>
<li>Tests for modules and functions can be traced back to an element in the software design specification and to the risk analysis; and</li>
<li>Tests for modules and functions can be traced to source code for the same modules and functions.</li>
</ul>
<p>Typical Tasks – Construction or Coding</p>
<ul>
<li>Traceability Analyses
<ul>
<li>Source Code to Design Specification (and vice versa)</li>
<li>Test Cases to Source Code and to Design Specification</li>
</ul></li>
<li>Source Code and Source Code Documentation Evaluation</li>
<li>Source Code Interface Analysis</li>
<li>Test Procedure and Test Case Generation (module, integration, system, and acceptance)</li>
</ul>
</section>
<section id="testing-by-the-software-developer" class="level4" data-number="2.5.2.5">
<h4 data-number="2.5.2.5" class="anchored" data-anchor-id="testing-by-the-software-developer"><span class="header-section-number">2.5.2.5</span> Testing by the Software Developer</h4>
<p>Software testing entails running software products under known conditions with defined inputs and documented outcomes that can be compared to their predefined expectations. It is a time consuming, difficult, and imperfect activity.</p>
<p>As such, it requires early planning in order to be effective and efficient. Test plans and test cases should be created as early in the software development process as feasible.</p>
<p>They should identify</p>
<ul>
<li>the schedules,</li>
<li>environments,</li>
<li>resources (personnel, tools, etc.),</li>
<li>methodologies,</li>
<li>cases (inputs, procedures, outputs, expected results),</li>
<li>documentation, and</li>
<li>reporting criteria.</li>
</ul>
<p>Descriptions of categories of software and software testing effort appear in the literature</p>
<ul>
<li>NIST Special Publication 500-235, Structured Testing: A Testing Methodology Using the Cyclomatic Complexity Metric;</li>
<li>NUREG/CR-6293, Verification and Validation Guidelines for High Integrity Systems; and</li>
<li>IEEE Computer Society Press, Handbook of Software Reliability Engineering.</li>
</ul>
<p>Testing of all program functionality does not mean all of the program has been tested. Testing of all of a program’s code does not mean all necessary functionality is present in the program. Testing of all program functionality and all program code does not mean the program is 100% correct! Software testing that finds no errors should not be interpreted to mean that errors do not exist in the software product; it may mean the testing was superficial.</p>
<p>An essential element of a software test case is the expected result. It is the key detail that permits objective evaluation of the actual test result. This necessary testing information is obtained from the corresponding, predefined definition or specification.</p>
<p>A software testing process should be based on principles that foster effective examinations of a software product. Applicable software testing tenets include:</p>
<ul>
<li>The expected test outcome is predefined;</li>
<li>A good test case has a high probability of exposing an error;</li>
<li>A successful test is one that finds an error;</li>
<li>There is independence from coding;</li>
<li>Both application (user) and software (programming) expertise are employed;</li>
<li>Testers use different tools from coders;</li>
<li>Examining only the usual case is insufficient;</li>
<li>Test documentation permits its reuse and an independent confirmation of the pass/fail status of a test outcome during subsequent review.</li>
</ul>
<p>Code-based testing is also known as structural testing or “white-box” testing. It identifies test cases based on knowledge obtained from the source code, detailed design specification, and other development documents. Structural testing can identify “dead” code that is never executed when the program is run. Structural testing is accomplished primarily with unit (module) level testing, but can be extended to other levels of software testing.</p>
<p>The level of structural testing can be evaluated using <strong>metrics that are designed to show what percentage of the software structure has been evaluated during structural testing</strong>. These metrics are typically referred to as <strong>“coverage”</strong> and are a measure of completeness with respect to test selection criteria. The amount of structural coverage should be commensurate with the level of risk posed by the software. Use of the term “coverage” usually means 100% coverage. Common structural coverage metrics include:</p>
<ul>
<li>Statement Coverage – This criteria requires sufficient test cases for each program statement to be executed at least once; however, its achievement is insufficient to provide confidence in a software product’s behavior.</li>
<li>Decision (Branch) Coverage – This criteria requires sufficient test cases for each program decision or branch to be executed so that each possible outcome occurs at least once. It is considered to be a minimum level of coverage for most software products, but decision coverage alone is insufficient for high-integrity applications.</li>
<li>Condition Coverage – This criteria requires sufficient test cases for each condition in a program decision to take on all possible outcomes at least once. It differs from branch coverage only when multiple conditions must be evaluated to reach a decision.</li>
<li>Multi-Condition Coverage – This criteria requires sufficient test cases to exercise all possible combinations of conditions in a program decision.</li>
<li>Loop Coverage – This criteria requires sufficient test cases for all program loops to be executed for zero, one, two, and many iterations covering initialization, typical running and termination (boundary) conditions.</li>
<li>Path Coverage – This criteria requires sufficient test cases for each feasible path, basis path, etc., from start to exit of a defined program segment, to be executed at least once. Because of the very large number of possible paths through a software program, path coverage is generally not achievable. The amount of path coverage is normally established based on the risk or criticality of the software under test.</li>
<li>Data Flow Coverage – This criteria requires sufficient test cases for each feasible data flow to be executed at least once. A number of data flow testing strategies are available.</li>
</ul>
<p>The following types of functional software testing involve generally increasing levels of effort:</p>
<ul>
<li>Normal Case – Testing with usual inputs is necessary. However, testing a software product only with expected, valid inputs does not thoroughly test that software product. By itself, normal case testing cannot provide sufficient confidence in the dependability of the software product.</li>
<li>Output Forcing – Choosing test inputs to ensure that selected (or all) software outputs are generated by testing.</li>
<li>Robustness – Software testing should demonstrate that a software product behaves correctly when given unexpected, invalid inputs. Methods for identifying a sufficient set of such test cases include Equivalence Class Partitioning, Boundary Value Analysis, and Special Case Identification (Error Guessing). While important and necessary, these techniques do not ensure that all of the most appropriate challenges to a software product have been identified for testing.</li>
<li>Combinations of Inputs – The functional testing methods identified above all emphasize individual or single test inputs. Most software products operate with multiple inputs under their conditions of use. Thorough software product testing should consider the combinations of inputs a software unit or system may encounter during operation. Error guessing can be extended to identify combinations of inputs, but it is an ad hoc technique. Cause-effect graphing is one functional software testing technique that systematically identifies combinations of inputs to a software product for inclusion in test cases.</li>
</ul>
<p>Functional and structural software test case identification techniques provide specific inputs for testing, rather than random test inputs. One weakness of these techniques is the difficulty in linking structural and functional test completion criteria to a software product’s reliability.</p>
<p><strong>Advanced software testing methods</strong>, such as statistical testing, can be employed to provide further assurance that a software product is dependable. Statistical testing uses randomly generated test data from defined distributions based on an operational profile (e.g., expected use, hazardous use, or malicious use of the software product). Large amounts of test data are generated and can be targeted to cover particular areas or concerns, providing an increased possibility of identifying individual and multiple rare operating conditions that were not anticipated by either the software product’s designers or its testers. Statistical testing also provides high structural coverage. It does require a stable software product. Thus, structural and functional testing are prerequisites for statistical testing of a software product.</p>
<p>Another aspect of software testing is the testing of software changes. Changes occur frequently during software development. These changes are the result of</p>
<ol type="1">
<li>debugging that finds an error and it is corrected,</li>
<li>new or changed requirements (“requirements creep”), and</li>
<li>modified designs as more effective or efficient implementations are found.</li>
</ol>
<p>Once a software product has been baselined (approved), any change to that product should have its own “mini life cycle,” including testing. Testing of a changed software product requires additional effort. It should demonstrate</p>
<ul>
<li>that the change was implemented correctly, and</li>
<li>that the change did not adversely impact other parts of the software product.</li>
</ul>
<p><strong>Regression analysis</strong> is the determination of the impact of a change based on review of the relevant documentation in order to identify the necessary regression tests to be run. <strong>Regression testing</strong> is the rerunning of test cases that a program has previously executed correctly and <strong>comparing the current result to the previous result in order to detect unintended effects of a software change</strong>. Regression analysis and regression testing should also be employed when using integration methods to build a software product to ensure that newly integrated modules do not adversely impact the operation of previously integrated modules.</p>
<p>In order to provide a thorough and rigorous examination of a software product, development testing is typically organized into levels: unit, integration, and system levels of testing.</p>
<ol class="example" type="1">
<li><strong>Unit (module or component) level testing</strong> focuses on the early examination of sub-program functionality and ensures that functionality not visible at the system level is examined by testing. Unit testing ensures that quality software units are furnished for integration into the finished software product.</li>
<li><strong>Integration level testing</strong> focuses on <em>the transfer of data</em> and <em>control across a program’s internal and external interfaces</em>. External interfaces are those with
<ol type="i">
<li>other software (including operating system software),</li>
<li>system hardware, and</li>
<li>the users and can be described as communications links.</li>
</ol></li>
<li><strong>System level testing</strong> demonstrates that all specified functionality exists and that the software product is trustworthy. This testing verifies the as-built program’s functionality and performance with respect to the requirements for the software product as exhibited on the specified operating platform(s). System level software testing addresses functional concerns and the following elements of a device’s software that are related to the intended use(s):
<ul>
<li>Performance issues (e.g., response times, reliability measurements);</li>
<li>Responses to stress conditions, e.g., behavior under maximum load, continuous use;</li>
<li>Operation of internal and external security features;</li>
<li>Effectiveness of recovery procedures, including disaster recovery;</li>
<li>Usability; <a href="https://dbdlab.tistory.com/entry/usability">(Usability vs Utility??)</a></li>
<li>Compatibility with other software products;</li>
<li>Behavior in each of the defined hardware configurations; and</li>
<li>Accuracy of documentation.</li>
</ul></li>
</ol>
<p>Control measures (e.g., a traceability analysis) should be used to ensure that the intended coverage is achieved.</p>
<p>System level testing also exhibits the software product’s behavior in the intended operating environment. The location of such testing is dependent upon the software developer’s ability to produce the target operating environment(s). Depending upon the circumstances, simulation and/or testing at (potential) customer locations may be utilized.</p>
<p>Test plans should identify the controls needed to ensure</p>
<ul>
<li>that the intended coverage is achieved and</li>
<li>that proper documentation is prepared when planned system level testing is conducted at sites not directly controlled by the software developer.</li>
</ul>
<p>Test procedures, test data, and test results</p>
<ul>
<li>should be documented in a manner permitting objective pass/fail decisions to be reached.</li>
<li>should also be suitable for review and objective decision making subsequent to running the test,</li>
<li>should be suitable for use in any subsequent regression testing.</li>
</ul>
<p>Errors detected during testing should be</p>
<ul>
<li>logged,</li>
<li>classified,</li>
<li>reviewed, and</li>
<li>resolved prior to release of the software.</li>
</ul>
<p>Software error data that is collected and analyzed during a development life cycle may be used to determine the suitability of the software product for release for commercial distribution. Test reports should comply with the requirements of the corresponding test plans.</p>
<p>Software testing tools are frequently used to ensure consistency, thoroughness, and efficiency in the testing of such software products and to fulfill the requirements of the planned testing activities.</p>
<p>Appropriate documentation providing evidence of the validation of these software tools for their intended use should be maintained (see section 6 of this guidance).</p>
<p>Typical Tasks – Testing by the Software Developer</p>
<ul>
<li>Test Planning</li>
<li>Structural Test Case Identification</li>
<li>Functional Test Case Identification</li>
<li>Traceability Analysis - Testing</li>
<li>Unit (Module) Tests to Detailed Design</li>
<li>Integration Tests to High Level Design</li>
<li>System Tests to Software Requirements</li>
<li>Unit (Module) Test Execution</li>
<li>Integration Test Execution</li>
<li>Functional Test Execution</li>
<li>System Test Execution</li>
<li>Acceptance Test Execution</li>
<li>Test Results Evaluation</li>
<li>Error Evaluation/Resolution</li>
<li>Final Test Report</li>
</ul>
</section>
<section id="user-site-testing" class="level4" data-number="2.5.2.6">
<h4 data-number="2.5.2.6" class="anchored" data-anchor-id="user-site-testing"><span class="header-section-number">2.5.2.6</span> User Site Testing</h4>
<p>Testing at the user site is <em>an essential part of software validation</em>. The Quality System regulation requires</p>
<ul>
<li>installation and</li>
<li>inspection procedures (including testing where appropriate) as well as</li>
<li>documentation of inspection and</li>
<li>testing to demonstrate proper installation. (See 21 CFR §820.170.)</li>
</ul>
<p>Likewise, manufacturing equipment must meet specified requirements, and automated systems must be validated for their intended use. (See 21 CFR §820.70(g) and 21 CFR §820.70(i) respectively.)</p>
<p>Terminology regarding user site testing can be confusing. Terms such as</p>
<ul>
<li>beta test,</li>
<li>site validation,</li>
<li>user acceptance test,</li>
<li>installation verification, and</li>
<li>installation testing have all been used to describe user site testing.</li>
</ul>
<p>For the purposes of this guidance, the term “user site testing” encompasses all of these and any other testing that takes place <em>outside of the developer’s controlled environment</em>.</p>
<p>This testing should take place at a user’s site with the actual hardware and software that will be part of the installed system configuration. The testing is accomplished through either actual or simulated use of the software being tested within the context in which it is intended to function.</p>
<p>Test planners should check with the FDA Center(s) with the corresponding product jurisdiction to determine whether there are any additional regulatory requirements for user site testing.</p>
<p>User site testing should follow a pre-defined written plan with</p>
<ul>
<li>a formal summary of testing and</li>
<li>a record of formal acceptance.</li>
</ul>
<p>The following documented evidence should be retained:</p>
<ul>
<li>all testing procedures,</li>
<li>test input data, and</li>
<li>test results</li>
</ul>
<p>There should be evidence that hardware and software are installed and configured as specified. Measures should ensure that all system components are exercised during the testing and that the versions of these components are those specified. The testing plan should specify testing throughout the full range of operating conditions and should specify continuation for a sufficient time to allow the system to encounter a wide spectrum of conditions and events in an effort to detect any latent faults that are not apparent during more normal activities.</p>
<p>Some of the evaluations of the system’s ability that have been performed earlier by the software developer at the developer’s site should be repeated at the site of actual use. These may include tests for:</p>
<ul>
<li>a high volume of data,</li>
<li>heavy loads or stresses,</li>
<li>security,</li>
<li>fault testing (avoidance, detection, tolerance, and recovery),</li>
<li>error messages, and</li>
<li>implementation of safety requirements.</li>
</ul>
<p>There should be an evaluation of the ability of the users of the system to understand and correctly interface with it.<br>
Operators should be able to perform the intended functions and respond in an appropriate and timely manner to all alarms, warnings, and error messages.<br>
Records should be maintained of both proper system performance and any system failures that are encountered.<br>
The revision of the system to compensate for faults detected during this user site testing should follow the same procedures and controls as for any other software change.</p>
<p>The developers of the software may or may not be involved in the user site testing.</p>
<ul>
<li>If the developers are involved, they may seamlessly carry over to the user’s site the last portions of design-level systems testing.</li>
<li>If the developers are not involved, it is all the more important that the user have persons who understand the importance of careful test planning, the definition of expected test results, and the recording of all test outputs.</li>
</ul>
<p>Typical Tasks – User Site Testing</p>
<ul>
<li>Acceptance Test Execution</li>
<li>Test Results Evaluation</li>
<li>Error Evaluation/Resolution</li>
<li>Final Test Report</li>
</ul>
</section>
<section id="maintenance-and-software-changes" class="level4" data-number="2.5.2.7">
<h4 data-number="2.5.2.7" class="anchored" data-anchor-id="maintenance-and-software-changes"><span class="header-section-number">2.5.2.7</span> Maintenance and Software Changes</h4>
<section id="hardware-vs-software" class="level5" data-number="2.5.2.7.1">
<h5 data-number="2.5.2.7.1" class="anchored" data-anchor-id="hardware-vs-software"><span class="header-section-number">2.5.2.7.1</span> Hardware vs Software</h5>
<p>Hardware maintenance typically includes</p>
<ul>
<li>preventive hardware maintenance actions,</li>
<li>component replacement, and</li>
<li>corrective changes.</li>
</ul>
<p>Software maintenance includes</p>
<ul>
<li>corrective,</li>
<li>perfective, and</li>
<li>adaptive maintenance</li>
<li>but does not include preventive maintenance actions or software component replacement.</li>
</ul>
</section>
<section id="maintenance-types" class="level5" data-number="2.5.2.7.2">
<h5 data-number="2.5.2.7.2" class="anchored" data-anchor-id="maintenance-types"><span class="header-section-number">2.5.2.7.2</span> Maintenance Types</h5>
<ul>
<li>Corrective maintenance: Changes made to correct errors and faults in the software.</li>
<li>Perfective maintenance: Changes made to the software to improve the performance, maintainability, or other attributes of the software system .</li>
<li>Adaptive maintenance: Changes to make the software system usable in a changed environment.</li>
</ul>
<p>Sufficient regression analysis and testing should be conducted to demonstrate that portions of the software not involved in the change were not adversely impacted. When changes are made to a software system,</p>
<ul>
<li>either during initial development or</li>
<li>during post release maintenance,</li>
</ul>
<p>This is in addition to testing that evaluates the correctness of the implemented change(s). The specific validation effort necessary for each software change is determined by</p>
<ul>
<li>the type of change,</li>
<li>the development products affected, and the</li>
<li>impact of those products on the operation of the software.</li>
</ul>
</section>
<section id="factors-of-limitting-validation-effort-needed-when-a-change-is-made" class="level5" data-number="2.5.2.7.3">
<h5 data-number="2.5.2.7.3" class="anchored" data-anchor-id="factors-of-limitting-validation-effort-needed-when-a-change-is-made"><span class="header-section-number">2.5.2.7.3</span> Factors of Limitting Validation Effort Needed When a Change Is Made</h5>
<ul>
<li>careful and complete documentation of the design structure and</li>
<li>careful and complete documentation of interrelationships of various modules,</li>
<li>interfaces, etc.</li>
<li>For example,
<ul>
<li>test documentation,</li>
<li>test cases, and</li>
<li>results of previous verification and validation testing All of them need to be archived if they are to be available for performing subsequent regression testing.</li>
</ul></li>
</ul>
<p>The following additional maintenance tasks should be addressed:</p>
<ul>
<li>Software Validation Plan Revision - For software that was previously validated, the existing software validation plan should be revised to support the validation of the revised software. If no previous software validation plan exists, such a plan should be established to support the validation of the revised software.</li>
<li>Anomaly Evaluation – Software organizations frequently maintain documentation, such as software problem reports that describe software anomalies discovered and the specific corrective action taken to fix each anomaly.
<ul>
<li>Too often, however, mistakes are repeated because software developers do not take the next step to determine the root causes of problems and make the process and procedural changes needed to avoid recurrence of the problem.</li>
<li>Software anomalies should be evaluated in terms of their severity and their effects on system operation and safety,</li>
<li>but they should also be treated as symptoms of process deficiencies in the quality system.</li>
<li>A root cause analysis of anomalies can identify specific quality system deficiencies.</li>
<li>Where trends are identified (e.g., recurrence of similar software anomalies), appropriate corrective and preventive actions must be implemented and documented to avoid further recurrence of similar quality problems. (See 21 CFR 820.100.)</li>
</ul></li>
<li>Problem Identification and Resolution Tracking - All problems discovered during maintenance of the software should be documented. The resolution of each problem should be tracked to ensure it is fixed, for historical reference, and for trending.</li>
<li>Proposed Change Assessment - All proposed modifications, enhancements, or additions should be assessed to determine the effect each change would have on the system. This information should determine the extent to which verification and/or validation tasks need to be iterated.</li>
<li>Task Iteration - For approved software changes, all necessary verification and validation tasks should be performed to ensure that planned changes are implemented correctly, all documentation is complete and up to date, and no unacceptable changes have occurred in software performance.</li>
<li>Documentation Updating – Documentation should be carefully reviewed to determine which documents have been impacted by a change. All approved documents (e.g., specifications, test procedures, user manuals, etc.) that have been affected should be updated in accordance with configuration management procedures. Specifications should be updated before any maintenance and software changes are made.</li>
</ul>
</section>
</section>
</section>
</section>
<section id="validation-of-automated-process-equipment-and-quality-system-software" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="validation-of-automated-process-equipment-and-quality-system-software"><span class="header-section-number">2.6</span> Validation of Automated Process Equipment and Quality System Software</h2>
<p>The Quality System regulation requires that “when computers or automated data processing systems are used as part of production or the quality system, the [device] manufacturer shall validate computer software for its intended use according to an established protocol.” (See 21 CFR §820.70(i)). This has been a regulatory requirement of FDA’s medical device Good Manufacturing Practice (GMP) regulations since 1978.</p>
<p>Computer systems that implement part of a device manufacturer’s production processes or quality system (or that are used to create and maintain records required by any other FDA regulation) are subject to the Electronic Records; Electronic Signatures regulation. (See 21 CFR Part 11.) This regulation establishes additional security, data integrity, and validation requirements when records are created or maintained electronically. These additional Part 11 requirements should be carefully considered and included in system requirements and software requirements for any automated record <code>keeping systems</code>. System validation and software validation should demonstrate that all Part 11 requirements have been met.</p>
<p>Computers and automated equipment are used extensively throughout all aspects of</p>
<ul>
<li>medical device design,</li>
<li>laboratory testing and analysis,</li>
<li>product inspection and acceptance,</li>
<li>production and process control,</li>
<li>environmental controls,</li>
<li>packaging,</li>
<li>labeling,</li>
<li>traceability,</li>
<li>document control,</li>
<li>complaint management, and many other aspects of the quality system.</li>
</ul>
<p>Increasingly, automated plant floor operations can involve extensive use of embedded systems in:</p>
<ul>
<li>programmable logic controllers;</li>
<li>digital function controllers;</li>
<li>statistical process control;</li>
<li>supervisory control and data acquisition;</li>
<li>robotics;</li>
<li>human-machine interfaces;</li>
<li>input/output devices; and</li>
<li>computer operating systems.</li>
</ul>
<p>All software tools used for software design are subject to the requirement for software validation, but the validation approach used for each application can vary widely.</p>
<p>Validation is typically supported by:</p>
<ul>
<li>verifications of the outputs from each stage of that software development life cycle; and</li>
<li>checking for proper operation of the finished software in the device manufacturer’s intended use environment.</li>
</ul>
<section id="how-much-validation-evidence-is-needed" class="level3" data-number="2.6.1">
<h3 data-number="2.6.1" class="anchored" data-anchor-id="how-much-validation-evidence-is-needed"><span class="header-section-number">2.6.1</span> How Much Validation Evidence Is Needed?</h3>
<p>The level of validation effort should be commensurate with</p>
<ul>
<li>the risk posed by the automated operation,</li>
<li>the complexity of the process software,</li>
<li>the degree to which the device manufacturer is dependent upon that automated process to produce a safe and effective device</li>
</ul>
<p>Documented requirements and risk analysis of the automated process help to define the scope of the evidence needed to show that the software is validated for its intended use. Without a plan, extensive testing may be needed for:</p>
<ul>
<li>a plant-wide electronic record and electronic signature system;</li>
<li>an automated controller for a sterilization cycle; or</li>
<li>automated test equipment used for inspection and acceptance of finished circuit boards in a lifesustaining / life-supporting device.</li>
</ul>
<p>High risk applications should not be running in the same operating environment with non-validated software functions, even if those software functions are not used. Risk mitigation techniques such as memory partitioning or other approaches to resource protection may need to be considered when high risk applications and lower risk applications are to be used in the same operating environment.</p>
<p>When software is upgraded or any changes are made to the software, the device manufacturer should consider how those changes may impact the “used portions” of the software and must reconfirm the validation of those portions of the software that are used. (See 21 CFR §820.70(i).)</p>
</section>
<section id="defined-user-equipment" class="level3" data-number="2.6.2">
<h3 data-number="2.6.2" class="anchored" data-anchor-id="defined-user-equipment"><span class="header-section-number">2.6.2</span> Defined User Equipment</h3>
<p>A very important key to software validation is a documented user requirements specification that defines:</p>
<ul>
<li>the “intended use” of the software or automated equipment; and</li>
<li>the extent to which the device manufacturer is dependent upon that software or equipment for production of a quality medical device.</li>
</ul>
<p>The device manufacturer (user) needs to define the expected operating environment including any required hardware and software configurations, software versions, utilities, etc. The user also needs to:</p>
<ul>
<li>document requirements for system performance, quality, error handling, startup, shutdown, security, etc.;</li>
<li>identify any safety related functions or features, such as sensors, alarms, interlocks, logical processing steps, or command sequences; and</li>
<li>define objective criteria for determining acceptable performance.</li>
</ul>
<p>The validation must be conducted in accordance with a documented protocol, and the validation results must also be documented. (See 21 CFR §820.70(i).) Test cases should be documented that will exercise the system to challenge its performance against the pre-determined criteria, especially for its most critical parameters.</p>
<p>Test cases should address</p>
<ul>
<li>error and alarm conditions,</li>
<li>startup, shutdown,</li>
<li>all applicable user functions and operator controls,</li>
<li>potential operator errors,</li>
<li>maximum and minimum ranges of allowed values, and</li>
<li>stress conditions applicable to the intended use of the equipment.</li>
</ul>
<p>The test cases should be executed and the results should be recorded and evaluated to determine whether the results support a conclusion that the software is validated for its intended use.</p>
<p>A device manufacturer may conduct a validation using their own personnel or may depend on a third party such as the equipment/software vendor or a consultant. In any case, the device manufacturer retains the ultimate responsibility for ensuring that the production and quality system software:</p>
<ul>
<li>is validated according to a written procedure for the particular intended use; and</li>
<li>will perform as intended in the chosen application.</li>
</ul>
<p>The device manufacturer should have documentation including:</p>
<ul>
<li>defined user requirements;</li>
<li>validation protocol used;</li>
<li>acceptance criteria;</li>
<li>test cases and results; and</li>
<li>a validation summary that objectively confirms that the software is validated for its intended use.</li>
</ul>
</section>
<section id="validation-of-off-the-shelf-software-and-automated-equipment" class="level3" data-number="2.6.3">
<h3 data-number="2.6.3" class="anchored" data-anchor-id="validation-of-off-the-shelf-software-and-automated-equipment"><span class="header-section-number">2.6.3</span> Validation of Off-The-Shelf Software and Automated Equipment</h3>
<p>Most of the automated equipment and systems used by device manufacturers are supplied by thirdparty vendors and are purchased off-the-shelf (OTS). <em>The device manufacturer is responsible for ensuring that the product development methodologies used by the OTS software developer are appropriate and sufficient for the device manufacturer’s intended use of that OTS software.</em></p>
<p>Where possible and depending upon the device risk involved, the device manufacturer should consider auditing the vendor’s design and development methodologies used in the construction of the OTS software and should assess the development and validation documentation generated for the OTS software. Such audits can be conducted by the device manufacturer or by a qualified third party.</p>
<p>The audit should demonstrate that the vendor’s procedures for and results of the verification and validation activities performed the OTS software are appropriate and sufficient for the safety and effectiveness requirements of the medical device to be produced using that software.</p>


</section>
</section>
</section>

 ]]></description>
  <category>Public Health</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/2022-12-10-FDA/index.html</guid>
  <pubDate>Wed, 14 Dec 2022 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/docs/blog/posts/2022-12-10-FDA/FDA_medical.PNG" medium="image"/>
</item>
</channel>
</rss>
