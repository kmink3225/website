---
title: template
subtitle: template
description: |
  template
categories:
  - template
author: Kwangmin Kim
date: 01/17/2023
format: 
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
draft: True
---
### convergence in probaiblity

If a sequence of random variables X₁, X₂, X₃, ... converges in probability to a random variable X, then as the sample size increases, the probability that the sample mean deviates from the true population mean by more than a given amount ε becomes smaller and smaller.

In other words, convergence in probability means that the sample mean approaches the true population mean with high probability as the sample size increases. However, it does not guarantee that the sample mean will converge to the true population mean for every single sample, as there may be some samples for which the deviation is greater than ε.

Convergence in probability is a weaker form of convergence than almost sure convergence, which requires that the sample mean converges to the true population mean with probability one (i.e., almost surely) as the sample size increases.

Convergence in probability is a concept in probability theory that describes the behavior of a sequence of random variables as the sample size becomes large. Specifically, a sequence of random variables X₁, X₂, X₃, ... converges in probability to a random variable X if, for any positive number ε, the probability that the absolute difference between Xn and X is greater than ε approaches zero as n approaches infinity:

lim_{n→∞} P(|Xn - X| > ε) = 0

In other words, as the sample size increases, the probability that the sample mean deviates from the true population mean by more than ε becomes smaller and smaller. This is a weaker form of convergence than almost sure convergence, which requires that the probability of the deviation going to zero as the sample size increases.

Convergence in probability is denoted by Xn →p X, which reads as "Xn converges in probability to X". It is an important concept in statistical inference, particularly in the context of large sample theory and the central limit theorem.

### convergence in distribution

If a sequence of random variables X₁, X₂, X₃, ... converges in distribution to a random variable X, then as the sample size increases, the distribution of the sample mean approaches the distribution of the true population mean.

In other words, convergence in distribution means that the sample mean approaches the true population mean in terms of its distribution as the sample size increases. This means that the shape, location, and scale of the distribution of the sample mean becomes more and more similar to the distribution of the true population mean as the sample size increases.

Convergence in distribution is a weaker form of convergence than almost sure convergence or convergence in probability, which require stronger conditions on the behavior of the sample mean as the sample size increases. However, it is still an important concept in statistical inference, particularly in the context of the central limit theorem and the asymptotic properties of estimators.

Convergence in distribution is a concept in probability theory that describes the limiting behavior of a sequence of random variables as the sample size becomes large. Specifically, a sequence of random variables X₁, X₂, X₃, ... converges in distribution to a random variable X if the cumulative distribution functions (CDFs) of the random variables converge to the CDF of X at all points where the CDF of X is continuous:

lim_{n→∞} F_n(x) = F(x)

where F_n(x) is the CDF of X_n, and F(x) is the CDF of X.

In other words, as the sample size increases, the CDF of the sample mean approaches the CDF of the true population mean at all points where the CDF of the population mean is continuous. This is a weaker form of convergence than almost sure convergence or convergence in probability, which require stronger conditions on the behavior of the sample mean as the sample size increases.

Convergence in distribution is denoted by Xn ⇒ X, which reads as "Xn converges in distribution to X". It is an important concept in statistical inference, particularly in the context of the central limit theorem and the asymptotic properties of estimators.