---
title: "EDA"
subtitle: "Explorative Data Analysis"
description: "Both EDA and Data Mining are used"
author: Kwangmin Kim
date: 2023-02-18
execute:
  warning: false
  message: false
format: 
  html:
    toc: true
    number-sections: true
    page-layout: full
    code-fold: true
---


```{r}
#| echo: false

rm(list=ls())

if(grepl('kkm',getwd())){
    datapath="C:/Users/kkm/Desktop/projects/website/docs/data/llfs_simulated_data.rds"
}else{
    datapath="C:/Users/kmkim/Desktop/projects/website/docs/data/llfs_simulated_data.rds"
}

```


<ul class="nav nav-pills" id="language-tab" role="tablist">

<li class="nav-item" role="presentation">

<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" role="tab" aria-controls="Korean" aria-selected="true">

Korean

</button>

</li>

<li class="nav-item" role="presentation">

<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" role="tab" aria-controls="knitr" aria-selected="false">

English

</button>

</li>

<div class="tab-content" id="language-tabcontent">

::: {#Korean .tab-pane .fade .show .active role="tabpanel" aria-labelledby="Korean-tab"}

**(한글 준비중)**

please, read the English section first. 


```{r}
#| echo: false

if(!require(janitor)) install.packages("janitor") 
if(!require(tidyverse)) install.packages("tidyverse") 
if(!require(tidymodels)) install.packages("tidymodels") 
if(!require(glmnet)) install.packages("glmnet") 
if(!require(MASS)) install.packages("MASS") 
if(!require(ggpubr)) install.packages("ggpubr") 
if(!require(car)) install.packages("car") 
if(!require(mixOmics)) install.packages("mixOmics") 

library(janitor)
library(tidyverse)
library(tidymodels)
library(glmnet)
library(MASS)
library(ggpubr) 
library(car) 
library(mixOmics)
set.seed(20230103) 
knitr::opts_chunk$set(message=FALSE,warning=FALSE)
```


```{r}
#| echo: false
# the number of samples
sample_size <- 1000
# the number of predictors
predictor_size <- 5000
# the number of groups
group_size <- sample(6:10,1) # at least more than 6, the number of the genotypes
# the number of predictors truly associated with a response variable
significant_predictors <- floor(predictor_size*sample((50:100)/1000,1)) 

## set the predictors associated with an outcome
### the number of predictors positively associated with an outcome
### the number of predictors negatively associated with an outcome
positively_associated_predictors<-floor(significant_predictors*0.4) 
negatively_associated_predictors<-significant_predictors-positively_associated_predictors 

## set the proportion of the groups in which the predictors are correlated with one another
### randomly sampling proportions to become their sum equal to 1
group_proportion_list<-sample(seq(1,1+2*(100-group_size)/group_size,
                            by=2*(100-group_size)/(group_size*(group_size-1)))/100,
                        group_size,replace=FALSE)%>%round(3) 
names(group_proportion_list)<-paste0("group",1:length(group_proportion_list))
### initialize a matrix with a size as sample_size by predictor_size
predictor_matrix <- matrix(0, ncol = predictor_size, nrow = sample_size)
### initialize a data frame and assign meta information used to generate simulated data
group_meta_data<-
    data.frame(
        group_name=c(names(group_proportion_list)),
        proportion=group_proportion_list)%>%
        mutate(
            group_n=(predictor_size*group_proportion_list)%>%round(0), # the number of predictors within each group 
            first_index=c(1,cumsum(group_n[-length(group_proportion_list)])+1), # the 1st index of predictors in each group
            last_index=cumsum(group_n), # the last index of predictors in each group
            group_correlation=sample((0:700)/1000,length(group_proportion_list),replace=TRUE), # within-group correlations among the within-group predictors
            group_effect=sample((-40:30)/100,length(group_proportion_list),replace=TRUE)) # effect of each group on an outcome variable
### set a group effect as 0.7 into a group with the smallest group number 
group_meta_data[which.min(group_meta_data[,"group_n"]),"group_effect"]<-0.7

### set a group effect as -0.5 into a group with the second smallest group number 
group_meta_data[group_meta_data[,"group_n"]==(sort(group_meta_data[,"group_n"])[2]),"group_effect"]<-(-0.5)

# initialize a data matrix to assign simulated values
## add some noise to data
data<-matrix(rnorm(sample_size*predictor_size,mean=0,sd=0.05), 
             nrow = sample_size, ncol = predictor_size)

# initialize a covariance matrix to assign simulated values
covariance_matrix<-matrix(rnorm(predictor_size*predictor_size,mean=0,sd=0.05),
                          nrow=predictor_size, ncol=predictor_size)
beta_coefficients <- rnorm(predictor_size,0,0.05)

answer_list<-list(
    'sample size'=sample_size,
    'predictor size'=predictor_size,
    'group size'=group_size,
    'significant predictors'=significant_predictors,
    'positively associated predictors'=positively_associated_predictors,
    'negatively associated predictors'=negatively_associated_predictors,
    'group proportion list'=group_proportion_list,
    'group meta data'=group_meta_data,
    'data noise intensity'=c('distribution'='rnorm','mean'=0,'sd'=0.05),
    'covariance noise intensity'=c('distribution'='rnorm','mean'=0,'sd'=0.05),
    'effect noise intensity on response'=c('distribution'='rnorm','mean'=0,'sd'=0.05),
    'link function between the response and predictors' = 'canonical logit link function',
    'link function noise intensity' = c('distribution'='rnorm','mean'=0,'sd'=0.05),
    'age_distirbution'='used data of a variable with the highest effect on outcome',
    'sex_distribution'='rbinom(n=sample size,p=0.5)',
    'genotype_distirbution'=c('e2' = '8.4%','e3' = '77.9%','e4' = '13.7%'))
```



```{r}

## Function List

color_function<-function(category_number){
return(
    if(category_number==2){
        c("darkblue","darkred")
    }else if(category_number==3){
        c("darkblue","darkred","yellow4")
    }else if(category_number==4){
        c("darkblue","darkred","yellow4","blueviolet")
    }else if(category_number==5){
        c("darkblue","darkred","yellow4","blueviolet","darkorange")
    }else{
        c("darkblue","darkred","yellow4","blueviolet","darkorange","darkgreen")
    }
    )
}

scale_function=function(vector=x,min=NULL,max=NULL,method){
    scaling_methods<-c('min_max normalization','customized normalization','standardization')

    if(method=="min-max"){
        output=(vector-min(vector))(max(vector)-min(vector))
    }else if(method=="customized"){
        output=(max-min)*(vector-min(vector))/(max(vector)-min(vector))+min
    }else if(method=="standarized"){
        output=(vector-mean(vector))/sd(vector)
    }else{
        paste0("Error!, no such a scaling method in this module. Please, put the first word of each method you want to use in the 'method' argument among the following tests: ", paste(scaling_methods,collapse=", "))
    }
  return(output)
}

multiple_shapiro_test<-function(in_data){
        normality_test<-apply(in_data[,unlist(lapply(in_data, is.numeric))],2,
                            function(x)shapiro.test(x))
        temp<-data.frame(matrix(nrow=length(normality_test),ncol=4))
        for (i in 1:length(normality_test)){
            temp[i,]<-c(
                coloumn_name=names(normality_test)[i],
                statistic=normality_test[[i]]$statistic,
                p_value=normality_test[[i]]$p.value,
                method=normality_test[[i]]$method)
        }
        names(temp)<-c('column_name','statistic','p_value','method')
        output<-temp%>%
            mutate(p_adjusted=p.adjust(p_value,method="bonferroni"),
            type=ifelse(p_adjusted<0.05,'not_normal','normal'))%>%
            dplyr::select('column_name','statistic','p_value','p_adjusted','type','method')
        return(output)
}    

multiple_levene_test<-function(in_data,categorical_variable){
        homoscedasticity_test<-apply(in_data[,unlist(lapply(in_data, is.numeric))],2,
                                    function(x)leveneTest(x~in_data[,categorical_variable]))
        temp<-data.frame(matrix(nrow=length(homoscedasticity_test),ncol=6))
            for (i in 1:length(homoscedasticity_test)){
                temp[i,]<-c(
                    coloumn_name=names(homoscedasticity_test)[i],
                    group_df=homoscedasticity_test[[i]]$Df[1],
                    residual_df=homoscedasticity_test[[i]]$Df[2],
                    statistic=homoscedasticity_test[[i]]$`F value`[1],
                    p_value=homoscedasticity_test[[i]]$`Pr(>F)`[1],
                    method="levene's test")
            }
            names(temp)<-c('column_name','group_df','residual_df','statistic','p_value','method')
            output<-temp%>%
                mutate(p_adjusted=p.adjust(p_value,method="bonferroni"),
                type=ifelse(p_adjusted<0.05,'heteroscedasticity','homoscedasticity'))%>%
                dplyr::select('column_name','group_df','residual_df','statistic','p_value','p_adjusted','type','method')
        return(output)} 

categorical_variable='outcome'

multiple_unpaired_t_test<-function(in_data,categorical_variable,homo_variables,hetero_variables){
    homo_unpaired_t_test<-apply(in_data[,unlist(lapply(in_data, is.numeric))][,homo_variables],2,
                                    function(x)t.test(x~in_data[,categorical_variable],var.equal=TRUE))
    hetero_unpaired_t_test<-apply(in_data[,unlist(lapply(in_data, is.numeric))][,hetero_variables],2,
                                    function(x)t.test(x~in_data[,categorical_variable],var.equal=FALSE)) 
    unpaired_t_test<-c(homo_unpaired_t_test,hetero_unpaired_t_test)

    temp<-data.frame(matrix(nrow=length(unpaired_t_test),ncol=7))
        for (i in 1:length(unpaired_t_test)){
            temp[i,]<-c(names(unpaired_t_test)[i], 
                        unpaired_t_test[[i]]$estimate,
                        unpaired_t_test[[i]]$parameter,
                        unpaired_t_test[[i]]$statistic,
                        unpaired_t_test[[i]]$p.value,
                        unpaired_t_test[[i]]$method)
        }
        names(temp)<-c('column_name',names(unpaired_t_test[[1]]$estimate),'df','statistic','p_value','method')
        output<-temp%>%
            mutate(p_adjusted=p.adjust(p_value,method="bonferroni"),
            type=ifelse(p_adjusted<0.05,'significant','insignificant'))%>%
            dplyr::select('column_name',names(unpaired_t_test[[1]]$estimate),'df','statistic','p_value','p_adjusted','type','method')
    return(output)} 


multiple_correlation_test<-function(in_data,in_numeric_variable){
    correlation_test<-apply(in_data[,unlist(lapply(in_data, is.numeric))],2,
                                    function(x)cor.test(x,in_data[,in_numeric_variable],method='pearson'))
    temp<-data.frame(matrix(nrow=length(correlation_test),ncol=6))
        for (i in 1:length(correlation_test)){
            temp[i,]<-c(names(correlation_test)[i], 
                        correlation_test[[i]]$estimate,
                        correlation_test[[i]]$parameter,
                        correlation_test[[i]]$statistic,
                        correlation_test[[i]]$p.value,
                        correlation_test[[i]]$method)
        }
        names(temp)<-c('column_name',names(correlation_test[[1]]$estimate),'df','statistic','p_value','method')
        output<-temp%>%
            mutate(p_adjusted=p.adjust(p_value,method="bonferroni"),
            type=ifelse(p_adjusted<0.05,'significant','insignificant'))%>%
            dplyr::select('column_name',names(correlation_test[[1]]$estimate),'df','statistic','p_value','p_adjusted','type','method')
    return(output)} 

multiple_anova_test<-function(in_data, in_categorical_variable){
    aov_test<-apply(in_data[,unlist(lapply(in_data, is.numeric))],2,
                function(x)aov(x~get(in_categorical_variable),data=in_data)%>%summary)

    temp<-data.frame(matrix(nrow=length(aov_test),ncol=10))
    for (i in 1:length(aov_test)){
        temp[i,]<-c(names(aov_test)[i], 
                    aov_test[[i]][[1]]$`Df`[1],
                    aov_test[[i]][[1]]$`Df`[2],
                    aov_test[[i]][[1]]$`Sum Sq`[1],
                    aov_test[[i]][[1]]$`Sum Sq`[2],
                    aov_test[[i]][[1]]$`Mean Sq`[1],
                    aov_test[[i]][[1]]$`Mean Sq`[2],
                    aov_test[[i]][[1]]$`F value`[1],
                    aov_test[[i]][[1]]$`Pr(>F)`[1],
                    'one_way_anova')
    }
    names(temp)<-c('column_name','group_df','residual_df','group_ssq','residual_ssq',
                    'group_msq','residual_msq','F_value','p_value','method')
    output<-temp%>%
            mutate(p_adjusted=p.adjust(p_value,method="bonferroni"),
            type=ifelse(p_adjusted<0.05,'significant','insignificant'))%>%
            dplyr::select('column_name','group_df','residual_df','group_ssq','residual_ssq',
                    'group_msq','residual_msq','F_value','p_value','method',
                    'p_adjusted','type','method')
    return(output)} 

main_statistical_test<-function(
    in_data,method,categorical_variable,in_numeric_variable,
    homo_variables=NULL,hetero_variables=NULL,
    fun1=multiple_shapiro_test,
    fun2=multiple_levene_test,
    fun3=multiple_unpaired_t_test){
    test_list<-c("shapiro wilks test","levene's test","student t test","pearson correlation test","anova")#,"ANCOVA","MANOVA","wilcoxon manwhitney",'kruskal wallis test')
    error_massage<-paste0("Error!, no such a test in this module. Please, put the first word of each method you want to use in the 'method' argument among the following tests: ", paste(test_list,collapse=", "))
    if(grepl('shapiro',method)){
        output=multiple_shapiro_test(in_data)
    }else if(grepl('levene',method)){
        output=multiple_levene_test(in_data,categorical_variable)
        # var.test()
    }else if(grepl('student',method)){
        # code unpaired vs paired t test in the future
        output=multiple_unpaired_t_test(in_data,categorical_variable,homo_variables,hetero_variables)
    }else if(grepl('kruskal',method)){
        return(error_massage)
    }else if(grepl('wilcoxon|manwhitney',method)){
        return(error_massage)
    }else if(grepl('anova|aov',method)){
        output=multiple_anova_test(in_data,categorical_variable)
    }else if(grepl('cor',method)){
        output=multiple_correlation_test(in_data,in_numeric_variable)
    }else{
        return(error_massage)
    }
    return(output)
}


getNumericSummaryTable=function(in_data,group_variable,summary_variable,set_color=color_function,...){
    # table
    temp<-in_data %>% 
    #group_by_at(vars(...)) %>% 
    group_by_at(vars(group_variable)) %>% 
    mutate(count=n())%>%
    summarise_at(vars(summary_variable,count),
                 list(mean=mean,
                 sd=sd,
                 min=min,
                 Q1=~quantile(., probs = 0.25),
                 median=median, 
                 Q3=~quantile(., probs = 0.75),
                 max=max))%>%
                 as.data.frame()%>%
                 rename(
                 n=count_mean)%>%
                 dplyr::select(-contains('count'))%>%
                 as.data.frame()
    names(temp)<-c("group",
    sapply(names(temp)[-1],function(x)str_replace(x,paste0(summary_variable,"_"),"")))
    output<-temp%>%
    mutate(
        variable=group_variable,
        summary=summary_variable,
        mean=mean%>%round(2),
        sd=sd%>%round(2),
        min=min%>%round(2),
        Q1=Q1%>%round(2),
        Q4=Q3%>%round(2),
        max=max%>%round(2),
        IQR_min=Q1-(Q3-Q1)*1.5%>%round(2),
    IQR_max=Q3+(Q3-Q1)*1.5%>%round(2),
    proportion=paste0(round(n/nrow(all_data)*100,2),"%"))%>%
    dplyr::select(variable,group,summary,n,proportion,mean,sd,min,IQR_min,Q1,median,Q3,IQR_max,max)
    return(output)
}

getNumericSummaryPlot=function(
    in_data=all_data,group_variable,summary_variable,
    set_color=color_function,
    summary_function=getNumericSummaryTable,...){
    # plot
    temp=getNumericSummaryTable(in_data,group_variable,summary_variable)
    temp2=temp
    names(temp2)[2]=group_variable
    plot<-
    in_data%>%
    dplyr::select(group_variable,summary_variable)%>%
    inner_join(.,temp2,by=group_variable)%>%
    ggplot(aes(x=age,fill=get(group_variable),color=get(group_variable)))+
    geom_histogram(aes(y=..density..),binwidth=1,alpha=0.5, position="identity")+
    geom_vline(aes(xintercept=mean,color=get(group_variable)), linetype="dashed", size=1.5) + 
    geom_density(aes(y=..density..),alpha=0.3) +
    scale_color_manual(values=set_color(nrow(temp2)))+
    scale_fill_manual(values=set_color(nrow(temp2)))+
    theme_bw()+
    theme(legend.position = c(.95, .95),
    legend.justification = c("right", "top"),
    legend.margin = margin(6, 6, 6, 6),
    legend.text = element_text(size = 10))+
    guides(fill=guide_legend(title=group_variable),
    color=FALSE)+
    geom_text(aes(label=round(mean,1),y=0,x=mean),
                vjust=-1,col='yellow',size=5)+
    ggtitle(paste0("Histogram & Density, ", summary_variable, " Grouped by ", group_variable))+
        labs(x=summary_variable, y = "Density")

    result<-plot
    return(result)
}
```


```{r}
# load simulation data
simulated_data<-read_rds(datapath)

# simple data pre-processing
all_data<-
    simulated_data%>%
    mutate(
      outcome=factor(outcome,levels=c("negative","positive")),
      sex=ifelse(sex==0,"man","woman"),
      sex=factor(sex,levels=c("man","woman")),
      genotype=factor(genotype,levels=c("e3","e2","e4"))
      )

# rename metabolite variables
names(all_data)[6:ncol(all_data)]<-paste0("meta",1:predictor_size)
 

```
# Summary 

## Summary of Exploratory Data Analysis (EDA) 
## Summary of Data Mining

# Supplements

## EDA

### Univariable Analysis

### Normality Test

```{r}
# raw data
normality_test_result<-multiple_shapiro_test(all_data)%>%
    filter(column_name!='id')%>%
    group_by(type)%>%
    summarise(count=n())%>%
    mutate(proportion=round(count/sum(count),3),
    total=sum(count))%>%
    dplyr::select(type,total,everything())
    
normality_test_result%>%
    knitr::kable(caption="Summary of the Result of Shapiro Wilk Tests on Numeric Variables")

```

Out of `r normality_test_result[1,'total']` numeric variables, the variables following a normal distribution are `r normality_test_result[1,'count']` (`r normality_test_result[1,'proportion']*100`%) and the ones that do not are `r normality_test_result[2,'count']` (`r normality_test_result[2,'proportion']*100`%).

### Visualization

#### 16 Variables That Follow Normal Distributions


```{r}
#| fig-width: 9
#| fig-height: 10

# 16 numeric variables randomly selected
normal_variables<-
    multiple_shapiro_test(all_data)%>%
        filter(p_value>0.05,column_name!='id')%>%
            dplyr::select(column_name)%>%
            pull%>%sample(16)

normal_data<-
    all_data%>%
        dplyr::select(outcome,normal_variables)%>%
        gather(key=metabolite,value=value,normal_variables)

normal_data%>%
    ggplot(aes(x=value))+
    geom_histogram(aes(y=..density..))+
    geom_density(color='red',linewidth=1.5)+
    facet_wrap(.~metabolite)+
    labs(title="Histogram, Numeric Variables Following Normal Distribution")

normal_data%>%
    ggplot(aes(x=metabolite,y=value))+
    geom_boxplot()+
    theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1))+
    labs(title="Boxplot, Numeric Variables Following Normal Distribution")

normal_data%>%
    ggplot(aes(x=value,fill=outcome))+
    geom_histogram(aes(y=..density..),alpha=0.5)+
    geom_density(linewidth=1.5,alpha=0.5)+
    scale_fill_manual(values=color_function(length(unique(normal_data$outcome))))+
    facet_wrap(.~metabolite)+
    labs(title="Numeric Variables Following Normal Distribution Grouped by Disease Status")    
normal_data%>%
    ggplot(aes(x=metabolite,y=value,fill=outcome))+
    geom_boxplot()+
    scale_fill_manual(values=color_function(length(unique(normal_data$outcome))))+
    theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1))+
    labs(title="Boxplot, Numeric Variables Following Normal Distribution")

```

#### Variables That Do Not Follow Normal Distributions

There is no variable that do not follow a normal distribution.

### Bivariable Analysis

#### AD vs Metabolites

Through the exploratory data analysis above, it was confirmed that all variables follow a normal distribution, and a t test is conducted to select metabolites that have a significant relationship with the disease, AD.

* Homoscedasticity Test

Leven's test is performed to confirm equal variance, one of the assumptions of the t test.

```{r}

leven_test_result<-
    main_statistical_test(in_data=all_data,method="levene",categorical_variable="outcome")%>%
    filter(column_name!='id')

homo_variable<-leven_test_result%>%
filter(p_adjusted>0.05)%>%
dplyr::select(column_name)%>%
pull()%>%
unique()

hetero_variable<-leven_test_result%>%
filter(p_adjusted<0.05)%>%
dplyr::select(column_name)%>%
pull()%>%
unique()

```

*  10 variables randomly selected out of `r length(homo_variable)` variables with equal variance: `r homo_variable%>%sample(10)`
* `r length(hetero_variable)` variables randomly selected with equal variance: `r hetero_variable`

```{r}

homo_variable_sample<-homo_variable%>%sample(10)
hetero_variable_sample<-hetero_variable

stratified_levene_data<-all_data%>%
    dplyr::select(outcome,homo_variable_sample,hetero_variable_sample)%>%
    gather(key=metabolite,value=value,c(homo_variable_sample,hetero_variable_sample))%>%
    mutate(levene_test=ifelse(metabolite%in%(homo_variable_sample),"homoscedasticity","heteroscedasticity"))

stratified_levene_data%>%
    ggplot(aes(x=metabolite,y=value,fill=outcome))+
    geom_boxplot()+
    scale_fill_manual(values=color_function(length(unique(stratified_levene_data$outcome))))+
    theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1))+
    facet_wrap(.~levene_test)+
    labs(title="Boxplot, Metabolites with Heteroscedasticity vs Homoscedasticity")

```

* Unpaired Two Sample Mean t Test

```{r}
t_test_result<-
    main_statistical_test(in_data=all_data,method="student",
                        categorical_variable="outcome",
                        homo_variables=homo_variable,
                        hetero_variables=hetero_variable)

metabolites_associated_AD<-
    t_test_result%>%
    filter(type=="significant"&column_name!='age')%>%
    arrange(p_adjusted)%>%
    dplyr::select(column_name)%>%pull

metabolites_associated_AD_data<-
    all_data%>%
    dplyr::select(outcome,sex,genotype,metabolites_associated_AD)%>%
    gather(key=metabolite,value=value,metabolites_associated_AD)        

metabolites_associated_AD_data%>%
    group_by(outcome)%>%
    summarise(mean=mean(value),sd=sd(value))%>%
    knitr::kable()

top_metabolites_associated_AD<-t_test_result%>%
    filter(type=="significant"&column_name!='age')%>%
    arrange(p_adjusted)%>%head(10)%>%
    dplyr::select(column_name)%>%pull

top_metabolites_associated_AD_data<-
    all_data%>%
    dplyr::select(outcome,top_metabolites_associated_AD)%>%
    gather(key=metabolite,value=value,top_metabolites_associated_AD)        

bottom_metabolites_associated_AD<-t_test_result%>%
    filter(type=="significant"&column_name!='age')%>%
    arrange(p_adjusted)%>%tail(10)%>%
    dplyr::select(column_name)%>%pull

bottom_metabolites_associated_AD_data<-
    all_data%>%
    dplyr::select(outcome,bottom_metabolites_associated_AD)%>%
    gather(key=metabolite,value=value,bottom_metabolites_associated_AD)        

a1<-top_metabolites_associated_AD_data%>%
    ggplot(aes(x=metabolite,y=value,fill=outcome))+
    geom_boxplot()+
    scale_fill_manual(values=color_function(length(unique(top_metabolites_associated_AD_data$outcome))))+
    theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1), legend.position="top")+
    labs(title="Boxplot, Metabolites Strongly Associated with AD")

a2<-bottom_metabolites_associated_AD_data%>%
    ggplot(aes(x=metabolite,y=value,fill=outcome))+
    geom_boxplot()+
    scale_fill_manual(values=color_function(length(unique(bottom_metabolites_associated_AD_data$outcome))))+
    theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1), legend.position="top")+
    labs(title="Boxplot, Metabolites Weakly Associated with AD")

ggarrange(a1, a2, ncol=2, nrow=1)
```

As a result of the t test, metabolites with the highest significance were designated as *strong metabolites* and metabolites with the lowest significance among metabolites significantly related to AD were designated as *weak metabolites*, and the expression level of metabolites between the disease status was confirmed through visualization. As a result, a greater difference was observed in strong metabolites than in weak metabolites, but both groups were not clearly separated in terms of AD. 

#### AD vs Sex

```{r}
ad_sex_summary<-all_data%>%
    group_by(outcome,sex)%>%
    summarise(count=n(),
            mean_age=mean(age),
            sd_age=sd(age))%>%
            ungroup%>%
    mutate(sum=sum(count),
    proportion=paste0(count/sum*100,"%"))%>%
    dplyr::select(outcome, sex,count,proportion,mean_age,sd_age)%>%
    mutate(p_value=chisq.test(all_data$outcome,all_data$sex)$p.value,
    method="chisquare_test")

ad_sex_summary%>%knitr::kable()
```

#### AD vs Genotype

```{r}
ad_genotype_summary<-all_data%>%
    group_by(outcome,genotype)%>%
    summarise(count=n(),
            mean_age=mean(age),
            sd_age=sd(age))%>%
            ungroup%>%
    mutate(sum=sum(count),
    proportion=paste0(count/sum*100,"%"))%>%
    dplyr::select(outcome, genotype,count,proportion,mean_age,sd_age)%>%
    mutate(p_value=chisq.test(all_data$outcome,all_data$genotype)$p.value,
    method="chisquare_test")
ad_genotype_summary%>%knitr::kable()
```


#### Age vs AD, Sex, Genotype

Age is known as a strong risk factor of AD or dementia. Human nerve system gets damaged as people are aged and the nerve fibrosis symptoms progress gradually. For this reason, we need to look into how the sample data are distributed in terms of age.

```{r}
ad_age_summary=getNumericSummaryTable(in_data=all_data,group_variable="outcome",summary_variable="age")
sex_age_summary=getNumericSummaryTable(in_data=all_data,group_variable="sex",summary_variable="age")
genotype_age_summary=getNumericSummaryTable(in_data=all_data,group_variable="genotype",summary_variable="age")
age_summary=rbind(
    ad_age_summary,
    sex_age_summary,
    genotype_age_summary)


```

```{r}
age_summary%>%knitr::kable()
```

```{r}

plot<- ggarrange(
    getNumericSummaryPlot(in_data=all_data,group_variable="outcome",summary_variable="age"),
    getNumericSummaryPlot(in_data=all_data,group_variable="sex",summary_variable="age"),
    getNumericSummaryPlot(in_data=all_data,group_variable="genotype",summary_variable="age"),
    ncol=2, nrow=2,legend="bottom")
```

The table above shows the summary statistics of age grouped by the affected status, AD and non AD. The difference of age between the two groups are about `r round(age_summary%>%filter(group=="positive")%>%dplyr::select(mean)- age_summary%>%filter(group=="negative")%>%dplyr::select(mean),2)`, but their standard deviations are `r round(age_summary%>%filter(group=="positive")%>%dplyr::select(sd),2)` and `r round(age_summary%>%filter(group=="negative")%>%dplyr::select(sd),2)`. Thus, it is hard to say their age in average differ in the affected status because the age variations of the two groups are overlapped. This research has two conflicting characteristics at the population level. 

The glaring difference of age is also shown below. As you can see, the people with a negative status `r (ad_age_summary[1,'mean'] - ad_age_summary[2,'mean'])%>%round(3)` years younger than those with a positive one.


```{r}
a1<-all_data%>%
    dplyr::select(outcome,age)%>%
    ggplot(aes(x=age,fill=outcome))+
    geom_histogram(aes(y=..density..),alpha=0.5)+
    geom_density(linewidth=1.5,alpha=0.5)+
    scale_fill_manual(values=color_function(length(unique(all_data$outcome))))+
    theme(legend.position="top")+
    labs(title="Histogram, Age Distribution Grouped by Disease Status")   
a2<-all_data%>%
    dplyr::select(outcome,age)%>%
    ggplot(aes(x=outcome,y=age,fill=outcome))+
    geom_boxplot()+
    scale_fill_manual(values=color_function(length(unique(all_data$outcome))))+
    theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1), legend.position="top")+
    labs(title="Boxplot, Age Distribution Grouped by Disease Status")

ggarrange(a1, a2, ncol=2, nrow=1)
```

#### Age vs Metabolites

```{r}
age_correlation_data<-
    main_statistical_test(in_data=all_data,in_numeric_variable = 'age',method = "cor")%>%
    filter(p_adjusted<0.05,column_name!='id')
```

`r nrow(age_correlation_data)` metabolites are significantly associated with age.


#### Genotype vs Metabolites

```{r}
genotype_aov<-main_statistical_test(in_data=all_data,categorical_variable="genotype",method='aov')
genotype_aov%>%
filter(column_name!='id',p_adjusted<0.05)%>%knitr::kable()

```

`r genotype_aov%>%filter(column_name!='id',p_adjusted<0.05)%>%nrow()` metabolites are significantly associated with the genotype variable.

### Multivariable Analysis

#### AD vs Sex vs Genotype vs Age

```{r}
all_data%>%
    group_by(outcome,sex,genotype)%>%
    summarise(count=n(),
    mean_age=mean(age),
    sd_age=sd(age))%>%ungroup%>%
    mutate(sum_count=sum(count),
    proportion=paste0(round(count/sum_count*100,3),'%'))%>%
    dplyr::select(outcome,sex,genotype,count,proportion, mean_age,sd_age)%>%
    knitr::kable()

```

Except for the disease status variable, it looks like there is no difference of age in average and count in the other categorical variables. Taking into account age varialble is significantly associated with the metabolites that are significantly associated with the disease status, outcome (or AD). There is no need to conduct futher exploratory data analysis in the multivariable analysis senction.

## Data Mining

### PCA (Principal Component Analysis)

```{r}
#| eval: false
#| echo: false



X<-all_data[,-c(1:5)]
result_pca<-mixOmics::pca(X)

plotIndiv(result_pca)  # plot the samples
plotVar(result_pca)    # plot the variables


# PCA


x_data = all_data[,-c(1:5)]
y_data =all_data[,1]

# Normalizing the data
normalize <- function(x) {return((x - min(x)) / (max(x) - min(x)))}
data_norm <- as.data.frame(lapply(x_data, normalize))
data_norm <- replace(data_norm, is.na(data_norm), 0.0)


# Extracting Principal Components
pr_out =prcomp(data_norm)
pr_components_all = pr_out$x


# 2- Dimensional PCA
K_prcomps = 2

pr_components = pr_components_all[,1:K_prcomps]

loadings <- as.data.frame(pr_out$rotation)


ggplot(data=all_data, aes(x=meta1, y=meta2)) +
geom_point(alpha=.3) +
stat_ellipse(type='norm', level=.99) +
geom_abline(intercept = 0, slope = loadings[2,1]/loadings[1,1]) +
geom_abline(intercept = 0, slope = loadings[2,2]/loadings[1,2])

pr_components_df = data.frame(pr_components)
pr_components_df = cbind(pr_components_df,digits_data$target)
names(pr_components_df)[K_prcomps+1] = "target"

out <- split( pr_components_df , f = pr_components_df$target )
zero_df = out$`0`;one_df = out$`1`;two_df = out$`2`; three_df = out$`3`; four_df = out$`4`
five_df = out$`5`;six_df = out$`6`;seven_df = out$`7`;eight_df = out$`8`;nine_df = out$`9`



# Plotting 2-dimensional PCA
ggplot(pr_components_df, aes(x = PC1, y = PC2, color = factor(target,labels = c("zero","one","two",
        "three","four","five","six","seven","eight","nine")))) + 
        geom_point()+ggtitle("2-D PCA on Digits Data") +
        labs(color = "Digtis")



# 3- Dimensional PCA
# Plotting 3-dimensional PCA
K_prcomps = 3

pr_components = pr_components_all[,1:K_prcomps]
pr_components_df = data.frame(pr_components)
pr_components_df = cbind(pr_components_df,digits_data$target)
names(pr_components_df)[K_prcomps+1] = "target"

pr_components_df$target = as.factor(pr_components_df$target)

out <- split( pr_components_df , f = pr_components_df$target )
zero_df = out$`0`;one_df = out$`1`;two_df = out$`2`; three_df = out$`3`; four_df = out$`4`
five_df = out$`5`;six_df = out$`6`;seven_df = out$`7`;eight_df = out$`8`;nine_df = out$`9`

library(scatterplot3d)

colors <- c("darkred", "darkseagreen4", "deeppink4", "greenyellow", "orange"
            , "navyblue", "red", "tan3", "steelblue1", "slateblue")
colors <- colors[as.numeric(pr_components_df$target)]
s3d = scatterplot3d(pr_components_df[,1:3], pch = 16, color=colors,
              xlab = "PC1",ylab = "PC2",zlab = "PC3",col.grid="lightblue",main = "3-D PCA on Digits Data")
legend(s3d$xyz.convert(3.1, 0.1, -3.5), pch = 16, yjust=0,
       legend = levels(pr_components_df$target),col =colors,cex = 1.1,xjust = 0)
       
# Chosing number of Principal Components
pr_var =pr_out$sdev ^2
pr_totvar = pr_var/sum(pr_var)
plot(cumsum(pr_totvar), xlab="Principal Component", ylab ="Cumilative Prop. of Var.",
     ylim=c(0,1),type="b",main = "PCAs vs. Cum prop of Var Explained")

```

### K-means Clustering

```{r}

# K means
km_fit = kmeans(all_data[,-c(1:5)],centers = 2,iter.max = 300 )

# "K-Means Clustering- Confusion matrix")
# table(all_data[,1],km_fit$cluster)

mat_avgss = matrix(nrow = 20, ncol = 2)

# Average within the cluster sum of square
print(paste("Avg. Within sum of squares"))
for (i in (1:20)){
  km_fit = kmeans(all_data[,-c(1:6)],centers = i,iter.max = 300 )
  mean_km = mean(km_fit$withinss)
  print(paste("K-Value",i,",Avg.within sum of squares",round(mean_km,2)))
  mat_avgss[i,1] = i
  mat_avgss[i,2] = mean_km
}

plot(mat_avgss[,1],mat_avgss[,2],type = 'o',xlab = "K_Value",ylab = "Avg. within sum of square")
title("Avg. within sum of squares vs. K-value")


mat_varexp = matrix(nrow = 20, ncol = 2)
# Percentage of Variance explained
print(paste("Percent. variance explained"))
for (i in (1:20)){
  km_fit = kmeans(all_data[,-c(1:6)],centers = i,iter.max = 300 )
  var_exp = km_fit$betweenss/km_fit$totss
  print(paste("K-Value",i,",Percent var explained",round(var_exp,4)))
  mat_varexp[i,1]=i
  mat_varexp[i,2]=var_exp
}

plot(mat_varexp[,1],mat_varexp[,2],type = 'o',xlab = "K_Value",ylab = "Percent Var explained")
title("Avg. within sum of squares vs. K-value")
```



```{r}
#| eval: false
#| echo: false

#SVD 
library(svd)

digits_data = read.csv("digitsdata.csv")

remove_cols = c("target")
x_data = digits_data[,!(names(digits_data) %in% remove_cols)]
y_data = digits_data[,c("target")]



sv2 <- svd(x_data,nu=15)

sv_check = sv2$d

# Computing the square of the singular values, which can be thought of as the vector of matrix energy
# in order to pick top singular values which preserve at least 80% of variance explained
energy <- sv2$d ^ 2
tot_varexp = data.frame(cumsum(energy) / sum(energy))

names(tot_varexp) = "cum_var_explained"
tot_varexp$K_value = 1:nrow(tot_varexp)

plot(tot_varexp[,2],tot_varexp[,1],type = 'o',xlab = "K_Value",ylab = "Prop. of Var Explained")
title("SVD - Prop. of Var explained with K-value")


```

```{r}
#| echo: false
#| eval: false

for (i in 1:p) {
 form = paste("lm(", paste0(var[i], collapse="+"), "~ . , data=as.data.frame(data) ) ")
 fit = eval(parse(text=form)); fit
 lm_result[i] = list(summary(fit))
}

```

:::

::: {#English .tab-pane .fade role="tabpanel" aria-labelledby="English-tab"}
```{r}
#| echo: false

if(!require(janitor)) install.packages("janitor") 
if(!require(tidyverse)) install.packages("tidyverse") 
if(!require(tidymodels)) install.packages("tidymodels") 
if(!require(glmnet)) install.packages("glmnet") 
if(!require(MASS)) install.packages("MASS") 
if(!require(ggpubr)) install.packages("ggpubr") 
if(!require(car)) install.packages("car") 
if(!require(mixOmics)) install.packages("mixOmics") 

library(janitor)
library(tidyverse)
library(tidymodels)
library(glmnet)
library(MASS)
library(ggpubr) 
library(car) 
library(mixOmics)
set.seed(20230103) 
knitr::opts_chunk$set(message=FALSE,warning=FALSE)
```


```{r}
#| echo: false
# the number of samples
sample_size <- 1000
# the number of predictors
predictor_size <- 5000
# the number of groups
group_size <- sample(6:10,1) # at least more than 6, the number of the genotypes
# the number of predictors truly associated with a response variable
significant_predictors <- floor(predictor_size*sample((50:100)/1000,1)) 

## set the predictors associated with an outcome
### the number of predictors positively associated with an outcome
### the number of predictors negatively associated with an outcome
positively_associated_predictors<-floor(significant_predictors*0.4) 
negatively_associated_predictors<-significant_predictors-positively_associated_predictors 

## set the proportion of the groups in which the predictors are correlated with one another
### randomly sampling proportions to become their sum equal to 1
group_proportion_list<-sample(seq(1,1+2*(100-group_size)/group_size,
                            by=2*(100-group_size)/(group_size*(group_size-1)))/100,
                        group_size,replace=FALSE)%>%round(3) 
names(group_proportion_list)<-paste0("group",1:length(group_proportion_list))
### initialize a matrix with a size as sample_size by predictor_size
predictor_matrix <- matrix(0, ncol = predictor_size, nrow = sample_size)
### initialize a data frame and assign meta information used to generate simulated data
group_meta_data<-
    data.frame(
        group_name=c(names(group_proportion_list)),
        proportion=group_proportion_list)%>%
        mutate(
            group_n=(predictor_size*group_proportion_list)%>%round(0), # the number of predictors within each group 
            first_index=c(1,cumsum(group_n[-length(group_proportion_list)])+1), # the 1st index of predictors in each group
            last_index=cumsum(group_n), # the last index of predictors in each group
            group_correlation=sample((0:700)/1000,length(group_proportion_list),replace=TRUE), # within-group correlations among the within-group predictors
            group_effect=sample((-40:30)/100,length(group_proportion_list),replace=TRUE)) # effect of each group on an outcome variable
### set a group effect as 0.7 into a group with the smallest group number 
group_meta_data[which.min(group_meta_data[,"group_n"]),"group_effect"]<-0.7

### set a group effect as -0.5 into a group with the second smallest group number 
group_meta_data[group_meta_data[,"group_n"]==(sort(group_meta_data[,"group_n"])[2]),"group_effect"]<-(-0.5)

# initialize a data matrix to assign simulated values
## add some noise to data
data<-matrix(rnorm(sample_size*predictor_size,mean=0,sd=0.05), 
             nrow = sample_size, ncol = predictor_size)

# initialize a covariance matrix to assign simulated values
covariance_matrix<-matrix(rnorm(predictor_size*predictor_size,mean=0,sd=0.05),
                          nrow=predictor_size, ncol=predictor_size)
beta_coefficients <- rnorm(predictor_size,0,0.05)

answer_list<-list(
    'sample size'=sample_size,
    'predictor size'=predictor_size,
    'group size'=group_size,
    'significant predictors'=significant_predictors,
    'positively associated predictors'=positively_associated_predictors,
    'negatively associated predictors'=negatively_associated_predictors,
    'group proportion list'=group_proportion_list,
    'group meta data'=group_meta_data,
    'data noise intensity'=c('distribution'='rnorm','mean'=0,'sd'=0.05),
    'covariance noise intensity'=c('distribution'='rnorm','mean'=0,'sd'=0.05),
    'effect noise intensity on response'=c('distribution'='rnorm','mean'=0,'sd'=0.05),
    'link function between the response and predictors' = 'canonical logit link function',
    'link function noise intensity' = c('distribution'='rnorm','mean'=0,'sd'=0.05),
    'age_distirbution'='used data of a variable with the highest effect on outcome',
    'sex_distribution'='rbinom(n=sample size,p=0.5)',
    'genotype_distirbution'=c('e2' = '8.4%','e3' = '77.9%','e4' = '13.7%'))
```



```{r}
color_function<-function(category_number){
return(
    if(category_number==2){
        c("darkblue","darkred")
    }else if(category_number==3){
        c("darkblue","darkred","yellow4")
    }else if(category_number==4){
        c("darkblue","darkred","yellow4","blueviolet")
    }else if(category_number==5){
        c("darkblue","darkred","yellow4","blueviolet","darkorange")
    }else{
        c("darkblue","darkred","yellow4","blueviolet","darkorange","darkgreen")
    }
    )
}

scale_function=function(vector=x,min=NULL,max=NULL,method){
    scaling_methods<-c('min_max normalization','customized normalization','standardization')

    if(method=="min-max"){
        output=(vector-min(vector))(max(vector)-min(vector))
    }else if(method=="customized"){
        output=(max-min)*(vector-min(vector))/(max(vector)-min(vector))+min
    }else if(method=="standarized"){
        output=(vector-mean(vector))/sd(vector)
    }else{
        paste0("Error!, no such a scaling method in this module. Please, put the first word of each method you want to use in the 'method' argument among the following tests: ", paste(scaling_methods,collapse=", "))
    }
  return(output)
}

multiple_shapiro_test<-function(in_data){
        normality_test<-apply(in_data[,unlist(lapply(in_data, is.numeric))],2,
                            function(x)shapiro.test(x))
        temp<-data.frame(matrix(nrow=length(normality_test),ncol=4))
        for (i in 1:length(normality_test)){
            temp[i,]<-c(
                coloumn_name=names(normality_test)[i],
                statistic=normality_test[[i]]$statistic,
                p_value=normality_test[[i]]$p.value,
                method=normality_test[[i]]$method)
        }
        names(temp)<-c('column_name','statistic','p_value','method')
        output<-temp%>%
            mutate(p_adjusted=p.adjust(p_value,method="bonferroni"),
            type=ifelse(p_adjusted<0.05,'not_normal','normal'))%>%
            dplyr::select('column_name','statistic','p_value','p_adjusted','type','method')
        return(output)
}    

multiple_levene_test<-function(in_data,categorical_variable){
        homoscedasticity_test<-apply(in_data[,unlist(lapply(in_data, is.numeric))],2,
                                    function(x)leveneTest(x~in_data[,categorical_variable]))
        temp<-data.frame(matrix(nrow=length(homoscedasticity_test),ncol=6))
            for (i in 1:length(homoscedasticity_test)){
                temp[i,]<-c(
                    coloumn_name=names(homoscedasticity_test)[i],
                    group_df=homoscedasticity_test[[i]]$Df[1],
                    residual_df=homoscedasticity_test[[i]]$Df[2],
                    statistic=homoscedasticity_test[[i]]$`F value`[1],
                    p_value=homoscedasticity_test[[i]]$`Pr(>F)`[1],
                    method="levene's test")
            }
            names(temp)<-c('column_name','group_df','residual_df','statistic','p_value','method')
            output<-temp%>%
                mutate(p_adjusted=p.adjust(p_value,method="bonferroni"),
                type=ifelse(p_adjusted<0.05,'heteroscedasticity','homoscedasticity'))%>%
                dplyr::select('column_name','group_df','residual_df','statistic','p_value','p_adjusted','type','method')
        return(output)} 

categorical_variable='outcome'

multiple_unpaired_t_test<-function(in_data,categorical_variable,homo_variables,hetero_variables){
    homo_unpaired_t_test<-apply(in_data[,unlist(lapply(in_data, is.numeric))][,homo_variables],2,
                                    function(x)t.test(x~in_data[,categorical_variable],var.equal=TRUE))
    hetero_unpaired_t_test<-apply(in_data[,unlist(lapply(in_data, is.numeric))][,hetero_variables],2,
                                    function(x)t.test(x~in_data[,categorical_variable],var.equal=FALSE)) 
    unpaired_t_test<-c(homo_unpaired_t_test,hetero_unpaired_t_test)

    temp<-data.frame(matrix(nrow=length(unpaired_t_test),ncol=7))
        for (i in 1:length(unpaired_t_test)){
            temp[i,]<-c(names(unpaired_t_test)[i], 
                        unpaired_t_test[[i]]$estimate,
                        unpaired_t_test[[i]]$parameter,
                        unpaired_t_test[[i]]$statistic,
                        unpaired_t_test[[i]]$p.value,
                        unpaired_t_test[[i]]$method)
        }
        names(temp)<-c('column_name',names(unpaired_t_test[[1]]$estimate),'df','statistic','p_value','method')
        output<-temp%>%
            mutate(p_adjusted=p.adjust(p_value,method="bonferroni"),
            type=ifelse(p_adjusted<0.05,'significant','insignificant'))%>%
            dplyr::select('column_name',names(unpaired_t_test[[1]]$estimate),'df','statistic','p_value','p_adjusted','type','method')
    return(output)} 


multiple_correlation_test<-function(in_data,in_numeric_variable){
    correlation_test<-apply(in_data[,unlist(lapply(in_data, is.numeric))],2,
                                    function(x)cor.test(x,in_data[,in_numeric_variable],method='pearson'))
    temp<-data.frame(matrix(nrow=length(correlation_test),ncol=6))
        for (i in 1:length(correlation_test)){
            temp[i,]<-c(names(correlation_test)[i], 
                        correlation_test[[i]]$estimate,
                        correlation_test[[i]]$parameter,
                        correlation_test[[i]]$statistic,
                        correlation_test[[i]]$p.value,
                        correlation_test[[i]]$method)
        }
        names(temp)<-c('column_name',names(correlation_test[[1]]$estimate),'df','statistic','p_value','method')
        output<-temp%>%
            mutate(p_adjusted=p.adjust(p_value,method="bonferroni"),
            type=ifelse(p_adjusted<0.05,'significant','insignificant'))%>%
            dplyr::select('column_name',names(correlation_test[[1]]$estimate),'df','statistic','p_value','p_adjusted','type','method')
    return(output)} 

multiple_anova_test<-function(in_data, in_categorical_variable){
    aov_test<-apply(in_data[,unlist(lapply(in_data, is.numeric))],2,
                function(x)aov(x~get(in_categorical_variable),data=in_data)%>%summary)

    temp<-data.frame(matrix(nrow=length(aov_test),ncol=10))
    for (i in 1:length(aov_test)){
        temp[i,]<-c(names(aov_test)[i], 
                    aov_test[[i]][[1]]$`Df`[1],
                    aov_test[[i]][[1]]$`Df`[2],
                    aov_test[[i]][[1]]$`Sum Sq`[1],
                    aov_test[[i]][[1]]$`Sum Sq`[2],
                    aov_test[[i]][[1]]$`Mean Sq`[1],
                    aov_test[[i]][[1]]$`Mean Sq`[2],
                    aov_test[[i]][[1]]$`F value`[1],
                    aov_test[[i]][[1]]$`Pr(>F)`[1],
                    'one_way_anova')
    }
    names(temp)<-c('column_name','group_df','residual_df','group_ssq','residual_ssq',
                    'group_msq','residual_msq','F_value','p_value','method')
    output<-temp%>%
            mutate(p_adjusted=p.adjust(p_value,method="bonferroni"),
            type=ifelse(p_adjusted<0.05,'significant','insignificant'))%>%
            dplyr::select('column_name','group_df','residual_df','group_ssq','residual_ssq',
                    'group_msq','residual_msq','F_value','p_value','method',
                    'p_adjusted','type','method')
    return(output)} 

main_statistical_test<-function(
    in_data,method,categorical_variable,in_numeric_variable,
    homo_variables=NULL,hetero_variables=NULL,
    fun1=multiple_shapiro_test,
    fun2=multiple_levene_test,
    fun3=multiple_unpaired_t_test){
    test_list<-c("shapiro wilks test","levene's test","student t test","pearson correlation test","anova")#,"ANCOVA","MANOVA","wilcoxon manwhitney",'kruskal wallis test')
    error_massage<-paste0("Error!, no such a test in this module. Please, put the first word of each method you want to use in the 'method' argument among the following tests: ", paste(test_list,collapse=", "))
    if(grepl('shapiro',method)){
        output=multiple_shapiro_test(in_data)
    }else if(grepl('levene',method)){
        output=multiple_levene_test(in_data,categorical_variable)
        # var.test()
    }else if(grepl('student',method)){
        # code unpaired vs paired t test in the future
        output=multiple_unpaired_t_test(in_data,categorical_variable,homo_variables,hetero_variables)
    }else if(grepl('kruskal',method)){
        return(error_massage)
    }else if(grepl('wilcoxon|manwhitney',method)){
        return(error_massage)
    }else if(grepl('anova|aov',method)){
        output=multiple_anova_test(in_data,categorical_variable)
    }else if(grepl('cor',method)){
        output=multiple_correlation_test(in_data,in_numeric_variable)
    }else{
        return(error_massage)
    }
    return(output)
}


getNumericSummaryTable=function(in_data,group_variable,summary_variable,set_color=color_function,...){
    # table
    temp<-in_data %>% 
    #group_by_at(vars(...)) %>% 
    group_by_at(vars(group_variable)) %>% 
    mutate(count=n())%>%
    summarise_at(vars(summary_variable,count),
                 list(mean=mean,
                 sd=sd,
                 min=min,
                 Q1=~quantile(., probs = 0.25),
                 median=median, 
                 Q3=~quantile(., probs = 0.75),
                 max=max))%>%
                 as.data.frame()%>%
                 rename(
                 n=count_mean)%>%
                 dplyr::select(-contains('count'))%>%
                 as.data.frame()
    names(temp)<-c("group",
    sapply(names(temp)[-1],function(x)str_replace(x,paste0(summary_variable,"_"),"")))
    output<-temp%>%
    mutate(
        variable=group_variable,
        summary=summary_variable,
        mean=mean%>%round(2),
        sd=sd%>%round(2),
        min=min%>%round(2),
        Q1=Q1%>%round(2),
        Q4=Q3%>%round(2),
        max=max%>%round(2),
        IQR_min=Q1-(Q3-Q1)*1.5%>%round(2),
    IQR_max=Q3+(Q3-Q1)*1.5%>%round(2),
    proportion=paste0(round(n/nrow(all_data)*100,2),"%"))%>%
    dplyr::select(variable,group,summary,n,proportion,mean,sd,min,IQR_min,Q1,median,Q3,IQR_max,max)
    return(output)
}

getNumericSummaryPlot=function(
    in_data=all_data,group_variable,summary_variable,
    set_color=color_function,
    summary_function=getNumericSummaryTable,...){
    # plot
    temp=getNumericSummaryTable(in_data,group_variable,summary_variable)
    temp2=temp
    names(temp2)[2]=group_variable
    plot<-
    in_data%>%
    dplyr::select(group_variable,summary_variable)%>%
    inner_join(.,temp2,by=group_variable)%>%
    ggplot(aes(x=age,fill=get(group_variable),color=get(group_variable)))+
    geom_histogram(aes(y=..density..),binwidth=1,alpha=0.5, position="identity")+
    geom_vline(aes(xintercept=mean,color=get(group_variable)), linetype="dashed", size=1.5) + 
    geom_density(aes(y=..density..),alpha=0.3) +
    scale_color_manual(values=set_color(nrow(temp2)))+
    scale_fill_manual(values=set_color(nrow(temp2)))+
    theme_bw()+
    theme(legend.position = c(.95, .95),
    legend.justification = c("right", "top"),
    legend.margin = margin(6, 6, 6, 6),
    legend.text = element_text(size = 10))+
    guides(fill=guide_legend(title=group_variable),
    color=FALSE)+
    geom_text(aes(label=round(mean,1),y=0,x=mean),
                vjust=-1,col='yellow',size=5)+
    ggtitle(paste0("Histogram & Density, ", summary_variable, " Grouped by ", group_variable))+
        labs(x=summary_variable, y = "Density")

    result<-plot
    return(result)
}
```


```{r}
# load simulation data
simulated_data<-read_rds(datapath)

# simple data pre-processing
all_data<-
    simulated_data%>%
    mutate(
      outcome=factor(outcome,levels=c("negative","positive")),
      sex=ifelse(sex==0,"man","woman"),
      sex=factor(sex,levels=c("man","woman")),
      genotype=factor(genotype,levels=c("e3","e2","e4"))
      )

# rename metabolite variables
names(all_data)[6:ncol(all_data)]<-paste0("meta",1:predictor_size)
 

```
# Summary 

## Summary of Exploratory Data Analysis (EDA) 
## Summary of Data Mining

# Supplements

## EDA

### Univariable Analysis

### Normality Test

```{r}
# raw data
normality_test_result<-multiple_shapiro_test(all_data)%>%
    filter(column_name!='id')%>%
    group_by(type)%>%
    summarise(count=n())%>%
    mutate(proportion=round(count/sum(count),3),
    total=sum(count))%>%
    dplyr::select(type,total,everything())
    
normality_test_result%>%
    knitr::kable(caption="Summary of the Result of Shapiro Wilk Tests on Numeric Variables")

```

Out of `r normality_test_result[1,'total']` numeric variables, the variables following a normal distribution are `r normality_test_result[1,'count']` (`r normality_test_result[1,'proportion']*100`%) and the ones that do not are `r normality_test_result[2,'count']` (`r normality_test_result[2,'proportion']*100`%).

### Visualization

#### 16 Variables That Follow Normal Distributions


```{r}
#| fig-width: 9
#| fig-height: 10

# 16 numeric variables randomly selected
normal_variables<-
    multiple_shapiro_test(all_data)%>%
        filter(p_value>0.05,column_name!='id')%>%
            dplyr::select(column_name)%>%
            pull%>%sample(16)

normal_data<-
    all_data%>%
        dplyr::select(outcome,normal_variables)%>%
        gather(key=metabolite,value=value,normal_variables)

normal_data%>%
    ggplot(aes(x=value))+
    geom_histogram(aes(y=..density..))+
    geom_density(color='red',linewidth=1.5)+
    facet_wrap(.~metabolite)+
    labs(title="Histogram, Numeric Variables Following Normal Distribution")

normal_data%>%
    ggplot(aes(x=metabolite,y=value))+
    geom_boxplot()+
    theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1))+
    labs(title="Boxplot, Numeric Variables Following Normal Distribution")

normal_data%>%
    ggplot(aes(x=value,fill=outcome))+
    geom_histogram(aes(y=..density..),alpha=0.5)+
    geom_density(linewidth=1.5,alpha=0.5)+
    scale_fill_manual(values=color_function(length(unique(normal_data$outcome))))+
    facet_wrap(.~metabolite)+
    labs(title="Numeric Variables Following Normal Distribution Grouped by Disease Status")    
normal_data%>%
    ggplot(aes(x=metabolite,y=value,fill=outcome))+
    geom_boxplot()+
    scale_fill_manual(values=color_function(length(unique(normal_data$outcome))))+
    theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1))+
    labs(title="Boxplot, Numeric Variables Following Normal Distribution")

```

#### Variables That Do Not Follow Normal Distributions

There is no variable that do not follow a normal distribution.

### Bivariable Analysis

#### AD vs Metabolites

Through the exploratory data analysis above, it was confirmed that all variables follow a normal distribution, and a t test is conducted to select metabolites that have a significant relationship with the disease, AD.

* Homoscedasticity Test

Leven's test is performed to confirm equal variance, one of the assumptions of the t test.

```{r}

leven_test_result<-
    main_statistical_test(in_data=all_data,method="levene",categorical_variable="outcome")%>%
    filter(column_name!='id')

homo_variable<-leven_test_result%>%
filter(p_adjusted>0.05)%>%
dplyr::select(column_name)%>%
pull()%>%
unique()

hetero_variable<-leven_test_result%>%
filter(p_adjusted<0.05)%>%
dplyr::select(column_name)%>%
pull()%>%
unique()

```

*  10 variables randomly selected out of `r length(homo_variable)` variables with equal variance: `r homo_variable%>%sample(10)`
* `r length(hetero_variable)` variables randomly selected with equal variance: `r hetero_variable`

```{r}

homo_variable_sample<-homo_variable%>%sample(10)
hetero_variable_sample<-hetero_variable

stratified_levene_data<-all_data%>%
    dplyr::select(outcome,homo_variable_sample,hetero_variable_sample)%>%
    gather(key=metabolite,value=value,c(homo_variable_sample,hetero_variable_sample))%>%
    mutate(levene_test=ifelse(metabolite%in%(homo_variable_sample),"homoscedasticity","heteroscedasticity"))

stratified_levene_data%>%
    ggplot(aes(x=metabolite,y=value,fill=outcome))+
    geom_boxplot()+
    scale_fill_manual(values=color_function(length(unique(stratified_levene_data$outcome))))+
    theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1))+
    facet_wrap(.~levene_test)+
    labs(title="Boxplot, Metabolites with Heteroscedasticity vs Homoscedasticity")

```

* Unpaired Two Sample Mean t Test

```{r}
t_test_result<-
    main_statistical_test(in_data=all_data,method="student",
                        categorical_variable="outcome",
                        homo_variables=homo_variable,
                        hetero_variables=hetero_variable)

metabolites_associated_AD<-
    t_test_result%>%
    filter(type=="significant"&column_name!='age')%>%
    arrange(p_adjusted)%>%
    dplyr::select(column_name)%>%pull

metabolites_associated_AD_data<-
    all_data%>%
    dplyr::select(outcome,sex,genotype,metabolites_associated_AD)%>%
    gather(key=metabolite,value=value,metabolites_associated_AD)        

metabolites_associated_AD_data%>%
    group_by(outcome)%>%
    summarise(mean=mean(value),sd=sd(value))%>%
    knitr::kable()

top_metabolites_associated_AD<-t_test_result%>%
    filter(type=="significant"&column_name!='age')%>%
    arrange(p_adjusted)%>%head(10)%>%
    dplyr::select(column_name)%>%pull

top_metabolites_associated_AD_data<-
    all_data%>%
    dplyr::select(outcome,top_metabolites_associated_AD)%>%
    gather(key=metabolite,value=value,top_metabolites_associated_AD)        

bottom_metabolites_associated_AD<-t_test_result%>%
    filter(type=="significant"&column_name!='age')%>%
    arrange(p_adjusted)%>%tail(10)%>%
    dplyr::select(column_name)%>%pull

bottom_metabolites_associated_AD_data<-
    all_data%>%
    dplyr::select(outcome,bottom_metabolites_associated_AD)%>%
    gather(key=metabolite,value=value,bottom_metabolites_associated_AD)        

a1<-top_metabolites_associated_AD_data%>%
    ggplot(aes(x=metabolite,y=value,fill=outcome))+
    geom_boxplot()+
    scale_fill_manual(values=color_function(length(unique(top_metabolites_associated_AD_data$outcome))))+
    theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1), legend.position="top")+
    labs(title="Boxplot, Metabolites Strongly Associated with AD")

a2<-bottom_metabolites_associated_AD_data%>%
    ggplot(aes(x=metabolite,y=value,fill=outcome))+
    geom_boxplot()+
    scale_fill_manual(values=color_function(length(unique(bottom_metabolites_associated_AD_data$outcome))))+
    theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1), legend.position="top")+
    labs(title="Boxplot, Metabolites Weakly Associated with AD")

ggarrange(a1, a2, ncol=2, nrow=1)
```

As a result of the t test, metabolites with the highest significance were designated as *strong metabolites* and metabolites with the lowest significance among metabolites significantly related to AD were designated as *weak metabolites*, and the expression level of metabolites between the disease status was confirmed through visualization. As a result, a greater difference was observed in strong metabolites than in weak metabolites, but both groups were not clearly separated in terms of AD. 

#### AD vs Sex

```{r}
ad_sex_summary<-all_data%>%
    group_by(outcome,sex)%>%
    summarise(count=n(),
            mean_age=mean(age),
            sd_age=sd(age))%>%
            ungroup%>%
    mutate(sum=sum(count),
    proportion=paste0(count/sum*100,"%"))%>%
    dplyr::select(outcome, sex,count,proportion,mean_age,sd_age)%>%
    mutate(p_value=chisq.test(all_data$outcome,all_data$sex)$p.value,
    method="chisquare_test")

ad_sex_summary%>%knitr::kable()
```

#### AD vs Genotype

```{r}
ad_genotype_summary<-all_data%>%
    group_by(outcome,genotype)%>%
    summarise(count=n(),
            mean_age=mean(age),
            sd_age=sd(age))%>%
            ungroup%>%
    mutate(sum=sum(count),
    proportion=paste0(count/sum*100,"%"))%>%
    dplyr::select(outcome, genotype,count,proportion,mean_age,sd_age)%>%
    mutate(p_value=chisq.test(all_data$outcome,all_data$genotype)$p.value,
    method="chisquare_test")
ad_genotype_summary%>%knitr::kable()
```


#### Age vs AD, Sex, Genotype

Age is known as a strong risk factor of AD or dementia. Human nerve system gets damaged as people are aged and the nerve fibrosis symptoms progress gradually. For this reason, we need to look into how the sample data are distributed in terms of age.

```{r}
ad_age_summary=getNumericSummaryTable(in_data=all_data,group_variable="outcome",summary_variable="age")
sex_age_summary=getNumericSummaryTable(in_data=all_data,group_variable="sex",summary_variable="age")
genotype_age_summary=getNumericSummaryTable(in_data=all_data,group_variable="genotype",summary_variable="age")
age_summary=rbind(
    ad_age_summary,
    sex_age_summary,
    genotype_age_summary)


```

```{r}
age_summary%>%knitr::kable()
```

```{r}

plot<- ggarrange(
    getNumericSummaryPlot(in_data=all_data,group_variable="outcome",summary_variable="age"),
    getNumericSummaryPlot(in_data=all_data,group_variable="sex",summary_variable="age"),
    getNumericSummaryPlot(in_data=all_data,group_variable="genotype",summary_variable="age"),
    ncol=2, nrow=2,legend="bottom")
```

The table above shows the summary statistics of age grouped by the affected status, AD and non AD. The difference of age between the two groups are about `r round(age_summary%>%filter(group=="positive")%>%dplyr::select(mean)- age_summary%>%filter(group=="negative")%>%dplyr::select(mean),2)`, but their standard deviations are `r round(age_summary%>%filter(group=="positive")%>%dplyr::select(sd),2)` and `r round(age_summary%>%filter(group=="negative")%>%dplyr::select(sd),2)`. Thus, it is hard to say their age in average differ in the affected status because the age variations of the two groups are overlapped. This research has two conflicting characteristics at the population level. 

The glaring difference of age is also shown below. As you can see, the people with a negative status `r (ad_age_summary[1,'mean'] - ad_age_summary[2,'mean'])%>%round(3)` years younger than those with a positive one.


```{r}
a1<-all_data%>%
    dplyr::select(outcome,age)%>%
    ggplot(aes(x=age,fill=outcome))+
    geom_histogram(aes(y=..density..),alpha=0.5)+
    geom_density(linewidth=1.5,alpha=0.5)+
    scale_fill_manual(values=color_function(length(unique(all_data$outcome))))+
    theme(legend.position="top")+
    labs(title="Histogram, Age Distribution Grouped by Disease Status")   
a2<-all_data%>%
    dplyr::select(outcome,age)%>%
    ggplot(aes(x=outcome,y=age,fill=outcome))+
    geom_boxplot()+
    scale_fill_manual(values=color_function(length(unique(all_data$outcome))))+
    theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1), legend.position="top")+
    labs(title="Boxplot, Age Distribution Grouped by Disease Status")

ggarrange(a1, a2, ncol=2, nrow=1)
```

#### Age vs Metabolites

```{r}
age_correlation_data<-
    main_statistical_test(in_data=all_data,in_numeric_variable = 'age',method = "cor")%>%
    filter(p_adjusted<0.05,column_name!='id')
```

`r nrow(age_correlation_data)` metabolites are significantly associated with age.


#### Genotype vs Metabolites

```{r}
genotype_aov<-main_statistical_test(in_data=all_data,categorical_variable="genotype",method='aov')
genotype_aov%>%
filter(column_name!='id',p_adjusted<0.05)%>%knitr::kable()

```

`r genotype_aov%>%filter(column_name!='id',p_adjusted<0.05)%>%nrow()` metabolites are significantly associated with the genotype variable.

### Multivariable Analysis

#### AD vs Sex vs Genotype vs Age

```{r}
all_data%>%
    group_by(outcome,sex,genotype)%>%
    summarise(count=n(),
    mean_age=mean(age),
    sd_age=sd(age))%>%ungroup%>%
    mutate(sum_count=sum(count),
    proportion=paste0(round(count/sum_count*100,3),'%'))%>%
    dplyr::select(outcome,sex,genotype,count,proportion, mean_age,sd_age)%>%
    knitr::kable()

```

Except for the disease status variable, it looks like there is no difference of age in average and count in the other categorical variables. Taking into account age varialble is significantly associated with the metabolites that are significantly associated with the disease status, outcome (or AD). There is no need to conduct futher exploratory data analysis in the multivariable analysis senction.

## Data Mining

### PCA (Principal Component Analysis)

```{r}
#| eval: false
#| echo: false



X<-all_data[,-c(1:5)]
result_pca<-mixOmics::pca(X)

plotIndiv(result_pca)  # plot the samples
plotVar(result_pca)    # plot the variables


# PCA


x_data = all_data[,-c(1:5)]
y_data =all_data[,1]

# Normalizing the data
normalize <- function(x) {return((x - min(x)) / (max(x) - min(x)))}
data_norm <- as.data.frame(lapply(x_data, normalize))
data_norm <- replace(data_norm, is.na(data_norm), 0.0)


# Extracting Principal Components
pr_out =prcomp(data_norm)
pr_components_all = pr_out$x


# 2- Dimensional PCA
K_prcomps = 2

pr_components = pr_components_all[,1:K_prcomps]

loadings <- as.data.frame(pr_out$rotation)


ggplot(data=all_data, aes(x=meta1, y=meta2)) +
geom_point(alpha=.3) +
stat_ellipse(type='norm', level=.99) +
geom_abline(intercept = 0, slope = loadings[2,1]/loadings[1,1]) +
geom_abline(intercept = 0, slope = loadings[2,2]/loadings[1,2])

pr_components_df = data.frame(pr_components)
pr_components_df = cbind(pr_components_df,digits_data$target)
names(pr_components_df)[K_prcomps+1] = "target"

out <- split( pr_components_df , f = pr_components_df$target )
zero_df = out$`0`;one_df = out$`1`;two_df = out$`2`; three_df = out$`3`; four_df = out$`4`
five_df = out$`5`;six_df = out$`6`;seven_df = out$`7`;eight_df = out$`8`;nine_df = out$`9`



# Plotting 2-dimensional PCA
ggplot(pr_components_df, aes(x = PC1, y = PC2, color = factor(target,labels = c("zero","one","two",
        "three","four","five","six","seven","eight","nine")))) + 
        geom_point()+ggtitle("2-D PCA on Digits Data") +
        labs(color = "Digtis")



# 3- Dimensional PCA
# Plotting 3-dimensional PCA
K_prcomps = 3

pr_components = pr_components_all[,1:K_prcomps]
pr_components_df = data.frame(pr_components)
pr_components_df = cbind(pr_components_df,digits_data$target)
names(pr_components_df)[K_prcomps+1] = "target"

pr_components_df$target = as.factor(pr_components_df$target)

out <- split( pr_components_df , f = pr_components_df$target )
zero_df = out$`0`;one_df = out$`1`;two_df = out$`2`; three_df = out$`3`; four_df = out$`4`
five_df = out$`5`;six_df = out$`6`;seven_df = out$`7`;eight_df = out$`8`;nine_df = out$`9`

library(scatterplot3d)

colors <- c("darkred", "darkseagreen4", "deeppink4", "greenyellow", "orange"
            , "navyblue", "red", "tan3", "steelblue1", "slateblue")
colors <- colors[as.numeric(pr_components_df$target)]
s3d = scatterplot3d(pr_components_df[,1:3], pch = 16, color=colors,
              xlab = "PC1",ylab = "PC2",zlab = "PC3",col.grid="lightblue",main = "3-D PCA on Digits Data")
legend(s3d$xyz.convert(3.1, 0.1, -3.5), pch = 16, yjust=0,
       legend = levels(pr_components_df$target),col =colors,cex = 1.1,xjust = 0)
       
# Chosing number of Principal Components
pr_var =pr_out$sdev ^2
pr_totvar = pr_var/sum(pr_var)
plot(cumsum(pr_totvar), xlab="Principal Component", ylab ="Cumilative Prop. of Var.",
     ylim=c(0,1),type="b",main = "PCAs vs. Cum prop of Var Explained")

```

### K-means Clustering

```{r}

# K means
km_fit = kmeans(all_data[,-c(1:5)],centers = 2,iter.max = 300 )

# "K-Means Clustering- Confusion matrix")
# table(all_data[,1],km_fit$cluster)

mat_avgss = matrix(nrow = 20, ncol = 2)

# Average within the cluster sum of square
print(paste("Avg. Within sum of squares"))
for (i in (1:20)){
  km_fit = kmeans(all_data[,-c(1:6)],centers = i,iter.max = 300 )
  mean_km = mean(km_fit$withinss)
  print(paste("K-Value",i,",Avg.within sum of squares",round(mean_km,2)))
  mat_avgss[i,1] = i
  mat_avgss[i,2] = mean_km
}

plot(mat_avgss[,1],mat_avgss[,2],type = 'o',xlab = "K_Value",ylab = "Avg. within sum of square")
title("Avg. within sum of squares vs. K-value")


mat_varexp = matrix(nrow = 20, ncol = 2)
# Percentage of Variance explained
print(paste("Percent. variance explained"))
for (i in (1:20)){
  km_fit = kmeans(all_data[,-c(1:6)],centers = i,iter.max = 300 )
  var_exp = km_fit$betweenss/km_fit$totss
  print(paste("K-Value",i,",Percent var explained",round(var_exp,4)))
  mat_varexp[i,1]=i
  mat_varexp[i,2]=var_exp
}

plot(mat_varexp[,1],mat_varexp[,2],type = 'o',xlab = "K_Value",ylab = "Percent Var explained")
title("Avg. within sum of squares vs. K-value")
```



```{r}
#| eval: false
#| echo: false

#SVD 
library(svd)

digits_data = read.csv("digitsdata.csv")

remove_cols = c("target")
x_data = digits_data[,!(names(digits_data) %in% remove_cols)]
y_data = digits_data[,c("target")]



sv2 <- svd(x_data,nu=15)

sv_check = sv2$d

# Computing the square of the singular values, which can be thought of as the vector of matrix energy
# in order to pick top singular values which preserve at least 80% of variance explained
energy <- sv2$d ^ 2
tot_varexp = data.frame(cumsum(energy) / sum(energy))

names(tot_varexp) = "cum_var_explained"
tot_varexp$K_value = 1:nrow(tot_varexp)

plot(tot_varexp[,2],tot_varexp[,1],type = 'o',xlab = "K_Value",ylab = "Prop. of Var Explained")
title("SVD - Prop. of Var explained with K-value")


```

```{r}
#| echo: false
#| eval: false

for (i in 1:p) {
 form = paste("lm(", paste0(var[i], collapse="+"), "~ . , data=as.data.frame(data) ) ")
 fit = eval(parse(text=form)); fit
 lm_result[i] = list(summary(fit))
}

```
:::
