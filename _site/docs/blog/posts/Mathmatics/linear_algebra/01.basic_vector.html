<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kwangmin Kim">
<meta name="dcterms.date" content="2023-03-30">
<meta name="description" content="Basic Linear Algebra">

<title>Kwangmin Kim - Basics (1) - Vector Operations</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../../">
<script src="../../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../../.././images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../../../index.html">
    <span class="navbar-title">Kwangmin Kim</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../docs/CV/index.html">
 <span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../docs/projects/index.html">
 <span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../docs/blog/index.html">
 <span class="menu-text">Blog</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../../about.html">
 <span class="menu-text">Me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/kmink3225"><i class="bi bi-github" role="img" aria-label="Github">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/kwangmin-kim-a5241b200/"><i class="bi bi-linkedin" role="img" aria-label="Linkedin">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../docs/blog/index.html"><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text">Blog</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction-linear-algebra-to-deep-learning" id="toc-introduction-linear-algebra-to-deep-learning" class="nav-link active" data-scroll-target="#introduction-linear-algebra-to-deep-learning"><span class="toc-section-number">1</span>  Introduction Linear Algebra to Deep Learning</a>
  <ul class="collapse">
  <li><a href="#scalar" id="toc-scalar" class="nav-link" data-scroll-target="#scalar"><span class="toc-section-number">1.1</span>  Scalar</a></li>
  <li><a href="#vector" id="toc-vector" class="nav-link" data-scroll-target="#vector"><span class="toc-section-number">1.2</span>  Vector</a>
  <ul class="collapse">
  <li><a href="#plotting-vectors-on-the-coordinate-plane" id="toc-plotting-vectors-on-the-coordinate-plane" class="nav-link" data-scroll-target="#plotting-vectors-on-the-coordinate-plane"><span class="toc-section-number">1.2.1</span>  Plotting Vectors on the Coordinate Plane</a></li>
  </ul></li>
  <li><a href="#basic-vector-operations" id="toc-basic-vector-operations" class="nav-link" data-scroll-target="#basic-vector-operations"><span class="toc-section-number">1.3</span>  Basic Vector Operations</a>
  <ul class="collapse">
  <li><a href="#addition-of-vectors" id="toc-addition-of-vectors" class="nav-link" data-scroll-target="#addition-of-vectors"><span class="toc-section-number">1.3.1</span>  Addition of Vectors</a></li>
  <li><a href="#subtraction-of-vectors" id="toc-subtraction-of-vectors" class="nav-link" data-scroll-target="#subtraction-of-vectors"><span class="toc-section-number">1.3.2</span>  Subtraction of Vectors</a></li>
  <li><a href="#scalar-multiplication-of-vectors" id="toc-scalar-multiplication-of-vectors" class="nav-link" data-scroll-target="#scalar-multiplication-of-vectors"><span class="toc-section-number">1.3.3</span>  Scalar Multiplication of Vectors</a></li>
  <li><a href="#inner-product-of-vectors" id="toc-inner-product-of-vectors" class="nav-link" data-scroll-target="#inner-product-of-vectors"><span class="toc-section-number">1.3.4</span>  Inner Product of Vectors</a></li>
  <li><a href="#unit-vector" id="toc-unit-vector" class="nav-link" data-scroll-target="#unit-vector"><span class="toc-section-number">1.3.5</span>  Unit Vector</a></li>
  <li><a href="#cross-product-of-vectors" id="toc-cross-product-of-vectors" class="nav-link" data-scroll-target="#cross-product-of-vectors"><span class="toc-section-number">1.3.6</span>  Cross Product of Vectors</a></li>
  <li><a href="#column-vector-row-vector" id="toc-column-vector-row-vector" class="nav-link" data-scroll-target="#column-vector-row-vector"><span class="toc-section-number">1.3.7</span>  Column Vector &amp; Row Vector</a></li>
  <li><a href="#linear-combination-of-vectors" id="toc-linear-combination-of-vectors" class="nav-link" data-scroll-target="#linear-combination-of-vectors"><span class="toc-section-number">1.3.8</span>  Linear Combination of vectors</a></li>
  <li><a href="#outer-product" id="toc-outer-product" class="nav-link" data-scroll-target="#outer-product"><span class="toc-section-number">1.3.9</span>  Outer Product</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Basics (1) - Vector Operations</h1>
<p class="subtitle lead">Motivation, Scalr, Vector, Addition, Scalar Multiplication, Inner Product, Dot Product, Linear Transformation, Hermitian Transpose, Norm, Unit Vector, Projection, Cross Product, Column Vector, Row Vector, Linear Combination of Vectors, Outer Product</p>
  <div class="quarto-categories">
    <div class="quarto-category">Mathematics</div>
  </div>
  </div>

<div>
  <div class="description">
    <p>Basic Linear Algebra</p>
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Kwangmin Kim </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">March 30, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="introduction-linear-algebra-to-deep-learning" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction Linear Algebra to Deep Learning</h1>
<p>Deep learning is a pile of neural networks that are made up of layers of interconnected nodes or neurons, and the weights of the connections between them are learned through a process called backpropagation.</p>
<p>Linear algebra is fundamental to deep learning because many of the computations involved in training neural networks can be expressed as linear algebra operations. For example, matrix multiplication is used to compute the output of each layer in a neural network, and the gradients of the loss function with respect to the weights are computed using the chain rule of calculus, which involves matrix multiplication and vector operations.</p>
<p>In addition to matrix multiplication, other linear algebra concepts such as eigenvectors, eigenvalues, and singular value decomposition (SVD) are also important in deep learning. For example, SVD can be used to reduce the dimensionality of a dataset or to compute principal components, which are useful for data visualization and feature extraction.</p>
<p>Linear algebra libraries such as Numpy, Scipy, and PyTorch provide efficient implementations of these operations, which are essential for training large-scale neural networks on GPUs. Without these libraries, implementing deep learning algorithms would be much more difficult and time-consuming.</p>
<p><a href="https://nbviewer.org/github/fastai/numerical-linear-algebra/blob/master/nbs/1.%20Why%20are%20we%20here.ipynb">Reference: Motivation to Learn Linear Algebra</a></p>
<section id="scalar" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="scalar"><span class="header-section-number">1.1</span> Scalar</h2>
<p>A scalar is a single mathematical quantity, usually a real number, which can be represented by a single value. Scalars are typically denoted by lowercase letters, such as <span class="math inline">\(a, b, c,\)</span> and so on.</p>
</section>
<section id="vector" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="vector"><span class="header-section-number">1.2</span> Vector</h2>
<p>A vector <span class="math inline">\(\textbf{v}\)</span> is a mathematical object that represents a quantity with both a magnitude and a direction. In <span class="math inline">\(n\)</span>-dimensional Euclidean space <span class="math inline">\(\mathbb{R}^n\)</span>, a vector <span class="math inline">\(\textbf{v}\)</span> is typically represented as an ordered list of <span class="math inline">\(n\)</span> real numbers:</p>
<ul>
<li>the magnitude of <span class="math inline">\(\mathbf{v} =\begin{bmatrix} x\\ y \end{bmatrix}\)</span> is <span class="math inline">\(||\mathbf{v}|| = \sqrt{x^{2} + y^{2}}\)</span></li>
<li>the direction of it is the angle with the x axis, <span class="math inline">\(\theta=\tan^{-1}(\frac{y}{x})\)</span></li>
<li>If magnitude and vector are equal, then they are equal vectors</li>
</ul>
<p><span class="math display">\[
\textbf{v}=
\begin{bmatrix}
  v_1 \\
  v_2 \\
  \vdots \\
  v_n
\end{bmatrix}
\]</span></p>
<p>where <span class="math inline">\(v_1, v_2, \ldots, v_n\)</span> are the components of the vector <span class="math inline">\(\textbf{v}\)</span>.</p>
<section id="plotting-vectors-on-the-coordinate-plane" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="plotting-vectors-on-the-coordinate-plane"><span class="header-section-number">1.2.1</span> Plotting Vectors on the Coordinate Plane</h3>
<p>Example</p>
<p>Map <span class="math inline">\(\begin{bmatrix} 3\\ 2 \end{bmatrix}\)</span> into <span class="math inline">\(x=3\)</span>, <span class="math inline">\(y=2\)</span> on the Coordinate Plane</p>
<div class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<p><img src="01.basic_vector_files/figure-html/cell-2-output-1.png" width="592" height="416"></p>
</div>
</div>
<p><a href="http://immersivemath.com/ila/ch02_vectors/ch02.html#auto_label_33">Reference: Read This Article with Interactive Visualization - Points and Vectors</a></p>
</section>
</section>
<section id="basic-vector-operations" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="basic-vector-operations"><span class="header-section-number">1.3</span> Basic Vector Operations</h2>
<section id="addition-of-vectors" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="addition-of-vectors"><span class="header-section-number">1.3.1</span> Addition of Vectors</h3>
<p>The addition of two vectors is the process of adding their corresponding components. If <span class="math inline">\(\textbf{a}\)</span> and <span class="math inline">\(\textbf{b}\)</span> are two vectors of the same dimension, then their sum <span class="math inline">\(\textbf{c} = \textbf{a} + \textbf{b}\)</span> is a vector whose <span class="math inline">\(i\)</span>-th component is the sum of the <span class="math inline">\(i\)</span>-th components of <span class="math inline">\(\textbf{a}\)</span> and <span class="math inline">\(\textbf{b}\)</span>.</p>
<p><span class="math display">\[
\begin{align*}
  \textbf{c}&amp;=\textbf{a}+\textbf{b}\\
  c_i &amp;= a_i + b_i
\end{align*}
\]</span></p>
<p>For example, if <span class="math inline">\(\textbf{a} = [1, 2, 3]\)</span> and <span class="math inline">\(\textbf{b} = [4, 5, 6]\)</span>, then their sum <span class="math inline">\(\textbf{c} = [5, 7, 9]\)</span>.</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="images/chap02_01.PNG" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="images/chap02_02.PNG" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img src="images/chap02_03.PNG" class="img-fluid"></p>
</div>
</div>
</div>
</section>
<section id="subtraction-of-vectors" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="subtraction-of-vectors"><span class="header-section-number">1.3.2</span> Subtraction of Vectors</h3>
<p>The subtraction of two vectors is the process of subtracting their corresponding components. If <span class="math inline">\(\textbf{a}\)</span> and <span class="math inline">\(\textbf{b}\)</span> are two vectors of the same dimension, then their difference <span class="math inline">\(\textbf{c} = \textbf{a} - \textbf{b}\)</span> is a vector whose <span class="math inline">\(i\)</span>-th component is the difference between the <span class="math inline">\(i\)</span>-th components of <span class="math inline">\(\textbf{a}\)</span> and <span class="math inline">\(\textbf{b}\)</span>. The formal definition is:</p>
<p><span class="math display">\[
\begin{align*}
  \textbf{c}&amp;=\textbf{a} - \textbf{b}\\
  c_i &amp;= a_i - b_i
\end{align*}
\]</span></p>
<p>For example, if <span class="math inline">\(\textbf{a} = [1, 2, 3]\)</span> and <span class="math inline">\(\textbf{b} = [4, 5, 6]\)</span>, then their difference <span class="math inline">\(\textbf{c} = [-3, -3, -3]\)</span>.</p>
</section>
<section id="scalar-multiplication-of-vectors" class="level3" data-number="1.3.3">
<h3 data-number="1.3.3" class="anchored" data-anchor-id="scalar-multiplication-of-vectors"><span class="header-section-number">1.3.3</span> Scalar Multiplication of Vectors</h3>
<p>The scalar multiplication of a vector is the process of multiplying each component of the vector by a scalar. If <span class="math inline">\(\textbf{a}\)</span> is a vector and <span class="math inline">\(k\)</span> is a scalar, then the scalar multiple <span class="math inline">\(\textbf{c} = k\textbf{a}\)</span> is a vector whose <span class="math inline">\(i\)</span>-th component is <span class="math inline">\(k\)</span> times the <span class="math inline">\(i\)</span>-th component of <span class="math inline">\(\textbf{a}\)</span>. The formal definition is:</p>
<p><span class="math display">\[
\begin{align*}
  \textbf{c}&amp;=k\textbf{a}\\
  c_i &amp;= ka_i
\end{align*}
\]</span></p>
<p>For example, if <span class="math inline">\(\textbf{a} = [1, 2, 3]\)</span> and <span class="math inline">\(k = 2\)</span>, then their scalar multiple <span class="math inline">\(\textbf{c} = [2, 4, 6]\)</span>.</p>
<p><a href="http://immersivemath.com/ila/ch02_vectors/ch02.html#sec_vec_arithmetic">Reference: Read This Article with Interactive Visualization - Properties of Vector Arithmetic</a></p>
</section>
<section id="inner-product-of-vectors" class="level3" data-number="1.3.4">
<h3 data-number="1.3.4" class="anchored" data-anchor-id="inner-product-of-vectors"><span class="header-section-number">1.3.4</span> Inner Product of Vectors</h3>
<p>The dot product of two vectors is the sum of the products of their corresponding components (a.k.a dot product &amp; scalar product). If <span class="math inline">\(\textbf{a}\)</span> and <span class="math inline">\(\textbf{b}\)</span> are two vectors of the same dimension, then their dot product <span class="math inline">\(c = \textbf{a} \cdot \textbf{b}\)</span> is a scalar given by the formula:</p>
<p><span class="math display">\[
\begin{align*}
  c&amp;=\textbf{a}\cdot \textbf{b}\\
  &amp;= \sum_{i=1}^{n}a_ib_i
\end{align*}
\]</span></p>
<ul>
<li>Dot product can be used to measure the similarity between two vectors.</li>
<li>For the two vectors, <span class="math inline">\(\mathbf{a} = [a_1, a_2, \cdots a_n]\)</span> , <span class="math inline">\(\mathbf{b} = [b_1, b_2, \cdots b_n]\)</span>, dot product can be defined as <span class="math display">\[
\mathbf{a} \cdot \mathbf{b} = \mathbf{a}^{T} \mathbf{b} = ||\mathbf{a}||\text{ } ||\mathbf{b}|| \cos \theta
\]</span></li>
<li>When two vectors are orthogonal, <span class="math inline">\(\cos 90^{\circ} = 0\)</span>, the similarity of the two vectors is 0.</li>
<li>In the Euclidean space, dot product is often called inner product (inner product is a generalization of dot product)</li>
</ul>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Inner Product vs Dot Product
</div>
</div>
<div class="callout-body-container callout-body">
<p>In general, an inner product is a mathematical operation that takes two vectors and produces a scalar. It satisfies certain properties, such as being linear in the first argument, conjugate linear in the second argument, and positive-definite. In other words, an inner product is a bilinear form that satisfies the following properties for all vectors <span class="math inline">\(\mathbf{x}\)</span>, <span class="math inline">\(\mathbf{y}\)</span>, and <span class="math inline">\(\mathbf{z}\)</span>, and all scalars <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>:</p>
<ul>
<li>“Linear in the first argument” means that for any fixed vector <span class="math inline">\(\mathbf u\)</span>, the function <span class="math inline">\(f\)</span> defined by <span class="math inline">\(f(\mathbf v) = \langle\mathbf u, \mathbf v\rangle\)</span> is a linear function of <span class="math inline">\(\mathbf v\)</span>, i.e., <span class="math inline">\(f(a\mathbf x + b\mathbf y) = af(\mathbf x) + bf(\mathbf y)\)</span> for any scalars <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, and vectors <span class="math inline">\(\mathbf{x}\)</span>, <span class="math inline">\(\mathbf{y}\)</span>.
<ul>
<li><span class="math inline">\(\langle a\mathbf{x} + b\mathbf{y}, \mathbf{z}\rangle = a\langle\mathbf{x}, \mathbf{z}\rangle + b\langle\mathbf{y}, \mathbf{z}\rangle\)</span>, the inner product is linear with respect to the first argument. If we multiply a vector by a scalar and add it to another vector, the resulting inner product is the same as if we had calculated the inner product of each vector separately and then added them.</li>
</ul></li>
<li>“Conjugate linear in the second argument” means that for any fixed vector <span class="math inline">\(\mathbf v\)</span>, the function <span class="math inline">\(g\)</span> defined by <span class="math inline">\(g(\mathbf u) = \langle\mathbf u, \mathbf v\rangle\)</span> is a conjugate linear function of <span class="math inline">\(\mathbf u\)</span>, i.e., <span class="math inline">\(g(a \mathbf x + b \mathbf y) = \bar{a} g(\mathbf x) + \bar{b} * g(\mathbf y)\)</span> for any scalars <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, and vectors <span class="math inline">\(\mathbf x\)</span>, <span class="math inline">\(\mathbf y\)</span>, where <span class="math inline">\(\bar{a}\)</span> denotes the complex conjugate of <span class="math inline">\(a\)</span>.
<ul>
<li><span class="math inline">\(\langle \mathbf{x}, a\mathbf{y}, b\mathbf{z}\rangle = a\langle\mathbf{x}, \mathbf{y}\rangle + b\langle\mathbf{x}, \mathbf{z}\rangle\)</span>. this property says that the inner product is linear with respect to the second argument, but with complex conjugation. If we multiply a vector by a scalar and add it to another vector, the resulting inner product is the same as if we had calculated the inner product of each vector separately, complex-conjugated the second vector, and then added them.</li>
</ul></li>
<li>“Symmetry” means <span class="math inline">\(\langle \mathbf{x},\mathbf{y}\rangle= \langle \mathbf{y},\mathbf{x}\rangle\)</span>
<ul>
<li>the order of the vectors doesn’t matter when calculating the inner product.<br>
</li>
</ul></li>
<li>“Positive-definite” means that for any nonzero vector v, the inner product <span class="math inline">\(\langle\mathbf u, \mathbf v\rangle\)</span> is a positive real number. In other words, the inner product of a vector with itself is always positive, except when the vector is the zero vector.
<ul>
<li><span class="math inline">\(\langle \mathbf{x},\mathbf{x}\rangle\ge 0, \langle \mathbf{x},\mathbf{x}\rangle=0\)</span> only if <span class="math inline">\(\mathbf{x}=0\)</span></li>
</ul></li>
</ul>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Linear Transformation
</div>
</div>
<div class="callout-body-container callout-body">
<p>A function is said to be linear if it satisfies two properties: <strong>additivity</strong> and <strong>homogeneity</strong>.</p>
<ol type="1">
<li>Additivity means that for any two inputs, the output of the function applied to their sum is equal to the sum of the outputs applied to each input separately. In other words, if we have a function <span class="math inline">\(f\)</span> and vectors <span class="math inline">\(\mathbf x\)</span> and <span class="math inline">\(\mathbf y\)</span>, then</li>
</ol>
<p><span class="math display">\[
f(\mathbf x + \mathbf y) = f(\mathbf x) + f(\mathbf y)
\]</span></p>
<ol start="2" type="1">
<li>Homogeneity means that for any input and scalar <span class="math inline">\(c\)</span>, the output of the function applied to the input scaled by <span class="math inline">\(c\)</span> is equal to the output applied to the unscaled input multiplied by <span class="math inline">\(c\)</span>. In other words,</li>
</ol>
<p><span class="math display">\[
f(c\mathbf x) = c f(\mathbf x)
\]</span> These two properties together are what we mean when we say a function is linear.</p>
<p>Try to compare <span class="math inline">\(y=2x\)</span> for liniearity vs <span class="math inline">\(y=2x^2\)</span> for non-linearity and which one satisfies the linear properties?</p>
</div>
</div>
<p>Let’s consider the standard inner product of two vectors in <span class="math inline">\(\mathbb R^2\)</span>, given by <span class="math inline">\(\langle \mathbf x, \mathbf y\rangle\)</span> = <span class="math inline">\(x_1y_1 + x_2y_2\)</span>, where <span class="math inline">\(\mathbf x = [x_1, x_2]^T\)</span> and <span class="math inline">\(\mathbf y = [y_1, y_2]^T\)</span>.</p>
<ol type="1">
<li>Linearity in the first argument:</li>
</ol>
<p><span class="math display">\[
\langle 2 \mathbf x + 3\mathbf y, \mathbf z\rangle = (2x_1 + 3y_1)z_1 + (2x_2 + 3y_2)z_2 = 2\langle \mathbf x, \mathbf z \rangle + 3\langle \mathbf y, \mathbf z \rangle
\]</span></p>
<ol start="2" type="1">
<li>Conjugate linearity in the second argument:</li>
</ol>
<p><span class="math display">\[
\langle \mathbf x, 2\mathbf y+3\mathbf z\rangle = x_1(2y_1 + 3z_1) + x_2(2y_2 + 3z_2) = 2\langle \mathbf x, \mathbf y \rangle + 3\langle \mathbf x, \mathbf z \rangle
\]</span></p>
<ol start="3" type="1">
<li>Symmetry:</li>
</ol>
<p><span class="math display">\[
\langle \mathbf x,\mathbf y\rangle = x_1y_1 + x_2y_2 = y_1x_1 + y_2x_2 = \langle \mathbf y, \mathbf x \rangle
\]</span></p>
<ol start="4" type="1">
<li>Positive-definite:</li>
</ol>
<p><span class="math display">\[
\langle \mathbf x,\mathbf x\rangle =  x_1^2 + x_2^2 \ge 0 = \langle \mathbf x, \mathbf x \rangle \text{ only if } \mathbf x = [0, 0]^T
\]</span></p>
<p>Let’s see another example of two complex vectors for <em>2. Conjugate linearity in the second argument</em>, <span class="math inline">\(\mathbf{u}=\begin{bmatrix} 1+i \\ 2 \end{bmatrix}\)</span> and <span class="math inline">\(\mathbf{v}=\begin{bmatrix} 3-2i \\ 1 \end{bmatrix}\)</span>.</p>
<p>Their inner product would be: <span class="math display">\[
\begin{aligned}
\langle \mathbf{u}, \mathbf{v} \rangle &amp;= \begin{bmatrix} 1+i \\ 2 \end{bmatrix}^H \begin{bmatrix} 3-2i \\ 1 \end{bmatrix} \\
&amp;= \begin{bmatrix} 1-i &amp; 2 \end{bmatrix} \begin{bmatrix} 3-2i \\ 1 \end{bmatrix} \\
&amp;= (1-i)(3-2i) + 2(1) \\
&amp;= 1 + i + 6 - 4i + 2 \\
&amp;= 9 - 3i.
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(H\)</span> is the Hermitian transpose, also known as the conjugate transpose, which is similar to the transpose operation, but also involves taking the complex conjugate of each element. For a matrix <span class="math inline">\(\mathbf A\)</span>, the Hermitian transpose is denoted by <span class="math inline">\(\mathbf A^H\)</span> or <span class="math inline">\(A^\dagger\)</span> and is defined as the transpose of the complex conjugate of <span class="math inline">\(\mathbf A\)</span>. Mathematically, for a matrix <span class="math inline">\(\mathbf A\)</span> with elements <span class="math inline">\(a_{i,j}\)</span>, the Hermitian transpose <span class="math inline">\(\mathbf A^H\)</span> is defined as:</p>
<p><span class="math display">\[
(\mathbf A^H)_{i,j} = \overline{a_{j,i}}
\]</span></p>
<p>where <span class="math inline">\(\overline{a_{j,i}}\)</span> denotes the complex conjugate of <span class="math inline">\(a_{j,i}\)</span>.</p>
<p>In the case of a real-valued matrix, the Hermitian transpose reduces to the ordinary transpose, denoted by <span class="math inline">\(\mathbf A^T\)</span>.</p>
<p>Now let’s see the conjugate linearity property in the second argument:</p>
<p><span class="math display">\[
\begin{aligned}
\langle \mathbf{u}, c \mathbf{v} \rangle &amp;= \begin{bmatrix} 1+i \\2 \end{bmatrix}^H \left(c \begin{bmatrix} 3-2i \\ 1 \end{bmatrix}\right) \\
&amp;= \begin{bmatrix} 1-i &amp; 2 \end{bmatrix} \begin{bmatrix} 3c-2ci \\ c \end{bmatrix} \\
&amp;= (1-i)(3c-2ci) + 2(c) \\
&amp;= 3c - 2ci + 2c - 2ci \\
&amp;= (3+2)c - 4ci \\
&amp;= c(3+2i) - 4i\overline{c}.
\end{aligned}
\]</span></p>
<p>We can see that the second component of the result is <span class="math inline">\(-4i\overline{c}\)</span>, which is the conjugate of <span class="math inline">\(4ic\)</span>. Therefore, we can say that the inner product is conjugate linear in the second argument.</p>
<p>A dot product is a specific type of inner product that is defined for Euclidean spaces, which are spaces with a notion of distance or length. The dot product of two vectors is defined as the sum of the products of their corresponding components. In other words, if <span class="math inline">\(\mathbf a = [a_1, a_2, ..., a_n]\)</span> and <span class="math inline">\(\mathbf b = [b_1, b_2, ..., b_n]\)</span> are two vectors in <span class="math inline">\(\mathbb R^n\)</span>, then their dot product is given by:</p>
<p><span class="math display">\[
\mathbf a \cdot \mathbf b = a_1b_1 + a_2b_2 + ... + a_nb_n
\]</span></p>
<p>The dot product satisfies some of the properties of an inner product, such as being linear in the first argument and symmetric. However, it is not conjugate linear in the second argument, and it is not positive-definite in general.</p>
<p>So, while a dot product is a specific type of inner product, not all inner products are dot products.</p>
</div>
</div>
<p>For example, if <span class="math inline">\(\textbf{a} = [1, 2, 3]\)</span> and <span class="math inline">\(\textbf{b} = [4, 5, 6]\)</span>, then their dot product <span class="math inline">\(c = 1\cdot 4 + 2\cdot 5 + 3\cdot 6 = 32\)</span>.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Norm
</div>
</div>
<div class="callout-body-container callout-body">
<p>The norm of a vector <span class="math inline">\(\mathbf{x}\)</span> is a non-negative scalar value that represents <strong>the size or length</strong> of the vector. The norm is denoted by <span class="math inline">\(||\mathbf{x}||\)</span> and satisfies the following properties:</p>
<ul>
<li>Non-negativity: <span class="math inline">\(||\mathbf{x}||\geq 0\)</span>, with equality if and only if <span class="math inline">\(\mathbf{x}=\mathbf{0}\)</span>.</li>
<li>Homogeneity: <span class="math inline">\(||\alpha\mathbf{x}||=|\alpha| \text{ }||\mathbf{x}||\)</span> for any scalar <span class="math inline">\(\alpha\)</span>.</li>
<li>Triangle Inequality: <span class="math inline">\(||\mathbf{x}+\mathbf{y}||\leq ||\mathbf{x}||+||\mathbf{y}||\)</span>.</li>
</ul>
<p>Here is an example of finding the Euclidean norm of a vector: Suppose we have a vector <span class="math inline">\(\mathbf{x}=\begin{bmatrix}1 \\ -2 \\ 2\end{bmatrix}\)</span>. We can find its norm as follows:</p>
<p><span class="math display">\[
||\mathbf x||=\sqrt{1^2+(-2)^2+2^2}=\sqrt{9}=3
\]</span></p>
<p>Therefore, the norm of <span class="math inline">\(\mathbf{x}\)</span> is 3.</p>
<p>There are several types of norms:</p>
<ul>
<li><p>Manhattan Norm or Absolute Norm or <span class="math inline">\(l_1\)</span>-norm <span class="math display">\[
\begin{equation*}
||\mathbf{x}||_{l_1} = \sum_{i=1}^{n} |x_i|
\end{equation*}
\]</span> where <span class="math inline">\(\mathbf{x}\)</span> is a vector of length <span class="math inline">\(n\)</span>. Example: For <span class="math inline">\(\mathbf{x} = [1, -2, 3]\)</span>, <span class="math inline">\(||\mathbf{x}||_{l_1} = |1| + |-2| + |3| = 6\)</span>.</p></li>
<li><p>Euclidean Norm or <span class="math inline">\(l_2\)</span>-norm <span class="math display">\[
\begin{equation*}
||\mathbf{x}||_{l_2} = \sqrt{\sum_{i=1}^{n} x_i^2}
\end{equation*}
\]</span> where <span class="math inline">\(\mathbf{x}\)</span> is a vector of length <span class="math inline">\(n\)</span>. Example: For <span class="math inline">\(\mathbf{x} = [1, 2, 3]\)</span>, <span class="math inline">\(||\mathbf{x}||_{l_2} = \sqrt{1^2 + 2^2 + 3^2} = \sqrt{14}\)</span>.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/chap02_05.PNG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption"><span class="math inline">\(l_2\)</span>-norm</figcaption><p></p>
</figure>
</div>
<ul>
<li>p-norm(<span class="math inline">\(l_2\)</span>-norm)</li>
</ul>
<p>For <span class="math inline">\(p \geq 1\)</span>, <span class="math display">\[
\begin{equation*}
||\mathbf{x}||_p = (\sum_{i=1}^n |x_i|^p)^{\frac{1}{p}}
\end{equation*}
\]</span> where <span class="math inline">\(\mathbf{x}\)</span> is a vector of length <span class="math inline">\(n\)</span>. Example: For <span class="math inline">\(\mathbf{x} = [1, 2, 3]\)</span>, <span class="math inline">\(||\mathbf{x}||_{l_p} = \sqrt{1^p + 2^p + 3^p}\)</span>.</p>
<ul>
<li>Maximum Norm <span class="math display">\[
\begin{equation*}
||\mathbf{x}||_{\infty} = \max_{1 \leq i \leq n} |x_i|
\end{equation*}
\]</span> where <span class="math inline">\(\mathbf{x}\)</span> is a vector of length <span class="math inline">\(n\)</span>. Example: For <span class="math inline">\(\mathbf{x} = [1, -2, 3]\)</span>, <span class="math inline">\(||\mathbf{x}||_{\infty} = \max{(1, |-2|, 3)} = 3\)</span>.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/chap02_06.PNG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption"><span class="math inline">\(l_1\)</span>-norm vs <span class="math inline">\(l_2\)</span>-norm vs <span class="math inline">\(\max\)</span>-norm</figcaption><p></p>
</figure>
</div>
<ul>
<li>Frobenius Norm: <span class="math display">\[
\begin{equation*}
||\mathbf{a}||_{F} = \sqrt{\sum_{i=1}^{m} \sum_{j=1}^{n} |a_{ij}|^2}
\end{equation*}
\]</span> where <span class="math inline">\(\mathbf{A}\)</span> is an <span class="math inline">\(m \times n\)</span> matrix. Example: For <span class="math inline">\(\mathbf{A} = \begin{bmatrix} 1 &amp; 2 \\ 3 &amp; 4 \end{bmatrix}\)</span>, <span class="math inline">\(||\mathbf{A}||_{F} = \sqrt{1^2 + 2^2 + 3^2 + 4^2} = \sqrt{30}\)</span>.</li>
</ul>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Projection
</div>
</div>
<div class="callout-body-container callout-body">
<p>Let <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> be two vectors. The projection of <span class="math inline">\(\mathbf{u}\)</span> onto <span class="math inline">\(\mathbf{v}\)</span> is defined as the vector:</p>
<p>This vector is the closest vector to <span class="math inline">\(\mathbf{u}\)</span> that lies on the line spanned by <span class="math inline">\(\mathbf{v}\)</span>. <span class="math display">\[
\text{proj}_{\mathbf v}\mathbf u =\frac{\mathbf u \mathbf v}{||\mathbf v||^2} \mathbf v
\]</span> <img src="images/chap02_04.PNG" class="img-fluid" alt="Projection"></p>
<ul>
<li><span class="math inline">\(\mathbf{w} = ||\mathbf{w}||\mathbf{v} = ||\mathbf{u}|| \cos \theta \mathbf{v}\)</span></li>
<li><span class="math inline">\(\mathbf{u}^T \mathbf{u} = ||\mathbf{u}|| ||\mathbf{u}|| = ||\mathbf{u}||^2\)</span></li>
<li>the magnitude of <span class="math inline">\(\mathbf{u}\)</span> = <span class="math inline">\(||\mathbf{u}|| = \sqrt{\mathbf{u}^T \mathbf{u}}\)</span></li>
<li>unit vector: a normalized vector by dividing it by its magnitude, so the magnitude of a unit vector is 1 <span class="math display">\[
\hat{\mathbf{u}} = \frac{\mathbf{u}}{||\mathbf{u}||} = \frac{\mathbf{u}}{\sqrt{\mathbf{u}^T \mathbf{u}}}
\]</span></li>
<li>Projected vector, <span class="math inline">\(\mathbf{w}\)</span>
<ul>
<li>the product of <span class="math inline">\(\frac{\mathbf{u}^T \mathbf{v}}{||\mathbf{v}||}\)</span> and a unit vector of <span class="math inline">\(\mathbf{v}\)</span> <span class="math display">\[
\frac{\mathbf{u}^T \mathbf{v}}{||\mathbf{v}||} \frac{\mathbf{v}}{||\mathbf{v}||} = \frac{\mathbf{u}^T \mathbf{v}}{||\mathbf{v}||^2}\mathbf{v}
\]</span></li>
</ul></li>
</ul>
<p>For example, let <span class="math inline">\(\mathbf{u} = \begin{bmatrix}2 \ 3\end{bmatrix}\)</span> and <span class="math inline">\(\mathbf{v} = \begin{bmatrix}1 \\ 1\end{bmatrix}\)</span>. Then, the projection of <span class="math inline">\(\mathbf{u}\)</span> onto <span class="math inline">\(\mathbf{v}\)</span> is:</p>
<p><span class="math display">\[
\text{proj}_{\mathbf v}\mathbf u =\frac{\mathbf u \mathbf v}{||\mathbf v||^2} \mathbf v =\frac{\begin{bmatrix}2 \\ 3\end{bmatrix}\begin{bmatrix}1 \\ 1\end{bmatrix}}{\bigg{|}\bigg{|}\begin{bmatrix}1 \\ 1\end{bmatrix}\bigg{|}\bigg{|}^2}=\frac{5}{2}\begin{bmatrix}1 \\ 1\end{bmatrix}=\begin{bmatrix}5 \\ 2\end{bmatrix}
\]</span></p>
<p>This vector is the closest vector to <span class="math inline">\(\mathbf{u}\)</span> that lies on the line spanned by <span class="math inline">\(\mathbf{v} = \begin{bmatrix}1 \\ 1\end{bmatrix}\)</span>.</p>
<p><a href="http://immersivemath.com/ila/ch03_dotproduct/ch03.html#auto_label_107">Reference: Read This Article with Interactive Visualization - Projection</a></p>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Cauchy-Schwarz Inequality
</div>
</div>
<div class="callout-body-container callout-body">
<p>a fundamental result in mathematics that relates to inner products and norms. It states that for any vectors <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> in an inner product space, the following inequality holds: <span class="math display">\[
  |\langle \mathbf u,\mathbf v\rangle|\le ||\mathbf u|| ||\mathbf v ||
\]</span></p>
<p>where <span class="math inline">\(\langle \mathbf{u}, \mathbf{v}\rangle\)</span> denotes the inner product of vectors <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span>, and <span class="math inline">\(|\mathbf{u}|\)</span> and <span class="math inline">\(|\mathbf{v}|\)</span> denote their respective norms. In terms of the cosine formula, the Schwarz inequality can be written as: <span class="math display">\[
\cos \theta \le 1
\]</span></p>
<p>where <span class="math inline">\(\theta\)</span> is the angle between vectors <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span>, and <span class="math inline">\(\cos{\theta} = \frac{\langle \mathbf{u}, \mathbf{v}\rangle}{|\mathbf{u}| |\mathbf{v}|}\)</span>.</p>
<p>Geometrically, the Schwarz inequality states that the magnitude of the projection of one vector onto the other cannot exceed the length of the vector being projected. In other words, it bounds the correlation between two vectors and ensures that their inner product is always less than or equal to the product of their norms.</p>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Triangle Inequality
</div>
</div>
<div class="callout-body-container callout-body">
<p>The triangle inequality states that for any two vectors <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span>, the length of the sum of the vectors is less than or equal to the sum of the lengths of the vectors themselves. In terms of the cosine formula, this can be expressed as: <span class="math display">\[
||\mathbf u + \mathbf v||^2 \le ||\mathbf u||^2 + 2||\mathbf u ||||\mathbf v || + ||\mathbf v ||^2
\]</span></p>
<p>equivalently,</p>
<p><span class="math display">\[
||\mathbf u + \mathbf v|| \le ||\mathbf u|| + ||\mathbf v ||
\]</span></p>
<p>this inequality means that the distance between two points in a space, represented by vectors, is always shorter than or equal to the sum of the distances between the two vectors. In other words, it is impossible to make a straight line from one point to another that is shorter than the distance represented by the two vectors.</p>
<div class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<p><img src="01.basic_vector_files/figure-html/cell-3-output-1.png" width="592" height="434"></p>
</div>
</div>
</div>
</div>
</section>
<section id="unit-vector" class="level3" data-number="1.3.5">
<h3 data-number="1.3.5" class="anchored" data-anchor-id="unit-vector"><span class="header-section-number">1.3.5</span> Unit Vector</h3>
<p>A unit vector is a vector that has a magnitude of 1. A unit vector can be obtained by dividing a non-zero vector <span class="math inline">\(\mathbf{v}\)</span> by its magnitude <span class="math inline">\(||\mathbf{v}||\)</span>,</p>
<p><span class="math display">\[
\begin{equation*}
  \mathbf{\hat{v}} = \frac{\mathbf{v}}{||\mathbf{v}||}
\end{equation*}
\]</span></p>
<p>where <span class="math inline">\(\mathbf{\hat{v}}\)</span> is the unit vector in the direction of <span class="math inline">\(\mathbf{v}\)</span>.</p>
<p>For example, let <span class="math inline">\(\mathbf{v} = \begin{bmatrix} 1 \ 2 \end{bmatrix}\)</span> be a non-zero vector in <span class="math inline">\(\mathbb{R}^2\)</span>. The magnitude of <span class="math inline">\(\mathbf{v}\)</span> is <span class="math inline">\(||\mathbf{v}|| = \sqrt{1^2 + 2^2} = \sqrt{5}\)</span>. Therefore, a unit vector in the direction of <span class="math inline">\(\mathbf{v}\)</span> is:</p>
<p><span class="math display">\[
\begin{equation*}
\mathbf{\hat{v}} = \frac{\mathbf{v}}{||\mathbf{v}||} = \frac{1}{\sqrt{5}}\begin{bmatrix} 1 \\ 2 \end{bmatrix} = \begin{bmatrix} \frac{1}{\sqrt{5}} \\ \frac{2}{\sqrt{5}} \end{bmatrix}
\end{equation*}
\]</span></p>
<p>Thus, <span class="math inline">\(\begin{bmatrix} \frac{1}{\sqrt{5}} \\ \frac{2}{\sqrt{5}} \end{bmatrix}\)</span> is a unit vector in the direction of <span class="math inline">\(\mathbf{v}\)</span>.</p>
</section>
<section id="cross-product-of-vectors" class="level3" data-number="1.3.6">
<h3 data-number="1.3.6" class="anchored" data-anchor-id="cross-product-of-vectors"><span class="header-section-number">1.3.6</span> Cross Product of Vectors</h3>
<p>The cross product of two vectors is a vector that is perpendicular to both of them. If <span class="math inline">\(\textbf{a}\)</span> and <span class="math inline">\(\textbf{b}\)</span> are two vectors in <span class="math inline">\(\mathbb{R}^3\)</span>, then their cross product <span class="math inline">\(\textbf{c} = \textbf{a} \times \textbf{b}\)</span> is a vector given by the formula</p>
<p><span class="math display">\[
\textbf{c} = \textbf{a} \times \textbf{b} \\
          = ||\textbf{a}|| ||\textbf{b}||\sin(\theta) \mathbf n           
\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\theta\)</span> is the angle between <span class="math inline">\(\textbf{a}\)</span> and <span class="math inline">\(\textbf{b}\)</span> in the plane containing them (hence, it <span class="math inline">\(0 \le \theta \le \pi\)</span>)</li>
<li><span class="math inline">\(||\textbf{a}||\)</span> and <span class="math inline">\(||\textbf{b}||\)</span> are the magnitudes of vectors <span class="math inline">\(||\textbf{a}||\)</span> and <span class="math inline">\(||\textbf{b}||\)</span></li>
<li>and <span class="math inline">\(||\textbf{n}||\)</span> is a unit vector perpendicular to the plane containing <span class="math inline">\(||\textbf{a}||\)</span> and <span class="math inline">\(||\textbf{a}||\)</span>, with direction such that the ordered set (<span class="math inline">\(||\textbf{a}||\)</span>, <span class="math inline">\(||\textbf{b}||\)</span>, <span class="math inline">\(||\textbf{n}||\)</span>) is positively-oriented.</li>
</ul>
<p>If the vectors <span class="math inline">\(\textbf{a}\)</span> and <span class="math inline">\(\textbf{b}\)</span> are parallel (that is, <span class="math inline">\(\theta\)</span> between them is either <span class="math inline">\(0\)</span> or <span class="math inline">\(\pi\)</span>), by the above formula, the cross product of <span class="math inline">\(\textbf{a}\)</span> and <span class="math inline">\(\textbf{b}\)</span> is the zero vector 0.</p>
<p><a href="https://en.wikipedia.org/wiki/Cross_product">Reference: read the explanations in wiki</a></p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="../linear_algebra/images/Cross_product_vector.svg.png" class="img-fluid" alt="By User:Acdx - Self-made, based on Image:Crossproduct.png, Public Domain"> <img src="../linear_algebra/images/Right_hand_rule_cross_product.svg" class="img-fluid" alt="Right_hand_rule_cross_product"></p>
</div>
</div>
</div>
<p>For example, <span class="math display">\[
\textbf{c} = \textbf{a} \times \textbf{b} = [a_2b_3 - a_3b_2, a_3b_1 - a_1b_3, a_1b_2 - a_2b_1]           
\]</span></p>
<p>If <span class="math inline">\(\textbf{a} = [1, 2, 3]\)</span> and <span class="math inline">\(\textbf{b} = [4, 5, 6]\)</span>, then their cross product <span class="math inline">\(\textbf{c} = [-3, 6, -3]\)</span>.</p>
</section>
<section id="column-vector-row-vector" class="level3" data-number="1.3.7">
<h3 data-number="1.3.7" class="anchored" data-anchor-id="column-vector-row-vector"><span class="header-section-number">1.3.7</span> Column Vector &amp; Row Vector</h3>
<p>A column vector <span class="math inline">\(\mathbf{u}\)</span> with <span class="math inline">\(n\)</span> elements is an <span class="math inline">\(m \times 1\)</span> matrix, which can be represented as: <span class="math display">\[
\mathbf{u} =
\begin{bmatrix}
u_{1} \\
u_{2} \\
\vdots \\
u_{m}
\end{bmatrix}
\]</span></p>
<p>In an <span class="math inline">\(m \times n\)</span> matrix, the column vectors can be represented as:</p>
<p><span class="math display">\[
\mathbf U  = \begin{bmatrix}  \mathbf u_{1} &amp;\mathbf u_{2} &amp; \dots &amp;\mathbf u_{n} \end{bmatrix} \\
=
\begin{bmatrix}
  u_{11} &amp; u_{12} &amp; \cdots &amp; u_{1n} \\
  u_{21} &amp; u_{22} &amp; \cdots &amp; u_{2n} \\
  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
  u_{m1} &amp; u_{m2} &amp; \cdots &amp; u_{mn}
\end{bmatrix}
\]</span></p>
<p>where <span class="math inline">\(u_i\)</span> is the <span class="math inline">\(i\)</span>-th element of the column vector <span class="math inline">\(\mathbf{u}\)</span>, <span class="math inline">\(n\)</span> is the number of columns, and <span class="math inline">\(m\)</span> is the number of rows in the matrices.</p>
<p>A row vector <span class="math inline">\(\mathbf{u}\)</span> with <span class="math inline">\(m\)</span> elements is a <span class="math inline">\(1 \times n\)</span> matrix, which can be represented as: <span class="math display">\[
\mathbf{u} =
\begin{bmatrix}
u_{1} &amp; u_{2} &amp; \cdots &amp; u_{m}
\end{bmatrix}
\]</span></p>
<p>In an <span class="math inline">\(m \times n\)</span> matrix, the row vectors can be represented as:</p>
<p><span class="math display">\[
\mathbf U  = \begin{bmatrix}  \mathbf u_{1} \\\mathbf u_{2} \\ \vdots \\\mathbf u_{m} \end{bmatrix} \\
=
\begin{bmatrix}
  u_{11} &amp; u_{12} &amp; \cdots &amp; u_{1n} \\
  u_{21} &amp; u_{22} &amp; \cdots &amp; u_{2n} \\
  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
  u_{m1} &amp; u_{m2} &amp; \cdots &amp; u_{mn}
\end{bmatrix}
\]</span></p>
<p>where <span class="math inline">\(u_i\)</span> is the <span class="math inline">\(i\)</span>-th element of the row vector <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(n\)</span> is the number of columns in the matrix.</p>
</section>
<section id="linear-combination-of-vectors" class="level3" data-number="1.3.8">
<h3 data-number="1.3.8" class="anchored" data-anchor-id="linear-combination-of-vectors"><span class="header-section-number">1.3.8</span> Linear Combination of vectors</h3>
<p>A linear combination of vectors <span class="math inline">\(\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_n\)</span> in a vector space <span class="math inline">\(V\)</span> over a field <span class="math inline">\(\mathbb{F}\)</span> is a vector of the form: <span class="math display">\[
a_1\mathbf{v_1}+a_2\mathbf{v_2}+\dots+a_n\mathbf{v_n}
\]</span></p>
<p>where <span class="math inline">\(a_1,a_2,\dots,a_n\in\mathbb{F}\)</span>.</p>
<p>For example, suppose we have two vectors <span class="math inline">\(\mathbf{v}_1=\begin{bmatrix} 1 \ 2 \ 3 \end{bmatrix}\)</span> and <span class="math inline">\(\mathbf{v}_2=\begin{bmatrix} 4 \ 5 \ 6 \end{bmatrix}\)</span> in <span class="math inline">\(\mathbb{R}^3\)</span>. Then, a linear combination of <span class="math inline">\(\mathbf{v}_1\)</span> and <span class="math inline">\(\mathbf{v}_2\)</span> is of the form:</p>
<p><span class="math display">\[
a_1\begin{bmatrix}1\\2\\3\end{bmatrix}+a_2\begin{bmatrix}4\\5\\6\end{bmatrix}=\begin{bmatrix}a_1+4a_2\\2a_1+5a_2\\3a_1+6a_2\end{bmatrix}
\]</span></p>
<p>Here, <span class="math inline">\(a_1\)</span> and <span class="math inline">\(a_2\)</span> are scalar coefficients that determine the resulting linear combination vector.</p>
</section>
<section id="outer-product" class="level3" data-number="1.3.9">
<h3 data-number="1.3.9" class="anchored" data-anchor-id="outer-product"><span class="header-section-number">1.3.9</span> Outer Product</h3>
<p>The outer product of two vectors <span class="math inline">\(\mathbf{u} = [u_1, u_2, \dots, u_m]^T\)</span> and <span class="math inline">\(\mathbf{v} = [v_1, v_2, \dots, v_n]^T\)</span> is a matrix <span class="math inline">\(\mathbf{u} \mathbf{v}^T\)</span> of size <span class="math inline">\(m \times n\)</span>, defined by:</p>
$$
<span class="math display">\[\begin{aligned}
\mathbf{u} \otimes \mathbf{v} &amp;=
\begin{bmatrix}
u_1v_1 &amp;u_1v_2&amp; \dots &amp; u_1v_n \\
u_2v_1 &amp;u_2v_2&amp; \dots &amp; u_2v_n \\
\vdots &amp;\vdots&amp; \ddots &amp; u_1v_n \\
u_mv_1 &amp;u_mv_2&amp; \dots &amp; u_mv_n \\

\end{bmatrix}
\end{aligned}\]</span>
<p>$$</p>
<p><span class="math display">\[
(\mathbf{u} \otimes \mathbf{v})_{i,j} = u_i v_j
\]</span></p>
<p>where <span class="math inline">\(\mathbf{u} = [u_1, u_2, \dots, u_m]\)</span> and <span class="math inline">\(\mathbf{v} = [v_1, v_2, \dots, v_n]\)</span>.</p>
<p>The outer product is also called the tensor product, and it is a type of binary operation between two vectors that results in a matrix. It is important in linear algebra and other fields such as physics and engineering.</p>
<p>Here is an example: Let <span class="math inline">\(\mathbf{u} = [2, 4, 6]^T\)</span> and <span class="math inline">\(\mathbf{v} = [1, 3]^T\)</span>. The outer product of <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> is:</p>
<p>So the outer product of <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> is a <span class="math inline">\(3 \times 2\)</span> matrix.</p>
<p><a href="../../../../../docs/blog/posts/Mathmatics/linear_algebra/02.basic_matrix.html">What is a matrix? Go to the Next Blog</a></p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>