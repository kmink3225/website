---
title: Conditional Probability & Bayes' Rule
subtitle: Conditional Probability, Bayes' Rule, Bayesean Statistics, Frequentist Statistics, Deductive reasoning, Inductive Reasoning, Total Probability Rule, Naive Bayes
description: | 
  Probability for statistics, machine learning and deep learning.
categories:
  - Statistics
author: Kwangmin Kim
date: 02/05/2023
draft: false
format: 
  html:
    toc: true
    number-sections: True
    code-fold: true
    page-layout: full
execute: 
  warning: false
  message: false
---

<ul class="nav nav-pills" id="language-tab" role="tablist">
  <li class="nav-item" role="presentation">
    <button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" role="tab" aria-controls="Korean" aria-selected="true">Korean</button>
  </li>
  <li class="nav-item" role="presentation">
    <button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" role="tab" aria-controls="knitr" aria-selected="false">English</button>
  </li>

<div class="tab-content" id="language-tabcontent">

<div class="tab-pane fade  show active" id="Korean" role="tabpanel" aria-labelledby="Korean-tab">

::: {#Korean .tab-pane .fade .show .active role="tabpanel" aria-labelledby="Korean-tab"}



## Conditional Probability

ì£¼ì‚¬ìœ„ë¥¼ ë˜ì§ˆ ë•Œ íŠ¹ì • ì£¼ì‚¬ìœ„ì˜ ëˆˆ (1~6)ì´ ë‚˜ì˜¬ í™•ë¥ ì€ **$\frac{1}{6}$ ìœ¼ë¡œ ê°™ë‹¤ (eqaully likely)ë¼ê³  ê°€ì •í•  ë•Œ** ì£¼ì‚¬ìœ„ì˜ ëˆˆì´ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” ëª¨ë“  ì§‘í•© í‘œë³¸ ê³µê°„ $S$ ì— ëŒ€í•œ íŠ¹ì • ì£¼ì‚¬ìœ„ì˜ ëˆˆì´ ë‚˜ì˜¤ëŠ” ì‚¬ê±´ $A$ ê°€ ë°œìƒí•  í™•ë¥ ì€ $\frac{n(A)}{n(S)}$ ì™€ ê°™ë‹¤. ì¡°ê±´ë¶€ í™•ë¥ ì€ 2ê°œ ì´ìƒì˜ ì‚¬ê±´ì— ëŒ€í•´ì„œ í•˜ë‚˜ì˜ ì‚¬ê±´ì´ ë‹¤ë¥¸ ì‚¬ê±´ì´ ë°œìƒí•  í™•ë¥ ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê°œë…ì„ ë§í•œë‹¤. ê°€ì¥ ê°„ë‹¨í•œ 2ê°œì˜ ì‚¬ê±´ $A, B$ ì— ëŒ€í•´ì„œ ì‚´í´ë³¼ ë•Œ ì¡°ê±´ë¶€ í™•ë¥ ì€ ë‹¤ìŒê³¼ (@eq-conditional_probability)ê³¼ ê°™ë‹¤.

$$
P(A|B)=\frac{P(A\cap B)}{P(B)}
$$ {#eq-conditional_probability}

ì˜ˆë¥¼ ë“¤ì–´, ì‚¬ê±´ $A$ ëŠ”  ì£¼ì‚¬ìœ„ì˜ ëˆˆì´ 1ì´ ë‚˜ì˜¤ëŠ” ì‚¬ê±´, ì‚¬ê±´ $B$ ëŠ” ì£¼ì‚¬ìœ„ì˜ ëˆˆì´ 3 ì´í•˜ê°€ ë‚˜ì˜¤ëŠ” ì‚¬ê±´ì´ë¼ê³  í–ˆì„ ë•Œ ì‚¬ê±´ $A$ ê°€ ì‚¬ê±´ $B$ ì˜ ë¶€ë¶„ ì§‘í•©ì´ë¯€ë¡œ ë‘ ì‚¬ê±´ì´ ì„œë¡œ ë…ë¦½ì´ ì•„ë‹ˆë‹¤. ì¦‰, $ A\cap B $ ì‚¬ê±´ì—ì„œ ì£¼ì‚¬ìœ„ì˜ ëˆˆì´ 1 ë‚˜ì˜¤ëŠ” ê²½ìš° ë°–ì— ì—†ë‹¤. ì´ë ‡ê²Œ ì‚¬ê±´ $B$ ê°€ ì£¼ì–´ì¡Œì„ ë•Œ í˜¹ì€ $B$ ê°€ ë¨¼ì € ì¼ì–´ë‚¬ì„ ë•Œ 1ì´ ë‚˜ì˜¬ í™•ë¥ ì€ ë‹¬ë¼ì§€ê²Œ ëœë‹¤. ì¦‰, $A$ ì˜ sample space = $\{1,2,3,4,5,6\}$ ì´ê³  $A|B$ ì˜ sample space = $\{1,2,3\}$ ì´ ë˜ê¸° ë•Œë¬¸ì— $P(A) \not= P(A|B)$ ê°€ ëœë‹¤. 

ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ê³„ì‚°ì„ í•˜ê²Œ ë˜ë©´, $P(A)=\frac{1}{6}, P(B)=\frac{3}{6}, P(A\cap B)=\frac{1}{6}$ ì¼ ë•Œ, 

$$
P(A|B)=\frac{P(A\cap B)}{P(B)}=\frac{\frac{1}{6}}{\frac{3}{6}}=\frac{1}{3}
$$ 

ì¸ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.
 
## Bayes' Rule

Bayes' rule (ë² ì´ì¦ˆ ì •ë¦¬)ëŠ” prior probability(ì‚¬ì „ í™•ë¥ )ê³¼ posterior probability(ì‚¬í›„ í™•ë¥ )ì˜ ê´€ê³„ë¥¼ ì¡°ê±´ë¶€ í™•ë¥ ì„ ì´ìš©í•˜ì—¬ í™•ë¦½í•œ ê²ƒì´ë‹¤. ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ, 2ê°œì˜ ì‚¬ê±´ Aì™€ Bë¡œ í•œì •ì‹œì¼œ ìƒê°í•´ë´¤ì„ ë•Œ, ì¡°ê±´ë¶€ í™•ë¥  $P(A|B)$ ëŠ” ê° ì‚¬ê±´ì˜ í™•ë¥  $P(A), P(B), P(B|A)$ ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²Œì‚°ë  ìˆ˜ ìˆë‹¤. ê·¸ë˜ì„œ ë² ì´ì¦ˆ ì •ë¦¬ëŠ” $P(B|A)$, $P(B|\overline{A})$, $P(A)$ ì˜ ì •ë³´ë¥¼ ì•Œê³ ìˆê±°ë‚˜ ê³„ì‚° ê°€ëŠ¥í•  ë•Œ ì•„ë˜ì™€ ê°™ì€ $P(A|B)$ ì˜ í™•ë¥ ì„ êµ¬í•  ìˆ˜ ìˆëŠ” ê³µì‹ì„ ì œê³µí•œë‹¤(@eq-Bayes_rule). 

### Activating Schema

Bayes' ruleì„ ì¢€ ë” ì§ê´€ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ìœ„í•´ì„  Bayes' ruleì™€ ì—°ê´€ëœ, ê·¸ë¦¬ê³  ìš°ë¦¬ì—ê²Œ ì¹œìˆ™í•œ ê°œë…ë“¤ì´ë‚˜ ë…¼ë¦¬ë“¤ì„ ìƒê¸°ì‹œí‚¬ í•„ìš”ê°€ ìˆë‹¤. ìš°ë¦¬ì—ê²Œ ì¹œìˆ™í•œ ê°œë…ì¸ ì—°ì—­ë²•ê³¼ ê·€ë‚©ë²•ì— ëŒ€í•´ì„œ ê°„ë‹¨ì´ ì‚´í´ë³¸ë‹¤. 

#### Deduction vs Induction Method (or Deductive Reasoning)

Deduction method (or deductive reasoning)ëŠ” 
ì—°ì—­(æ¼”ç¹¹, deduction)ì´ë€ ì´ë¯¸ ì•Œê³  ìˆëŠ” í•˜ë‚˜ ë˜ëŠ” ë‘˜ ì´ìƒì˜ ëª…ì œë¥¼ ì „ì œë¡œ í•˜ì—¬ ëª…í™•íˆ ê·œì •ëœ ë…¼ë¦¬ì  í˜•ì‹ë“¤ì— ê·¼ê±°í•´ ìƒˆë¡œìš´ ëª…ì œë¥¼ ê²°ë¡ ìœ¼ë¡œ ì´ëŒì–´ë‚´ëŠ” ì¶”ë¦¬ì˜ ë°©ë²•ì´ë‹¤. ì—°ì—­ì„ ì¼ë°˜ì ì¸ ì‚¬ì‹¤ì´ë‚˜ ì›ë¦¬ì—ì„œ ê°œë³„ì ì´ê³  íŠ¹ìˆ˜í•œ ì‚¬ì‹¤ì´ë‚˜ ì›ë¦¬ë¥¼ ì´ëŒì–´ë‚´ëŠ” ê²ƒìœ¼ë¡œ ì •ì˜í•˜ê¸°ë„ í•œë‹¤. í•˜ì§€ë§Œ ì „ì œì™€ ê²°ë¡ ì´ ëª¨ë‘ íŠ¹ìˆ˜ ëª…ì œì¸ ê²½ìš°ë„ ìˆìœ¼ë¯€ë¡œ ì´ëŠ” ì§€ë‚˜ì¹˜ê²Œ í˜‘ì†Œí•œ ì´í•´ë¼ê³  í•  ìˆ˜ ìˆë‹¤.  
 
ì—°ì—­ì€ ê·€ë‚©(æ­¸ç´, induction)ê³¼ ë‹¬ë¦¬ ì „ì œì™€ ê²°ë¡ ì˜ êµ¬ì²´ì ì¸ ë‚´ìš©ì€ ë¬¸ì œë¡œ ì‚¼ì§€ ì•Šìœ¼ë©° ì—„ê²©í•œ ë…¼ë¦¬ì  ê·œì¹™ì— ì˜ì¡´í•œë‹¤. ê·€ë‚©ì—ì„œ ì¶”ë¡ ì˜ íƒ€ë‹¹ì„±ì€ ì „ì œì™€ ê²°ë¡ ì„ ë’·ë°›ì¹¨í•˜ëŠ” ë‚´ìš©ì— ë‹¬ë ¤ ìˆë‹¤. ê·€ë‚©ì  ì¶”ë¡ ì€ ê·¼ë³¸ì ìœ¼ë¡œ ê´€ì°°ê³¼ ì‹¤í—˜ì—ì„œ ì–»ì€ ë¶€ë¶„ì ì´ê³  íŠ¹ìˆ˜í•œ ì‚¬ë¡€ë¥¼ ê·¼ê±°ë¡œ ì „ì²´ì— ì ìš©ì‹œí‚¤ëŠ” ì´ë¥¸ë°” â€˜ê·€ë‚©ì  ë¹„ì•½â€™ì„ í†µí•´ ì´ë£¨ì–´ì§„ë‹¤. ë•Œë¬¸ì— ê·€ë‚©ì—ì„œ ì–»ì–´ì§„ ê²°ë¡ ì€ ì¼ì •í•œ ê°œì—°ì„±ì„ ì§€ë‹ ë¿ì´ë©°, ì‚¬ì‹¤ ì •ë³´ì— ë”°ë¼ íƒ€ë‹¹ì„±ì˜ ì •ë„ë„ ë‹¬ë¼ì§„ë‹¤. í•˜ì§€ë§Œ ì—°ì—­ì—ì„œëŠ” ë…¼ë¦¬ì  í˜•ì‹ì˜ íƒ€ë‹¹ì„±ì„ ê°–ì¶”ê³  ìˆëŠ” í•œ, ê²°ë¡ ì€ ì „ì œë“¤ë¡œë¶€í„° í•„ì—°ì„±ì„ ê°€ì§€ê³  ë„ì¶œëœë‹¤. ì—°ì—­ì—ì„œëŠ” ì „ì œê°€ ê²°ë¡ ì„ í™•ë¦½í•´ ì£¼ëŠ” ê²°ì •ì  ê·¼ê±°ê°€ ëœë‹¤. ì „ì œê°€ ì°¸ì¼ ê²½ìš° ê·¸ëŸ¬í•œ ì „ì œì— ì˜í•´ ë’·ë°›ì¹¨ë˜ëŠ” ê²°ë¡  ì—­ì‹œ ë°˜ë“œì‹œ ì°¸ì´ ë˜ë©°, ì „ì œì™€ ê²°ë¡  ì‚¬ì´ì˜ ì´ëŸ¬í•œ í•„ì—° ê´€ê³„ëŠ” ë…¼ë¦¬ì  í˜•ì‹ê³¼ ê·œì¹™ì˜ íƒ€ë‹¹ì„±ì— ê·¼ê±°í•´ ì„±ë¦½í•œë‹¤.  
 
ì´ì²˜ëŸ¼ ì—°ì—­ì€ ê²°ë¡ ì˜ ë‚´ìš©ì´ ì´ë¯¸ ì „ì œ ì†ì— í¬í•¨ë˜ì–´ ìˆë‹¤ëŠ” ì ì—ì„œ ì§„ë¦¬ë³´ì¡´ì (truth-preserving) ì„±ê²©ì„ ì§€ë‹Œë‹¤. ì—°ì—­ì€ ì „ì œì— ì—†ì—ˆë˜ ìƒˆë¡œìš´ ì‚¬ì‹¤ì  ì§€ì‹ì˜ í™•ì¥ì„ ê°€ì ¸ë‹¤ ì£¼ì§€ëŠ” ëª»í•˜ë©°, ì´ë¯¸ ì „ì œ ì†ì— í¬í•¨ë˜ì–´ ìˆëŠ” ì •ë³´ë¥¼ ëª…í™•í•˜ê³  ìƒˆë¡­ê²Œ ë„ì¶œí•´ë‚¼ ë¿ì´ë‹¤.  
 
í•˜ì§€ë§Œ ì—°ì—­ì  ì¶”ë¦¬(deductive inference)ëŠ” ë…¼ë¦¬ì  ì¼ê´€ì„±ê³¼ ì²´ê³„ì„±ì„ ê°€ì ¸ë‹¤ ì¤€ë‹¤. ë•Œë¬¸ì— ì¼ìƒ ìƒí™œì—ì„œë„ ë„ë¦¬ ì ìš©ë˜ì–´ ë‚˜íƒ€ë‚œë‹¤. ì–´ë–¤ í–‰ìœ„ê°€ ì˜³ì€ ê²ƒì¸ì§€ ì•„ë‹Œì§€ë¥¼ ë”°ì§€ëŠ” ìœ¤ë¦¬ì  íŒë‹¨ë“¤ì€ ëŒ€ë¶€ë¶„ ì—°ì—­ì  ë°©ë²•ì— ê¸°ì´ˆí•´ ë‚˜íƒ€ë‚œë‹¤. ê°œë³„ í–‰ìœ„ì˜ ìœ í˜•ì„ í¬ê´„í•˜ëŠ” ë³´í¸ì  ê·œë²”ì— ê¸°ì´ˆí•´ ì˜³ê³  ê·¸ë¦„ì„ íŒë‹¨í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ê·¸ë¦¬ê³  ìˆ˜í•™ì˜ ë§ì€ ë¶„ì•¼ë“¤ë„ ì—°ì—­ì  ì¶”ë¦¬ì— ì˜ì¡´í•œë‹¤.  
 
ì£¼ì–´ì§„ ì „ì œë“¤ì—ì„œ ë…¼ë¦¬ì ì¸ ë°©ì‹ìœ¼ë¡œ ê²°ë¡ ì„ ë„ì¶œí•˜ëŠ” ì—°ì—­ì  ì¶”ë¦¬ì˜ ë°©ë²•ê³¼ ì ˆì°¨ë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ì²´ê³„í™”í•œ ê²ƒì´ ì—°ì—­ë²•(deductive method)ì´ë‹¤. ì—°ì—­ì  ì¶”ë¡  ê·œì¹™ê³¼ í˜•ì‹ì— ëŒ€í•œ íƒêµ¬ì˜ ì—­ì‚¬ëŠ” ë§¤ìš° ì˜¤ë˜ë˜ì—ˆë‹¤. ì¼ì°ì´ ì•„ë¦¬ìŠ¤í† í…”ë ˆìŠ¤ëŠ” ì‚¼ë‹¨ë…¼ë²•ì˜ í˜•ì‹ì„ í™•ë¦½í•˜ì˜€ê³ , ì˜¤ëŠ˜ë‚ ì—ë„ ìƒˆë¡œìš´ ì¶”ë¡  ê·œì¹™ì„ ì°¾ëŠ” ì¼ì€ ë…¼ë¦¬í•™ì˜ ê°€ì¥ ì¤‘ìš”í•œ ê³¼ì œ ê°€ìš´ë° í•˜ë‚˜ì´ë‹¤.  
 
ì—°ì—­ì  ì¶”ë¦¬ì˜ ë°©ë²•ì€ í•˜ë‚˜ì˜ ì „ì œì—ì„œ ê²°ë¡ ì´ ë„ì¶œë˜ëŠ” ì§ì ‘ì¶”ë¦¬ì™€ 2ê°œ ì´ìƒì˜ ì „ì œì—ì„œ ê²°ë¡ ì´ ë‚˜íƒ€ë‚˜ëŠ” ê°„ì ‘ì¶”ë¦¬ë¡œ ë‚˜ë‰œë‹¤. â€˜ëŒ€ì „ì œâ†’ì†Œì „ì œâ†’ê²°ë¡ â€™ì˜ í˜•ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” ì‚¼ë‹¨ë…¼ë²•ì´ ê°„ì ‘ì¶”ë¦¬ì˜ ì „í˜•ì  í˜•ì‹ì´ë‹¤. ì´ ë•Œ ê²°ë¡ ì˜ ì£¼ì–´ ê°œë…ì„ â€˜ì†Œê°œë…â€™, ê²°ë¡ ì˜ ìˆ ì–´ ê°œë…ì„ â€˜ëŒ€ê°œë…â€™, ëŒ€ì „ì œì™€ ì†Œì „ì œì— ê³µí†µìœ¼ë¡œ í¬í•¨ë˜ì–´ ë‘ ì „ì œë¥¼ ì—°ê²°í•˜ëŠ” ê°œë…ì„ â€˜ë§¤ê°œë…â€™ì´ë¼ê³  í•œë‹¤.  
 
ëª¨ë“  ì‚¬ëŒì€ ì£½ëŠ”ë‹¤. A â†’ B (ëŒ€ì „ì œ)
ì†Œí¬ë¼í…ŒìŠ¤ëŠ” ì‚¬ëŒì´ë‹¤. C â†’ A (ì†Œì „ì œ)

ì†Œí¬ë¼í…ŒìŠ¤ëŠ” ì£½ëŠ”ë‹¤. C â†’ Bì´ë‹¤. (ê²°ë¡ ) 
 
ì—°ì—­ì€ ì „ì œë¡œë¶€í„° ê²°ë¡ ì„ ë„ì¶œí•´ë‚´ëŠ” ê²ƒì´ë¯€ë¡œ ì¼ì •í•œ ëª…ì œë¥¼ ì¶œë°œì ìœ¼ë¡œ í•œë‹¤. ê·¸ëŸ°ë° ëª¨ë“  ì—°ì—­ì˜ ì¶œë°œì ì´ ë˜ëŠ” ìµœì´ˆì˜ ëª…ì œëŠ” ê²°ì½” ì—°ì—­ì— ì˜í•´ ë„ì¶œë  ìˆ˜ ì—†ë‹¤. ê·¸ëŸ¬í•œ ì¶œë°œì ì€ ê²°êµ­ ì¸ê°„ì˜ ë‹¤ì–‘í•œ ê²½í—˜ì´ë‚˜ ì‹¤ì²œ ë“±ì˜ ê²°ê³¼ë¥¼ ì¼ë°˜í™”í•˜ëŠ” ê³¼ì •ì„ í†µí•´ì„œ í˜•ì„±ëœë‹¤. ë•Œë¬¸ì— ì‹¤ì œì˜ í•™ë¬¸ ì—°êµ¬ê°€ ìˆœìˆ˜íˆ ì—°ì—­ì  í˜•íƒœë¡œì„œë§Œ ì´ë£¨ì–´ì§ˆ ìˆ˜ëŠ” ì—†ìœ¼ë©° ê´€ì°°ì´ë‚˜ ì‹¤í—˜ ë“±ì˜ ì¦ëª… ê³¼ì •ê³¼ í†µì¼ë˜ì–´ ì ìš©ëœë‹¤. ì˜¤ëŠ˜ë‚ ì—ëŠ” ì „ì œë¡œ ì‚¼ì€ ê°€ì„¤ì„ ê²€ì¦í•˜ê¸° ìœ„í•´ ê·¸ ê°€ì„¤ì—ì„œ ëª‡ ê°œì˜ ëª…ì œë¥¼ ì—°ì—­í•´ ì‹¤í—˜ê³¼ ê´€ì°° ë“±ì„ ìˆ˜í–‰í•˜ëŠ” ê°€ì„¤ì—°ì—­ë²•(å‡èªªæ¼”ç¹¹æ³•, hypothetical deductive method)ì´ ë„ë¦¬ ì“°ì´ê³  ìˆë‹¤.

[Source: naver encyclopedia -deductive method](https://terms.naver.com/entry.naver?docId=1126605&cid=40942&categoryId=31530)

 
#### Induction Method (or Inductive Reasoning)

#### Frequentism vs Bayeseanism

[source: Frequentism vs Bayeseanism](https://www.redjournal.org/article/S0360-3016(21)03256-9/fulltext)


### Definition of Bayes' Rule
$$
P(A|B)=\frac{P(B|A)P(A)}{P(B)}
$$ {#eq-Bayes_rule}

* $P(A|B)$: posterior probability
* $P(A)$: prior probability
* $P(B|A)$: likelihood
* $P(B)$: marginal probability

ì´ ê³µì‹ì„ ì´í•´í•˜ê¸° ìœ„í•´ì„ , Law of Total Probability (ì „ í™•ë¥  ë²•ì¹™) ë˜ëŠ” Total Probability Rule (ì „ í™•ë¥  ì •ë¦¬)ì„ ì´í•´í•´ì•¼í•œë‹¤.

### Total Probability Rule

::: {#thm-general}

Let $A_1, A_2, ..., A_k$ be a set of mutually exclusive and exhaustive events. Let $A$ be a event and a partition of sample space $\Omega$, then 

$$
P(B)=\sum_{i=1}^{n}P(B|A_i)P(A_i)
$$

:::

::: columns
::: {.column width="50%"}
![Law of Total Probability Example - Two Events](law%20of%20total%20probability2.PNG)

[Source: Law of ToTal Probability with Proof](https://byjus.com/maths/total-probability-theorem/)
:::
::: {.column width="50%"}
![Law of Total Probability Example - Multiple Events](law%20of%20total%20probability.PNG)

[Source: MIT RES.6-012 Introduction to Probability, Spring 2018 - Youtube](https://www.youtube.com/watch?v=8odFouBR2wE)
:::
:::


$$
\begin{aligned}
P(B)&=P(B\cap A) + P(B\cap \overline A)\\
    &=P(B\cap A) + P(B\cap \overline A)\\
    &=P(B|A)P(A)+P(B|\overline A)P(\overline A)\\
\end{aligned}
$$

$$
\begin{aligned}
\therefore 
P(A|B)&=\frac{P(A \cap B)}{P(B)}\\
      &=\frac{P(B|A)P(A)}{P(B|A)P(A)+P(B|\overline A)P(\overline A)}
\end{aligned}
$$

$$
P(A\cap B)=P(B|A)P(A)=P(A|B)P(B)
$$


### ì˜ˆì œ

[ì˜ìƒ ìë£Œ ](https://www.youtube.com/watch?v=Y4ecU7NkiEI&t=29s)
[ìŠ¬ê¸°ë¡œìš´ í†µê³„ìƒí™œ ë¸”ë¡œê·¸ ](https://statisticsplaybook.tistory.com/30)

ì˜ˆì œë¡œ ì•Œì•„ë³´ê¸° - ì´ˆì½œë¦¿ì„ ì¤€ ì½”ë‹ˆì˜ ë§ˆìŒ
í­ìˆ˜ëŠ” í‰ì†Œ ê´€ì‹¬ì´ ìˆë˜ ì½”ë‹ˆì—ê²Œì„œ ì´ˆì½œë¦¿ì„ ì„ ë¬¼ë°›ìŠµë‹ˆë‹¤. í­ìˆ˜ëŠ” ì´ˆì½œë¦¿ì„ ì¤€ ì½”ë‹ˆê°€ ë‚˜ë¥¼ ì¢‹ì•„í•˜ëŠ”ì§€ê°€ ê¶ê¸ˆí•˜ê¸° ë•Œë¬¸ì— ì´ê²ƒì„ í†µê³„ì ìœ¼ë¡œ í•´ë´…ë‹ˆë‹¤. ë¨¼ì € ìƒí™©ì„ ê°„ë‹¨íˆ ë‚˜íƒ€ë‚´ê¸° ìœ„í•´ì„œ ë‹¤ìŒ ë‘ ìƒí™©ì„ ê°€ì •í•©ë‹ˆë‹¤.

 

P(A) (ì‚¬ê±´ "í˜¸ê°"): ìƒëŒ€ë°©ì´ ë‚˜ë¥¼ ì¢‹ì•„í•œë‹¤. 

P(B) (ì‚¬ê±´ "ì´ˆì½œë¦¿"): ì´ˆì½œë¦¿ì„ ë°›ì•˜ë‹¤.

 
í­ìˆ˜ëŠ” ì‚¬ê±´ "í˜¸ê°"ì— ëŒ€í•œ í™•ë¥ , ì¦‰, ì½”ë‹ˆê°€ ë‚˜ë¥¼ ì¢‹ì•„í•  í™•ë¥ ì„ 50%, ì¢‹ì•„í•˜ì§€ ì•Šì„ í™•ë¥ ì„ 50%ë¡œ ê°€ì •í•©ë‹ˆë‹¤. ì¦‰, 
P(A)=0.5  ë¡œ í‘œí˜„ì´ ë  ê²ƒì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ì´ìœ ëŠ” í­ìˆ˜ëŠ” ì´ˆì½œë¦¿ì„ ì¤€ ì½”ë‹ˆ ë§ˆìŒì— ëŒ€í•œ ì•„ë¬´ëŸ° ì •ë³´ê°€ ì—†ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤!

**The Principle of Insufficient Reason(ì´ìœ ë¶ˆì¶©ë¶„ì˜ ì›ë¦¬): í•˜ë‚˜ì˜ ì‚¬ê±´ì„ ê¸°ëŒ€í• ë§Œí•œ ì–´ë–¤ ì´ìœ ê°€ ì—†ëŠ” ê²½ìš°ì—ëŠ” ê°€ëŠ¥í•œ ëª¨ë“  ì‚¬ê±´ì— ë™ì¼í•œ í™•ë¥ ì„ í• ë‹¹í•´ì•¼ í•œë‹¤ëŠ” ì›ì¹™.**

ì‰½ê²Œ ì´í•´í•˜ê¸° ìœ„í•˜ì—¬, ì£¼ë³€ì— 100ëª…ì˜ ì‚¬ëŒì´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤. ì´ìœ ë¶ˆì¶©ë¶„ì˜ ì›ë¦¬ì— ë”°ë¼ 50ëª…ì€ ëˆ„êµ°ê°€ë¡œë¶€í„° í˜¸ê°ì„ ë°›ê³  ìˆê³ , 50ëª…ì€ í˜¸ê°ì„ ì–»ê³  ìˆì§€ ì•Šê³  ìˆê² ë„¤ìš”!

 

ê·¸ë¦¬ê³  í­ìˆ˜ëŠ” ì¡°ì‚¬ë¥¼ í†µí•´ ë‘ ê°€ì§€ ì •ë³´ë¥¼ ì•Œê²Œë©ë‹ˆë‹¤.

* ì–´ë–¤ ì‚¬ëŒì´ ìƒëŒ€ë°©ì—ê²Œ í˜¸ê°ì´ ìˆì–´ì„œ ì´ˆì½œë¦¿ì„ ì¤„ í™•ë¥ ì€ 40%ì´ë‹¤. -> P(B|A)=0.4 
* ì–´ë–¤ ì‚¬ëŒì´ ìƒëŒ€ë°©ì—ê²Œ í˜¸ê°ì´ ì—†ì§€ë§Œ "ì˜ˆì˜ìƒ" ì´ˆì½œë¦¿ì„ ì¤„ í™•ë¥ ì€ 30%ì´ë‹¤. (ì–´ì¥ ê´€ë¦¬ ê·¸ë§Œã… ) -> P(B|Ac)=0.3
 

ì´ ì •ë³´ë¥¼ í† ëŒ€ë¡œ ì•„ë˜ ë‘ê°€ì§€ë¥¼ ìœ ì¶”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ìƒëŒ€ë°©ì—ê²Œ í˜¸ê°ì´ ìˆì§€ë§Œ ì´ˆì½œë¦¿ì„ ì£¼ì§€ ì•Šì„ í™•ë¥ ì€ 60%ì´ë‹¤. -> P(Bc|A)=0.6
í˜¸ê°ì´ ì—†ì–´ì„œ ì´ˆì½œë¦¿ì„ ì£¼ì§€ ì•Šì„ í™•ë¥ ì€ 70%ì´ë‹¤. -> P(Bc|Ac)=0.7

ì–»ì€ ì •ë³´ ì •ë¦¬í•´ë³´ê¸°
ìœ„ ë‚´ìš©ë“¤ì„ í† ëŒ€ë¡œ ìƒê°í•´ë³¼ ë•Œ, ìš°ë¦¬ëŠ” ì•„ë˜ì™€ ê°™ì´ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

* ê°ì„ ì–»ê³  ìˆëŠ” 50ëª… ì¤‘ 40%ì¸ 20ëª…ì€ ì´ˆì½œë¦¿ì„ ë°›ìŠµë‹ˆë‹¤.
* ê°ì„ ì–»ê³  ìˆëŠ” 50ëª… ì¤‘ 60%ì¸ 30ëª…ì€ ì´ˆì½œë¦¿ì„ ë°›ì§€ ëª»í•©ë‹ˆë‹¤.
* ê°ì˜ ëŒ€ìƒì´ ì•„ë‹Œ 50ëª… ì¤‘ 30%ì¸ 15ëª…ì€ ì˜ˆì˜ìƒ ì¤€ ì´ˆì½œë¦¿ì„ ë°›ìŠµë‹ˆë‹¤.
* ê°ì˜ ëŒ€ìƒì´ ì•„ë‹Œ 50ëª… ì¤‘ 70%ì¸ 35ëª…ì€ ì´ˆì½œë¦¿ì„ ë°›ì§€ ëª»í•©ë‹ˆë‹¤.

ì, ì´ì œ í­ìˆ˜ê°€ ê¶ê¸ˆí•œ P(ì´ˆì½œë¦¿ì„ ë°›ì•˜ì„ ë•Œ, ì´ˆì½œë¦¿ì„ ì¤€ ì‚¬ëŒì´ ë‚˜ë¥¼ ì¢‹ì•„í•  í™•ë¥ )ì„ ìœ„ì—ì„œ ì•½ì†í•œ ê¸°í˜¸ë¡œ í‘œí˜„í•œë‹¤ë©´ 
P(A|B) ìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ì´ê²ƒì€ í­ìˆ˜ê°€ ì¡°ì‚¬í•œ í™•ë¥ ,

$$
P(í˜¸ê°ì´ìˆì–´ì„œì´ˆì½œë¦¿ì„ì¤„í™•ë¥ )=P(B|A)
$$

ì—ì„œ ì¡°ê±´ê³¼ ê²°ê³¼ê°€ ë’¤ë°”ë€ ê²ƒì…ë‹ˆë‹¤. ì´ í™•ë¥ ì„ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ì •ë¦¬í•´ë´…ì‹œë‹¤.
ì‚¬ê±´ "í˜¸ê°" : ìƒëŒ€ë°©ì´ ë‚˜ë¥¼ ì¢‹ì•„í•œë‹¤ -> P(A) = 50% ì´ê³  (ì´ìœ ë¶ˆì¶©ë¶„ì˜ ì›ë¦¬, ì‚¬ì „ê°€ì •!),
ì‚¬ê±´ "ì´ˆì½œë¦¿" : ì´ˆì½œë¦¿ì„ ë°›ì•˜ë‹¤ -> P(B) = (20+15)/100 = 35% (ì •ë¦¬í•œ ë…¸ë€ìƒ‰ ë¶€ë¶„)ì…ë‹ˆë‹¤.
ì–´ë–¤ ì‚¬ëŒì´ ìƒëŒ€ë°©ì—ê²Œ í˜¸ê°ì´ ìˆì–´ì„œ ì´ˆì½œë¦¿ì„ ì¤„ í™•ë¥ ì€ 40%ì´ë‹¤. -> P(B|A)=40% (í­ìˆ˜ê°€ ì¡°ì‚¬í•œ ì •ë³´)

 

ì´ê²ƒì„ ë² ì´ì¦ˆì •ë¦¬ì˜ ìˆ˜ì‹ì— ë„£ì–´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

 

P(A|B)=P(B|A)âˆ—P(A)/P(B)=(0.4âˆ—0.5)/0.35=0.57 

ì´ë¼ëŠ” í™•ë¥ ì´ ë‚˜ì˜µë‹ˆë‹¤. ë”°ë¼ì„œ, í­ìˆ˜ëŠ” ì²˜ìŒì˜ ì´ìœ ë¶ˆì¶©ë¶„ì˜ ì›ë¦¬ë¡œ ê°€ì •í–ˆë˜, ìƒëŒ€ë°©ì´ ë‚˜ë¥¼ ì¢‹ì•„í•  í™•ë¥  50%(ì‚¬ì „í™•ë¥ ) 
P(A)ë¥¼ 57%(ì‚¬í›„í™•ë¥ ) P(A|B) ë¡œ ì—…ë°ì´íŠ¸ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

 

ì´ë²ˆ ê¸€ì˜ ê°€ì¥ ì¤‘ìš”í•œ ìš”ì§€ëŠ”, ë² ì´ì¦ˆ ì •ë¦¬ë¼ëŠ” ê²ƒì€ ìƒˆë¡œìš´ ì •ë³´ë¥¼ í†µí•´ ì‚¬ì „ í™•ë¥ ì„ ì—…ë°ì´íŠ¸ í•˜ì—¬ ì‚¬í›„ í™•ë¥ ì— ëŒ€í•œ ì •í™•ë„ë¥¼ ë†’ì—¬ê°€ëŠ” ê²ƒì´ë¼ëŠ” ì ì…ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ëŸ¬í•œ ê°œë…ë“¤ì´ ì–´ë–»ê²Œ ë°ì´í„° ë¶„ì„ì— í™œìš©ë  ìˆ˜ ìˆëŠ”ì§€ í•œ ë²ˆ ìƒê°í•´ë³´ê³ ì í•©ë‹ˆë‹¤. 

 

í˜¹ì‹œ ë‚´ìš©ì— ì˜¤ë¥˜ê°€ ìˆë‹¤ë©´ ì–¸ì œë“ ì§€ ëŒ“ê¸€/í”¼ë“œë°± ë‹¬ì•„ì£¼ì„¸ìš” ğŸ† ì˜ëª»ëœ ë‚´ìš© ì•Œë ¤ì£¼ì‹œëŠ” ê²ƒ ì–¸ì œë‚˜ í™˜ì˜ì…ë‹ˆë‹¤ ğŸ‘©â€ğŸš€


## Generalized Bayes' Rule

::: {#thm-general}

Let $A_1, A_2, ..., A_k$ be a set of mutually exclusive and exhaustive events. Let $A$ be a event, then 

$$
P(A_i|B)=\frac{P(B|A_i)P(A_i)}{\sum_{j=1}^{k}P(B|A_i)P(A_i)}
$$

:::

::: {#thm-classic}

If in $N$ identical and independent repeated experiments, an event $A$ happens $n$ times, the the probability of $A$ is defined by
$$
P(A)=\lim_{N\to\infty}\frac{n}{N}
$$

:::

* The case of the sample space consisting of $N$ distinctive not equally likely elements,
* The case of the uncountable sample space 
*
*
*
*
*
*
*
*
*
*
*
:::
</div>

<div class="tab-pane fade" id="English" role="tabpanel" aria-labelledby="English-tab">

::: {#English .tab-pane .fade role="tabpanel" aria-labelledby="English-tab"}


Bayes' rule provides a formula how to calculate $P(A|B)$ if $P(B|A)$, $P(B|\overline{A})$, $P(A)$ are available
:::


</div>



## Blog Guide Map Link

* [Statistics Blog](../guide_map/index.qmd)
* [Engineering Blog](../../Engineering/guide_map/index.qmd)
* [Deep Learning Blog](../../DL/guide_map/index.qmd)
* [Machine Learning Blog](../../ML/guide_map/index.qmd)
* [Mathematics Blog](../../Mathmatics/guide_map/index.qmd)
* [Patent Blog](../../Patent/guide_map/index.qmd)
* [Validation Blog](../../Validation/guide_map/index.qmd)



