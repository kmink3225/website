<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kwangmin Kim">
<meta name="dcterms.date" content="2023-02-05">
<meta name="description" content="Probability for statistics, machine learning and deep learning. Studying conditional probability is fundamental to stochastic processes, reinforcement learning, and naive Bayes classification, so it’s important to understand the concept.">

<title>Kwangmin Kim - Conditional Probability &amp; Bayes’ Rule</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../../">
<script src="../../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../../.././images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../../../index.html">
    <span class="navbar-title">Kwangmin Kim</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../docs/CV/index.html">
 <span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../docs/projects/index.html">
 <span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../docs/blog/index.html">
 <span class="menu-text">Blog</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../../about.html">
 <span class="menu-text">Me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/kmink3225"><i class="bi bi-github" role="img" aria-label="Github">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/kwangmin-kim-a5241b200/"><i class="bi bi-linkedin" role="img" aria-label="Linkedin">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../docs/blog/index.html"><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text">Blog</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#blog-guide-map-link" id="toc-blog-guide-map-link" class="nav-link active" data-scroll-target="#blog-guide-map-link"><span class="toc-section-number">6</span>  Blog Guide Map Link</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Conditional Probability &amp; Bayes’ Rule</h1>
<p class="subtitle lead">Conditional Probability, Bayes’ Rule, Bayesean Statistics, Frequentist Statistics, Deductive Method, Inductive Method, Proof by Contratiction, Hypothetical Deductive Method, Total Probability Rule, Naive Bayes</p>
  <div class="quarto-categories">
    <div class="quarto-category">Statistics</div>
  </div>
  </div>

<div>
  <div class="description">
    <p>Probability for statistics, machine learning and deep learning. Studying conditional probability is fundamental to stochastic processes, reinforcement learning, and naive Bayes classification, so it’s important to understand the concept.</p>
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Kwangmin Kim </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 5, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<ul class="nav nav-pills" id="language-tab" role="tablist">
<li class="nav-item" role="presentation">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" role="tab" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item" role="presentation">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" role="tab" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" role="tabpanel" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" role="tabpanel" aria-labelledby="Korean-tab">
<section id="conditional-probability" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="conditional-probability"><span class="header-section-number">1</span> Conditional Probability</h2>
<p>조건부 확률은 조건이 주어졌을 때 한 사건이 발생할 확률이며 하나의 사건이 다른 사건에 영향을 미쳐 그 확률값이 달라지는 것을 의미한다. 즉, 한 사건, B가 조건으로 주어지고 다른 사건A가 발생할 확률 <span class="math inline">\(P(A|B)\)</span> 가 사건 A가 발생할 확률 <span class="math inline">\(P(A)\)</span> 와 다르다는 것을 의미한다 (<span class="math inline">\(P(A)\not=P(A|B)\)</span>).</p>
<p>예를 들어, 주사위를 던질 때 특정 주사위의 눈 (1~6)이 나올 확률은 <strong><span class="math inline">\(\frac{1}{6}\)</span> 으로 같다 (eqaully likely)라고 가정할 때</strong> 주사위의 눈이 나올 수 있는 모든 집합 표본 공간 <span class="math inline">\(S\)</span> 에 대한 특정 주사위의 눈이 나오는 사건 <span class="math inline">\(A\)</span> 가 발생할 확률은 <span class="math inline">\(\frac{n(A)}{n(S)}\)</span> 와 같다. 다시 말해서, 조건부 확률은 2개 이상의 사건에 대해서 하나의 사건이 다른 사건이 발생할 확률에 영향을 미치는 개념을 말한다. 가장 간단한 2개의 사건 <span class="math inline">\(A, B\)</span> 에 대해서 살펴볼 때 조건부 확률은 다음과 (<a href="#eq-conditional_probability">Equation&nbsp;1</a>)과 같다.</p>
<div id="def-conditional_probability" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 </strong></span>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are events in sample space <span class="math inline">\(S\)</span>, and <span class="math inline">\(P(B)&gt;0\)</span>, then the conditional probability of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span>, written <span class="math inline">\(P(A|B)\)</span>, is <span id="eq-conditional_probability"><span class="math display">\[
P(A|B)=\frac{P(A\cap B)}{P(B)}
\tag{1}\]</span></span></p>
</div>
<p>위의 정의에서 볼 수 있듯이, sample space <span class="math inline">\(S\)</span> 가 B로 update 되어 P(B|B)=1이 되고 사건 A의 outcome이 B에 관해서 조정된다.</p>
<p>예를 들어, 사건 <span class="math inline">\(A\)</span> 는 주사위의 눈이 1이 나오는 사건, 사건 <span class="math inline">\(B\)</span> 는 주사위의 눈이 3 이하가 나오는 사건이라고 했을 때 사건 <span class="math inline">\(A\)</span> 가 사건 <span class="math inline">\(B\)</span> 의 부분 집합이므로 두 사건이 서로 독립이 아니다. 즉, $ AB $ 사건에서 주사위의 눈이 1 나오는 경우 밖에 없다. 이렇게 사건 <span class="math inline">\(B\)</span> 가 주어졌을 때 혹은 <span class="math inline">\(B\)</span> 가 먼저 일어났을 때 1이 나올 확률은 달라지게 된다. 즉, <span class="math inline">\(A\)</span> 의 sample space = <span class="math inline">\(\{1,2,3,4,5,6\}\)</span> 이고 <span class="math inline">\(A|B\)</span> 의 sample space = <span class="math inline">\(\{1,2,3\}\)</span> 이 되기 때문에 <span class="math inline">\(P(A) \not= P(A|B)\)</span> 가 된다.</p>
<p>좀 더 구체적으로 계산을 하게 되면, <span class="math inline">\(P(A)=\frac{1}{6}, P(B)=\frac{3}{6}, P(A\cap B)=\frac{1}{6}\)</span> 일 때,</p>
<p><span class="math display">\[
P(A|B)=\frac{P(A\cap B)}{P(B)}=\frac{\frac{1}{6}}{\frac{3}{6}}=\frac{1}{3}
\]</span></p>
<p>인 것을 알 수 있다.</p>
<p>사건 A, B가 독립일 때 두 두사건이 동시에 발생할 확률은 <span class="math inline">\(P(A \cap B)=P(A)P(B)=P(B)P(A)\)</span> 이다. 반면에, 두 사건이 독립이 아니라면 <a href="#eq-conditional_probability">Equation&nbsp;1</a> 을 이용하여 <span class="math inline">\(P(A \cap B)\)</span> 는 <span class="math inline">\(P(B|A)P(A)\)</span> 또는 <span class="math inline">\(P(A|B)P(B)\)</span> 로 표현될 수 있다.독립일 때 동시에 발생할 확률에서 <span class="math inline">\(P(A)\)</span> 가 B를 조건으로 봤을 때 동시에 발생할 확률 <span class="math inline">\(P(A|B)\)</span> 로 바뀐 것을 볼 수 있다.</p>
</section>
<section id="bayes-rule" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="bayes-rule"><span class="header-section-number">2</span> Bayes’ Rule</h2>
<p>Bayes’ rule (베이즈 정리)는 prior probability(사전 확률)과 posterior probability(사후 확률)의 관계를 조건부 확률을 이용하여 확립한 것이다.</p>
<ul>
<li>prior probability(사전 확률)는 데이터를 얻기 전 연구자의 가설이 들어간 일종의 사건 발생의 신뢰도로 해석하기도 하고 prior probability density function (사전 확률 밀도 함수) 라고도 표현된다.</li>
<li>posterior probability(사후 확률)는 데이터가 주어진 후 연구자의 가설이 들어간 사건 발생의 신뢰도로 해석하기도 하고 posterior probability desnsity function(사후 확률 밀도 함수) 라고도 표현된다.</li>
</ul>
<p>좀 더 구체적으로, 2개의 사건 A와 B로 한정시켜 생각해봤을 때, 조건부 확률 <span class="math inline">\(P(A|B)\)</span> 는 각 사건의 확률 <span class="math inline">\(P(A), P(B), P(B|A)\)</span> 를 사용하여 게산될 수 있다. 그래서 베이즈 정리는 <span class="math inline">\(P(B|A)\)</span>, <span class="math inline">\(P(B|\overline{A})\)</span>, <span class="math inline">\(P(A)\)</span> 의 정보를 알고있거나 계산 가능할 때 아래와 같은 <span class="math inline">\(P(A|B)\)</span> 의 확률을 구할 수 있는 공식을 제공한다(<a href="#eq-Bayes_rule">Equation&nbsp;2</a>).</p>
<section id="activating-schema" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="activating-schema"><span class="header-section-number">2.1</span> Activating Schema</h3>
<p>Bayes’ rule을 좀 더 직관적으로 이해하기 위해선 Bayes’ rule와 연관된 친숙한 개념들을 상기시킬 필요가 있다. 우리에게 친숙한 개념인 연역법과 귀납법에 대해서 간단이 살펴본다.</p>
<section id="deduction-vs-induction-method" class="level4" data-number="2.1.1">
<h4 data-number="2.1.1" class="anchored" data-anchor-id="deduction-vs-induction-method"><span class="header-section-number">2.1.1</span> Deduction vs Induction Method</h4>
<section id="deduction-method" class="level5" data-number="2.1.1.1">
<h5 data-number="2.1.1.1" class="anchored" data-anchor-id="deduction-method"><span class="header-section-number">2.1.1.1</span> Deduction Method</h5>
<p>연역법 (deduction method or deductive reasoning)는 하나 (=대전제) 또는 둘 이상의 명제(=대전제+소전제들)를 전제로 하여 명확한 논리에 근거해 새로운 명제(결론)를 도출하는 방법이다. 보통 일반적인 명제에서 구체적인 명제로 도출해내는 방식으로 연역법을 설명하기도 한다. 연역법은 전제와 결론의 타당성보다는 결론을 이끌어내는 논리 전개에 엄격함을 요구한다. 그래서 명쾌한 논리가 보장된다면 연역적 추론의 결론은 그 전제들이 결정적 근거가 되어 전제와 결론이 필연성을 갖게 된다. 따라서, 전제가 진리(=참)이면 결론도 항상 진리(=참)이고 전제가 거짓이면 결론도 거짓으로 도출된다. 하지만, 모든 연역적 추론에서 출발되는 최초의 명제가 결코 연역에 의해 도출될 수 없다는 약점을 갖고있다. 즉, 반드시 검증된 명제를 대전제로 하여 연역적 추리를 시작해야한다. <a href="https://terms.naver.com/entry.naver?docId=1126605&amp;cid=40942&amp;categoryId=31530">Source: naver encyclopedia -deductive method</a> (cf.&nbsp;<a href="https://en.wikipedia.org/wiki/Proof_by_contradiction">귀류법</a>)</p>
<p>예를 들어, 아리스토텔레스의 삼단논법의 논리 형식이 가장 많이 인용이 된다. 대전제와 소전제가 하나씩있는 둘 이상의 명제로부터 결론이 도출되는 예를 살펴보자.</p>
<ol type="1">
<li>대전제: 모든 사람은 죽는다.</li>
<li>소전제: 소크라테스는 사람이다.</li>
<li>결론: 그러므로 소크라테스도 죽는다.</li>
</ol>
</section>
<section id="induction-method" class="level5" data-number="2.1.1.2">
<h5 data-number="2.1.1.2" class="anchored" data-anchor-id="induction-method"><span class="header-section-number">2.1.1.2</span> Induction Method</h5>
<p>귀납법 (deduction method or deductive reasoning)은 전제와 결론을 뒷받침하는 논리에 의해 그 타당성이 평가된다. 귀납적 추론은 관찰과 실험에서 얻은 특수한 사례 (= data)를 근거로 전체에 적용시키는 <strong>귀납적 비약</strong>을 통해 이루어진다. 이와 같이 귀납에서 얻어진 결론은 일정한 개연성을 지닐 뿐이며, 특정 data에 따라 귀납적 추론의 타당성에 영향을 미친다. 그러므로, 검증된 data가 많을 수록 신뢰도와 타당성이 증가한다는 특징이 있다.하지만, 귀납적 추론의 결론이 진리인 것은 아니다. <a href="https://terms.naver.com/entry.naver?docId=1068410&amp;cid=40942&amp;categoryId=31530">Source: naver encyclopedia - inductive method</a></p>
<ol type="1">
<li>특수한 사례 (or data): 소크라테스는 죽었다, 플라톤도 죽었다, 아리스토텔레스도 죽었다.</li>
<li>소전제: 소크라테스는 사람이다.</li>
<li>결론: 그러므로 소크라테스도 죽는다.</li>
</ol>
<p>위와 같이 연역적 추론과 귀납적 추론은 서로 반대되는 개념으로 각 각 강점과 약점이 있으며 현실에서는 서로 상호 보완적으로 쓰이고 있다. 따라서, 전제로 삼는 대전제 역시 검증 과정이 필요하고 그 가설에서 몇 개의 명제를 연역해 실험과 관찰 등을 수행하는 가설연역법(hypothetical deductive method)이 널리 쓰이고 있다.</p>
</section>
</section>
<section id="frequentism-vs-bayeseanism" class="level4" data-number="2.1.2">
<h4 data-number="2.1.2" class="anchored" data-anchor-id="frequentism-vs-bayeseanism"><span class="header-section-number">2.1.2</span> Frequentism vs Bayeseanism</h4>
<p>통계학에선 모수(parameter)를 추정하는 여러 방법론들이 있는데 이번 블로그에서는 Frequentism와 Bayeseanism, 이 2가지 방법론에 초점을 둔다.</p>
<section id="frequentism-frequentist-statistics" class="level5" data-number="2.1.2.1">
<h5 data-number="2.1.2.1" class="anchored" data-anchor-id="frequentism-frequentist-statistics"><span class="header-section-number">2.1.2.1</span> Frequentism (frequentist statistics)</h5>
<p>통계학에서 가장 널리쓰이고 있는 방법론으로, 연역법에 근거한 결론 도출 방식을 이용한다. 간단히 말하면, 이미 알려진 분포에서 연구자의 관측치가 발생할 확률을 관찰하여 결론을 유도 하는 방법이다. p-value에 의한 결론 도출방식이 그 대표적인 예이다. 연구자의 데이터가 여러 수학자와 통계학자들이 증명해 놓은 분포하에서 발생한 사실이 입증이 됐을 때 연구자의 관측치가 그 named distribution(like normal distribution)에서 발생할 확률이 낮을 수록 p-value가 작아지고 일정 유의수준에 따라 연구자는 귀무가설을 기각하는 논리방식을 따른다.</p>
</section>
<section id="bayeseanism" class="level5" data-number="2.1.2.2">
<h5 data-number="2.1.2.2" class="anchored" data-anchor-id="bayeseanism"><span class="header-section-number">2.1.2.2</span> Bayeseanism</h5>
<p>통계학에서 역시 많이 쓰이는 방법론으로, 귀납법에 근거한 결론 도출 방식을 이용한다. 간단히 말하면, 확률을 확률변수가 갖는 sample space에 대한 특정 사건이 발생한 사건의 비로 보는 것 (equally likely라고 가정)이 아니라 내가 설정한 가설에 대한 신뢰도로 바라보는 것이다. 따라서, 사전에 이미 알고있는 데이터가 있어 사전 확률 (prior probability)을 알고있고 이 사전 확률이 추가적인 data에 의해 조정되는 사후 확률 (posterior probability)이 계산된다. 이때 사전 확률자체보다는 추가적인 data와 사후 확률을 계산하는데 사용되는 likelihood의 타당성이 더 중요하다. 더 구체적인 내용은 Bayesean statistics에 기본이 되는 Bayes’ rule에서 살펴보기로 한다.</p>
<p><a href="https://www.redjournal.org/article/S0360-3016(21)03256-9/fulltext">source: Frequentism vs Bayeseanism</a></p>
</section>
</section>
</section>
<section id="bayes-rule-formula" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="bayes-rule-formula"><span class="header-section-number">2.2</span> Bayes’ Rule Formula</h3>
<div id="thm-Bayes" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 </strong></span><span id="eq-Bayes_rule"><span class="math display">\[
\begin{aligned}
P(A|B)&amp;=\frac{P(B|A)P(A)}{P(B)}\\
      &amp;=\frac{P(B|A)P(A)}{P(B|A)P(A)+P(B|\overline A)P(\overline A)}
\end{aligned}
\tag{2}\]</span></span></p>
</div>
<ul>
<li><span class="math inline">\(P(A|B)\)</span>: posterior probability, B(data)가 주어졌을때 가설 A에 대한 신뢰도</li>
<li><span class="math inline">\(P(A)\)</span>: prior probability, 가설 A에대한 신뢰도</li>
<li><span class="math inline">\(P(B|A)\)</span>: likelihood, 가설 A가 주어졌을때 B(Data)가 발생할 신뢰도</li>
<li><span class="math inline">\(P(B)\)</span>: marginal probability, Data의 신뢰도</li>
</ul>
<p><a href="#eq-Bayes_rule">Equation&nbsp;2</a> 의 두 분째 등식을 이해하기 위해선, Law of Total Probability (전 확률 법칙) 또는 Total Probability Rule (전 확률 정리)을 이해해야한다.</p>
</section>
<section id="total-probability-rule" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="total-probability-rule"><span class="header-section-number">2.3</span> Total Probability Rule</h3>
<div id="thm-general" class="theorem">
<p><span class="theorem-title"><strong>Theorem 2 </strong></span>Let <span class="math inline">\(A_1, A_2, ..., A_k\)</span> be a set of mutually exclusive and exhaustive events. Let <span class="math inline">\(A\)</span> be a event and a partition of sample space <span class="math inline">\(\Omega\)</span>, then</p>
<p><span class="math display">\[
P(B)=\sum_{i=1}^{n}P(B|A_i)P(A_i)
\]</span></p>
</div>
<div class="columns">
<div class="column" style="width:50%;">
<div id="fig-two_events" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="law of total probability2.PNG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Law of Total Probability Example - Two Events</figcaption><p></p>
</figure>
</div>
<p><a href="https://byjus.com/maths/total-probability-theorem/">Source: Law of ToTal Probability with Proof</a></p>
</div><div class="column" style="width:50%;">
<div id="fig-multiple_events" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="law of total probability.PNG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;2: Law of Total Probability Example - Multiple Events</figcaption><p></p>
</figure>
</div>
<p><a href="https://www.youtube.com/watch?v=8odFouBR2wE">Source: MIT RES.6-012 Introduction to Probability, Spring 2018 - Youtube</a></p>
</div>
</div>
<p><span id="eq-total_conditional_probability"><span class="math display">\[
\begin{aligned}
P(B)&amp;=P(B\cap A) + P(B\cap \overline A)\\
    &amp;=P(B\cap A) + P(B\cap \overline A)\\
    &amp;=P(B|A)P(A)+P(B|\overline A)P(\overline A)\\
P(A\cap B)&amp;=P(B|A)P(A)=P(A|B)P(B)\\
\therefore
P(A|B)&amp;=\frac{P(A \cap B)}{P(B)}\\
      &amp;=\frac{P(B|A)P(A)}{P(B|A)P(A)+P(B|\overline A)P(\overline A)}
\end{aligned}
\tag{3}\]</span></span></p>
<p>Law of total probability 를 이용하여 Bayes’ rule이 <a href="#eq-total_conditional_probability">Equation&nbsp;3</a> 와 같이 변형되었다. 최종식을 보면 좀 더 직관적인 해석이 가능해지는데 P(B) 가 A와의 교집합 확률의 총합이 되면서 분자가 그 일부가 되는 비율의 개념으로 해석될 수 있다. <a href="#fig-two_events">Figure&nbsp;1</a> 를 보면 <span class="math inline">\(P(A|B)=\frac{P(B \cap A)}{P(B)}=\frac{P(B \cap A)}{P(B \cap A)+P(B \cap \overline A)}\)</span> 로 표현되는 것을 볼 수 있다. 그 것을 조금 더 일반화 한 경우는 <a href="#fig-multiple_events">Figure&nbsp;2</a> 를 참고하여 유추할 수 있다.</p>
</section>
<section id="notation" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="notation"><span class="header-section-number">2.4</span> Notation</h3>
<p><span class="math display">\[
\begin{aligned}
P(A|B)&amp;=\frac{P(B|A)P(A)}{P(B|A)P(A)+P(B|\overline A)P(\overline A)}\\
P(\theta|x)&amp;=\frac{P(x|\theta)P(\theta)}{P(x|\theta)P(\theta)+P(x|\overline \theta)P(\overline \theta)}
\end{aligned}
\]</span></p>
<p>많은 참고 문헌에서 사건 A, B를 모수, <span class="math inline">\(\theta\)</span> 와 data, <span class="math inline">\(x\)</span> 로 표현하기도 한다. 즉, data <span class="math inline">\(x\)</span> 가 주어졌을 때 모수 <span class="math inline">\(\theta\)</span> 가 발생할 확률이 data에 의해서 update된다.</p>
<ul>
<li><span class="math inline">\(P(\theta)\)</span>
<ul>
<li>prior probability density function</li>
<li>데이터없이 초기에 임시로 부여된 모델 또는 모수의 확률</li>
</ul></li>
<li><span class="math inline">\(P(x|\theta)\)</span>
<ul>
<li>likelihood</li>
<li>초기에 임시로 부여된 모델 또는 모수가 주어졌을 때 data x가 발생할 우도</li>
<li>좀 더 파격적으로 해석하면, 초기에 임시로 부여된 모델 또는 모수가 data x에 들어맞을(or fittng) 확률</li>
</ul></li>
<li><span class="math inline">\(P(x)\)</span>
<ul>
<li>marginal proability</li>
<li>데이터가 발생할 확률로 <span class="math inline">\(\theta\)</span> 와 상관없기 때문에 상수로 취급한다.</li>
</ul></li>
<li><span class="math inline">\(P(\theta|x)\)</span>
<ul>
<li>posterior probability density function</li>
<li>data가 주어졌을 때 모델 또는 모수의 확률</li>
<li>Bayes’ Rule에 의한 최적화에서 다음 최적화 iteration에서 Prior로 쓰인다.</li>
</ul></li>
</ul>
<p><span class="math inline">\(P(x)\)</span> 는 상수이기 때문에 생략가능 하여 아래의 식과 같이 정리 할 수 있다. <span class="math display">\[
P(\theta|x)\propto P(x|\theta)P(\theta)
\]</span></p>
<p><span class="math inline">\(P(\theta|x)\)</span> 는 <span class="math inline">\(P(x|\theta)P(\theta)\)</span> 에만 영향을 받는 것을 볼 수 있다.</p>
</section>
<section id="예제" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="예제"><span class="header-section-number">2.5</span> 예제</h3>
<p>펭수는 평소 관심이 있던 코니에게서 초콜릿을 선물받았다. 펭수는 초콜릿을 준 코니가 나를 좋아하는지가 궁금하기 때문에 이것을 통계적으로 계산해본다.</p>
<p>펭수는 먼저 다음 두 상황을 가정한다.</p>
<ul>
<li><span class="math inline">\(P(like)=0.5\)</span>
<ul>
<li>코니가 펭수를 좋아한다는 가설의 신뢰도는 반 반이다. 즉, 정보없는 상태에서의 펭수의 prior probability.</li>
<li>0.5로 설정한 이유는 다음의 원리를 따랐다. <strong>The Principle of Insufficient Reason(이유불충분의 원리- 하나의 사건을 기대할만한 어떤 이유가 없는 경우에는 가능한 모든 사건에 동일한 확률을 할당해야 한다는 원칙).</strong></li>
</ul></li>
<li><span class="math inline">\(P(choco)\)</span>
<ul>
<li>초콜릿을 받았다라는 data가 발생할 신뢰도</li>
</ul></li>
</ul>
<p><strong>펭수는 코니에게 자신을 좋아하는지 알 길이 없으니 사람이 호감이 있을 때에 대한 초콜릿 선물 데이터를 조사</strong>하기 시작한다. 즉, 호감의 근거는 초콜릿으로 한정했고 초콜릿 선물 방식의 불확실성을 호감으로 설명하는 문헌을 찾기 시작했다. 그리고 펭수는 도서관에 있는 일반인 100명을 대상으로 초콜릿과 호감과의 관계를 연구한 <em>초콜릿과 호감</em> 논문을 통해 두 가지 정보를 알게된다.</p>
<ul>
<li>일반적으로, 어떤 사람이 상대방에게 호감이 있어서 초콜릿을 줄 확률은 <span class="math inline">\(40%\)</span> 이다. 즉, <span class="math inline">\(P(choco|like)=0.4\)</span></li>
<li>일반적으로, 어떤 사람이 상대방에게 호감이 없지만 <em>예의상</em> 초콜릿을 줄 확률은 <span class="math inline">\(30%\)</span> 이다. 즉, <span class="math inline">\(P(choco|\overline{like})=0.3\)</span></li>
<li>위의 2가지 정보로 유추 가능한 정보
<ul>
<li><span class="math inline">\(P(\overline{choco}|like)=0.6\)</span></li>
<li><span class="math inline">\(P(\overline{choco}|\overline{like})=0.7\)</span></li>
</ul></li>
<li>초콜릿에 관한 조사를 토대로 얻은 4가지 정보로 유추할 수 있는 정보
<ul>
<li><span class="math inline">\(P(choco|like)=0.4\)</span>: like를 받고 있는 50명 중 <span class="math inline">\(40%\)</span> 인 20명은 초콜릿을 받는다.</li>
<li><span class="math inline">\(P(\overline{choco}|like)=0.6\)</span>: like를 받고 있는 50명 중 <span class="math inline">\(60%\)</span> 인 30명은 초콜릿을 받지 못한다.</li>
<li><span class="math inline">\(P(choco|\overline{like})=0.3\)</span>: like를 받지 않는 50명 중 <span class="math inline">\(30%\)</span> 인 15명은 예의상 준 초콜릿을 받는다.</li>
<li><span class="math inline">\(P(\overline{choco}|\overline{like})=0.7\)</span>: like를 받지 않는 50명 중 <span class="math inline">\(70%\)</span> 인 35명은 초콜릿을 받지 못한다.</li>
</ul></li>
</ul>
<p>펭수의 관점으로 정보를 재분류</p>
<ul>
<li>펭수가 궁금한 정보
<ul>
<li><span class="math inline">\(P(like|choco)=?\)</span>, posterior probability</li>
</ul></li>
<li>펭수가 가정한 정보
<ul>
<li><span class="math inline">\(P(like)=0.5\)</span>, prior probability by <strong>The Principle of Insufficient Reason</strong></li>
</ul></li>
<li>펭수가 조사한 정보
<ul>
<li><span class="math inline">\(P(choco|like)=0.4\)</span>, likelihood</li>
<li><span class="math inline">\(P(choco)\)</span>: marginal probability
<ul>
<li><span class="math inline">\(P(choco)=P(choco|like)+P(choco|\overline{like})=\frac{20+15}{100}=0.35\)</span></li>
</ul></li>
</ul></li>
</ul>
<p>위의 정리한 정보를 Bayes’ rule에 대입하면,</p>
<p><span class="math display">\[
P(like|choco)=\frac{P(choco|like)\times P(like)}{P(choco)}=\frac{0.4\times 0.5}{0.35}=0.57
\]</span></p>
<p>펭수의 prior probability(<span class="math inline">\(P(A)=0.5\)</span>)가 posterior probability(<span class="math inline">\(P(A|B)=0.57\)</span>)로 업데이트 될 수 있다. <em>초콜릿과 호감</em> 논문을 읽고 코니가 자신을 좋아할 확률이 높아진 것에 대해 기대감을 얻은 용기가 없는 펭수는 100명 보다 더 많은 독립적인 사람들로 실험한 논문을 찾아 다시 자신의 업데이트 된 사전 확률을 계속해서 업데이트할 생각이다. 그리고 자신의 사전 확률을 추가적인 데이터를 갖고 사후 확률로 계속해서 업데이트시켜 정확한 확률을 구한다.</p>
<p>위의 예시는 <a href="https://www.youtube.com/watch?v=Y4ecU7NkiEI&amp;t=29s">영상 자료: 초콜릿을 준 코니의 마음</a>을 시청하고 영감을 얻은 슬기로운 통계생활 tistory에 있는 <a href="https://statisticsplaybook.tistory.com/30">Source: 베이즈 정리(Bayes’ rule) 완벽히 정리하기 슬기로운 통계생활 블로그</a>를 요약 및 약간의 각색을 한 것이다.</p>
</section>
</section>
<section id="generalized-bayes-rule" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="generalized-bayes-rule"><span class="header-section-number">3</span> Generalized Bayes’ Rule</h2>
<div id="thm-general" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3 </strong></span>Let <span class="math inline">\(A_1, A_2, ..., A_k\)</span> be a set of mutually exclusive and exhaustive events. Let <span class="math inline">\(A\)</span> be a event, then</p>
<p><span class="math display">\[
P(A_i|B)=\frac{P(B|A_i)P(A_i)}{\sum_{j=1}^{k}P(B|A_i)P(A_i)}
\]</span></p>
</div>
</section>
<section id="maximum-a-posterior-estimation-map" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="maximum-a-posterior-estimation-map"><span class="header-section-number">4</span> Maximum a Posterior Estimation (MAP)</h2>
<p>Maximum a posterior estimation는 statistical estimation methods의 큰 기둥 중 하나인 maximum likelihood estimation과 더불어 parameter <span class="math inline">\(\theta\)</span> 를 추정하는데 많이 사용되는 방법론이다. 사후 확률 밀도 함수 <span class="math inline">\(f(x|\theta)\)</span> 또는 <span class="math inline">\(P(x|\theta)\)</span> 를 최대화하는 <span class="math inline">\(\theta\)</span> 의 추정치를 구하는 방법이며 아래와 같은 argument로 표현할 수 있다.</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\theta}&amp;=\arg \max_{\theta}\frac{f(x|\theta)f(\theta)}{\int f(x|\theta)f(\theta)}\\
            &amp;\propto\arg \max_{\theta}f(x|\theta)f(\theta)
\end{aligned}
\]</span></p>
<p>최대 우도 추정량과 달리 최대 사후 추정량에는 최대화하는 식에 사전 확률이 추가되어 있는 것을 볼 수 있다. 그러므로 분자 부분인 <span class="math inline">\(f(x|\theta)f(\theta)\)</span> 만을 최대화 한다. 분모 부분인 <span class="math inline">\(\int f(x|\theta)f(\theta)\)</span> nomarlizing penalty 또는 constant로 간주한다. 여기서 <span class="math inline">\(P(\theta)\)</span> 초기 가정치 인데 아무렇게나 설정하기 보다는 good estimate로 설정해야 통계학자들로부터의 공격을 최소화시킬 수 있다. MAP는 나이브 베이즈의 알고리즘의 핵심이다.</p>
<p>[참고] 최대 우도 추정량 <span class="math display">\[
\begin{aligned}
\hat{\theta}=\arg \max_{\theta}L(x|\theta)=\arg \max_{\theta}\Pi_{i=1}^{n}f(x|\theta)
\end{aligned}
\]</span></p>
</section>
<section id="naive-bayes-classifier" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="naive-bayes-classifier"><span class="header-section-number">5</span> Naive Bayes Classifier</h2>
<p>Naive Bayes에 대한 구체적인 글은 <a href="../../../../../docs/blog/posts/ML/2023-02-06_naive_bayes/index.html">다른 블로그</a>에 소개한다. Naive Bayes는 Bayes’ Rule을 이용해 <span class="math inline">\(\theta\)</span> 를 최적화 시킨다. Naive Bayes의 Naive는 features 또는 explanotry variables이 서로 conditionally indepdent라고 가정한 것에서 이름 붙여졌다.</p>
</section>
</div>
</div>
<div id="English" class="tab-pane fade" role="tabpanel" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" role="tabpanel" aria-labelledby="English-tab">
<p>Bayes’ rule provides a formula how to calculate <span class="math inline">\(P(A|B)\)</span> if <span class="math inline">\(P(B|A)\)</span>, <span class="math inline">\(P(B|\overline{A})\)</span>, <span class="math inline">\(P(A)\)</span> are available</p>
</div>
</div>
<section id="blog-guide-map-link" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="blog-guide-map-link"><span class="header-section-number">6</span> Blog Guide Map Link</h2>
<ul>
<li><a href="../../../../../docs/blog/posts/statistics/guide_map/index.html">Statistics Blog</a></li>
<li><a href="../../../../../docs/blog/posts/Engineering/guide_map/index.html">Engineering Blog</a></li>
<li><a href="../../../../../docs/blog/posts/DL/guide_map/index.html">Deep Learning Blog</a></li>
<li><a href="../../../../../docs/blog/posts/ML/guide_map/index.html">Machine Learning Blog</a></li>
<li><a href="../../../../../docs/blog/posts/Mathmatics/guide_map/index.html">Mathematics Blog</a></li>
<li><a href="../../../../../docs/blog/posts/Patent/guide_map/index.html">Patent Blog</a></li>
<li><a href="../../../../../docs/blog/posts/Validation/guide_map/index.html">Validation Blog</a></li>
</ul>


</section>

</div></ul></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>