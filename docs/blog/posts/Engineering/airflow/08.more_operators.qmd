---
title: "More Operators"
subtitle: DAG Creation, Bash Operator, Task Performance Subject, 
description: |
  template
categories:
  - Engineering
author: Kwangmin Kim
date: 05/01/2023
format: 
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
comments: 
  utterances: 
    repo: ./docs/comments
draft: False
---

<ul class="nav nav-pills" id="language-tab" role="tablist">
  <li class="nav-item" role="presentation">
    <button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" role="tab" aria-controls="Korean" aria-selected="true">Korean</button>
  </li>
  <li class="nav-item" role="presentation">
    <button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" role="tab" aria-controls="knitr" aria-selected="false">English</button>
  </li>

<div class="tab-content" id="language-tabcontent">

<div class="tab-pane fade  show active" id="Korean" role="tabpanel" aria-labelledby="Korean-tab">

::: {#Korean .tab-pane .fade .show .active role="tabpanel" aria-labelledby="Korean-tab"}

# More Operators

| File Path | Operator (Class) | Importance | Note |
|:---------|:-----|---|:-----------|
|airflow.models.bashoperator|BaseOperator| *** | * 오퍼레이터를 직접 개발하고싶은 경우 이 클래스 상속하여 개발 (execute() 함수를 재정의하여 사용) <br> * 아래 오퍼레이터들은 모두 이 클래스를 상속하여 개발되어 있음 <br> * Airflow를 잘 쓰려면 이 오퍼레이터 상속/개발하는 것을 자유자재로 할 줄 알아야 함. |
|airflow.operators.bash     |BashOperator| *** | * bash 쉘 스크립트를 실행 <br> * 가장 많이 사용하는 오퍼레이터 중 하나임 |
|airflow.operators.branch   |BaseBranchOperator| ** | * 직접 사용할 수는 없음. <br> * 이 클래스를 상속하여 choose_branch 함수를 구현해야 함 (그냥 사용시 에러 발생) <br> * 그러나 이 클래스 상속해서 사용하는것보다 @task.branch 데코레이터 사용을 권장 |
|airflow.operators.datetime |BranchDateTimeOperator|   | * 특정 Datetime 구간을 주어 Job 날짜가 구간에 속하는지 여부에 따라 분기 결정|
|airflow.operators.email |EmailOperator|   | 이메일 전송하는 오퍼레이터 (Airflow 파라미터에 SMTP 서버 등 사전 셋팅 필요)   |
|airflow.operators.generic_transfer|GenericTransfer|   | 데이터를 소스에서 타겟으로 전송 (Airflow 커넥션에 등록되어 있는 대상만 가능)   |
|airflow.operators.latest_only|LatestOnlyOperator|   | 이 Task 뒤에 연결되어 있는 task들을 모두 가장 최근의 Job만 실행하게끔 하는 오퍼레이터   |
|airflow.operators.subdag|SubDagOperator   |   | * 일종의 task 그룹화, 해당 오퍼레이터 안에 다른 오퍼레이터를 둘 수 있음 (Task group과 유사)   |
|airflow.operators.trigger_dagrun|TriggerDagRunOperator | **  | * 다른 DAG을 수행하기 위한 오퍼레이터  |
|airflow.operators.weekday|BranchDayOfWeekOperator |   | * 특정 요일에 따라 분기처리할 수 있는 오퍼레이터   |
|airflow.operators.python|PythonOperator   | ***  | * 어떤 파이썬 함수를 실행시키기 위한 오퍼레이터   |
|airflow.operators.python|BranchPythonOperator   | *   | * 파이썬 함수 실행 결과에 따라 task를 선택적으로 실행시킬 때 사용되는 오퍼레이터 |
|airflow.operators.python|ShortCircuitOperator   |   | * 파이썬 함수 return 값이 False면 후행 Task를 Skip처리하고 dag을 종료시키는 오퍼레이터 |
|airflow.operators.python|PythonVirtualenvOperator   |   | * 파이썬 가상환경 생성후 Job 수행하고 마무리되면 가상환경을 삭제해주는 오퍼레이터 |
|airflow.operators.python|ExternalPythonOperator   |   | * 기존에 존재하는 파이썬 가상환경에서 Job 수행하게 하는 오퍼레이터|

## Provider Operator

* airflow web service >> Admin >> Providers

# TriggerDagRun Operator

## DAG간 의존관계 설정

* DAG 의존관계 설정 방법
  1. TriggerDagRun Operator
    
  ```{dot}
  digraph G {
    compound=true;
    rankdir=LR;
    subgraph cluster0 {
      rankdir=TB;
      task1 [shape=box];
      task2 [shape=box];
      task3 [shape=box];
      task4 [shape=box];
      label= "Task Flow";
    }

    task1 -> task2;
    task1 -> task3;
    task1 -> task4; 
  }
  ```

  * task1: PythonOperator 등
  * task2,3,4: TriggerDagRun 오퍼레이터 다른 DAG 을 실행시키는 오퍼레이터
  
  2. ExternalTask Sensor

  ```{dot}
  digraph G {
    compound=true;
    rankdir=LR;
    subgraph cluster0 {
      rankdir=TB;
      sensor1 [shape=box];
      sensor2 [shape=box];
      sensor3 [shape=box];
      sensor4 [shape=box];
      label= "Task Flow";
    }

    sensor1 -> task1;
    sensor2 -> task1;
    sensor3 -> task1; 
    sensor4 -> task1; 
  }
  ```

  * 다른 DAG의 Task의 완료를 기다리는 센서
* DAG간 의존관계 설정
  * 방식 
    * TriggerDagRun Operator: 실행할 다른 DAG 의 ID 를 지정하여 수행 
    * ExternalTask 센서: 본 Task 가 수행되기 전 다른 DAG 의 완료를 기다린 후 수행
  * 권고 사용 시점
    * TriggerDagRun Operator: Trigger 되는 DAG 의 선행 DAG 이 하나만 있을 경우
    * ExternalTask 센서: Trigger 되는 DAG 의 선행 DAG 이 2 개 이상인 경우


## TriggerDagRun 오퍼레이터

```markdown

from airflow.operators.trigger_dagrun import TriggerDagRunOperator

with DAG(...) as dag:

    start_task = BashOperator(
        task_id='start_task',
        bash_command='echo "start!"',
    )

    trigger_dag_task = TriggerDagRunOperator(
        task_id='trigger_dag_task', #필수값
        trigger_dag_id='dags_python_operator', #필수값
        trigger_run_id=None,
        execution_date='{{data_interval_start}}',
        reset_dag_run=True,
        wait_for_completion=False,
        poke_interval=60,
        allowed_states=['success'],
        failed_states=None
        )

    start_task >> trigger_dag_task

```

## TriggerDagRun 오퍼레이터- run_id

* DAG의 수행 방식과 시간을 유일하게 식별해주는 키
* 같은 시간이라 해도 수행 방식 (Schedule, manual, Backfill) 에 따라 키가 달라짐
* 스케줄에 의해 실행된 경우 scheduled__{{data_interval_start}} 값을 가짐

```markdown

from airflow.operators.trigger_dagrun import TriggerDagRunOperator

with DAG(...) as dag:

    start_task = BashOperator(
        task_id='start_task',
        bash_command='echo "start!"',
    )

    trigger_dag_task = TriggerDagRunOperator(
        task_id='trigger_dag_task', 
        trigger_dag_id='dags_python_operator',
        trigger_run_id=None, # rund_id 값 직접 지정
        execution_date='{{data_interval_start}}', # manual_{{execution_date}} 로 수행
        reset_dag_run=True, # 이미 run_id 값이 있는 경우에도 재수행할 것 인지 결정
        wait_for_completion=False,
        poke_interval=60,
        allowed_states=['success'],
        failed_states=None
        )

    start_task >> trigger_dag_task

```

# SimpleHttp 오퍼레이터 서울시 공공데이터 키 발급받기

## 서울시 공공데이터 보기 

* https://data.seoul.go.kr/
* 서울시가 보유한 데이터 다운로드 가능
* Csv, json, xml 등을 직접 다운로드 받거나 openAPI 통해 다운 가능
* openAPI 이용할 경우 api KEY 발급받아야 함 로그인 필요

## API 사용을 위한 키 발급 받기

# SimpleHttp 오퍼레이터 API 받아오기

## SimpleHttpOperator 란?

* HTTP 요청을 하고 결과로 text 를 리턴 받는 오퍼레이터 리턴 값은 Xcom 에 저장
* HTTP 를 이용하여 API 를 처리하는 RestAPI 호출시 사용 가능
* 오퍼레이터 명세 확인하기

## 커넥션 등록

* airflow web service >> Admin >> Plus button
* Conn_id: 다른 conn 이름과 중복되지 않게 작성
* Connection_type: HTTP
* Host: http://openapi.seoul.go.kr
* Port: 8088
* Test 버튼 클릭시 “405:Method Not Allowed” 가 뜨지만 무방함


## SimpleHttpOperator 작성

```markdown
from airflow providers http operators http import SimpleHttpOperator
with DAG(...) as dag:
  tb_cycle_station_info = SimpleHttpOperator(
    task_id ='tb_cycle_station_info',
    http_conn_id = 'openapi.seoul.go.kr',
    endpoint ='yourapikey/json/tbCycleStationInfo/1/10',
    method ='GET',
    headers ={'Content-Type: 'application/json',
              charset': 'utf-8',
              'Accept': '*/*'
              }
  )
```

* SimpleHttpOperator를 여러 DAG 에 작성했는데 API 키가 바뀐다면?
* API키를 코드에 노출시키지 않고 싶다면?
* Key에 아래 이름이 있을 경우 val 을 자동 마스킹처리하여 보여줌
  * 'access_token',
  * 'api_key',
  * 'apikey',
  * 'authorization',
  * 'passphrase',
  * 'passwd',
  * 'password',
  * 'private_key',
  * 'secret',
  * 'token'

```markdown
from airflow providers http operators http import SimpleHttpOperator
with DAG(...) as dag:
  tb_cycle_station_info = SimpleHttpOperator(
    task_id ='tb_cycle_station_info',
    http_conn_id = 'openapi.seoul.go.kr',
    endpoint = '{{var.value.apikey_openapi_seoul_go_kr }}/json/tbCycleStationInfo/1/10/',
    method ='GET',
    headers ={'Content-Type: 'application/json',
              charset': 'utf-8',
              'Accept': '*/*'
              }
  )
```
* 서울시 공공데이터 추출하는 DAG 이 여러 개 있어도 API 키를 하나로 관리 가능
* API 키를 코드에 노출시키지 않음

# Custom 오퍼레이터 Study

## Airflow 의 꽃 , Custom 오퍼레이터

* Airflow는 오퍼레이터를 직접 만들어 사용할 수 있도록 클래스를 제공 (BaseOperator)
* BaseOperator 상속시 두 가지 메서드를 재정의해야 함 (Overriding)
  1. def__init__
    * 클래스에서 객체 생성시 객체에 대한 초기값 지정하는 함수
  2. def execute(self, context)
    * __init__ 생성자로 객체를 얻은 후 execute 메서드를 실행시키도록 되어 있음
    * 비즈니스 로직은 execute 에 구현 필요
* 오퍼레이터 기능 정의
  * 서울시 공공데이터 API 를 호출하여 전체 데이터를 받은 후 .csv 파일로 저장하기
* 오퍼레이터와 dag 의 위치
  * /dags/dags_seoul_api.py
    ```markdown
    from operators.seoul_api_to_csv_operator
    import SeoulApiToCsvOperator
    ```
  * /plugins/operators/seoul_api_to_csv_operator.py
* Template 사용 가능한 파라미터 지정하기

```markdown


```

# Custom 오퍼레이터 개발

## Custom 오퍼레이터 만들기

* __init__ 생성자 재정의

```markdown
class SeoulApiToCsvOperator(BaseOperator):
  template_fields = (' endpoint', ' path','file_ name','base_dt')
  
  def __init__(self , dataset_nm , path , file_name , base_dt=None , **kwargs):
    super().__init__(**kwargs)
    self.http_conn_id = 'openapi.seoul.go.kr'
    self.path = path
    self.file_name = file_name
    self.endpoint = '{{var.value.apikey_openapi_seoul_go_kr}}/json/' + datset_nm
    self.base_dt =base_dt
```

* execute 메서드 재정의
* dag 생성

## Summary

* Custom 오퍼레이터를 만들면 왜 좋을까 ?
  * 만약 custom 오퍼레이터를 만들지 않았다면
    * 개발자마다 각자 서울 공공데이터 데이터셋 추출 저장하는 파이썬 파일을 만들어 PythonOperator 를 이용해 개발했을 것
    * 비슷한 동작을 하는 파이썬 파일이 관리되지 않은 채 수십 개 만들어지면 그 자체로 비효율 발생
* 특정기능을 하는 모듈을 만들어 놓고 , 상세 조건은 파라미터로 받게끔하여 모듈을 재사용할 수 있도록 유도
  *  Custom 오퍼레이터 개발



:::
</div>

<div class="tab-pane fade" id="English" role="tabpanel" aria-labelledby="English-tab">

::: {#English .tab-pane .fade role="tabpanel" aria-labelledby="English-tab"}

:::


</div>


# Go to Blog Content List

[Blog Content List](../../content_list.qmd)