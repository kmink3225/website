---
title: "Eigenvalue"
subtitle: 'Eigenvalue, Eigenvector, Eigendecomposition, Quadratic Form'
description: |
  Eigenvalues could be used for understanding characteristics or properties of a square matrix and determining what type of a quadratic form the matrix belongs to.
categories:
  - Mathematics
author: Kwangmin Kim
date: 05/27/2023
format: 
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
execute:
  warning: false
  meassage: false
draft: False
---

```{r}
library(tidyverse)
library(mosaic)
library(mvtnorm)
```

# Introduction

Eigenvalues could be used for understanding characteristics or properties of a square matrix and determining what type of a quadratic form the matrix belongs to.

## Definition

:::{#def-eigenvalue}
## Eigenvalues and Eigenvectors

Let $\mathbf{A}$ be an $n × n$ square matrix. A scalar $\lambda$ is called an eigenvalue of $\mathbf{A}$ if there exists a non-zero vector $\mathbf{v}$ such that
$$
\mathbf{Av}=\lambda\mathbf{v}
$$

Such a vector $\mathbf{v}$ is called an eigenvector corresponding to $\lambda$.
:::



## Properties

* Eigenvalues are scalar values: Eigenvalues are scalars and represent the scaling factor by which the corresponding eigenvectors are stretched or shrunk when multiplied by a matrix.
* When a matrix is ​​expressed in quadratic form, there exists a symmetric matrix that satisfies the uniqueness of the quadratic form and all eigenvalues ​​corresponding to the symmetric matrix having real numbers as elements are real numbers. Depending on the signs of the eigenvalues, a quadratic form can be classified into 5 types:
  * $\mathbf{A}$ is said to be a positive definite (PD) matrix if the eigenvalues of $\mathbf{A}$ are all positive.
  $$
  \mathbf{A} > 0 \text{ iff } \lambda_{\text{min}}(\mathbf{A}) > 0
  $$
  * $\mathbf{A}$ is said to be a positive semi-definite (PSD) matrix if the eigenvalues of $\mathbf{A}$ are not negative.
  $$
  \mathbf{A} \ge 0 \text{ iff } \lambda_{\text{min}}(\mathbf{A}) \ge 0
  $$
  * $\mathbf{A}$ is said to be a negative definite (ND) matrix if the eigenvalues of $\mathbf{A}$ are all negative.
  $$
  \mathbf{A} < 0 \text{ iff } \lambda_{\text{max}}(\mathbf{A}) < 0
  $$
  * $\mathbf{A}$ is said to be a negative semi-definite (NSD) matrix if the eigenvalues of $\mathbf{A}$ are not positive.
  $$
  \mathbf{A} \le 0 \text{ iff } \lambda_{\text{max}}(\mathbf{A}) \le 0
  $$
  * $\mathbf{A}$ is said to be a indefinite (NSD) matrix if the eigenvalues of $\mathbf{A}$ have both signs.
  $$
  \mathbf{A} \lessgtr 0 \text{ iff } \lambda_{\text{max}}(\mathbf{A}) \lessgtr 0
  $$
* Sum of eigenvalues: The sum of the eigenvalues of a matrix is equal to the trace of the matrix, where the trace is the sum of the diagonal elements. 
  $$
  \sum_{i=1}^n \lambda_i = \text{tr}(\mathbf{A})
  $$.
* Product of eigenvalues: The product of the eigenvalues of a matrix is equal to the determinant of the matrix. 
  $$
  \prod_{i=1}^n \lambda_i = \det(\mathbf{A})=|\mathbf{A}|
  $$.  
* Eigenvalues are solutions to the characteristic equation: For a square matrix $\mathbf{A}$ of size $n\times n$, the eigenvalues $\lambda$ satisfy the characteristic equation $\det(\mathbf{A} - \lambda\mathbf{I}) = 0$, where $\mathbf{I}$ is the identity matrix of size $n\times n$.
  * The characteristic equation is an equation associated with a square matrix that helps determine its eigenvalues, which are crucial for understanding the behavior and properties of the matrix $\mathbf{A}$.
  $$
  \det(\mathbf{A} - \lambda\mathbf{I}) = 0
  $$
  The equation indicates that the matrix $\mathbf{A} - \lambda\mathbf{I}$ does not have full rank and has a nontrivial null space.
* Eigenvalues of similar matrices: Similar matrices have the same eigenvalues. If two matrices $\mathbf{A}$ and $\mathbf{B}$ are similar (i.e., $\mathbf{A} = \mathbf{PBP}^{-1}$ for some invertible matrix $\mathbf{P}$), then they have the same eigenvalues.
* Eigenvalues of triangular matrices: The eigenvalues of a triangular matrix are equal to its diagonal entries. In other words, for an upper triangular matrix, the eigenvalues are the elements on its main diagonal.


## Example

Let $\mathbf{A}$ be the matrix


To find the eigenvalues of $\mathbf A$, we solve the characteristic equation $\text{det}(\mathbf A - \lambda \mathbf I ) = 0$, where I is the n × n identity matrix.

$$
\begin{align*}
  \text{det}(\mathbf A - \lambda \mathbf I ) 
  &= 
    \begin{vmatrix} 
    3 - \lambda & 1 \\ 
    1 & 3 - \lambda 
    \end{vmatrix} \\
  &= 
  (3 - \lambda)(3 - \lambda) - 1 \\
  &= \lambda^2 - 6\lambda + 8 = 0
\end{align*}
$$

Solving this quadratic equation gives us the eigenvalues of $\mathbf A$: $\lambda_1 = 2$ and $\lambda_2 = 4$.

To find the eigenvectors corresponding to $\lambda_1 = 2$, we solve the equation $(\mathbf A - 2 \mathbf I)\mathbf{v} = \mathbf{0}$, where $\mathbf I$ is the $2 \times 2$ identity matrix.

$$
\begin{align*}
  (\mathbf A - 2 \mathbf I)\mathbf{v} = 
    \begin{bmatrix} 
      1 & 1 \\ 
      1 & 1 
    \end{bmatrix}
  \begin{bmatrix} 
    x \\ 
    y 
  \end{bmatrix} = 
  \begin{bmatrix} 
    0 \\ 
    0 
  \end{bmatrix}
\end{align*}
$$

Solving this system of equations gives us the eigenvectors corresponding to $\lambda_1 = 2$: $\mathbf{v_1} = \begin{bmatrix} -1 \\ 1 \end{bmatrix}$

Similarly, for $\lambda_2 = 4$, we solve the equation $(\mathbf A - 4\mathbf I)\mathbf{v}$ = $\mathbf{0}$ to get the eigenvectors corresponding to $\lambda_2 = 4$: $\mathbf{v_2} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$

::: {.panel-tabset}

## R

```{r}
PD <-matrix(c(1,0,0,1),ncol=2,byrow = TRUE)
PSD <- matrix(c(1,1,1,1),ncol=2,byrow = TRUE)
ND <- matrix(c(-1,0,0,-1),ncol=2,byrow = TRUE)
NSD <- matrix(c(-1,-1,-1,-1),ncol=2,byrow = TRUE)
Ind <- matrix(c(1,0,0,1),ncol=2,byrow = TRUE)

sym_mat <-matrix(c(6,-4,12,-4,6,-2,12,-2,3),ncol=3,byrow = TRUE)
eigen(sym_mat)$values

# trace
diag(sym_mat)%>%sum()
sum(eigen(sym_mat)$values)

# product of eigenvalues : more convenient than using a for loop
exp(sum(log(eigen(sym_mat)$values)))
det(sym_mat)
```

 

## Python

```{python}
import numpy as np

# Define the matrix A
A = np.array([[2, 1], [1, 3]])

# Calculate the eigenvalues and eigenvectors
eigenvalues, eigenvectors = np.linalg.eig(A)

# Print the eigenvalues
print("Eigenvalues:")
for eigenvalue in eigenvalues:
    print(eigenvalue)


```
:::