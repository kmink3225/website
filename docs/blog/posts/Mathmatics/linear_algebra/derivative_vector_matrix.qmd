---
title: "Matrix Calculus (1) - Matrix to Vector Derivatives"
subtitle: the sum of squares, covariance matrix, and correlation matrix
description: |
  template
categories:
  - Mathematics
author: Kwangmin Kim
date: 04/02/2023
format: 
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
draft: false
execute:
  echo: false
---

## Matrix to Vector Derivatives

The matrix-to-vector derivative is a derivative where a function $f(\mathbf{X})$ maps an $m \times n$ matrix $\mathbf{X}$ to a $p$-dimensional vector $\mathbf{y}$, and we want to find the derivative of $\mathbf{y}$ with respect to $\mathbf{X}$. It is denoted by $\frac{\partial \mathbf{y}}{\partial \mathbf{X}}$.

Formally, let $\mathbf{X} \in \mathbb{R}^{m \times n}$ and $\mathbf{y} = f(\mathbf{X}) \in \mathbb{R}^p$ be a function that maps an $m \times n$ matrix to a $p$-dimensional vector. Then, the matrix-to-vector derivative is defined as:
$$
\begin{bmatrix}
\frac{\partial \mathbf{y}}{\partial x_{11}} & \frac{\partial \mathbf{y}}{\partial x_{12}} & \cdots & \frac{\partial \mathbf{y}}{\partial x_{1n}} \\
\frac{\partial \mathbf{y}}{\partial x_{21}} & \frac{\partial \mathbf{y}}{\partial x_{22}} & \cdots & \frac{\partial \mathbf{y}}{\partial x_{2n}} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial \mathbf{y}}{\partial x_{m1}} & \frac{\partial \mathbf{y}}{\partial x_{m2}} & \cdots & \frac{\partial \mathbf{y}}{\partial x_{mn}} \\
\end{bmatrix}
$$

where each element of the matrix is the derivative of the corresponding element of $\mathbf{y}$ with respect to the corresponding element of $\mathbf{X}$.

For example, let $f(\mathbf{X}) = \mathbf{A}\mathbf{X}+\mathbf{b}$, where $\mathbf{A} \in \mathbb{R}^{p \times m}$, $\mathbf{X} \in \mathbb{R}^{m \times n}$, and $\mathbf{b} \in \mathbb{R}^p$. Then, the matrix-to-vector derivative of $\mathbf{y} = f(\mathbf{X})$ with respect to $\mathbf{X}$ is:
$$
\frac{\partial \mathbf{y}}{\partial \mathbf{X}} = \mathbf{A}
$$

### Differentiation of Quadratic Form

This is because the output of this differentiation is a vector (with respect to $\mathbf{x}$), rather than a scalar.

The differentiation of a quadratic form is the process of finding the gradient of a quadratic form with respect to its input vector.

Given a quadratic form $f(\mathbf{x})=\mathbf{x}^T \mathbf{A} \mathbf{x}$, where $\mathbf{x}$ is an $n$-dimensional column vector, $\mathbf{b} \in \mathbb{R}^n$ is a vector, and $\mathbf{A}$ is an $n \times n$ symmetric matrix, the derivative of $f(\mathbf{x})$ with respect to $\mathbf{x}$ is given by:

$$
\nabla_{\mathbf x} f(\mathbf x) = (A + A^T)\mathbf x + b
$$

In this expression, $\mathbf{A}^T$ is the transpose of $\mathbf{A}$.

$\mathbf A+\mathbf A^T$ is written instead of $2\mathbf A$ when calculating the gradient of a quadratic form. It is because in general, the matrix $\mathbf A$ might not be symmetric, so $\mathbf A\neq \mathbf A^T$. However, for any matrix $\mathbf A$, we have $\mathbf A+\mathbf A^T = (\mathbf A+\mathbf A^T)^T$, which is a symmetric matrix. Therefore, by writing the gradient as $\nabla_x f(x) = (\mathbf A+\mathbf A^T)x$, we ensure that the gradient is always a symmetric matrix, even if $\mathbf A$ is not symmetric. This is useful in many applications where symmetric matrices are preferred. But if $\mathbf A$ is constrained to be a symmetric matrix, $2\mathbf A$ can be written.

### When $\mathbf{A}$ is Symmetric

As an example, consider the quadratic form $f(\mathbf{x})=x_1^2+2x_1x_2+3x_2^2$, which can be written in the form $\mathbf{x}^T \mathbf{A} \mathbf{x}$, where:

$$
\mathbf x=\begin{bmatrix} x_1 \ x_2 \end{bmatrix}, \mathbf A=\begin{bmatrix} 1 & 1 \\ 1 & 3 \end{bmatrix}
$$


The derivative of $f(\mathbf{x})$ with respect to $\mathbf{x}$ is then:

$$
\frac{\partial f(\mathbf{x})}{\partial \mathbf{x}}=(\mathbf{A}+\mathbf{A}^T)\mathbf{x}=\begin{bmatrix}2 & 2\\2 & 6\end{bmatrix}\begin{bmatrix}x_1 \\ x_2\end{bmatrix}=\begin{bmatrix}2x_1+2x_2\\2x_1+6x_2\end{bmatrix}
$$

This represents the gradient vector of $f(\mathbf{x})$ at any point $\mathbf{x}$.

### When $\mathbf{A}$ is Not Symmetric

Let $\mathbf{A} = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix}$ and $\mathbf{x} = \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}$.

Then, we have $\mathbf{x}^T \mathbf{A} \mathbf{x} = \begin{bmatrix} x_1 & x_2 \end{bmatrix} \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = \begin{bmatrix} x_1 & x_2 \end{bmatrix} \begin{bmatrix} x_1 + 2x_2 \\ 3x_1 + 4x_2 \end{bmatrix} = x_1^2 + 5x_1x_2 + 4x_2^2$.

To find the gradient of this quadratic form, we can take the partial derivatives of $x_1$ and $x_2$ with respect to each variable:

$$
\frac{\partial}{\partial x_1} (\mathbf{x}^T \mathbf{A} \mathbf{x}) = 2x_1 + 5x_2
$$

$$
\frac{\partial}{\partial x_2} (\mathbf{x}^T \mathbf{A} \mathbf{x}) = 5x_1 + 8x_2
$$

$$
\frac{\partial f(\mathbf{x})}{\partial \mathbf{x}}=(\mathbf{A}+\mathbf{A}^T)\mathbf{x}=\begin{bmatrix}1+1 & 2+3\\3+2 & 4+4\end{bmatrix}\begin{bmatrix}x_1 \\ x_2\end{bmatrix}=\begin{bmatrix}2 & 5\\5 & 8\end{bmatrix}\begin{bmatrix}x_1 \\ x_2\end{bmatrix} = \begin{bmatrix} 2x_1 + 5x_2 \\ 5x_1 + 8x_2 \end{bmatrix}
$$

So the gradient of $\mathbf{x}^T \mathbf{A} \mathbf{x}$ is $\nabla_x f(x) = \begin{bmatrix} 2x_1 + 5x_2 \\ 5x_1 + 8x_2 \end{bmatrix}$.