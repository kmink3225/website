---
title: p-values
subtitle: Statistical Hypothesis Test 
description: |
  p-value is one of the most commonly used statistcal index to show significance level of a hypothesis testing result of your experiment.
categories:
  - Statistics
author: Kwangmin Kim
date: 12/15/2022
image: coding.jpg
image-alt: "test"
draft: False
---

<ul class="nav nav-pills" id="language-tab" role="tablist">
  <li class="nav-item" role="presentation">
    <button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" role="tab" aria-controls="Korean" aria-selected="true">Korean</button>
  </li>
  <li class="nav-item" role="presentation">
    <button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" role="tab" aria-controls="knitr" aria-selected="false">English</button>
  </li>

<div class="tab-content" id="language-tabcontent">

<div class="tab-pane fade  show active" id="Korean" role="tabpanel" aria-labelledby="Korean-tab">

### Significance

실험 결과가 우연히 생성된 것보다 더 극단적인 경우를 통계적으로 유의하다고 한다. (결과가 귀무 가설 하의 분포와 다른 분포에서 나올 수 있다고 생각해 보십시오.)

### p-value

'p-값'의 p는 '확률'을 나타냅니다. p-값은 실험에서 관찰된 결과가 귀무 가설 하에서 발생할 수 있는 극단적인 결과를 얻을 확률의 합계입니다. 즉, p-값은 실험 결과가 우연히 얻어질 확률입니다.

### Alpha

우연한 결과가 통계적으로 유의미하다고 하기 위해 실험의 실제 결과를 넘어서야 하는 극단적이거나 드문 결과의 확률 임계값입니다.

### Type 1 error

귀무가설이 참인데 실수로 귀무가설을 기각하는 오류

### Type 2 error

대립가설이 참인데 실수로 귀무가설을 기각하지 못하는 오류

## p-value: Good vs Bad?

### Goodness

p-값은 테스트 결과의 유의성을 측정할 때 효율적이고 효과적인 통계 지표입니다. 회귀 분석을 수행했다고 가정해 봅시다. 그런 다음 회귀 모델의 결과로 베타 계수와 표준 오차를 얻을 수 있습니다.

|              | high Standard Error    |     low Standard Error |
|--------------|:-----------------------|-----------------------:|
| high $\beta$ | Unclear Interpretation |                     OK |
| low $\beta$  | OK                     | Unclear Interpretation |

: Number of Cases of How You Interpret Regresssion Result

위의 표는 회귀 모델의 결과를 해석할 수 있는 경우의 수를 보여줍니다. 각 계수 $\beta$ 에 대해 4개의 경우가 있습니다. 

1.  **high $\beta$ and high Standard Error** mean that 해당 변수가 강한 영향을 미치나 그 영향이 변동될 수 있음을 의미하므로 회귀 모델에서 도출된 $\beta$ 계수는 유의하지 않을 가능성이 높습니다. 그 효과가 통계적으로 유의미한지 확신할 수 없습니다.
2.  **high $\beta$ and low Standard Error** mean that the corresponding variable has a strong effect, and its variation is small, so the $\beta$ coefficient resulted from your regression model is likely to be significant.
3.  **low $\beta$ and high Standard Error** mean that the corresponding variable has a weak effect on your reponse variable, its effect has a high variation. So, we can clearly interprete the variable with the $\beta$ as a variable that is not significantly associated with your response variable.
4.  **low $\beta$ and high Standard Error** mean that the corresponding variable has a weak effect on your reponse variable, but its effect has a low variation. So, it is difficult to conclude that the variable is significant.

The p-value could be used to provide a clearer interpretation of the unclear situation (i.e. (high $\beta$, high Standard Error), (low $\beta$, high Standard Error) ) by looking at the ratio of the estimated value of a parameter(= $\beta$) to its standard error on the distribution under the null hypothesis. By general convention, the cut-off of p-value indicating statistical signficance is 0.05.

### Badness

Despite the goodness of p-value, it is controversial to make a decision based solely on the p-value. As mentioned above, p-value is the probability that the result of your experiment is due to chance. In addition, looking into $\frac{\beta}{\frac{s.e}{\sqrt{n}}}$, the p-value gets smaller as the sample size becomes larger and larger. **It should be avoided that something is proved just because a low p-value is calucated**.

Even if a result is statistically significant, that does not necessarily mean it has real significance. A small difference that has no practical meaning can be statistically significant if the sample size is large enough. It is because large samples ensure that meaningless effects can become big enough to possibly exclude chance due to simple math.

The American Statistical Association (ASA) has released a statement of six principles for researchers and journal editors on p-values:\
[Source: ASA Statement on Statistical Significance and p-values](https://www.amstat.org/asa/files/pdfs/p-valuestatement.pdf)

1.  P-values can indicate how incompatible the data are with a specified statistical model.
2.  P-values do not measure the probability that the studied hypothesis is true, or the probability that the data produced by random chance alone.
3.  Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.
4.  Proper inference requires full reporting and transparency.
5.  A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.
6.  By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.

## How to use p-vlaues?

Personally, I make use of p-values as a tool in data science to just check whether a model result or a set of variables that appears interesting and useful is in the range of normal variability by chance in the exploratory data analysis(EDA) or data mining step.

If you want to get a statistical significance level through p-values, other methodologies could help increase the accuracy of real significance such as permuted p-values, q-values, and penalization on multiple comparison tests


</div>

<div class="tab-pane fade" id="English" role="tabpanel" aria-labelledby="English-tab">

### Significance

It is said to be statistically significant if a result of your experiment is more extreme than one that is produced by chance. (Try thinking that your result could have come from a different distribution from the one under the null hypothesis.)

### p-value

p of 'p-value' stands for 'probability'. The p-value is the summation of the probabilities of obtaining results as extreme as the observed results from your experiments could occur under the null hypothesis. In other words, p-value is the probability that the result of your experiment is obtained by chance.

### Alpha

The probability threshold of the extreme or rarer results that chance results must be beyond actual results of your experiments in order to be said to be statistically significant.

### Type 1 error

concluding $H_o$ or the null hypothesis is true by mistake.

### Type 2 error

concluding $H_a$ or the alternative hypothesis is true by mistake.

## p-value: Good vs Bad?

### Goodness

p-value is an efficient and effective statistical index when to measure the significance of your test result. Let's make an assumption that you have conducted a regression analysis. Then, you can get beta coefficients and their standard errors as results of your regression model.

|              | high Standard Error    |     low Standard Error |
|--------------|:-----------------------|-----------------------:|
| high $\beta$ | Unclear Interpretation |                     OK |
| low $\beta$  | OK                     | Unclear Interpretation |

: Number of Cases of How You Interpret Regresssion Result

The above table shows the number of cases you can interprete the results of your regression model. There are 4 cases for each coefficient $\beta$.

1.  **high $\beta$ and high Standard Error** mean that the corresponding variable has a strong effect but its effect may be fluctuated, so the $\beta$ coefficient resulted from your regression model is likely to be not significant. We are not sure that its effect is statistically significant.
2.  **high $\beta$ and low Standard Error** mean that the corresponding variable has a strong effect, and its variation is small, so the $\beta$ coefficient resulted from your regression model is likely to be significant.
3.  **low $\beta$ and high Standard Error** mean that the corresponding variable has a weak effect on your reponse variable, its effect has a high variation. So, we can clearly interprete the variable with the $\beta$ as a variable that is not significantly associated with your response variable.
4.  **low $\beta$ and high Standard Error** mean that the corresponding variable has a weak effect on your reponse variable, but its effect has a low variation. So, it is difficult to conclude that the variable is significant.

The p-value could be used to provide a clearer interpretation of the unclear situation (i.e. (high $\beta$, high Standard Error), (low $\beta$, high Standard Error) ) by looking at the ratio of the estimated value of a parameter(= $\beta$) to its standard error on the distribution under the null hypothesis. By general convention, the cut-off of p-value indicating statistical signficance is 0.05.

### Badness

Despite the goodness of p-value, it is controversial to make a decision based solely on the p-value. As mentioned above, p-value is the probability that the result of your experiment is due to chance. In addition, looking into $\frac{\beta}{\frac{s.e}{\sqrt{n}}}$, the p-value gets smaller as the sample size becomes larger and larger. **It should be avoided that something is proved just because a low p-value is calucated**.

Even if a result is statistically significant, that does not necessarily mean it has real significance. A small difference that has no practical meaning can be statistically significant if the sample size is large enough. It is because large samples ensure that meaningless effects can become big enough to possibly exclude chance due to simple math.

The American Statistical Association (ASA) has released a statement of six principles for researchers and journal editors on p-values:\
[Source: ASA Statement on Statistical Significance and p-values](https://www.amstat.org/asa/files/pdfs/p-valuestatement.pdf)

1.  P-values can indicate how incompatible the data are with a specified statistical model.
2.  P-values do not measure the probability that the studied hypothesis is true, or the probability that the data produced by random chance alone.
3.  Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.
4.  Proper inference requires full reporting and transparency.
5.  A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.
6.  By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.

## How to use p-vlaues?

Personally, I make use of p-values as a tool in data science to just check whether a model result or a set of variables that appears interesting and useful is in the range of normal variability by chance in the exploratory data analysis(EDA) or data mining step.

If you want to get a statistical significance level through p-values, other methodologies could help increase the accuracy of real significance such as permuted p-values, q-values, and penalization on multiple comparison tests

</div>