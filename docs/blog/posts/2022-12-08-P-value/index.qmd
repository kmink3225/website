---
title: P-value
subtitle: Statistical Hypothesis Test 
description: |
  P value is one of the most commonly used statistcal index to show confidence of a hypothesis testing result of your experiment.
categories:
  - Statistics
author: Kwangmin Kim
date: 12/08/2022
image: coding.png
image-alt: "test"
draft: False
---

## Significance
It is said to be statistically significant if a result of your experiment is more extreme than one that is produced by chance.

## p-value
p of 'p-value' stands for 'probability'. The p-value is the summation of the probabilities of obtaining results as extreme as the results of your experiments under the null hypothesis.

## Alpha
The probability threshold of the extreme or rarer results that chance results must be beyond actual results of your experiments in order to be said to be statistically significant.

## Type 1 error
concluding $H_o$ or the null hypothesis is true by mistake.

## Type 2 error
concluding $H_a$ or the alternative hypothesis is true by mistake.

## p-value: Good vs Bad 

### Goodness
p-value is an efficient and effective statistical index when to measure thesignificance of your test result.
Let's make an assumption that you have conducted a regression analysis. Then, you can get beta coefficients and their standard errors as results of your regression model.

|              | high Standard Error | low Standard Error |
|--------------|:--------------------|-------------------:|
| high $\beta$ |       Unclear       |         OK         |
| low  $\beta$ |         OK          |       Unclear      |
: Number of Cases of How You Interpret Regresssion Result

The above table shows the number of cases you can interprete the results of your regression model. There are 4 cases for each coefficient $\beta$.

1. high $\beta$ and high Standard Error mean that the corresponding variable has a strong effect but its effect may be fluctu
1.
1.
1.

### Badness
Be careful of using the p-value Considerable controversy has surrounded the use of the p-value in recent years. One
psychology journal has gone so far as to “ban” the use of p-values in submitted papers
on the grounds that publication decisions based solely on the p-value were resulting
in the publication of poor research. Too many researchers, only dimly aware of what a
p-value really means, root around in the data, and among different possible hypotheses
to test, until they find a combination that yields a significant p-value and, hence, a
paper suitable for publication.
The real problem is that people want more meaning from the p-value than it contains.
Here’s what we would like the p-value to convey:
The probability that the result is due to chance.
We hope for a low value, so we can conclude that we’ve proved something. This is
how many journal editors were interpreting the p-value. But here’s what the p-value
actually represents:
The probability that, given a chance model, results as extreme as the observed results
could occur.
The difference is subtle but real. A significant p-value does not carry you quite as far
along the road to “proof ” as it seems to promise. The logical foundation for the conclusion
“statistically significant” is somewhat weaker when the real meaning of the pvalue
is understood.
In March 2016, the American Statistical Association, after much internal deliberation,
revealed the extent of misunderstanding about p-values when it issued a cautionary
statement regarding their use. The ASA statement stressed six principles for researchers
and journal editors:
1. P-values can indicate how incompatible the data are with a specified statistical
model.
2. P-values do not measure the probability that the studied hypothesis is true, or the
probability that the data were produced by random chance alone.
3. Scientific conclusions and business or policy decisions should not be based only
on whether a p-value passes a specific threshold.
4. Proper inference requires full reporting and transparency.
5. A p-value, or statistical significance, does not measure the size of an effect or the
importance of a result.
6. By itself, a p-value does not provide a good measure of evidence regarding a
model or hypothesis.
