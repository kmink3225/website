# ë°ì´í„° í‘œì¤€í™” í”„ë ˆì„ì›Œí¬ ì•„í‚¤í…ì³

```{mermaid}
graph TB
    subgraph "Input Layer"
        A[ìµœì´ˆ í‘œì¤€í™” ë°ì´í„°<br/>í…Œì´ë¸”/ì»¬ëŸ¼] --> B[DataLoader]
        A1[ì‚¬ìš©ì ë…¼ë¦¬ëª… ì…ë ¥<br/>Streamlit UI] --> B
        A2[ì½”ë“œ ìŠ¤ë‹ˆí«<br/>Streamlit UI] --> B
    end
    
    subgraph "Processing Layer"
        B -->|ë…¼ë¦¬ëª…| C[TokenProcessor<br/>í† í° ë¶„ì„]
        C --> |ë‹¨ì–´|D[Domain NLP Engine<br/>KoBERT<br/>ë„ë©”ì¸ ë¶„ë¥˜]
        D --> E[AbbreviationManager<br/>ê·œì¹™ ê¸°ë°˜ ì•½ì–´ ìƒì„±]
        
        RAG[RAG System<br/>í‘œì¤€í™” ê·œì¹™ ê²€ìƒ‰<br/>+ GPT-4o ì¶”ì²œ]
        NLP[Terminology NLP Engine<br/> Pre-trained Model KoSRoBERTa<br/> ë‹¨ì–´/ìš©ì–´ í´ëŸ¬ìŠ¤í„°ë§]
        
        RAG --> C
        D -->|ë‹¨ì–´| NLP
    end

    B --> |ì½”ë“œ ìŠ¤ë‹ˆí«| RAG
    B --> |ë…¼ë¦¬ëª…| NLP

    subgraph "Actors"
        DBA[DBA]
        DS[Data Steward]
        SD[ê°œë°œì/ì‚¬ìš©ì]
    end

    NLP --> DS
    DS --> MD

    subgraph "Metadata Management Layer"
        MD[í†µí•© ì‚¬ì „<br/>ë‹¨ì–´/ë„ë©”ì¸/ì½”ë“œ/ìš©ì–´]
        E --> MD
        MD --> F[RuleAnalyzer<br/>ì¼ê´€ì„± ê²€ì¦]
        MD --> H[DataCompletenessAnalyzer<br/>ì™„ì „ì„± ê²€ì¦]
    end
    
    subgraph "Analysis Layer"
        F --> G[ReportGenerator<br/>ì¢…í•© ë¶„ì„ ë³´ê³ ]
        H --> G
        NLP --> G
        RAG --> REC[ë…¼ë¦¬ëª… ì¶”ì²œ]
        E --> ABR[ì•½ì–´ ìƒì„±]
    end
    
    subgraph "Output Layer"
        G --> UI1[ê²€ì¦ ê²°ê³¼ ëŒ€ì‹œë³´ë“œ]
        REC --> UI2[ë…¼ë¦¬ëª… ì¶”ì²œ íƒ­]
        ABR --> UI3[ì•½ì–´ ìƒì„± íƒ­]
    end
    
    %% ìŠ¤íƒ€ì¼ë§
    style A fill:#e1f5fe
    style A1 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style A2 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style RAG fill:#fff8e1,stroke:#ff8f00,stroke-width:3px
    style NLP fill:#e8f5e8,stroke:#388e3c,stroke-width:3px
    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px
    style E fill:#4caf50,stroke:#2e7d32,stroke-width:3px
    style MD fill:#fce4ec,stroke:#ad1457,stroke-width:2px
    style G fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style UI1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style UI2 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style UI3 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px

```

### NLP Engine Domain Classifier

```{mermaid}
graph TB
    subgraph DS ["Data Sources"]
        A["í‘œì¤€í™” ì›ì¹™ PDF<br/>200ê°œ ê·œì¹™"] --> B["LLM<br/>Claude 4 Sonnet"]
        A1["í‘œì¤€ ë‹¨ì–´ ì‚¬ì „<br/>14ê·¸ë£¹ ë¶„ë¥˜"] --> C["Domain Generator<br/>í…œí”Œë¦¿ ê¸°ë°˜"]
        A2["ê¸°ì¡´ ë„ë©”ì¸ ì‚¬ì „<br/>ì¤‘ë³µ ê²€ì¦ìš©"] --> C
    end

    subgraph TDG ["Training Data Pipeline"]
        B -->|2,868ê°œ| D["domain_data.parquet<br/>êµ¬ì¡°í™” ë°ì´í„°"]
        C -->|2,800ê°œ| E["generated.parquet<br/>ê· ë“± ë¶„í¬"]
        D --> F["Parquet Merger<br/>ìŠ¤í‚¤ë§ˆ í†µí•©"]
        E --> F
        F -->|ì¤‘ë³µ ì œê±°| I["training_dataset<br/>5,632ê°œ ìµœì¢…"]
    end

    subgraph ML ["NLP Model Architecture"]
        I --> J["KoBERT Tokenizer<br/>vocab_size=8,002<br/>max_length=32"]
        J --> K["KoBERT Encoder<br/>monologg/kobert<br/>768 hidden_size"]
        K --> L["Pooler Output<br/>[CLS] token"]
        L --> M["Dropout Layer<br/>dropout=0.3"]
        M --> N["Linear Classifier<br/>768 â†’ 14 classes"]
        N --> Q["AdamW Optimizer<br/>lr=2e-5, batch=64"]
    end

    subgraph EVAL ["Model Performance"]
        Q --> R1["Train Acc: 94.18%"]
        Q --> R2["Test Acc: 95.39%"]
        Q --> R3["F1-Score: 0.94"]
    end

    subgraph DEPLOY ["Model Deployment"]
        R1 --> S["kobert_classifier.pth<br/>ëª¨ë¸ ì €ì¥"]
        S --> T["Inference Function<br/>ë‹¨ì¼ ë„ë©”ì¸ ì˜ˆì¸¡"]
        T --> U["Classification Result<br/>í´ë˜ìŠ¤ + ì‹ ë¢°ë„"]
        S -.->|êµ¬í˜„ ì˜ˆì •| V["Streamlit Web App<br/>ì‹¤ì‹œê°„ ë¶„ë¥˜ ì¸í„°í˜ì´ìŠ¤"]
        V -.-> W["ì›¹ ê¸°ë°˜ ë¶„ë¥˜ ì„œë¹„ìŠ¤<br/>CSV ì—…ë¡œë“œ + ì‹œê°í™”"]
    end

    CT["14ê°œ ë„ë©”ì¸ ê·¸ë£¹"]

    %% ì—°ê²°ì„  ë° ë°ì´í„° íë¦„
    N -.->|ë¶„ë¥˜ ëŒ€ìƒ| CT
    I -.->|ê· ë“± ë¶„í¬ ë³´ì¥| R2
    C -.->|í…œí”Œë¦¿ ë‹¤ì–‘ì„±| R3

    %% ìŠ¤íƒ€ì¼ë§
    classDef dataSource fill:#e1f5fe
    classDef pipeline fill:#f3e5f5
    classDef model fill:#e8f5e8
    classDef eval fill:#fff3e0
    classDef deploy fill:#fce4ec

    class A,A1,A2,B,C dataSource
    class D,E,F,I pipeline
    class J,K,L,M,N,Q model
    class R1,R2,R3 eval
    class S,T,U,V,W deploy
```

### NLP Engine Terminology Clustering

```{mermaid}
graph TB
    subgraph INPUT ["Data Input"]
        A["Excel ë©”íƒ€ë°ì´í„°<br/>ìš©ì–´ ì‚¬ì „ ì‘ì—…ìš©_labIDE.xlsx"]
        A1["ì†ì„±ëª…_ìˆ˜ì •<br/>ì»¬ëŸ¼ ë©”íƒ€ë°ì´í„°"]
        A2["í…Œì´ë¸”ëª…_ìˆ˜ì •<br/>í…Œì´ë¸” ë©”íƒ€ë°ì´í„°"]
        
        A --> A1
        A --> A2
    end

    subgraph PREP ["Term Preprocessing"]
        B["Term Extraction<br/>í•œê¸€/ì˜ë¬¸/ë¬¼ë¦¬ëª… ë¶„ë¦¬"]
        C["Data Cleaning<br/>ì¤‘ë³µ ì œê±°, ë¹ˆ ê°’ í•„í„°ë§"]
        D["Term Standardization<br/>5,000+ ìš©ì–´ ì •ì œ"]
        
        A1 --> B
        A2 --> B
        B --> C
        C --> D
    end

    subgraph EMBED ["Embedding Generation"]
        E["SentenceTransformer<br/>jhgan/ko-sroberta-multitask"]
        F["Batch Processing<br/>batch_size=32"]
        G["Vector Generation<br/>768-dim embeddings"]
        
        D --> E
        E --> F
        F --> G
    end

    subgraph CLUSTER ["Clustering Pipeline"]
        H["Similarity Calculation<br/>Cosine Similarity Matrix"]
        I["HDBSCAN Clustering<br/>min_cluster_size=2"]
        J["Agglomerative Clustering<br/>Alternative Method"]
        
        G --> H
        H --> I
        H --> J
    end

    subgraph ANALYSIS ["Cluster Analysis"]
        K["Representative Term<br/>Selection Logic"]
        L["Similarity Scoring<br/>Intra-cluster Coherence"]
        M["Term Type Analysis<br/>Korean/English/Physical"]
        N["System Distribution<br/>Cross-system Mapping"]
        
        I --> K
        J --> K
        K --> L
        L --> M
        M --> N
    end

    subgraph OUTPUT ["Results & Visualization"]
        O["Excel Export<br/>4ê°œ ì‹œíŠ¸ ê²°ê³¼"]
        P["Cluster Summary<br/>í‘œì¤€í™” ì¶”ì²œì•ˆ"]
        Q["Visualization<br/>ë¶„í¬ ì°¨íŠ¸"]
        R["Similar Term Search<br/>Query Interface"]
        
        N --> O
        O --> P
        P --> Q
        Q --> R
    end

    %% ì—°ê²°ì„ 
    G -.->|ì„ë² ë”© ë²¡í„°| H
    I -.->|í´ëŸ¬ìŠ¤í„° ë¼ë²¨| K
    K -.->|ëŒ€í‘œ ìš©ì–´| P

    %% ìŠ¤íƒ€ì¼ë§
    classDef inputBox fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    classDef prepBox fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef embedBox fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef clusterBox fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef analysisBox fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    classDef outputBox fill:#e0f2f1,stroke:#00695c,stroke-width:2px

    class A,A1,A2 inputBox
    class B,C,D prepBox
    class E,F,G embedBox
    class H,I,J clusterBox
    class K,L,M,N analysisBox
    class O,P,Q,R outputBox
```


### í†µí•© NLP ë©”íƒ€ë°ì´í„° í‘œì¤€í™” í”Œë«í¼

```{mermaid}
graph TB
    subgraph INPUT ["Data Sources"]
        A1["í‘œì¤€í™” ì›ì¹™ PDF<br/>200ê°œ ê·œì¹™"]
        A2["í‘œì¤€ ë‹¨ì–´ ì‚¬ì „<br/>14ê·¸ë£¹ ë¶„ë¥˜"]
        A3["Excel ë©”íƒ€ë°ì´í„°<br/>ìš©ì–´ ì‚¬ì „ ì‘ì—…ìš©"]
        A4["ê¸°ì¡´ ë„ë©”ì¸ ì‚¬ì „<br/>ì¤‘ë³µ ê²€ì¦ìš©"]
    end

    subgraph DATAPREP ["Data Preparation"]
        subgraph TRAIN_DATA ["Training Data Generation"]
            B1["LLM Data Generator<br/>Claude 4 Sonnet"]
            B2["Domain Generator<br/>í…œí”Œë¦¿ ê¸°ë°˜"]
            B4["Data Merger<br/>ìŠ¤í‚¤ë§ˆ í†µí•©"]
            
            A1 --> B1
            A2 --> B2
            A4 --> B2
            B1 --> B4
            B2 --> B4
        end
        
        subgraph REAL_DATA ["Operational Data Processing"]
            B3["Term Extractor<br/>í•œê¸€/ì˜ë¬¸/ë¬¼ë¦¬ëª…"]
            B5["Data Cleaning<br/>ì¤‘ë³µ ì œê±°, ì •ì œ"]
            
            A3 --> B3
            B3 --> B5
        end
    end

    subgraph PROCESSING ["Parallel NLP Processing"]
        subgraph DOMAIN ["Domain Classification Model"]
            C1["Training Dataset<br/>5,632ê°œ ìƒì„± ë„ë©”ì¸"]
            C2["KoBERT Classifier<br/>768â†’14 classes"]
            C3["Model Training<br/>95.39% ì •í™•ë„"]
            C4["New Domain Prediction<br/>ì‹ ê·œ ë„ë©”ì¸ ë¶„ë¥˜"]
            
            C1 --> C2 --> C3 --> C4
        end
        
        subgraph CLUSTER ["Advanced Term Clustering"]
            D1["Real Term Dataset<br/>1,000+ ìš´ì˜ ìš©ì–´"]
            D2["SentenceTransformer<br/>ko-sroberta-multitask"]
            D3["Multi-Method Clustering<br/>HDBSCAN + Agglomerative"]
            D4["Dimensionality Reduction<br/>t-SNE, UMAP, PCA"]
            D5["Advanced Analytics<br/>ë„¤íŠ¸ì›Œí¬ ë¶„ì„ + í’ˆì§ˆ ë©”íŠ¸ë¦­"]
            
            D1 --> D2 --> D3 --> D4 --> D5
        end
    end

    subgraph INTEGRATION ["Results Integration"]
        E1["Domain Classification<br/>ì‹ ê·œ ìš©ì–´ ê·¸ë£¹ ì˜ˆì¸¡"]
        E2["Interactive Visualization<br/> ëŒ€ì‹œë³´ë“œ + ë„¤íŠ¸ì›Œí¬"]
        E3["Quality Metrics<br/>ì‹¤ë£¨ì—£ ì ìˆ˜ + í´ëŸ¬ìŠ¤í„° í’ˆì§ˆ"]
        E4["Standardization Engine<br/>í†µí•© í‘œì¤€í™” ê¶Œì¥ì•ˆ"]
        
        C4 --> E1
        D5 --> E2
        E2 --> E3
        E1 --> E4
        E3 --> E4
    end

    subgraph DEPLOYMENT ["Advanced Visualization & Export"]
        F1["ML Model Storage<br/>kobert_classifier.pth"]
        F2["Interactive Dashboard<br/>Plotly HTML + ì›Œë“œí´ë¼ìš°ë“œ"]
        F3["Network Visualization<br/>ìœ ì‚¬ë„ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„"]
        F4["Streamlit Web Platform<br/>í†µí•© NLP ë¶„ì„ ë„êµ¬"]
        F5["Multi-format Export<br/>Excel + HTML + ì‹œê°í™”"]
        
        E1 --> F1
        E2 --> F2
        E2 --> F3
        F1 --> F4
        F2 --> F4
        F3 --> F4
        F4 --> F5
    end

    %% ë°ì´í„° íë¦„
    B4 --> C1
    B5 --> D1
    E1 -.->|ë¶„ë¥˜ ëª¨ë¸| E4
    E2 -.->|ì‹œê°í™” ë¶„ì„| E3
    E3 -.->|í’ˆì§ˆ ê²€ì¦| E4

    %% ìŠ¤íƒ€ì¼ë§
    classDef inputStyle fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    classDef prepStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef domainStyle fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef clusterStyle fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef integrationStyle fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    classDef deployStyle fill:#e0f2f1,stroke:#00695c,stroke-width:2px

    class A1,A2,A3,A4 inputStyle
    class B1,B2,B3,B4,B5 prepStyle
    class C1,C2,C3,C4 domainStyle
    class D1,D2,D3,D4,D5 clusterStyle
    class E1,E2,E3,E4 integrationStyle
    class F1,F2,F3,F4,F5 deployStyle
```

### í‘œì¤€í™” í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ ì•„í‚¤í…ì³

```{mermaid}
graph TB
    %% Main Entry Point
    Main[DataStandardizationAnalyzer<br/>ë©”ì¸ ë¶„ì„ê¸°]
    
    %% Core Processing Classes
    DataLoader[DataLoader<br/>ë°ì´í„° ë¡œë”]
    TokenProcessor[TokenProcessor<br/>í† í° ì²˜ë¦¬ê¸°]
    AbbreviationManager[AbbreviationManager<br/>ì•½ì–´ ê´€ë¦¬ì]
    RuleAnalyzer[RuleAnalyzer<br/>ê·œì¹™ ë¶„ì„ê¸°]
    
    %% Rule Checker Classes
    subgraph RuleCheckers["ê·œì¹™ ê²€ì¦ê¸°ë“¤"]
        
    end
    
    %% Analysis Classes
    CompletenessAnalyzer[CompletenessAnalyzer<br/>ì™„ì „ì„± ë¶„ì„ê¸°]
    VocabularyAnalyzer[VocabularyAnalyzer<br/>ì–´íœ˜ ë¶„ì„ê¸°]
    
    %% Output Classes
    ReportGenerator[ReportGenerator<br/>ë³´ê³ ì„œ ìƒì„±ê¸°]
    TroubleShooting[TroubleShooting<br/>ë””ë²„ê¹… ë„êµ¬]
    
    %% Data Structures
    subgraph DataStructures["ë°ì´í„° êµ¬ì¡°"]
        EntityInfo[EntityInfo<br/>ì—”í‹°í‹° ì •ë³´]
        RuleViolation[RuleViolation<br/>ê·œì¹™ ìœ„ë°˜ ì •ë³´]
        TokenAnalysis[TokenAnalysis<br/>í† í° ë¶„ì„ ê²°ê³¼]
    end
    
    %% Enums
    subgraph Enums["ì—´ê±°í˜•"]
        AbbreviationStrategy[AbbreviationStrategy<br/>ì•½ì–´ ìƒì„± ì „ëµ]
        DuplicateResolutionStrategy[DuplicateResolutionStrategy<br/>ì¤‘ë³µ í•´ê²° ì „ëµ]
    end
    
    %% External Data
    ExcelFile[(Excel File<br/>ë…¼ë¦¬ëª… ì·¨í•© ë°ì´í„°)]
    DomainDict[(Domain Dictionary<br/>ë„ë©”ì¸ ì‚¬ì „)]
    
    %% Output Files
    Results[(ë¶„ì„ ê²°ê³¼<br/>Excel/Text Files)]
    GlossaryDict[(ìš©ì–´ì‚¬ì „<br/>Glossary Dictionary)]
    
    %% Main Flow
    Main --> DataLoader
    Main --> RuleAnalyzer
    Main --> CompletenessAnalyzer
    Main --> ReportGenerator
    Main --> TroubleShooting
    
    %% Data Loading
    ExcelFile --> DataLoader
    DataLoader --> |í…Œì´ë¸”/ì»¬ëŸ¼ ë°ì´í„°| RuleAnalyzer
    
    %% Token Processing Flow
    RuleAnalyzer --> TokenProcessor
    RuleAnalyzer --> AbbreviationManager
    TokenProcessor --> AbbreviationManager
    
    %% Rule Checking
    RuleAnalyzer --> RuleCheckers
    RuleCheckers --> EntityInfo
    RuleCheckers --> RuleViolation
    
    %% Abbreviation Management
    AbbreviationManager --> AbbreviationStrategy
    AbbreviationManager --> DuplicateResolutionStrategy
    AbbreviationManager --> TokenAnalysis
    
    %% Analysis Flow
    RuleAnalyzer --> |ë¶„ì„ ê²°ê³¼| ReportGenerator
    DataLoader --> |ì›ë³¸ ë°ì´í„°| CompletenessAnalyzer
    DataLoader --> |ë…¼ë¦¬ëª… ë°ì´í„°| VocabularyAnalyzer
    
    %% Domain Integration
    DomainDict --> |ë„ë©”ì¸ ë§¤í•‘| GlossaryDict
    RuleAnalyzer --> |ì—”í‹°í‹° ì •ë³´| GlossaryDict
    
    %% Output Generation
    ReportGenerator --> Results
    CompletenessAnalyzer --> Results
    VocabularyAnalyzer --> Results
    
    %% Debugging
    TroubleShooting --> AbbreviationManager
    TroubleShooting --> TokenProcessor
    
    %% Styling
    classDef mainClass fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    classDef coreClass fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef ruleClass fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    classDef dataClass fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    classDef outputClass fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    
    class Main mainClass
    class DataLoader,TokenProcessor,AbbreviationManager,RuleAnalyzer coreClass
    class BasicRuleChecker,ConsonantRuleChecker,VowelRuleChecker,LengthRuleChecker ruleClass
    class EntityInfo,RuleViolation,TokenAnalysis,AbbreviationStrategy,DuplicateResolutionStrategy dataClass
    class ReportGenerator,CompletenessAnalyzer,VocabularyAnalyzer,TroubleShooting,Results,GlossaryDict outputClass
```


### NLP Classifier ë‹¤ì´ì–´ê·¸ë¨ (0805 ìµœì‹ )

```{mermaid}
graph TD
    %% Data Generation
    subgraph DataGen["í›ˆë ¨ ë°ì´í„° ìƒì„±"]
        RuleGen[ê·œì¹™ê¸°ë°˜ ìƒì„±ê¸°<br/>2,800ê°œ ë„ë©”ì¸]
        LLMGen[LLM ìƒì„±ê¸°<br/>2,800ê°œ ë„ë©”ì¸]
    end
    
    %% Data Processing
    DataMerger[ë°ì´í„° í†µí•©<br/>ì¤‘ë³µì œê±°]
    TrainingData[í†µí•© í›ˆë ¨ì…‹<br/>~5,600ê°œ ë„ë©”ì¸<br/>14ê°œ ê·¸ë£¹]
    
    %% Model Training
    subgraph ModelTrain["KoBERT ë¶„ë¥˜ê¸°"]
        Tokenizer[KoBERT<br/>Tokenizer]
        Model[KoBERT Encoder<br/>+ Classifier Head]
        Training[ëª¨ë¸ í›ˆë ¨<br/>3 epochs]
    end
    
    %% Output
    TrainedModel[í›ˆë ¨ëœ ëª¨ë¸<br/>kobert_domain_classifier.pth]
    Prediction[ë„ë©”ì¸ ë¶„ë¥˜ ì˜ˆì¸¡<br/>ì‹ ë¢°ë„ í¬í•¨]
    
    %% Flow
    RuleGen --> DataMerger
    LLMGen --> DataMerger
    DataMerger --> TrainingData
    
    TrainingData --> Tokenizer
    Tokenizer --> Model
    Model --> Training
    Training --> TrainedModel
    
    TrainedModel --> Prediction
    
    %% Domain Groups Box
    DomainGroups[" 14ê°œ ë„ë©”ì¸ ê·¸ë£¹<br/>ë‚ ì§œ, ëª…, ë²ˆí˜¸, ì‹ë³„, ì½”ë“œ, ë¶„ë¥˜, ê°’,<br/> ìˆ˜, ìœ¨, ë‚´ìš©, ë³´ì•ˆ, ë‹¨ìœ„, ì§‘í•©, ì¼ë°˜ë‹¨ì–´"]
    
    TrainingData -.-> DomainGroups
    
    %% Styling
    classDef generation fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef processing fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef model fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    classDef output fill:#f1f8e9,stroke:#558b2f,stroke-width:2px
    classDef info fill:#f5f5f5,stroke:#757575,stroke-width:1px
    
    class RuleGen,LLMGen generation
    class DataMerger,TrainingData processing
    class Tokenizer,Model,Training model
    class TrainedModel,Prediction output
    class DomainGroups info
```

```{mermaid}
graph TB
    %% Data Generation Phase
    subgraph DataGeneration["ğŸ“Š í›ˆë ¨ ë°ì´í„° ìƒì„±"]
        %% Rule-based Generation
        subgraph RuleBased["ğŸ”§ ê·œì¹™ê¸°ë°˜ ìƒì„±"]
            StandardWordDict[(í‘œì¤€ ë‹¨ì–´ ì‚¬ì „<br/>tokenized_word_initial_pool)]
            DomainDict[(ê¸°ì¡´ ë„ë©”ì¸ ì‚¬ì „<br/>domain_dictionary)]
            
            DomainGenerator[EnhancedDomainGenerator<br/>ê·œì¹™ê¸°ë°˜ ë„ë©”ì¸ ìƒì„±ê¸°]
            
            StandardWordDict --> DomainGenerator
            DomainDict --> DomainGenerator
            
            DomainGenerator --> RuleGeneratedData[(ê·œì¹™ìƒì„± ë°ì´í„°<br/>2,800ê°œ ë„ë©”ì¸<br/>14ê°œ ê·¸ë£¹)]
        end
        
        %% LLM Generation  
        subgraph LLMBased["ğŸ¤– LLM ê¸°ë°˜ ìƒì„±"]
            LLMPrompt[LLM í”„ë¡¬í”„íŠ¸<br/>PCR ì‹¤í—˜ íŠ¹í™”]
            LLMModel[Large Language Model]
            
            LLMPrompt --> LLMModel
            LLMModel --> DomainDataMD[(domain_data.md<br/>2,800ê°œ ë„ë©”ì¸<br/>14ê°œ ê·¸ë£¹)]
        end
    end
    
    %% Data Processing Phase
    subgraph DataProcessing["ğŸ”„ ë°ì´í„° ì²˜ë¦¬"]
        %% MD to Parquet Conversion
        MDParser[MDâ†’Parquet ë³€í™˜ê¸°<br/>parse_md_to_dataframe]
        DomainDataMD --> MDParser
        MDParser --> LLMParquet[(domain_data.parquet<br/>êµ¬ì¡°í™”ëœ ë°ì´í„°)]
        
        %% Rule-based to Parquet
        RuleGeneratedData --> RuleParquet[(domain_generated_domains_for_training.parquet<br/>ê·œì¹™ê¸°ë°˜ êµ¬ì¡°í™” ë°ì´í„°)]
        
        %% Data Merging
        DataMerger[ë°ì´í„° ë³‘í•©ê¸°<br/>merge_domain_data]
        LLMParquet --> DataMerger
        RuleParquet --> DataMerger
        DataMerger --> MergedData[(í†µí•© í›ˆë ¨ ë°ì´í„°<br/>~5,600ê°œ ë„ë©”ì¸<br/>ì¤‘ë³µì œê±° í›„)]
    end
    
    %% Model Training Phase
    subgraph ModelTraining["ğŸ§  KoBERT ë¶„ë¥˜ê¸° í›ˆë ¨"]
        %% Data Preparation
        DataLoader[DomainDataset<br/>ë°ì´í„° ë¡œë”]
        MergedData --> DataLoader
        
        %% Tokenization
        KoBERTTokenizer[KoBERT Tokenizer<br/>monologg/kobert]
        DataLoader --> KoBERTTokenizer
        
        %% Model Architecture
        subgraph ModelArch["ëª¨ë¸ ì•„í‚¤í…ì²˜"]
            KoBERTModel[KoBERT Encoder<br/>Pre-trained Model]
            DropoutLayer[Dropout Layer<br/>0.3]
            ClassifierHead[Classification Head<br/>Linear Layer]
            
            KoBERTModel --> DropoutLayer
            DropoutLayer --> ClassifierHead
        end
        
        KoBERTTokenizer --> ModelArch
        
        %% Training Components
        Optimizer[AdamW Optimizer<br/>lr=2e-5]
        LossFunction[CrossEntropyLoss]
        TrainingLoop[Training Loop<br/>3 epochs, batch=64]
        
        ModelArch --> TrainingLoop
        Optimizer --> TrainingLoop
        LossFunction --> TrainingLoop
        
        %% Model Output
        TrainingLoop --> TrainedModel[Trained Model<br/>kobert_domain_classifier.pth]
    end
    
    %% Evaluation Phase
    subgraph ModelEvaluation["ğŸ“ˆ ëª¨ë¸ í‰ê°€"]
        TestDataset[Test Dataset<br/>20% ë¶„í• ]
        DetailedEval[ìƒì„¸ í‰ê°€<br/>detailed_evaluation]
        
        DataLoader --> TestDataset
        TrainedModel --> DetailedEval
        TestDataset --> DetailedEval
        
        DetailedEval --> EvalResults[(í‰ê°€ ê²°ê³¼<br/>ì •í™•ë„, ë¶„ë¥˜ ë³´ê³ ì„œ<br/>í˜¼ë™ í–‰ë ¬)]
    end
    
    %% Prediction Phase
    subgraph Prediction["ğŸ”® ì˜ˆì¸¡ ì„œë¹„ìŠ¤"]
        InputDomain[ì…ë ¥ ë„ë©”ì¸ëª…<br/>ì˜ˆ: ì‹¤í—˜ì‹œì‘ì¼ì]
        PredictFunction[predict í•¨ìˆ˜]
        
        TrainedModel --> PredictFunction
        InputDomain --> PredictFunction
        PredictFunction --> PredResult[(ì˜ˆì¸¡ ê²°ê³¼<br/>ë„ë©”ì¸ ê·¸ë£¹ + ì‹ ë¢°ë„)]
    end
    
    %% Data Flow Labels
    DataGeneration -.-> DataProcessing
    DataProcessing -.-> ModelTraining  
    ModelTraining -.-> ModelEvaluation
    ModelTraining -.-> Prediction
    
    %% Domain Groups
    subgraph DomainGroups["ğŸ“‹ 14ê°œ ë„ë©”ì¸ ê·¸ë£¹"]
        Groups["ë‚ ì§œ, ë³´ì•ˆ, ì½”ë“œ, ë¶„ë¥˜, ëª…, ë²ˆí˜¸<br/>ì‹ë³„, ë‚´ìš©, ê°’, ìˆ˜, ìœ¨, ë‹¨ìœ„<br/>ì§‘í•©, ì¼ë°˜ë‹¨ì–´"]
    end
    
    %% Key Components Styling
    classDef dataSource fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef ruleEngine fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef llmEngine fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    classDef processing fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef model fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    classDef output fill:#f1f8e9,stroke:#558b2f,stroke-width:2px
    
    class StandardWordDict,DomainDict,DomainDataMD,MergedData dataSource
    class DomainGenerator,MDParser,DataMerger processing
    class LLMModel,LLMPrompt llmEngine
    class KoBERTModel,KoBERTTokenizer,DataLoader,TrainingLoop model
    class TrainedModel,EvalResults,PredResult output
```

### airflow í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨

```{mermaid}
graph TB
    subgraph "Phase 1: ê¸°ë³¸ í™˜ê²½ êµ¬ì¶•"
        A1["ğŸ³ Docker Composeë¡œ<br/>Airflow ì„¤ì¹˜"] --> A2["ğŸ”— Connection ì„¤ì •<br/>PostgreSQL, API endpoints"]
        A2 --> A3["ğŸ“ ê¸°ë³¸ DAG ì‘ì„±<br/>BashOperator í…ŒìŠ¤íŠ¸"]
    end
    
    subgraph "Phase 2: í•µì‹¬ ì›Œí¬í”Œë¡œìš° êµ¬í˜„"
        B1["ğŸ Python Operatorë¡œ<br/>NLP ì—”ì§„ ì—°ë™"] --> B2["ğŸ“¡ Xcomìœ¼ë¡œ<br/>ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•"]
        B2 --> B3["ğŸ”€ ë¶„ê¸° ì²˜ë¦¬ë¡œ<br/>ë‹¤ì–‘í•œ ì…ë ¥ íƒ€ì… ëŒ€ì‘"]
    end
    
    subgraph "Phase 3: ê³ ê¸‰ ê¸°ëŠ¥ ì ìš©"
        C1["ğŸ‘ï¸ Sensorë¡œ<br/>ì‹¤ì‹œê°„ ì²˜ë¦¬"] --> C2["âš™ï¸ Custom Operator<br/>ê°œë°œ"]
        C2 --> C3["ğŸ“Š ëª¨ë‹ˆí„°ë§ ë°<br/>ì•Œë¦¼ ì„¤ì •"]
    end

    subgraph "ë©”ì¸ íŒŒì´í”„ë¼ì¸ DAG íë¦„"
        D1["ğŸ“¥ DataLoader<br/>ë°ì´í„° ìˆ˜ì§‘"] --> D2{"ğŸ”„ ì…ë ¥ íƒ€ì…<br/>ë¶„ê¸°"}
        
        D2 -->|í…Œì´ë¸”/ì»¬ëŸ¼| D3["ğŸ”¤ TokenProcessor<br/>í† í° ë¶„ì„"]
        D2 -->|ì‚¬ìš©ì ì…ë ¥| D4["ğŸ¤– RAG System<br/>ê·œì¹™ ê²€ìƒ‰"]
        D2 -->|ì½”ë“œ ìŠ¤ë‹ˆí«| D4
        
        D3 --> D5["ğŸ§  Domain NLP Engine<br/>ë„ë©”ì¸ ë¶„ë¥˜"]
        D4 --> D6["ğŸ“š Terminology NLP<br/>ìš©ì–´ í´ëŸ¬ìŠ¤í„°ë§"]
        D5 --> D6
        
        D6 --> D7["ğŸ“– í†µí•© ì‚¬ì „<br/>ë©”íƒ€ë°ì´í„° í†µí•©"]
        D7 --> D8["âœ… ê²€ì¦ ì‹œìŠ¤í…œ<br/>í’ˆì§ˆ ê²€ì¦"]
        D8 --> D9["ğŸ“Š ReportGenerator<br/>ê²°ê³¼ ë³´ê³ ì„œ"]
        D9 --> D10["ğŸ–¥ï¸ ëŒ€ì‹œë³´ë“œ<br/>ì—…ë°ì´íŠ¸"]
    end

    subgraph "ì‹¤ì‹œê°„ ì²˜ë¦¬ DAG"
        E1["ğŸ‘ï¸ FileSensor<br/>ìƒˆ ë°ì´í„° ê°ì§€"] --> E2["âš¡ ë¹ ë¥¸ ì²˜ë¦¬<br/>íŒŒì´í”„ë¼ì¸"]
        E2 --> E3["ğŸ”„ ì¦‰ì‹œ ë°˜ì˜<br/>ì¶”ì²œ ì—…ë°ì´íŠ¸"]
    end

    A3 --> B1
    B3 --> C1
    C3 --> D1
    D10 --> E1

    %% ìŠ¤íƒ€ì¼ë§
    style A1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style A2 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style A3 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    
    style B1 fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style B2 fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style B3 fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    
    style C1 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style C2 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style C3 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    
    style D1 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style D2 fill:#ffebee,stroke:#d32f2f,stroke-width:3px
    style D3 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style D4 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style D5 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style D6 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style D7 fill:#fce4ec,stroke:#ad1457,stroke-width:2px
    style D8 fill:#e0f2f1,stroke:#00695c,stroke-width:2px
    style D9 fill:#e0f2f1,stroke:#00695c,stroke-width:2px
    style D10 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    
    style E1 fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    style E2 fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    style E3 fill:#fff3e0,stroke:#ef6c00,stroke-width:2px

```

## ğŸ¯ **Airflow ë„ì…ì´ í•„ìš”í•œ ì´ìœ **

1. **ë³µì¡í•œ ì˜ì¡´ê´€ê³„**: Processing Layerì˜ ì—¬ëŸ¬ NLP ì—”ì§„ë“¤ê³¼ RAG ì‹œìŠ¤í…œ ê°„ ì˜ì¡´ì„±
2. **ì •ê¸°ì  ë°°ì¹˜ ì²˜ë¦¬**: ë©”íƒ€ë°ì´í„° ê°±ì‹ , ëª¨ë¸ ì¬í›ˆë ¨, í’ˆì§ˆ ê²€ì¦
3. **ì‹¤ì‹œê°„ì— ê°€ê¹Œìš´ ì²˜ë¦¬**: ìƒˆë¡œìš´ ë°ì´í„° ì…ë ¥ ì‹œ ìë™ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
4. **ëª¨ë‹ˆí„°ë§ í•„ìš”ì„±**: ê° ì»´í¬ë„ŒíŠ¸ë³„ ì„±ëŠ¥ ë° í’ˆì§ˆ ì§€í‘œ ì¶”ì 

## ğŸ—ï¸ **Airflow ì•„í‚¤í…ì²˜ ì„¤ê³„**

### **1. DAG êµ¬ì¡° ì„¤ê³„**

```python
# ë©”ì¸ ë°ì´í„° ì²˜ë¦¬ DAG
with DAG(
    dag_id="metadata_standardization_pipeline",
    schedule="0 2 * * *",  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ ì‹¤í–‰
    start_date=pendulum.datetime(2024, 1, 1, tz="Asia/Seoul"),
    catchup=False,
    tags=["metadata", "standardization", "nlp"]
) as dag:
```

### **2. í•µì‹¬ ì›Œí¬í”Œë¡œìš° ë§¤í•‘**

| ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ | Airflow êµ¬í˜„ ë°©ì‹ | ì‚¬ìš©í•  Operator |
|:---|:---|:---|
| **DataLoader** | ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬ | `PythonOperator`, `PostgresOperator` |
| **TokenProcessor** | í† í° ë¶„ì„ ë°°ì¹˜ ì‘ì—… | `PythonOperator` |
| **Domain NLP Engine** | ML ëª¨ë¸ ì¶”ë¡  | `PythonOperator`, `KubernetesPodOperator` |
| **RAG System** | RAG ê²€ìƒ‰ ë° GPT í˜¸ì¶œ | `PythonOperator`, `SimpleHttpOperator` |
| **Terminology NLP** | ìš©ì–´ í´ëŸ¬ìŠ¤í„°ë§ | `PythonOperator` |
| **í†µí•© ì‚¬ì „ ê´€ë¦¬** | ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ | `PostgresOperator`, `PythonOperator` |
| **ê²€ì¦ ì‹œìŠ¤í…œ** | í’ˆì§ˆ ê²€ì¦ ë°°ì¹˜ | `PythonOperator`, `BranchPythonOperator` |
| **ë³´ê³ ì„œ ìƒì„±** | ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„± | `PythonOperator`, `EmailOperator` |

## ğŸ”§ **í™œìš©í•  Airflow ê¸°ëŠ¥ë“¤**

### **1. Sensor í™œìš© (ì‹¤ì‹œê°„ ì²˜ë¦¬)**
```python
# ìƒˆë¡œìš´ ë°ì´í„° ì…ë ¥ ê°ì§€
new_data_sensor = FileSensor(
    task_id='detect_new_standardization_data',
    filepath='/data/input/new_data.flag',
    fs_conn_id='data_fs',
    poke_interval=30,  # 30ì´ˆë§ˆë‹¤ ì²´í¬
    mode='reschedule'
)
```

### **2. ë¶„ê¸° ì²˜ë¦¬ (BranchPythonOperator)**
```python
def decide_processing_path(**context):
    # ë°ì´í„° ìœ í˜•ì— ë”°ë¥¸ ì²˜ë¦¬ ë¶„ê¸°
    data_type = context['ti'].xcom_pull(key='data_type')
    if data_type == 'table_column':
        return 'token_processing_task'
    elif data_type == 'user_input':
        return 'nlp_processing_task'
    else:
        return 'rag_processing_task'

branch_task = BranchPythonOperator(
    task_id='decide_processing_path',
    python_callable=decide_processing_path
)
```

### **3. Xcomì„ í†µí•œ ë°ì´í„° ê³µìœ **
```python
# TokenProcessor ê²°ê³¼ë¥¼ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ë‹¬
@task
def token_analysis(**context):
    tokens = process_tokens(context['ti'].xcom_pull(key='input_data'))
    return {'tokens': tokens, 'domain_hints': extract_domain_hints(tokens)}

@task  
def domain_classification(**context):
    token_data = context['ti'].xcom_pull(task_ids='token_analysis')
    domains = classify_domains(token_data['tokens'])
    return domains
```

### **4. Task Groupsìœ¼ë¡œ ëª¨ë“ˆí™”**
```python
with TaskGroup("nlp_processing_group") as nlp_group:
    token_task = PythonOperator(
        task_id='token_processing',
        python_callable=process_tokens
    )
    
    domain_task = PythonOperator(
        task_id='domain_classification', 
        python_callable=classify_domains
    )
    
    terminology_task = PythonOperator(
        task_id='terminology_clustering',
        python_callable=cluster_terminology
    )
    
    token_task >> [domain_task, terminology_task]
```

### **5. Connection & Hook (ì™¸ë¶€ ì‹œìŠ¤í…œ ì—°ë™)**
```python
# PostgreSQL ë©”íƒ€ë°ì´í„° DB ì—°ë™
postgres_hook = PostgresHook(postgres_conn_id='metadata_db')

# RAG ì‹œìŠ¤í…œ API ì—°ë™  
@task
def call_rag_system(**context):
    http_hook = SimpleHttpHook(http_conn_id='rag_api')
    response = http_hook.run(
        endpoint='/search',
        data={'query': context['ti'].xcom_pull(key='search_query')},
        headers={'Content-Type': 'application/json'}
    )
    return response.json()
```

### **6. ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì„¤ì •**
```python
# SLA ì„¤ì •ìœ¼ë¡œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
dag_defaults = {
    'sla': timedelta(hours=2),  # 2ì‹œê°„ ë‚´ ì™„ë£Œ
    'email_on_failure': True,
    'email_on_retry': False,
    'email': ['data-team@company.com'],
    'retries': 2,
    'retry_delay': timedelta(minutes=10)
}

# í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨ ì‹œ ì•Œë¦¼
quality_check_task = PythonOperator(
    task_id='data_quality_check',
    python_callable=check_data_quality,
    on_failure_callback=send_quality_alert
)
```

## ğŸ“… **DAG êµ¬ì„± ì˜ˆì‹œ**

### **ë©”ì¸ íŒŒì´í”„ë¼ì¸ DAG**
```python
# 1. ë°ì´í„° ìˆ˜ì§‘
data_loader >> 

# 2. ë³‘ë ¬ ì²˜ë¦¬
[token_processor, rag_processor] >>

# 3. NLP ì—”ì§„ë“¤
[domain_nlp, terminology_nlp] >>

# 4. ê²°ê³¼ í†µí•©
metadata_integration >>

# 5. ê²€ì¦
[rule_analyzer, completeness_analyzer] >>

# 6. ë³´ê³ ì„œ ìƒì„±
report_generator >>

# 7. ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸
dashboard_update
```

### **ì‹¤ì‹œê°„ ì²˜ë¦¬ DAG**
```python
# Sensorë¡œ ìƒˆ ì…ë ¥ ê°ì§€
new_input_sensor >>

# ë¹ ë¥¸ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
[quick_token_analysis, rag_recommendation] >>

# ê²°ê³¼ ì¦‰ì‹œ ë°˜ì˜
update_recommendations
```

## ğŸ› ï¸ **êµ¬í˜„ ìˆœì„œ**

### **Phase 1: ê¸°ë³¸ í™˜ê²½ êµ¬ì¶•**
1. **Docker Composeë¡œ Airflow ì„¤ì¹˜** (`02.env_setting.qmd` ì°¸ê³ )
2. **Connection ì„¤ì •** - PostgreSQL, API endpoints (`09.connection_hook.qmd`)
3. **ê¸°ë³¸ DAG ì‘ì„±** (`03.operator_basic.qmd`)

### **Phase 2: í•µì‹¬ ì›Œí¬í”Œë¡œìš° êµ¬í˜„**
1. **Python Operatorë¡œ NLP ì—”ì§„ ì—°ë™** (`04.python_operator.qmd`)
2. **Xcomìœ¼ë¡œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•** (`06.data_share.qmd`)
3. **ë¶„ê¸° ì²˜ë¦¬ë¡œ ë‹¤ì–‘í•œ ì…ë ¥ íƒ€ì… ëŒ€ì‘** (`07.task_handling.qmd`)

### **Phase 3: ê³ ê¸‰ ê¸°ëŠ¥ ì ìš©**
1. **Sensorë¡œ ì‹¤ì‹œê°„ ì²˜ë¦¬** (`10.sensor.qmd`)
2. **Custom Operator ê°œë°œ** (`08.more_operators.qmd`)
3. **ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì„¤ì •** (`11.airflow_functions.qmd`)

## ğŸ¯ **ê¸°ëŒ€ íš¨ê³¼**

1. **ìë™í™”**: ìˆ˜ë™ ê°œì… ì—†ì´ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
2. **ì‹ ë¢°ì„±**: ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„, ì•Œë¦¼ìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´
3. **í™•ì¥ì„±**: ìƒˆë¡œìš´ NLP ëª¨ë¸ì´ë‚˜ ê²€ì¦ ë¡œì§ ì‰½ê²Œ ì¶”ê°€
4. **ëª¨ë‹ˆí„°ë§**: ê° ë‹¨ê³„ë³„ ì„±ëŠ¥ ë° í’ˆì§ˆ ì§€í‘œ ì‹¤ì‹œê°„ ì¶”ì 
5. **ì¼ê´€ì„±**: í‘œì¤€í™”ëœ ì›Œí¬í”Œë¡œìš°ë¡œ ë°ì´í„° í’ˆì§ˆ ë³´ì¥

ì´ë ‡ê²Œ Airflowë¥¼ ë„ì…í•˜ë©´ ë³µì¡í•œ ë©”íƒ€ë°ì´í„° í‘œì¤€í™” ì‹œìŠ¤í…œì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê³  ìë™í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

## ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### Ver5.1

```{mermaid}
graph TB
    subgraph "Data Input Layer"
        A[ìµœì´ˆ í‘œì¤€í™” ë°ì´í„°<br/>í…Œì´ë¸”/ì»¬ëŸ¼ ëª…ì„¸ì„œ] --> B[DataLoader]
        A1[Streamlit UI<br/>ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°] --> B
        A2[ì½”ë“œ ìŠ¤ë‹ˆí«<br/>ë³€ìˆ˜ëª…/ì»¬ëŸ¼ëª…] --> B
    end
    
    subgraph "Processing Layer"
        B -.-> |ë…¼ë¦¬ëª…| C[TokenProcessor<br/>í† í° ë¶„ì„]
        B -.-> |ê³µí†µì½”ë“œ| MD3[CodeTable<br/>ì½”ë“œ í…Œì´ë¸”]
        B -.-> |ì½”ë“œ ìŠ¤ë‹ˆí«| LLM    
        C --> D[DomainClassifier<br/>ë„ë©”ì¸ ê·¸ë£¹ ë¶„ë¥˜]
        D --> E[AbbreviationManager<br/>ì•½ì–´ ìƒì„±]
        E --> MD1[WordDictionary<br/>í‘œì¤€ ë‹¨ì–´ ì‚¬ì „]
        D --> MD2[DomainDictionary<br/>ë„ë©”ì¸ ì‚¬ì „]
        

        subgraph "RAG"
            subgraph "RAG Knowledge Base"
                KB1[í‘œì¤€í™” ê·œì¹™ ë¬¸ì„œ<br/>PDF/DOCX]
                KB2[ë„¤ì´ë° ì»¨ë²¤ì…˜<br/>ê°€ì´ë“œë¼ì¸]
                KB3[ë„ë©”ì¸ ìš©ì–´ ì‚¬ì „<br/>ê¸°ì¡´ ìš©ì–´ DB]
                KB4[ì½”ë“œ íŒ¨í„´ ì˜ˆì‹œ<br/>ë³€ìˆ˜ëª… ë§¤í•‘]
                
                KB1 --> EMB[OpenAI Embeddings<br/>text-embedding-3-small]
                KB2 --> EMB
                KB3 --> EMB
                KB4 --> EMB
                EMB --> FAISS[Vector Store<br/>ë²¡í„° ê²€ìƒ‰ ì—”ì§„]
            end

            subgraph "RAG Enhancement Module"
                RAG1[RAG Retriever<br/>ê´€ë ¨ ê·œì¹™ ê²€ìƒ‰]
                RAG3[Context Matcher<br/>ìœ ì‚¬ íŒ¨í„´ ê²€ìƒ‰]
                LLM[GPT-4o<br/>ì½”ë“œ to ë…¼ë¦¬ëª… ì¶”ì²œ]
            end
        end
    

        subgraph "Metadata Management Layer"
            MD1[WordDictionary<br/>í‘œì¤€ ë‹¨ì–´ ì‚¬ì „]
            MD2[DomainDictionary<br/>ë„ë©”ì¸ ì‚¬ì „]
            MD3[CodeTable<br/>ì½”ë“œ í…Œì´ë¸”]
            MD4[TerminologyDictionary<br/>ìš©ì–´ ì‚¬ì „]
            MD1 --> MD4         
            MD2 --> MD4         
            MD3 --> MD4         
        end
        
        E --> ABR[ìƒì„±ëœ ì•½ì–´]
        MD4 --> H[DataCompletenessAnalyzer<br/>ì™„ì „ì„± ê²€ì¦]
        MD4 --> F[RuleAnalyzer<br/>ì¼ê´€ì„± ê·œì¹™ ê²€ì¦]
        ABR --> F
        RAG1 --> LLM
        LLM --> C
    
        subgraph "NLP Domain Model"
            DG[DomainGenerator<br/>ë„ë©”ì¸ ë°ì´í„° ìƒì„±]
            DC[Domain Model Training<br/>Bi-LSTM + Attention]
            D[DomainClassifier<br/>ë„ë©”ì¸ ê·¸ë£¹ ë¶„ë¥˜]
            DG --> DC
        end
        
        subgraph "NLP Terminology Model"
            NLP1[SBERT Model<br/>ë¬¸ì¥ ì„ë² ë”©]
            NLP2[ALBERT Model<br/>ë¬¸ë§¥ ì´í•´]
            NLP3[Similarity Calculator<br/>ì½”ì‚¬ì¸ ìœ ì‚¬ë„]
            NLP4[Clustering Engine<br/>K-means/DBSCAN]
            ST1[SimilarTermClassifier<br/>ìœ ì‚¬ ìš©ì–´ ë¶„ë¥˜]
            ST2[TermClusteringAnalyzer<br/>ìš©ì–´ í´ëŸ¬ìŠ¤í„°ë§]
            
            NLP1 --> NLP3
            NLP2 --> NLP3
            NLP3 --> NLP4
            NLP1 -.->|ì„ë² ë”©| ST1
            NLP2 -.->|ë¬¸ë§¥ ë¶„ì„| ST1
            NLP4 -.->|í´ëŸ¬ìŠ¤í„°ë§| ST2
        end

        
    end

    subgraph "Analysis Layer"
        F --> G[ReportGenerator<br/>ë¶„ì„ ê²°ê³¼ ë³´ê³ ]
        F --> I[VocabularyAnalyzer<br/>ë‹¨ì–´ ë¶„ì„]
        D --> J[DomainGroupAnalyzer<br/>ë„ë©”ì¸ ê·¸ë£¹ í†µê³„]
        F --> K[TroubleShooting<br/>ë””ë²„ê¹…]
        H --> G
        ST1 --> G
        ST2 --> G
        RAG3 --> G
    end
    
    subgraph "Output Layer"
        G --> L[ëª…ëª… ê·œì¹™ ë¶„ì„ ë‚´ì—­]
        I --> N[ë‹¨ì–´ í†µê³„ ë¶„ì„ ê²°ê³¼]
        J --> O[ë„ë©”ì¸ ê·¸ë£¹ ë¶„ë¥˜ ê²°ê³¼<br/>í‘œì¤€í™” ê¶Œì¥ì‚¬í•­]
        K --> P[ì˜¤ë¥˜ ì§„ë‹¨]
        LLM --> REC[ë…¼ë¦¬ëª… ì¶”ì²œ ê²°ê³¼]
        ABR --> ABR_OUT[ì•½ì–´ ìƒì„± ê²°ê³¼]
    end
    
    subgraph "Streamlit Interface"
        STR1[ì•½ì–´ ìƒì„± íƒ­<br/>ë…¼ë¦¬ëª… to ì•½ì–´]
        STR2[ë…¼ë¦¬ëª… ì¶”ì²œ íƒ­<br/>ì½”ë“œ to ë…¼ë¦¬ëª…]
        STR3[ê²€ì¦ ê²°ê³¼ íƒ­<br/>í’ˆì§ˆ ë¶„ì„]
        
        L --> STR3
        N --> STR3
        O --> STR3
        P --> STR3
        REC --> STR2
        ABR_OUT --> STR1
    end
    
    %% ëª¨ë“ˆ ê°„ ì—°ê²°
    FAISS --> RAG1
    FAISS --> RAG3
    RAG3 --> LLM
    

    LLM --> E
    DC -.->|í•™ìŠµëœ ëª¨ë¸| D
    MD4 --> NLP1
    MD4 --> NLP2
    
    %% ìŠ¤íƒ€ì¼ë§
    style A fill:#e1f5fe
    style A1 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style A2 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style KB1 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style KB2 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style KB3 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style KB4 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style EMB fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style FAISS fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style RAG1 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style RAG2 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style RAG3 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style LLM fill:#ffebee,stroke:#c62828,stroke-width:3px
    style E fill:#4caf50,stroke:#2e7d32,stroke-width:3px
    style ABR fill:#4caf50,stroke:#2e7d32,stroke-width:2px
    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px
    style STR1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style STR2 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style STR3 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style REC fill:#ffebee,stroke:#c62828,stroke-width:2px
    style ABR_OUT fill:#4caf50,stroke:#2e7d32,stroke-width:2px
```

### Ver5.0

```{mermaid}
graph TB
    subgraph "Data Input Layer"
        A[ìµœì´ˆ í‘œì¤€í™” ë°ì´í„°<br/>í…Œì´ë¸”/ì»¬ëŸ¼ ëª…ì„¸ì„œ] --> B[DataLoader]
        A1[Streamlit UI<br/>ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°] --> B
        A2[ì½”ë“œ ìŠ¤ë‹ˆí«<br/>ë³€ìˆ˜ëª…/ì»¬ëŸ¼ëª…] --> B
    end
    
    subgraph "Processing Layer"
        
        subgraph "RAG Knowledge Base"
            KB1[í‘œì¤€í™” ê·œì¹™ ë¬¸ì„œ<br/>PDF/DOCX]
            KB2[ë„¤ì´ë° ì»¨ë²¤ì…˜<br/>ê°€ì´ë“œë¼ì¸]
            KB3[ë„ë©”ì¸ ìš©ì–´ ì‚¬ì „<br/>ê¸°ì¡´ ìš©ì–´ DB]
            KB4[ì½”ë“œ íŒ¨í„´ ì˜ˆì‹œ<br/>ë³€ìˆ˜ëª… ë§¤í•‘]
            
            KB1 --> EMB[OpenAI Embeddings<br/>text-embedding-3-small]
            KB2 --> EMB
            KB3 --> EMB
            KB4 --> EMB
            EMB --> FAISS[Vector Store<br/>ë²¡í„° ê²€ìƒ‰ ì—”ì§„]
        end

        subgraph "RAG Enhancement Module"
            RAG1[RAG Retriever<br/>ê´€ë ¨ ê·œì¹™ ê²€ìƒ‰]
            RAG2[Code Analyzer<br/>ì½”ë“œ to ë…¼ë¦¬ëª… ì¶”ì²œ]
            RAG3[Context Matcher<br/>ìœ ì‚¬ íŒ¨í„´ ê²€ìƒ‰]
            LLM[GPT-4o<br/>ë…¼ë¦¬ëª… ì¶”ì²œ ì „ìš©]
            
            FAISS --> RAG1
            FAISS --> RAG2
            FAISS --> RAG3
            RAG2 --> LLM
            RAG3 --> LLM
        end
        
        subgraph "Metadata Management Layer"
            MD1[WordDictionary<br/>í‘œì¤€ ë‹¨ì–´ ì‚¬ì „]
            MD2[DomainDictionary<br/>ë„ë©”ì¸ ì‚¬ì „]
            MD3[CodeTable<br/>ì½”ë“œ í…Œì´ë¸”]
            MD4[TerminologyDictionary<br/>ìš©ì–´ ì‚¬ì „]
            MD1 --> MD4         
            MD2 --> MD4         
            MD3 --> MD4         
        end

        subgraph "NLP Domain Model"
            DG[DomainGenerator<br/>ë„ë©”ì¸ ë°ì´í„° ìƒì„±]
            DC[Domain Model Training<br/>Bi-LSTM + Attention]
            D[DomainClassifier<br/>ë„ë©”ì¸ ê·¸ë£¹ ë¶„ë¥˜]
            DG --> DC
            DC -.->|í•™ìŠµëœ ëª¨ë¸| D
        end
        
        subgraph "NLP Terminology Model"
            NLP1[SBERT Model<br/>ë¬¸ì¥ ì„ë² ë”©]
            NLP2[ALBERT Model<br/>ë¬¸ë§¥ ì´í•´]
            NLP3[Similarity Calculator<br/>ì½”ì‚¬ì¸ ìœ ì‚¬ë„]
            NLP4[Clustering Engine<br/>K-means/DBSCAN]
            ST1[SimilarTermClassifier<br/>ìœ ì‚¬ ìš©ì–´ ë¶„ë¥˜]
            ST2[TermClusteringAnalyzer<br/>ìš©ì–´ í´ëŸ¬ìŠ¤í„°ë§]
            
            NLP1 --> NLP3
            NLP2 --> NLP3
            NLP3 --> NLP4
            NLP1 -.->|ì„ë² ë”©| ST1
            NLP2 -.->|ë¬¸ë§¥ ë¶„ì„| ST1
            NLP4 -.->|í´ëŸ¬ìŠ¤í„°ë§| ST2
        end

        B --> |ë…¼ë¦¬ëª…| C[TokenProcessor<br/>í† í° ë¶„ì„]
        B --> |ì½”ë“œ|RAG2
        C --> D
        D --> E[AbbreviationManager<br/>ì•½ì–´ ìƒì„±]
        RAG1 --> 
        
        LLM --> E
        E --> MD1[WordDictionary<br/>í‘œì¤€ ë‹¨ì–´ ì‚¬ì „]
        D --> MD2[DomainDictionary<br/>ë„ë©”ì¸ ì‚¬ì „]
        B --> MD3[CodeTable<br/>ì½”ë“œ í…Œì´ë¸”]
        
        
        
        MD4 --> NLP1
        MD4 --> NLP2
        
        E --> ABR[ìƒì„±ëœ ì•½ì–´]

        
        
        
        MD4 --> H[DataCompletenessAnalyzer<br/>ì™„ì „ì„± ê²€ì¦]
        MD4 --> F[RuleAnalyzer<br/>ì¼ê´€ì„± ê·œì¹™ ê²€ì¦]
        ABR --> F
    end
    
    subgraph "Analysis Layer"
        F --> G[ReportGenerator<br/>ë¶„ì„ ê²°ê³¼ ë³´ê³ ]
        F --> I[VocabularyAnalyzer<br/>ë‹¨ì–´ ë¶„ì„]
        D --> J[DomainGroupAnalyzer<br/>ë„ë©”ì¸ ê·¸ë£¹ í†µê³„]
        F --> K[TroubleShooting<br/>ë””ë²„ê¹…]
        H --> G
        ST1 --> G
        ST2 --> G
        RAG3 --> G
    end
    
    subgraph "Output Layer"
        G --> L[ëª…ëª… ê·œì¹™ ë¶„ì„ ë‚´ì—­]
        I --> N[ë‹¨ì–´ í†µê³„ ë¶„ì„ ê²°ê³¼]
        J --> O[ë„ë©”ì¸ ê·¸ë£¹ ë¶„ë¥˜ ê²°ê³¼<br/>í‘œì¤€í™” ê¶Œì¥ì‚¬í•­]
        K --> P[ì˜¤ë¥˜ ì§„ë‹¨]
        LLM --> REC[ë…¼ë¦¬ëª… ì¶”ì²œ ê²°ê³¼]
        ABR --> ABR_OUT[ì•½ì–´ ìƒì„± ê²°ê³¼]
    end
    
    subgraph "Streamlit Interface"
        STR1[ì•½ì–´ ìƒì„± íƒ­<br/>ë…¼ë¦¬ëª… to ì•½ì–´]
        STR2[ë…¼ë¦¬ëª… ì¶”ì²œ íƒ­<br/>ì½”ë“œ to ë…¼ë¦¬ëª…]
        STR3[ê²€ì¦ ê²°ê³¼ íƒ­<br/>í’ˆì§ˆ ë¶„ì„]
        
        L --> STR3
        N --> STR3
        O --> STR3
        P --> STR3
        REC --> STR2
        ABR_OUT --> STR1
        REC --> STR1
    end
    
    %% ìŠ¤íƒ€ì¼ë§
    style A fill:#e1f5fe
    style A1 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style A2 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style KB1 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style KB2 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style KB3 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style KB4 fill:#fff8e1,stroke:#ff8f00,stroke-width:2px
    style EMB fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style FAISS fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style RAG1 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style RAG2 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style RAG3 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style LLM fill:#ffebee,stroke:#c62828,stroke-width:3px
    style E fill:#4caf50,stroke:#2e7d32,stroke-width:3px
    style ABR fill:#4caf50,stroke:#2e7d32,stroke-width:2px
    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px
    style STR1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style STR2 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style STR3 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style REC fill:#ffebee,stroke:#c62828,stroke-width:2px
    style ABR_OUT fill:#4caf50,stroke:#2e7d32,stroke-width:2px
```

### Ver4.0

```{mermaid}
graph TB
    subgraph "Data Input Layer"
        A[ìµœì´ˆ í‘œì¤€í™” ë°ì´í„°<br/>í…Œì´ë¸”/ì»¬ëŸ¼ ëª…ì„¸ì„œ] --> B[DataLoader]
        A1[Streamlit UI<br/>ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°] --> B
    end
    
    subgraph "Processing Layer"
        B --> C[TokenProcessor<br/>í† í° ë¶„ì„]
        C --> D[DomainClassifier<br/>ë„ë©”ì¸ ê·¸ë£¹ ë¶„ë¥˜]
        D --> E[AbbreviationManager<br/>ì•½ì–´ ìƒì„±]
        
        E -->  MD1[WordDictionary<br/>í‘œì¤€ ë‹¨ì–´ ì‚¬ì „]
        D --> MD2[DomainDictionary<br/>ë„ë©”ì¸ ì‚¬ì „]
        B --> MD3[CodeTable<br/>ì½”ë“œ í…Œì´ë¸”]
        
        subgraph "Metadata Management Layer"
            MD1[WordDictionary<br/>í‘œì¤€ ë‹¨ì–´ ì‚¬ì „]
            MD2[DomainDictionary<br/>ë„ë©”ì¸ ì‚¬ì „]
            MD3[CodeTable<br/>ì½”ë“œ í…Œì´ë¸”]
            MD4[TerminologyDictionary<br/>ìš©ì–´ ì‚¬ì „]
            MD1 --> MD4         
            MD2 --> MD4         
            MD3 --> MD4         
        end
        
        MD4 --> NLP1
        MD4 --> NLP2

        
        subgraph "NLP Domain Model"
            DG[DomainGenerator<br/>ë„ë©”ì¸ ë°ì´í„° ìƒì„±]
            DC[Domain Model Training<br/>Bi-LSTM + Attention]
            DG --> DC
            DC -.->|í•™ìŠµëœ ëª¨ë¸| D
        end
        
        subgraph "NLP Terminology Model"
            NLP1[SBERT Model<br/>ë¬¸ì¥ ì„ë² ë”©]
            NLP2[ALBERT Model<br/>ë¬¸ë§¥ ì´í•´]
            NLP3[Similarity Calculator<br/>ì½”ì‚¬ì¸ ìœ ì‚¬ë„]
            NLP4[Clustering Engine<br/>K-means/DBSCAN]
            ST1[SimilarTermClassifier<br/>ìœ ì‚¬ ìš©ì–´ ë¶„ë¥˜]
            ST2[TermClusteringAnalyzer<br/>ìš©ì–´ í´ëŸ¬ìŠ¤í„°ë§]
            
            NLP1 --> NLP3
            NLP2 --> NLP3
            NLP3 --> NLP4
            NLP1 -.->|ì„ë² ë”©| ST1
            NLP2 -.->|ë¬¸ë§¥ ë¶„ì„| ST1
            NLP4 -.->|í´ëŸ¬ìŠ¤í„°ë§| ST2

        end
        
    
        MD4 --> H[DataCompletenessAnalyzer<br/>ì™„ì „ì„± ê²€ì¦]
        MD4 --> F[RuleAnalyzer<br/>ì¼ê´€ì„± ê·œì¹™ ê²€ì¦]
    end
    
    subgraph "Analysis Layer"
        F --> G[ReportGenerator<br/>ë¶„ì„ ê²°ê³¼ ë³´ê³ ]
        F --> I[VocabularyAnalyzer<br/>ë‹¨ì–´ ë¶„ì„]
        D --> J[DomainGroupAnalyzer<br/>ë„ë©”ì¸ ê·¸ë£¹ í†µê³„]
        F --> K[TroubleShooting<br/>ë””ë²„ê¹…]
        H --> G
        ST1 --> G
        ST2 --> G
    end
    
    subgraph "Output Layer"
        G --> L[ëª…ëª… ê·œì¹™ ë¶„ì„ ë‚´ì—­]
        I --> N[ë‹¨ì–´ í†µê³„ ë¶„ì„ ê²°ê³¼]
        J --> O[ë„ë©”ì¸ ê·¸ë£¹ ë¶„ë¥˜ ê²°ê³¼<br/>í‘œì¤€í™” ê¶Œì¥ì‚¬í•­]
        K --> P[ì˜¤ë¥˜ ì§„ë‹¨]
        

    end
    
    subgraph "Presentation Layer"
        L --> STR[Streamlit ì‹¤ì‹œê°„ ë°˜ì˜]
        N --> STR[Streamlit ì‹¤ì‹œê°„ ë°˜ì˜]
        O --> STR[Streamlit ì‹¤ì‹œê°„ ë°˜ì˜]
        P --> STR[Streamlit ì‹¤ì‹œê°„ ë°˜ì˜]
    end
    
    %% ìŠ¤íƒ€ì¼ë§
    style A fill:#e1f5fe
    style A1 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px
    style DG fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style DC fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style J fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style MD1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style MD2 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style MD3 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style MD4 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style ST1 fill:#e8eaf6,stroke:#5c6bc0,stroke-width:2px
    style ST2 fill:#e8eaf6,stroke:#5c6bc0,stroke-width:2px
    style L fill:#e8f5e8
    style N fill:#e8f5e8
    style O fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style P fill:#e8f5e8

```



### Ver3.0

```{mermaid}

graph TB
    subgraph "Data Input Layer"
        A[ìµœì´ˆ í‘œì¤€í™” ë°ì´í„°<br/>í…Œì´ë¸”/ì»¬ëŸ¼ ëª…ì„¸ì„œ] --> B[DataLoader]
        A1[Streamlit UI<br/>ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°] --> B
    end
    
    subgraph "Processing Layer"
        B --> C[TokenProcessor<br/>í† í° ë¶„ì„]
        C --> D[DomainClassifier<br/>ë„ë©”ì¸ ê·¸ë£¹ ë¶„ë¥˜]
        D --> E[AbbreviationManager<br/>ì•½ì–´ ìƒì„±]
        
        E -->  MD1[WordDictionary<br/>í‘œì¤€ ë‹¨ì–´ ì‚¬ì „]
        D --> MD2[DomainDictionary<br/>ë„ë©”ì¸ ì‚¬ì „]
        B --> MD3[CodeTable<br/>ì½”ë“œ í…Œì´ë¸”]
        
        subgraph "Metadata Management Layer"
            MD1[WordDictionary<br/>í‘œì¤€ ë‹¨ì–´ ì‚¬ì „]
            MD2[DomainDictionary<br/>ë„ë©”ì¸ ì‚¬ì „]
            MD3[CodeTable<br/>ì½”ë“œ í…Œì´ë¸”]
            MD4[TerminologyDictionary<br/>ìš©ì–´ ì‚¬ì „]
            MD1 --> MD4         
            MD2 --> MD4         
            MD3 --> MD4         
        end
        
        MD4[TerminologyDictionary<br/>ìš©ì–´ ì‚¬ì „] --> H[DataCompletenessAnalyzer<br/>ì™„ì „ì„± ê²€ì¦]
        MD4[TerminologyDictionary<br/>ìš©ì–´ ì‚¬ì „] --> F[RuleAnalyzer<br/>ì¼ê´€ì„± ê·œì¹™ ê²€ì¦]
        
        subgraph "NLP Model Lifecycle"
            DG[DomainGenerator<br/>ë„ë©”ì¸ ë°ì´í„° ìƒì„±]
            DC[Domain Model Training<br/>Bi-LSTM + Attention]
            DG --> DC
            DC -.->|í•™ìŠµëœ ëª¨ë¸| D
        end
    end
    
    subgraph "Analysis Layer"
        F --> G[ReportGenerator<br/>ë¶„ì„ ê²°ê³¼ ë³´ê³ ]
        F --> I[VocabularyAnalyzer<br/>ë‹¨ì–´ ë¶„ì„]
        D --> J[DomainGroupAnalyzer<br/>ë„ë©”ì¸ ê·¸ë£¹ í†µê³„]
        F --> K[TroubleShooting<br/>ë””ë²„ê¹…]
        H --> G[ReportGenerator<br/>ë¶„ì„ ê²°ê³¼ ë³´ê³ ]
    end
    
    subgraph "Output Layer"
        G --> L[ëª…ëª… ê·œì¹™ ë¶„ì„ ë‚´ì—­]
        
        I --> N[ë‹¨ì–´ í†µê³„ ë¶„ì„ ê²°ê³¼]
        J --> O[ë„ë©”ì¸ ê·¸ë£¹ ë¶„ë¥˜ ê²°ê³¼<br/>í‘œì¤€í™” ê¶Œì¥ì‚¬í•­]
        K --> P[ì˜¤ë¥˜ ì§„ë‹¨]
    end
    
    %% ìŠ¤íƒ€ì¼ë§
    style A fill:#e1f5fe
    style A1 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px
    style DG fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style DC fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style J fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style MD1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style MD2 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style MD3 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style MD4 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style L fill:#e8f5e8
    style M fill:#fff3e0
    style N fill:#e8f5e8
    style O fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style P fill:#e8f5e8
```

### Ver2.0

```{mermaid}
graph TB
    subgraph "Data Input Layer"
        A[Excel íŒŒì¼<br/>í…Œì´ë¸”/ì»¬ëŸ¼ ëª…ì„¸ì„œ] --> B[DataLoader]
        A1[Streamlit UI<br/>ì‚¬ìš©ì ì…ë ¥ ìš©ì–´] --> B
    end
    
    subgraph "Processing Layer"
        B --> C[TokenProcessor<br/>í† í° ë¶„ì„]
        C --> D[DomainClassifier<br/>ë„ë©”ì¸ ê·¸ë£¹ ë¶„ë¥˜]
        D --> E[AbbreviationManager<br/>ì•½ì–´ ìƒì„±]
        E --> F[RuleAnalyzer<br/>ì¼ê´€ì„± ê·œì¹™ ê²€ì¦]
        
        subgraph "NLP Model Lifecycle"
            DG[DomainGenerator<br/>ë„ë©”ì¸ ë°ì´í„° ìƒì„±]
            DC[Domain Model Training<br/>Bi-LSTM + Attention]
            DG --> DC
            DC -.->|í•™ìŠµëœ ëª¨ë¸| D
        end
    end
    
    subgraph "Analysis Layer"
        F --> G[ReportGenerator<br/>ë¶„ì„ ê²°ê³¼ ë³´ê³ ]
        B --> H[DataCompletenessAnalyzer<br/>ì™„ì „ì„± ë¶„ì„]
        F --> I[VocabularyAnalyzer<br/>ë‹¨ì–´ ë¶„ì„]
        D --> J[DomainGroupAnalyzer<br/>ë„ë©”ì¸ ê·¸ë£¹ í†µê³„]
        F --> K[TroubleShooting<br/>ë””ë²„ê¹…]
    end
    
    subgraph "Output Layer"
        G --> L[ëª…ëª… ê·œì¹™ ë¶„ì„ ë‚´ì—­]
        H --> M[ë°ì´í„° í’ˆì§ˆ ì™„ì „ì„± ë¶„ì„ ê²°ê³¼]
        I --> N[ë‹¨ì–´ í†µê³„ ë¶„ì„ ê²°ê³¼]
        J --> O[ë„ë©”ì¸ ê·¸ë£¹ ë¶„ë¥˜ ê²°ê³¼<br/>í‘œì¤€í™” ê¶Œì¥ì‚¬í•­]
        K --> P[ì˜¤ë¥˜ ì§„ë‹¨]
    end
    
    %% ìŠ¤íƒ€ì¼ë§
    style A fill:#e1f5fe
    style A1 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px
    style DG fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style DC fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style J fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style L fill:#e8f5e8
    style M fill:#fff3e0
    style N fill:#e8f5e8
    style O fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style P fill:#e8f5e8

```

### Ver1.0
```{mermaid}
graph TB
    subgraph "Data Input Layer"
        A[Excel íŒŒì¼<br/>í…Œì´ë¸”/ì»¬ëŸ¼ ëª…ì„¸ì„œ] --> B[DataLoader]
    end
    
    subgraph "Processing Layer"
        B --> C[TokenProcessor<br/>í† í° ë¶„ì„]
        C --> D[AbbreviationManager<br/>ì•½ì–´ ìƒì„±]
        D --> E[RuleAnalyzer<br/>ì¼ê´€ì„± ê·œì¹™ ê²€ì¦]
    end
    
    subgraph "Analysis Layer"
        E --> F[ReportGenerator<br/>ë¶„ì„ ê²°ê³¼ ë³´ê³ ]
        B --> G[DataCompletenessAnalyzer<br/>ì™„ì „ì„± ë¶„ì„]
        E --> H[VocabularyAnalyzer<br/>ë‹¨ì–´ ë¶„ì„]
        E --> I[TroubleShooting<br/>ë””ë²„ê¹…]
    end
    
    subgraph "Output Layer"
        F --> J[ëª…ëª… ê·œì¹™ ë¶„ì„ ë‚´ì—­]
        G --> K[ë°ì´í„° í’ˆì§ˆ ì™„ì „ì„± ë¶„ì„ ê²°ê³¼]
        H --> L[ë‹¨ì–´ í†µê³„ ë¶„ì„ ê²°ê³¼]
        I --> M[ì˜¤ë¥˜ ì§„ë‹¨]
    end
    
    style A fill:#e1f5fe
    style J fill:#e8f5e8
    style K fill:#fff3e0
    style L fill:#e8f5e8
    style M fill:#e8f5e8
```

## DataLoader í´ë˜ìŠ¤ ìƒì„¸ í”Œë¡œìš°

```{mermaid}
flowchart TD
    Start([ì‹œì‘]) --> Init[DataLoader ì´ˆê¸°í™”]
    Init --> FontSetup{í°íŠ¸ ì„¤ì •}
    FontSetup -->|ì„±ê³µ| LoadData[Excel ë°ì´í„° ë¡œë”©]
    FontSetup -->|ì‹¤íŒ¨| ContinueLoad[ê²½ê³  í›„ ê³„ì† ì§„í–‰]
    ContinueLoad --> LoadData
    
    LoadData --> ValidateFile{íŒŒì¼ ì¡´ì¬ í™•ì¸}
    ValidateFile -->|íŒŒì¼ ì—†ìŒ| Error1[ì˜¤ë¥˜: íŒŒì¼ ì—†ìŒ]
    ValidateFile -->|íŒŒì¼ ìˆìŒ| ReadSheets[ì‹œíŠ¸ë³„ ë°ì´í„° ì½ê¸°]
    
    ReadSheets --> Sheet1[ìˆ˜ì • í…Œì´ë¸” ëª…ì„¸ì„œ<br/>Sheet 2]
    ReadSheets --> Sheet2[ìˆ˜ì • ì»¬ëŸ¼ ëª…ì„¸ì„œ<br/>Sheet 3]
    ReadSheets --> Sheet3[ì›ë³¸ í…Œì´ë¸” ëª…ì„¸ì„œ<br/>Sheet 4]
    ReadSheets --> Sheet4[ì›ë³¸ ì»¬ëŸ¼ ëª…ì„¸ì„œ<br/>Sheet 5]
    
    Sheet1 --> PrepareData[í…Œì´ë¸” ë°ì´í„° ì „ì²˜ë¦¬]
    Sheet2 --> PrepareData
    Sheet3 --> PrepareData
    Sheet4 --> PrepareData
    
    PrepareData --> ExtractColumns[í•„ìš” ì»¬ëŸ¼ ì¶”ì¶œ]
    ExtractColumns --> JoinData[í…Œì´ë¸”-ì»¬ëŸ¼ ë°ì´í„° ì¡°ì¸]
    
    JoinData --> RawJoin[ì›ë³¸ ë°ì´í„° ì¡°ì¸<br/>tabl_phys_name ê¸°ì¤€]
    JoinData --> ModJoin[ìˆ˜ì • ë°ì´í„° ì¡°ì¸<br/>tabl_phys_name ê¸°ì¤€]
    
    RawJoin --> Summary[ë°ì´í„° ìš”ì•½ ì¶œë ¥]
    ModJoin --> Summary
    Summary --> Success([ì™„ë£Œ])
    
    Error1 --> End([ì¢…ë£Œ])
    
    style Start fill:#c8e6c9
    style Success fill:#c8e6c9
    style Error1 fill:#ffcdd2
    style End fill:#ffcdd2
```

## í† í° ì²˜ë¦¬ ë° ì•½ì–´ ìƒì„± í”Œë¡œìš°

```{mermaid}
flowchart TD
    Input[ë…¼ë¦¬ëª… ì…ë ¥] --> Tokenize[TokenProcessor<br/>í† í°í™”]
    
    Tokenize --> CleanText[íŠ¹ìˆ˜ë¬¸ì ì œê±°]
    CleanText --> SplitTokens[ê³µë°±/ë°‘ì¤„ ê¸°ì¤€ ë¶„ë¦¬]
    SplitTokens --> RemoveStopWords[ë¶ˆìš©ì–´ ì œê±°]
    
    RemoveStopWords --> ProcessTokens{ê° í† í° ì²˜ë¦¬}
    
    ProcessTokens --> CheckLength{í† í° ê¸¸ì´ í™•ì¸}
    CheckLength -->|4ê¸€ì ì´í•˜| KeepOriginal[ì›ë³¸ ìœ ì§€]
    CheckLength -->|4ê¸€ì ì´ˆê³¼| CheckCommon{í†µìš© ì•½ì–´ í™•ì¸}
    
    CheckCommon -->|í†µìš© ì•½ì–´ ìˆìŒ| UseCommon[í†µìš© ì•½ì–´ ì‚¬ìš©]
    CheckCommon -->|í†µìš© ì•½ì–´ ì—†ìŒ| GenerateNew[ìƒˆ ì•½ì–´ ìƒì„±]
    
    GenerateNew --> ExtractConsonants[ììŒ ì¶”ì¶œ]
    ExtractConsonants --> FilterConsecutive[ì—°ì† ììŒ ì œê±°]
    FilterConsecutive --> CheckConsonantLength{ììŒ ê¸¸ì´ í™•ì¸}
    
    CheckConsonantLength -->|4ê¸€ì ì´ìƒ| TakeFirst4[ì²« 4ê°œ ììŒ ì‚¬ìš©]
    CheckConsonantLength -->|4ê¸€ì ë¯¸ë§Œ| AddVowels[ëª¨ìŒ ì¶”ê°€]
    
    TakeFirst4 --> CheckDuplicate{ì¤‘ë³µ í™•ì¸}
    AddVowels --> CheckDuplicate
    
    CheckDuplicate -->|ì¤‘ë³µ ì—†ìŒ| RegisterAbbr[ì•½ì–´ ë“±ë¡]
    CheckDuplicate -->|ì¤‘ë³µ ìˆìŒ| ResolveDuplicate[ì¤‘ë³µ í•´ê²°]
    
    ResolveDuplicate --> AddRemainingConsonants[ë‚¨ì€ ììŒ ì¶”ê°€]
    AddRemainingConsonants --> StillDuplicate{ì—¬ì „íˆ ì¤‘ë³µ?}
    StillDuplicate -->|ì˜ˆ| AddVowelsByPosition[ìœ„ì¹˜ë³„ ëª¨ìŒ ì¶”ê°€]
    StillDuplicate -->|ì•„ë‹ˆì˜¤| RegisterAbbr
    
    AddVowelsByPosition --> FinalCheck{ì—¬ì „íˆ ì¤‘ë³µ?}
    FinalCheck -->|ì˜ˆ| AddSequentialNumber[ìˆœì°¨ ë²ˆí˜¸ ì¶”ê°€]
    FinalCheck -->|ì•„ë‹ˆì˜¤| RegisterAbbr
    
    AddSequentialNumber --> RegisterAbbr
    RegisterAbbr --> KeepOriginal
    UseCommon --> KeepOriginal
    KeepOriginal --> CombineTokens[í† í° ê²°í•©]
    
    CombineTokens --> FinalAbbr[ìµœì¢… ì•½ì–´ ìƒì„±]
    
    style Input fill:#e3f2fd
    style FinalAbbr fill:#e8f5e8
    style CheckDuplicate fill:#fff3e0
    style ResolveDuplicate fill:#fff3e0
```

## ê·œì¹™ ê²€ì¦ ì‹œìŠ¤í…œ

```{mermaid}
flowchart TD
    Start[ë¶„ì„ ì‹œì‘] --> ValidateInput[ì…ë ¥ ë°ì´í„° ê²€ì¦]
    ValidateInput --> ProcessRows[í–‰ë³„ ì²˜ë¦¬]
    
    ProcessRows --> ExtractEntity[ì—”í‹°í‹° ì •ë³´ ì¶”ì¶œ]
    ExtractEntity --> TokenizeLogical[ë…¼ë¦¬ëª… í† í°í™”]
    TokenizeLogical --> CheckRules[ì¼ê´€ì„± ê·œì¹™ ê²€ì¦]
    
    CheckRules --> BasicRules[ê¸°ë³¸ ê·œì¹™ ê²€ì¦<br/>- ë¶ˆìš©ì–´ ì‚¬ìš© ê¸ˆì§€<br/>- í†µìš© ì•½ì–´ ì‚¬ìš©<br/>- ì†Œë¬¸ì ì‚¬ìš©]
    CheckRules --> LengthRules[ê¸¸ì´ ê·œì¹™ ê²€ì¦<br/>- 4ê¸€ì ì´í•˜ ì›ë³¸ ìœ ì§€<br/>- 4ê¸€ì êµ¬ì„± ì›ì¹™]
    CheckRules --> ConsonantRules[ììŒ ê·œì¹™ ê²€ì¦<br/>- ììŒ ìš°ì„ ìˆœìœ„<br/>- ì—°ì† ììŒ ì²˜ë¦¬]
    CheckRules --> VowelRules[ëª¨ìŒ ê·œì¹™ ê²€ì¦<br/>- ëª¨ìŒ ìœ„ì¹˜ ì²˜ë¦¬<br/>- 4ê¸€ì ë¯¸ë§Œ ë³´ì™„]
    
    BasicRules --> CollectViolations[ìœ„ë°˜ ì‚¬í•­ ìˆ˜ì§‘]
    LengthRules --> CollectViolations
    ConsonantRules --> CollectViolations
    VowelRules --> CollectViolations
    
    CollectViolations --> GenerateReport[ì²˜ë¦¬ ê²°ê³¼ ìƒì„±]
    GenerateReport --> Summary[ìš”ì•½ í†µê³„]
    GenerateReport --> SystemAnalysis[ì‹œìŠ¤í…œë³„ ë¶„ì„]
    GenerateReport --> ViolationDetails[ìœ„ë°˜ ìƒì„¸ ë¶„ì„]
    
    Summary --> Dashboard[ê²°ê³¼ ì¶œë ¥]
    SystemAnalysis --> Dashboard
    ViolationDetails --> Dashboard
    
    style Start fill:#c8e6c9
    style Dashboard fill:#c8e6c9
    style CollectViolations fill:#ffecb3
```

```{mermaid}
flowchart TD
    A[DataFrame ì…ë ¥] --> B[ì…ë ¥ ë°ì´í„° ê²€ì¦]
    B --> C[í–‰ë³„ ìˆœíšŒ ì‹œì‘]
    C --> D[ì—”í‹°í‹° ì •ë³´ ì¶”ì¶œ]
    D --> E[ë…¼ë¦¬ëª… í† í°í™”]
    E --> F[ë¬¼ë¦¬ëª… í† í°í™”]
    F --> G[í‘œì¤€ ì•½ì–´ ìƒì„±]
    G --> H[í† í°ë³„ ê·œì¹™ ê²€ì¦ ì‹œì‘]
    
    H --> I[ê·œì¹™ ê²€ì¦ê¸° ìˆœíšŒ]
    I --> J[1. ConsonantRuleChecker]
    J --> K[2. VowelRuleChecker]
    K --> L[3. LengthRuleChecker]
    L --> M[4. BasicRuleChecker]
    
    M --> N[ìœ„ë°˜ ì‚¬í•­ ìˆ˜ì§‘]
    N --> O[ìœ„ë°˜ ê·œì¹™ ë²ˆí˜¸ ì •ë¦¬]
    O --> P[ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ìƒì„±]
    P --> Q{ë” ë§ì€ í† í°?}
    Q -->|Yes| H
    Q -->|No| R{ë” ë§ì€ í–‰?}
    R -->|Yes| C
    R -->|No| S[ìµœì¢… DataFrame ìƒì„±]
    S --> T[í†µê³„ ì •ë³´ ìƒì„±]
    T --> U[ê²°ê³¼ ë°˜í™˜]
    
    style A fill:#e3f2fd
    style J fill:#fff3e0
    style K fill:#fff3e0
    style L fill:#fff3e0
    style M fill:#fff3e0
    style U fill:#e8f5e8
```

### 4.1. RuleAnalyzer ê·œì¹™ ê²€ì¦ê¸° ì²˜ë¦¬ ìˆœì„œ

```{mermaid}
graph LR
    A[í† í° ì…ë ¥] --> B[ConsonantRuleChecker]
    B --> |ê·œì¹™ 3,4,5,6,7,8,9,10,11| C[VowelRuleChecker]
    C --> |ê·œì¹™ 2| D[LengthRuleChecker]
    D --> |ê·œì¹™ 13| E[BasicRuleChecker]
    E --> |ê·œì¹™ 1,12,14| F[ìœ„ë°˜ì‚¬í•­ í†µí•©]
    
    style B fill:#ffeb3b
    style C fill:#ff9800
    style D fill:#2196f3
    style E fill:#9c27b0
    style F fill:#4caf50
```

### ê°œë³„ ê·œì¹™ ê²€ì¦ê¸° ìƒì„¸ ë¡œì§

```{mermaid}
flowchart TD
    subgraph "ConsonantRuleChecker"
        A1[ììŒ ìš°ì„ ìˆœìœ„ ê²€ì¦] --> A2[ì—°ì† ììŒ ê²€ì‚¬]
        A2 --> A3[ììŒ ì¡°í•© ê·œì¹™]
        A3 --> A4[ìœ„ë°˜ì‚¬í•­ ë°˜í™˜]
    end
    
    subgraph "VowelRuleChecker"
        B1[ëª¨ìŒ í¬í•¨ ê·œì¹™] --> B2[ììŒ ê°œìˆ˜ ê¸°ë°˜ ëª¨ìŒ í•„ìš”ì„±]
        B2 --> B3[ìœ„ë°˜ì‚¬í•­ ë°˜í™˜]
    end
    
    subgraph "LengthRuleChecker"
        C1[í† í° ê¸¸ì´ ê²€ì¦] --> C2[ì•½ì–´ ê¸¸ì´ ê·œì¹™]
        C2 --> C3[ìœ„ë°˜ì‚¬í•­ ë°˜í™˜]
    end
    
    subgraph "BasicRuleChecker"
        D1[ë¶ˆìš©ì–´ ê²€ì‚¬] --> D2[ê¸°ë³¸ ì•½ì–´ ê·œì¹™]
        D2 --> D3[ì†Œë¬¸ì ì‚¬ìš© ê·œì¹™]
        D3 --> D4[ìœ„ë°˜ì‚¬í•­ ë°˜í™˜]
    end
    
    style A1 fill:#ffcdd2
    style B1 fill:#f8bbd9
    style C1 fill:#c5cae9
    style D1 fill:#dcedc1
```



## ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ë° ROI

```{mermaid}
mindmap
  root((ë°ì´í„° í‘œì¤€í™”<br/>í† í° ë¶„ì„ê¸°))
    ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜
      ë°ì´í„° í’ˆì§ˆ í–¥ìƒ
        ì¼ê´€ëœ ëª…ëª… ê·œì¹™
        í‘œì¤€í™”ëœ ì•½ì–´ ì²´ê³„
        ì˜¤ë¥˜ ê°ì†Œ
      ìš´ì˜ íš¨ìœ¨ì„±
        ìë™í™”ëœ ê²€ì¦
        ë¹ ë¥¸ ë¬¸ì œ ì‹ë³„
        ê°œë°œ ìƒì‚°ì„± í–¥ìƒ
      ê·œì • ì¤€ìˆ˜
        í‘œì¤€ ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜
        ê°ì‚¬ ëŒ€ì‘ ìš©ì´
        ë¬¸ì„œí™” ìë™í™”
    ê¸°ìˆ ì  í˜œíƒ
      í™•ì¥ì„±
        ëª¨ë“ˆí™”ëœ êµ¬ì¡°
        í”ŒëŸ¬ê·¸ì¸ ë°©ì‹ ê·œì¹™ ì¶”ê°€
        ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ ì§€ì›
      ìœ ì§€ë³´ìˆ˜ì„±
        ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬
        í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ êµ¬ì¡°
        ë””ë²„ê¹… ë„êµ¬ ì œê³µ
      ì„±ëŠ¥
        ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›
        ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
        ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥
```

## 6. êµ¬í˜„ ìš°ì„ ìˆœìœ„ ë° ë¡œë“œë§µ

```{mermaid}
gantt
    title ë°ì´í„° í‘œì¤€í™” ì‹œìŠ¤í…œ êµ¬í˜„ ë¡œë“œë§µ
    dateFormat  YYYY-MM-DD
    section Phase 1: ê¸°ì´ˆ êµ¬ì¶•
    DataLoader êµ¬í˜„           :done, phase1a, 2024-01-01, 2024-01-15
    TokenProcessor êµ¬í˜„       :done, phase1b, 2024-01-16, 2024-01-30
    AbbreviationManager êµ¬í˜„  :done, phase1c, 2024-01-31, 2024-02-15
    
    section Phase 2: ê·œì¹™ ì—”ì§„
    RuleAnalyzer êµ¬í˜„         :active, phase2a, 2024-02-16, 2024-03-01
    ê·œì¹™ ê²€ì¦ê¸° êµ¬í˜„          :phase2b, 2024-03-02, 2024-03-15
    
    section Phase 3: ë¶„ì„ ë° ë³´ê³ 
    ReportGenerator êµ¬í˜„      :phase3a, 2024-03-16, 2024-03-30
    VocabularyAnalyzer êµ¬í˜„   :phase3b, 2024-03-31, 2024-04-15
    
    section Phase 4: ìš´ì˜ ì§€ì›
    TroubleShooting êµ¬í˜„      :phase4a, 2024-04-16, 2024-04-30
    ì„±ëŠ¥ ìµœì í™”              :phase4b, 2024-05-01, 2024-05-15
    ë¬¸ì„œí™” ë° êµìœ¡           :phase4c, 2024-05-16, 2024-05-30
```

## ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ë° KPI

```{mermaid}
graph LR
    subgraph "í’ˆì§ˆ ì§€í‘œ"
        A[ê·œì¹™ ì¤€ìˆ˜ìœ¨<br/>95% ì´ìƒ]
        B[ìë™ ê²€ì¦ë¥ <br/>100%]
        C[ì˜¤ë¥˜ ê°ì†Œìœ¨<br/>80% ì´ìƒ]
    end
    
    subgraph "íš¨ìœ¨ì„± ì§€í‘œ"
        D[ì²˜ë¦¬ ì‹œê°„<br/>< 5ë¶„/1000ê±´]
        E[ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰<br/>< 1GB]
        F[CPU ì‚¬ìš©ë¥ <br/>< 50%]
    end
    
    subgraph "ë¹„ì¦ˆë‹ˆìŠ¤ ì§€í‘œ"
        G[ê°œë°œ ìƒì‚°ì„±<br/>30% í–¥ìƒ]
        H[ë°ì´í„° í’ˆì§ˆ<br/>ì ìˆ˜ í–¥ìƒ]
        I[ìš´ì˜ ë¹„ìš©<br/>20% ì ˆê°]
    end
    
    A --> G
    B --> H
    C --> I
    D --> G
    E --> I
    F --> I
    
    style A fill:#e8f5e8
    style B fill:#e8f5e8
    style C fill:#e8f5e8
    style D fill:#e3f2fd
    style E fill:#e3f2fd
    style F fill:#e3f2fd
    style G fill:#fff3e0
    style H fill:#fff3e0
    style I fill:#fff3e0
```

## ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë° ëŒ€ì‘ ë°©ì•ˆ

```{mermaid}
flowchart TD
    subgraph "ê¸°ìˆ ì  ë¦¬ìŠ¤í¬"
        TR1[ì„±ëŠ¥ ì €í•˜]
        TR2[ë©”ëª¨ë¦¬ ë¶€ì¡±]
        TR3[ê·œì¹™ ì¶©ëŒ]
    end
    
    subgraph "ìš´ì˜ì  ë¦¬ìŠ¤í¬"
        OR1[ì‚¬ìš©ì êµìœ¡ ë¶€ì¡±]
        OR2[ë°ì´í„° í’ˆì§ˆ ë¬¸ì œ]
        OR3[ì‹œìŠ¤í…œ ì¥ì• ]
    end
    
    subgraph "ëŒ€ì‘ ë°©ì•ˆ"
        TR1 --> M1[ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”]
        TR2 --> M2[ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ë„ì…]
        TR3 --> M3[ê·œì¹™ ìš°ì„ ìˆœìœ„ ì •ì˜]
        
        OR1 --> M4[êµìœ¡ í”„ë¡œê·¸ë¨ ê°œë°œ]
        OR2 --> M5[ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ê°•í™”]
        OR3 --> M6[ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•]
    end
    
    M1 --> Success[ì„±ê³µì  ìš´ì˜]
    M2 --> Success
    M3 --> Success
    M4 --> Success
    M5 --> Success
    M6 --> Success
    
    style Success fill:#c8e6c9
    style TR1 fill:#ffcdd2
    style TR2 fill:#ffcdd2
    style TR3 fill:#ffcdd2
    style OR1 fill:#ffe0b2
    style OR2 fill:#ffe0b2
    style OR3 fill:#ffe0b2
```

---

## ìš”ì•½

ì´ ë°ì´í„° í‘œì¤€í™” í† í° ë¶„ì„ê¸°ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í•µì‹¬ ê°€ì¹˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤:

1. **ìë™í™”ëœ ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬**: ìˆ˜ë™ ê²€ì¦ì—ì„œ ìë™í™”ëœ ì‹œìŠ¤í…œìœ¼ë¡œ ì „í™˜
2. **í‘œì¤€í™”ëœ ëª…ëª… ê·œì¹™**: ì¼ê´€ëœ ë°ì´í„°ë² ì´ìŠ¤ ëª…ëª… ì²´ê³„ êµ¬ì¶•
3. **ìš´ì˜ íš¨ìœ¨ì„± í–¥ìƒ**: ê°œë°œì ìƒì‚°ì„± ì¦ëŒ€ ë° ì˜¤ë¥˜ ê°ì†Œ
4. **í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**: ìƒˆë¡œìš´ ê·œì¹™ ë° ìš”êµ¬ì‚¬í•­ ëŒ€ì‘ ìš©ì´
5. **í¬ê´„ì ì¸ ë¶„ì„ ê¸°ëŠ¥**: ìƒì„¸í•œ ë³´ê³ ì„œ ë° íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì§€ì›

ì´ ì‹œìŠ¤í…œì„ í†µí•´ ì¡°ì§ì€ ë°ì´í„° ê±°ë²„ë„ŒìŠ¤ë¥¼ ê°•í™”í•˜ê³ , ê°œë°œ í”„ë¡œì„¸ìŠ¤ë¥¼ ê°œì„ í•˜ë©°, ì¥ê¸°ì ìœ¼ë¡œ ìœ ì§€ë³´ìˆ˜ ë¹„ìš©ì„ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

## DataCompletenessAnalyzer ìƒì„¸ í”Œë¡œìš°

```{mermaid}
flowchart TD
    Start[ì™„ì „ì„± ë¶„ì„ ì‹œì‘] --> ValidateInput[ì…ë ¥ ë°ì´í„° ê²€ì¦]
    ValidateInput --> ProcessData[ë°ì´í„° ì²˜ë¦¬]
    
    ProcessData --> TableAnalysis[í…Œì´ë¸” ì™„ì „ì„± ë¶„ì„<br/>- ë…¼ë¦¬ëª…_êµ­ë¬¸<br/>- ë…¼ë¦¬ëª…_ì˜ë¬¸<br/>- ë¬¼ë¦¬ëª…]
    ProcessData --> ColumnAnalysis[ì»¬ëŸ¼ ì™„ì „ì„± ë¶„ì„<br/>- ë…¼ë¦¬ëª…_êµ­ë¬¸<br/>- ë…¼ë¦¬ëª…_ì˜ë¬¸<br/>- ë¬¼ë¦¬ëª…<br/>- ì„¤ëª…]
    
    TableAnalysis --> CalculateCompleteness[ì™„ì „ì„± ë¹„ìœ¨ ê³„ì‚°]
    ColumnAnalysis --> CalculateCompleteness
    
    CalculateCompleteness --> GenerateReport[ì™„ì „ì„± ë³´ê³ ì„œ ìƒì„±]
    GenerateReport --> TableSummary[í…Œì´ë¸” ì™„ì „ì„± ìš”ì•½]
    GenerateReport --> ColumnSummary[ì»¬ëŸ¼ ì™„ì „ì„± ìš”ì•½]
    GenerateReport --> OverallSummary[ì „ì²´ ìš”ì•½ í†µê³„]
    
    TableSummary --> Results[ë¶„ì„ ê²°ê³¼ ì¶œë ¥]
    ColumnSummary --> Results
    OverallSummary --> Results
    
    style Start fill:#c8e6c9
    style Results fill:#c8e6c9
    style TableAnalysis fill:#e3f2fd
    style ColumnAnalysis fill:#e8f5e8
    style CalculateCompleteness fill:#fff3e0
```


## Domain Generator


```{mermaid}
flowchart TD
    A[ì‹œì‘] --> B["ì´ˆê¸°í™”<br/>â€¢ 13ê°œ ë„ë©”ì¸ ê·¸ë£¹ ì •ì˜<br/>â€¢ ê¸°ì¡´ ë„ë©”ì¸ ë¡œë“œ<br/>â€¢ ìƒì„± ê·œì¹™ ì„¤ì •"]
    
    B --> C["ê° ê·¸ë£¹ë³„ ë„ë©”ì¸ ìƒì„±<br/>ê°€ì¤‘ì¹˜ ê¸°ë°˜ ê°œìˆ˜ í• ë‹¹"]
    
    C --> D["ë„ë©”ì¸ ìƒì„± ë£¨í”„<br/>í…œí”Œë¦¿ + ì£¼ì œì–´ + ìˆ˜ì‹ì–´ ì¡°í•©"]
    
    D --> E{ì¤‘ë³µ ê²€ì‚¬}
    E -->|ì¤‘ë³µ| F{ìµœëŒ€ ì‹œë„ ì´ˆê³¼?}
    E -->|ì‹ ê·œ| G[ë„ë©”ì¸ ì¶”ê°€]
    
    F -->|Yes| H[ë‹¤ìŒ ê·¸ë£¹]
    F -->|No| D
    
    G --> I{ëª©í‘œ ê°œìˆ˜ ë‹¬ì„±?}
    I -->|No| D
    I -->|Yes| H
    
    H --> J{ëª¨ë“  ê·¸ë£¹ ì™„ë£Œ?}
    J -->|No| C
    J -->|Yes| K["í’ˆì§ˆ ë¶„ì„ ë° ì €ì¥<br/>â€¢ ì¤‘ë³µ/ê¸¸ì´/ë¶„í¬ í™•ì¸<br/>â€¢ Excel íŒŒì¼ ì €ì¥"]
    
    K --> L[ì™„ë£Œ]
    
    %% ìŠ¤íƒ€ì¼ë§
    classDef startEnd fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000000
    classDef process fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000000
    classDef decision fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000000
    classDef generation fill:#e8f5e8,stroke:#388e3c,stroke-width:2px,color:#000000
    
    class A,L startEnd
    class B,K process
    class E,F,I,J decision
    class C,D,G,H generation

```




## Domain Classifier

### English

```{mermaid}
flowchart TD
    A[ì‹œì‘] --> B["ë°ì´í„° ì¤€ë¹„<br/>â€¢ ì˜ì–´ ë…¼ë¦¬ëª… 24ê°œ<br/>â€¢ ë¼ë²¨ ì¸ì½”ë”©<br/>â€¢ NLTK í† í°í™”<br/>â€¢ Train/Test ë¶„í• "]
    
    B --> C["ëª¨ë¸ êµ¬ì¶•<br/>BiLSTM + Recency-weighted Attention"]
    
    C --> D["í•™ìŠµ ë£¨í”„<br/>Forward â†’ Loss â†’ Backward"]
    
    D --> E{20 ì—í¬í¬<br/>ì™„ë£Œ?}
    E -->|No| D
    E -->|Yes| F["ëª¨ë¸ ì €ì¥ ë° ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸<br/>â€¢ OOV ì²˜ë¦¬<br/>â€¢ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ì¶œë ¥"]
    
    F --> G[ì™„ë£Œ]
    
    %% ìŠ¤íƒ€ì¼ë§
    classDef startEnd fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000000
    classDef process fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000000
    classDef model fill:#e8f5e8,stroke:#388e3c,stroke-width:2px,color:#000000
    classDef training fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000000
    classDef decision fill:#ffebee,stroke:#c62828,stroke-width:2px,color:#000000
    
    class A,G startEnd
    class B,F process
    class C model
    class D training
    class E decision

```

### Koreans
```{mermaid}
flowchart TD
    A[ì‹œì‘] --> B1
    
    subgraph B ["ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"]
        B1[Excel íŒŒì¼ ì½ê¸°] --> B2[ë¬¸ì ì–´íœ˜ ì‚¬ì „ êµ¬ì¶•]
        B2 --> B3[ë¼ë²¨ ì¸ì½”ë”©]
        B3 --> B4[Train/Val/Test ë¶„í• ]
    end
    
    B4 --> C["ëª¨ë¸ êµ¬ì¶•<br/>Embedding â†’ Bi-LSTM â†’ Attention â†’ Dense"]
    
    C --> D["í•™ìŠµ ë£¨í”„<br/>Forward Pass â†’ Loss ê³„ì‚° â†’ Backward Pass"]
    
    D --> E{ì„±ëŠ¥ ê°œì„ ?}
    E -->|Yes| F[ëª¨ë¸ ì €ì¥]
    E -->|No| G[ì¡°ê¸° ì¢…ë£Œ ì¹´ìš´í„° ì¦ê°€]
    
    F --> H{í•™ìŠµ ì¢…ë£Œ?}
    G --> H
    H -->|ê³„ì†| D
    H -->|ì™„ë£Œ| I1
    
    subgraph I ["ëª¨ë¸ í‰ê°€"]
        I1[í…ŒìŠ¤íŠ¸ ì •í™•ë„] --> I2[í˜¼ë™ í–‰ë ¬]
        I2 --> I3[ë¶„ë¥˜ ë¦¬í¬íŠ¸]
    end
    
    I3 --> J[ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ë° ì €ì¥]
    J --> K[ì™„ë£Œ]
    
    classDef startEnd fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000000
    classDef process fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000000
    classDef decision fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000000
    classDef evaluation fill:#e8f5e8,stroke:#388e3c,stroke-width:2px,color:#000000
    
    class A,K startEnd
    class B,C,D process
    class E,H decision
    class F,G,I,J evaluation

```



### Domain Class Integreation

```{mermaid}
flowchart TB
    A[ì‹œì‘] --> B[ì‹œìŠ¤í…œ ì„ íƒ]
    
    subgraph DG ["1. Domain Generator"]
        direction LR
        C["ì´ˆê¸°í™”<br/>â€¢ 13ê°œ ë„ë©”ì¸ ê·¸ë£¹ ì •ì˜<br/>â€¢ ê¸°ì¡´ ë„ë©”ì¸ ë¡œë“œ<br/>â€¢ ìƒì„± ê·œì¹™ ì„¤ì •"]
        D["ë„ë©”ì¸ ìƒì„±<br/>í…œí”Œë¦¿ + ì£¼ì œì–´ + ìˆ˜ì‹ì–´"]
        E{ì¤‘ë³µ ê²€ì‚¬}
        F["í’ˆì§ˆ ë¶„ì„ ë° ì €ì¥<br/>Excel íŒŒì¼ ì¶œë ¥"]
        
        C --> D --> E --> F
    end
    
    subgraph DC ["2. ë„ë©”ì¸ ë¶„ë¥˜ê¸°"]
        direction LR
        G["ë„ë©”ì¸ ë°ì´í„° ë¡œë“œ<br/>ìƒì„±ëœ ë„ë©”ì¸ ì‚¬ìš©"]
        H["ì „ì²˜ë¦¬<br/>ë¬¸ì/ë‹¨ì–´ ì–´íœ˜ ì‚¬ì „ êµ¬ì¶•"]
        I["ëª¨ë¸ êµ¬ì¶•<br/>Bi-LSTM + Attention"]
        J["í•™ìŠµ ë° í‰ê°€"]
        K["ë„ë©”ì¸ ë¶„ë¥˜ ëª¨ë¸<br/>(í•œê¸€/ì˜ì–´ ëª¨ë‘ ì§€ì›)"]
        
        G --> H --> I --> J --> K
    end
    
    subgraph APP ["3. ì‘ìš© ì‹œìŠ¤í…œ"]
        direction LR
        L["ì‚¬ìš©ì ì…ë ¥<br/>(í•œê¸€/ì˜ì–´ ë„ë©”ì¸)"]
        M["ë„ë©”ì¸ ë¶„ë¥˜ ì‹¤í–‰"]
        N["ê²°ê³¼ ì¶œë ¥ ë°<br/>í‘œì¤€í™” ì ìš©"]
        
        L --> M --> N
    end
    
    %% ì—°ê²° ê´€ê³„
    B --> C
    F -.->|ìƒì„±ëœ ë°ì´í„°| G
    K -.->|í•™ìŠµëœ ëª¨ë¸| M
    
    %% ìŠ¤íƒ€ì¼ë§
    classDef startEnd fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000000
    classDef generator fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000000
    classDef korean fill:#e8f5e8,stroke:#388e3c,stroke-width:2px,color:#000000
    classDef rag fill:#e1f5fe,stroke:#0277bd,stroke-width:2px,color:#000000
    classDef application fill:#ffebee,stroke:#c62828,stroke-width:2px,color:#000000
    classDef decision fill:#fce4ec,stroke:#ad1457,stroke-width:2px,color:#000000
    
    class A,B startEnd
    class C,D,E,F generator
    class G,H,I,J,K korean
    class L,M,N,O,P rag
    class Q,S,T,U1,U,V application
    class R decision
```

## Streamlit Presentation


```{mermaid}
flowchart TD
    A[ì‚¬ìš©ì ì…ë ¥] --> B{ì…ë ¥ ìœ í˜•}
    
    B -->|ë…¼ë¦¬ëª…| C[ì•½ì–´ ìƒì„± íƒ­]
    B -->|ì½”ë“œ| D[ë…¼ë¦¬ëª… ì¶”ì²œ íƒ­]
    B -->|ê²€ì¦ ìš”ì²­| E[ê²€ì¦ ê²°ê³¼ íƒ­]
    
    C --> F[RAG ê²€ìƒ‰ + LLM ì²˜ë¦¬]
    D --> F
    E --> G[ê·œì¹™ ê¸°ë°˜ ê²€ì¦]
    
    F --> H[ì•½ì–´/ë…¼ë¦¬ëª… ìƒì„±]
    G --> I[í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°]
    
    H --> J[ê²°ê³¼ í™”ë©´]
    I --> J
    
    J --> K[ì‚¬ìš©ì í”¼ë“œë°±]
    K --> L[í•™ìŠµ ë°ì´í„° ì—…ë°ì´íŠ¸]
    
    style A fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style B fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style C fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style D fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style E fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style J fill:#ffebee,stroke:#c62828,stroke-width:2px
```

### í•µì‹¬ ê¸°ëŠ¥ë³„ ì²˜ë¦¬ íë¦„

```{mermaid}
flowchart TD
    START[ì‹œì‘] --> INPUT[ì‚¬ìš©ì ì…ë ¥]
    
    INPUT --> FUNC1[ ë…¼ë¦¬ëª… ê¸°ë°˜ <br>ì•½ì–´ ìƒì„± ê¸°ëŠ¥]
    INPUT --> FUNC2[ì½”ë“œ ê¸°ë°˜ <br>ë…¼ë¦¬ëª… ì¶”ì²œ ê¸°ëŠ¥]
    INPUT --> FUNC3[ê·œì¹™ ê¸°ë°˜ <br>ê²€ì¦ ê¸°ëŠ¥]
    
    FUNC1 --> PROCESS1[ë…¼ë¦¬ëª… ë¶„ì„<br/>+ RAG ê²€ìƒ‰]
    FUNC2 --> PROCESS2[ì½”ë“œ ë¶„ì„<br/>+ íŒ¨í„´ ë§¤ì¹­]
    FUNC3 --> PROCESS3[ê·œì¹™ ê²€ì¦<br/>+ í’ˆì§ˆ ì¸¡ì •]
    
    PROCESS1 --> RESULT1[ì•½ì–´ + ì„¤ëª…]
    PROCESS2 --> RESULT2[ë…¼ë¦¬ëª… ëª©ë¡]
    PROCESS3 --> RESULT3[ê²€ì¦ ì ìˆ˜]
    
    RESULT1 --> OUTPUT[ê²°ê³¼ ì¶œë ¥]
    RESULT2 --> OUTPUT
    RESULT3 --> OUTPUT
    
    OUTPUT --> FEEDBACK[ì‚¬ìš©ì í”¼ë“œë°±]
    FEEDBACK --> LEARN[ì‹œìŠ¤í…œ í•™ìŠµ]
    
    style START fill:#c8e6c9,stroke:#388e3c,stroke-width:2px
    style INPUT fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style OUTPUT fill:#ffebee,stroke:#c62828,stroke-width:2px
    style LEARN fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
```



### ì‹œìŠ¤í…œ êµ¬ì„±ìš”ì†Œ

```{mermaid}
flowchart LR
    subgraph "ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤"
        UI[Streamlit ì•±]
        TAB1[ì•½ì–´ ìƒì„±]
        TAB2[ë…¼ë¦¬ëª… ì¶”ì²œ]
        TAB3[ê²€ì¦ ê²°ê³¼]
    end
    
    subgraph "AI ì²˜ë¦¬"
        RAG[RAG ì‹œìŠ¤í…œ]
        LLM[GPT-4o]
        EMB[ì„ë² ë”© ê²€ìƒ‰]
    end
    
    subgraph "ë°ì´í„° ì²˜ë¦¬"
        TOKEN[í† í° ë¶„ì„]
        DOMAIN[ë„ë©”ì¸ ë¶„ë¥˜]
        RULE[ê·œì¹™ ê²€ì¦]
    end
    
    UI --> TAB1
    UI --> TAB2
    UI --> TAB3
    
    TAB1 --> RAG
    TAB2 --> RAG
    TAB3 --> RULE
    
    RAG --> LLM
    RAG --> EMB
    
    LLM --> TOKEN
    TOKEN --> DOMAIN
    DOMAIN --> RULE
    
    style UI fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style RAG fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style LLM fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style TOKEN fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
```

### ìš©ì–´ í‘œì¤€í™” RAG ì‹œìŠ¤í…œ ì „ì²´ ì•„í‚¤í…ì²˜

```{mermaid}
flowchart TB
    subgraph "Data Sources"
        DS1[í‘œì¤€í™” ê·œì¹™ ë¬¸ì„œ<br/>PDF/DOCX]
        DS2[ê¸°ì¡´ ìš©ì–´ ì‚¬ì „<br/>Excel/CSV]
        DS3[ë„ë©”ì¸ ë¶„ë¥˜ ë°ì´í„°<br/>í•™ìŠµ ë°ì´í„°]
        DS4[ì½”ë“œ/ë³€ìˆ˜ëª…<br/>ì‚¬ìš©ì ì…ë ¥]
    end
    
    subgraph "RAG Knowledge Base"
        KB1[ë¬¸ì„œ ë²¡í„° ì €ì¥ì†Œ<br/>FAISS]
        KB2[ìš©ì–´ íŒ¨í„´ ì„ë² ë”©<br/>OpenAI Embeddings]
        KB3[ë„ë©”ì¸ ê·œì¹™ ì¸ë±ìŠ¤<br/>Semantic Search]
    end
    
    subgraph "LLM Processing"
        LLM1[ê·œì¹™ ê¸°ë°˜ ì•½ì–´ ìƒì„±<br/>GPT-4o]
        LLM2[ì½”ë“œ ê¸°ë°˜ ë…¼ë¦¬ëª… ì¶”ì²œ<br/>Context-aware]
        LLM3[ì¼ê´€ì„± ê²€ì¦ ë° ê°œì„ <br/>Multi-turn Chat]
    end
    
    subgraph "Streamlit Interface"
        UI1[ì•½ì–´ ìƒì„± íƒ­<br/>ë…¼ë¦¬ëª… to ë¬¼ë¦¬ëª…]
        UI2[ë…¼ë¦¬ëª… ì¶”ì²œ íƒ­<br/>ì½”ë“œ to ë…¼ë¦¬ëª…]
        UI3[ê²€ì¦ ê²°ê³¼ íƒ­<br/>í’ˆì§ˆ í‰ê°€]
        UI4[íˆìŠ¤í† ë¦¬ ê´€ë¦¬<br/>ì‚¬ìš©ì í”¼ë“œë°±]
    end
    
    subgraph "Core Processing"
        CP1[TokenProcessor<br/>í† í° ë¶„ì„]
        CP2[DomainClassifier<br/>Bi-LSTM ë¶„ë¥˜]
        CP3[AbbreviationManager<br/>ì•½ì–´ ìƒì„± ì—”ì§„]
        CP4[RuleAnalyzer<br/>ê·œì¹™ ê²€ì¦]
    end
    
    subgraph "Quality Assurance"
        QA1[RAGAS í‰ê°€<br/>ë‹µë³€ í’ˆì§ˆ ì¸¡ì •]
        QA2[ì¼ê´€ì„± ì²´í¬<br/>ê¸°ì¡´ ìš©ì–´ ëŒ€ë¹„]
        QA3[í”¼ë“œë°± ë£¨í”„<br/>í•™ìŠµ ê°œì„ ]
    end
    
    %% ë°ì´í„° íë¦„
    DS1 --> KB1
    DS2 --> KB2
    DS3 --> KB3
    DS4 --> UI2
    
    %% RAG ê²€ìƒ‰ íë¦„
    KB1 --> LLM1
    KB2 --> LLM2
    KB3 --> LLM3
    
    %% UI ìƒí˜¸ì‘ìš©
    UI1 --> CP1
    UI2 --> CP2
    UI3 --> CP4
    UI4 --> QA3
    
    %% ì²˜ë¦¬ íë¦„
    CP1 --> CP3
    CP2 --> CP3
    CP3 --> CP4
    CP4 --> QA1
    
    %% LLM í†µí•©
    LLM1 --> CP3
    LLM2 --> CP1
    LLM3 --> CP4
    
    %% í’ˆì§ˆ ë³´ì¦
    QA1 --> QA2
    QA2 --> QA3
    QA3 --> KB1
    
    %% ê²°ê³¼ ì¶œë ¥
    CP4 --> UI3
    QA1 --> UI3
    QA2 --> UI4
    
    %% ìŠ¤íƒ€ì¼ë§
    style DS1 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style DS2 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style DS3 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style DS4 fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    
    style KB1 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style KB2 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style KB3 fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    
    style LLM1 fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style LLM2 fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style LLM3 fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    
    style UI1 fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style UI2 fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style UI3 fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style UI4 fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    
    style QA1 fill:#ffebee,stroke:#c62828,stroke-width:2px
    style QA2 fill:#ffebee,stroke:#c62828,stroke-width:2px
    style QA3 fill:#ffebee,stroke:#c62828,stroke-width:2px
```

### ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ë³„ í”Œë¡œìš°

#### ì‹œë‚˜ë¦¬ì˜¤ 1: ì˜ì–´ ë…¼ë¦¬ëª… â†’ ì•½ì–´ ìƒì„±

```{mermaid}
sequenceDiagram
    participant U as ì‚¬ìš©ì
    participant ST as Streamlit UI
    participant RAG as RAG ì‹œìŠ¤í…œ
    participant LLM as GPT-4o
    participant DB as ê²€ì¦ ì—”ì§„
    
    U->>ST: ì˜ì–´ ë…¼ë¦¬ëª… ì…ë ¥
    ST->>RAG: ìœ ì‚¬ ìš©ì–´ ê²€ìƒ‰
    RAG->>LLM: ê·œì¹™ ë¬¸ì„œ + ìœ ì‚¬ íŒ¨í„´ ì œê³µ
    LLM->>DB: ì•½ì–´ ìƒì„± ìš”ì²­
    DB->>DB: ê·œì¹™ ê²€ì¦ ìˆ˜í–‰
    DB->>ST: ì•½ì–´ + ì¤€ìˆ˜ìœ¨ ë°˜í™˜
    ST->>U: ê²°ê³¼ í‘œì‹œ + ì‹œê°í™”
    
    Note over U,DB: ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
    Note over RAG,LLM: ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì²œ
```

#### ì‹œë‚˜ë¦¬ì˜¤ 2: ì½”ë“œ â†’ ë…¼ë¦¬ëª… ì¶”ì²œ

```{mermaid}
sequenceDiagram
    participant U as ì‚¬ìš©ì
    participant ST as Streamlit UI
    participant CA as ì½”ë“œ ë¶„ì„ê¸°
    participant RAG as RAG ì‹œìŠ¤í…œ
    participant LLM as GPT-4o
    
    U->>ST: ì½”ë“œ ìŠ¤ë‹ˆí« ì…ë ¥
    ST->>CA: ë³€ìˆ˜ëª… ì¶”ì¶œ
    CA->>RAG: íŒ¨í„´ ë§¤ì¹­ ê²€ìƒ‰
    RAG->>LLM: ì»¨í…ìŠ¤íŠ¸ + ê·œì¹™ ì œê³µ
    LLM->>ST: ë…¼ë¦¬ëª… ì¶”ì²œ ëª©ë¡
    ST->>U: ì‹ ë¢°ë„ë³„ ì¶”ì²œ í‘œì‹œ
    
    Note over CA,RAG: AST íŒŒì‹± + ë²¡í„° ê²€ìƒ‰
    Note over LLM,ST: ë©€í‹°í„´ ëŒ€í™” ì§€ì›
```

### í•µì‹¬ ê¸°ìˆ  ìŠ¤íƒ í†µí•© êµ¬ì¡°

```{mermaid}
graph LR
    subgraph "Frontend"
        A[Streamlit UI]
        B[ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°]
        C[ì±„íŒ… ì¸í„°í˜ì´ìŠ¤]
    end
    
    subgraph "Backend Processing"
        D[LangChain LCEL]
        E[RAG íŒŒì´í”„ë¼ì¸]
        F[ë©€í‹°í„´ ëŒ€í™”]
    end
    
    subgraph "AI/ML Models"
        G[OpenAI GPT-4o]
        H[FAISS ë²¡í„° DB]
        I[Bi-LSTM ë¶„ë¥˜ê¸°]
    end
    
    subgraph "Data Layer"
        J[ë¬¸ì„œ ë¡œë”]
        K[ì„ë² ë”© ì²˜ë¦¬]
        L[ê²€ì¦ ì—”ì§„]
    end
    
    subgraph "Quality Assurance"
        M[RAGAS í‰ê°€]
        N[í”¼ë“œë°± ë£¨í”„]
        O[ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§]
    end
    
    %% ì—°ê²° ê´€ê³„
    A --> D
    B --> E
    C --> F
    
    D --> G
    E --> H
    F --> I
    
    G --> J
    H --> K
    I --> L
    
    J --> M
    K --> N
    L --> O
    
    %% í”¼ë“œë°± ë£¨í”„
    M --> E
    N --> D
    O --> A
    
    %% ìŠ¤íƒ€ì¼ë§
    style A fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style D fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style G fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style J fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    style M fill:#ffebee,stroke:#c62828,stroke-width:2px
```

### ê¸°ëŒ€ íš¨ê³¼ ë° ROI

```{mermaid}
pie title ì—…ë¬´ íš¨ìœ¨ì„± í–¥ìƒ
    "ìë™í™”ëœ ì•½ì–´ ìƒì„±" : 40
    "ì¼ê´€ì„± ê²€ì¦ ìë™í™”" : 25
    "ì½”ë“œ ê¸°ë°˜ ì¶”ì²œ" : 20
    "í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ" : 15
```

```{mermaid}
graph LR
    subgraph "ì •ëŸ‰ì  íš¨ê³¼"
        A["ì²˜ë¦¬ ì‹œê°„<br/>90% ë‹¨ì¶•"]
        B["ì˜¤ë¥˜ìœ¨<br/>80% ê°ì†Œ"]
        C["ì¼ê´€ì„±<br/>95% í–¥ìƒ"]
    end
    
    subgraph "ì •ì„±ì  íš¨ê³¼"
        D["ê°œë°œì ë§Œì¡±ë„<br/>í–¥ìƒ"]
        E["í‘œì¤€í™” ì •ì°©<br/>ë¬¸í™” ì¡°ì„±"]
        F["ë°ì´í„° í’ˆì§ˆ<br/>ì²´ê³„í™”"]
    end
    
    A --> D
    B --> E
    C --> F
    
    style A fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style B fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style C fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style D fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style E fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style F fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
```


# LLFS Study


```{mermaid}

flowchart TB
    subgraph DC ["Data Collection"]
        MCBS[Multi Centered Blood Sampling]
        MS[Mass Spectrometry]
        DT[Data Collection <br> & Engineering]
        
        MCBS --> MS
        MS --> DT
    end
    
    subgraph QC ["Quality Control"]
        IAD[Identify Anomaly Data]
        IMV[Identify Missing Values]

    end
    
    subgraph AN ["Analytics"]
        EDA[EDA]
        DM[Data Mining]
        SA[Statistical Analysis]
        ML[Machine Learning]
        DN[Clinical Domain Knowledge]
        
        EDA --> DM
        DM --> SA
        SA --> ML
        ML --> DN
    end
    
    subgraph RC ["Reporting and Conclusion"]
        SWF[Sharing with Coworkers &<br> Writing a Manuscript]
    end
    
    %% í´ëŸ¬ìŠ¤í„° ê°„ ì—°ê²°
    DT --> IAD
    IMV --> EDA
    DN --> SWF
    
    %% ìŠ¤íƒ€ì¼ë§
    style DC fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style QC fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style AN fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style RC fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    
    style MCBS fill:#e1f5fe
    style MS fill:#e1f5fe
    style DT fill:#e1f5fe
    style IAD fill:#fff8e1
    style IMV fill:#fff8e1
    style EDA fill:#e8f5e8
    style DM fill:#e8f5e8
    style SA fill:#e8f5e8
    style ML fill:#e8f5e8
    style SWF fill:#fce4ec
```
