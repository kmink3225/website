---
title: "Basic Matrix (1) - Matrix Operations"
subtitle: template
description: |
  template
categories:
  - Mathematics
author: Kwangmin Kim
date: 03/31/2023
format: 
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
execute:
  warning: false
  message: false
  eval: false
draft: true
---


<ul class="nav nav-pills" id="language-tab" role="tablist">
  <li class="nav-item" role="presentation">
    <button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" role="tab" aria-controls="Korean" aria-selected="true">Korean</button>
  </li>
  <li class="nav-item" role="presentation">
    <button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" role="tab" aria-controls="knitr" aria-selected="false">English</button>
  </li>

<div class="tab-content" id="language-tabcontent">

<div class="tab-pane fade  show active" id="Korean" role="tabpanel" aria-labelledby="Korean-tab">

## Matrix

행렬은 행과 열로 배열된 요소들로 이루어진 직사각형 형태의 배열로, 일반적으로 실수를 포함한 요소들로 구성된다. 만약 $\mathbf{A}$ 가 $m \times n$ 행렬이라면, 다음과 같이 나타낼 수 있다:

$$
\begin{bmatrix} 
  a_{11} & a_{12} & \cdots & a_{1n} \\
  a_{21} & a_{22} & \cdots & a_{2n} \\
  \vdots & \vdots & \ddots & \vdots \\
  a_{m1} & a_{m2} & \cdots & a_{mn}
\end{bmatrix} 
$$

where $a_{ij}$ is the element in the $i$-th row and $j$-th column of the matrix $\mathbf{A}$.

## Terminology

### Column Vector

열 벡터는 하나의 열로 구성된 행렬이며, 일반적으로 $\mathbf{v}$ 로 표기되며, 수직으로 배열된 요소를 포함합니다. 다음과 같이 나타낼 수 있다:
$$
\mathbf{v} = \begin{bmatrix} 
  v_1 \\
  v_2 \\
  \vdots \\
  v_n
\end{bmatrix}
$$

where $v_1, v_2, \ldots, v_n$ are the elements of the column vector $\mathbf{v}$.

### Row Vector

행 벡터는 하나의 행으로 구성된 행렬입니다. 다음과 같이 나타낼 수 있다:

$$
\begin{bmatrix} 
  v_1 & v_2 & \cdots & v_n 
\end{bmatrix}
$$

where $v_1, v_2, ..., v_n$ are the elements of the row vector.


### Elements

"Component," "element," 및 "entry"라는 용어는 벡터, 행렬 또는 다른 수학적 객체 내의 개별 값들을 가리키는 데 사용된다. 이 용어들은 종종 상호적으로 사용되지만, 구체적인 사용법에는 미묘한 차이가 있을 수 있다:

* Component(요소): "Component(요소)"라는 용어는 주로 벡터나 텐서 내의 개별 값들을 가리킬 때 사용된다. 이 용어는 각 값이 벡터나 텐서의 일부로서의 역할을 강조하며, 전체적인 표현에 기여한다는 점을 강조한다. Component는 주로 벡터나 텐서 내에서 특정한 위치 또는 인덱스에 연관되어 사용된다.
* Element(요소): "Element(요소)"라는 용어는 더 일반적이며, 벡터, 행렬, 집합, 그룹 등 수학적 객체 내의 개별 값들을 묘사하는 데 사용될 수 있다. 이 용어는 값들이 더 큰 수학적 구조에 속한다는 것을 의미하며, 그 문맥 내에서 작동되거나 분석될 수 있다는 것을 나타낸다.
* Entry(항): "Entry(항)"라는 용어는 일반적으로 행렬이나 배열에 대해 이야기할 때 사용된다. 이 용어는 행과 열로 구성된 행렬 내의 개별 값들을 가리킨다. 항은 종종 행과 열 인덱스로 지정된 위치에 의해 식별된다.
* 행렬 $\mathbf{A}$ 의 항(Entry), $a_{ij}$ 라 표기되는 것은 행렬의 $i$ 번째 행과 $j$ 번째 열에 위치한 요소를 의미한다. 이는 행렬 내의 특정한 값이다.
* 행렬 $\mathbf{A}$ 의 대각 항(Diagonal entry), $a_{ii}$ 라 표기되는 것은 행렬의 $i$ 번째 행과 $i$ 번째 열에 위치한 요소를 의미한다. 이는 행 인덱스와 열 인덱스가 동일한 행렬의 주 대각선에 위치한 값이다.

## Basic Matrix Operations

### Matrix addition 

같은 크기를 가진 두 행렬의 합은 대응하는 항목들을 더하여 얻은 동일한 크기의 행렬이다.

두 개의 $m \times n$ 행렬 $\mathbf{A}$ 와 $\mathbf{B}$ 가 주어졌을 때, 그들의 합 $\mathbf{C} = \mathbf{A} + \mathbf{B}$ 는 다음과 같이 정의된다:

$$
c_{i,j}=a_{i,j}+b_{i,j}​
$$
for $1 \leq i \leq m$ and $1 \leq j \leq n$.

$$
\begin{bmatrix}
  1 & 2 \\
  3 & 4 \\
  5 & 6
\end{bmatrix} +
\begin{bmatrix}
  -1 & 0 \\
  2 & -3 \\
  -5 & 4
\end{bmatrix} =
\begin{bmatrix}
  0 & 2 \\
  5 & 1 \\
  0 & 10
\end{bmatrix}
$$

### Scalar multiplication 

스칼라와 행렬의 곱은 행렬의 각 항목을 스칼라와 곱한 결과로 얻은 행렬이다.

주어진 스칼라 $k$ 와 $m \times n$ 행렬 $\mathbf{A}$ 에 대해서, 그들의 곱 $k\mathbf{A}$ 는 다음과 같이 정의된다:
$$
(k\mathbf{A})_{i,j} = k(a_{i,j})
$$

for $1 \leq i \leq m$ and $1 \leq j \leq n$.

Example:
$$
2\begin{bmatrix}
1 & 2 \\
3 & 4 \\
5 & 6
\end{bmatrix} =
\begin{bmatrix}
2 & 4 \\
6 & 8 \\
10 & 12
\end{bmatrix}
$$

### Isomorphism

$A$ 와 $B$ 가 두 개의 집합이며 각각에 정의된 연산이 있다고 가정하자. $A$ 에서 $B$ 로의 동형사상은 연산의 구조와 성질을 보존하는 일대일 대응 $\phi: A \to B$ 이다. 보다 정확히 말하면, 임의의 원소 $a, a' \in A$ 와 $A$ 에서의 $\star$ 연산과 $B$ 에서의 $\diamond$ 연산에 대해 다음 성질이 성립한다:

1. $\phi(a \star a') = \phi(a) \diamond \phi(a')$ (operation preservation)
2. $\phi^{-1}(b_1 \diamond b_2) = \phi^{-1}(b_1) \star \phi^{-1}(b_2)$ (inverse preservation)

만약 $A$ 와 $B$ 사이에 동형사상이 존재한다면, $A$ 와 $B$ 는 동형이라고 하고 $A \cong B$ 로 표기한다.

$$
\begin{align*}
  \exists f : A &\rightarrow B \text{ s.t. } f \text{ is an isomorphism} \\ 
  & \Leftrightarrow A \cong B \\
  & \Leftrightarrow B \cong A \\
  & \Leftrightarrow A \text{ is isomorphic to } B \\
  & \Leftrightarrow B \text{ is isomorphic to } A
\end{align*}
$$

* 행렬과 벡터는 덧셈과 스칼라곱에 한해서 동형이다.
* 일반적으로 연산은 집합 내에서 닫혀있는 집합 연산을 의미한다. 내적은 벡터를 벡터로 변환하는 것이 아니라 스칼라를 얻기 때문에 연산으로 간주할 수 없고 함수나 관계로 간주되어야 한다.
  * 연산은 보통 집합 내의 요소를 결합하여 같은 집합의 다른 요소를 생성하는 규칙 또는 절차를 의미한다. 행렬과 벡터에 대한 덧셈과 스칼라곱은 연산이지만, 내적은 벡터가 아닌 스칼라를 생성하므로 연산의 전통적인 정의에 부합하지 않는다. 따라서 내적은 벡터 사이의 함수나 관계로 보는 것이 더 적합하다.
 
## Rules for Matrix Operations

You reference some rules of matrix operations in the other blog (See [the basic matrix operation](./02.basic_matrix.qmd)).

### Commutative Law of Matrix Addition

Matrix addition is commutative, which means that changing the order of the matrices being added does not affect the result.

$$
\begin{align*}
\mathbf A + \mathbf B = \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} + \begin{bmatrix}
5 & 6 \\
7 & 8
\end{bmatrix} = \begin{bmatrix}
1 + 5 & 2 + 6 \\
3 + 7 & 4 + 8
\end{bmatrix} = \begin{bmatrix}
6 & 8 \\
10 & 12
\end{bmatrix}
\\
\mathbf B + \mathbf A = \begin{bmatrix}
5 & 6 \\
7 & 8
\end{bmatrix} + \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} = \begin{bmatrix}
5 + 1 & 6 + 2 \\
7 + 3 & 8 + 4
\end{bmatrix} = \begin{bmatrix}
6 & 8 \\
10 & 12
\end{bmatrix}
\end{align*}
$$

### Distributive Law

Matrix addition distributes over matrix multiplication, which means that multiplying a matrix by the sum of two matrices is the same as multiplying the matrix by each individual matrix and then adding the results.

$$
\begin{align*}
\mathbf A (\mathbf B + \mathbf C )
&= \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} \cdot \left( \begin{bmatrix}
5 & 6 \\
7 & 8
\end{bmatrix} + \begin{bmatrix}
9 & 10 \\
11 & 12
\end{bmatrix} \right) = \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} \cdot \begin{bmatrix}
14 & 16 \\
18 & 20
\end{bmatrix} = \begin{bmatrix}
70 & 76 \\
158 & 172
\end{bmatrix}
\end{align*}
$$

$$
\begin{align*}
\mathbf A \mathbf B + \mathbf A \mathbf C 
&= \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} \cdot \begin{bmatrix}
5 & 6 \\
7 & 8
\end{bmatrix} + \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} \cdot \begin{bmatrix}
9 & 10 \\
11 & 12
\end{bmatrix} = \begin{bmatrix}
19 & 22 \\
43 & 50
\end{bmatrix} + \begin{bmatrix}
23 & 26 \\
31 & 34
\end{bmatrix} = \begin{bmatrix}
70 & 76 \\
158 & 172
\end{bmatrix}
\end{align*}
$$


### Associative Law

Matrix addition is associative, which means that changing the grouping of the matrices being added does not affect the result.

$$
\begin{align*}
(\mathbf A + \mathbf B )+ \mathbf C 
&= \left( \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} + \begin{bmatrix}
5 & 6 \\
7 & 8
\end{bmatrix} \right) + \begin{bmatrix}
9 & 10 \\
11 & 12
\end{bmatrix} = \begin{bmatrix}
1 + 5 & 2 + 6 \\
3 + 7 & 4 + 8
\end{bmatrix} + \begin{bmatrix}
9 & 10 \\
11 & 12
\end{bmatrix} = \begin{bmatrix}
6 & 8 \\
10 & 12
\end{bmatrix} + \begin{bmatrix}
9 & 10 \\
11 & 12
\end{bmatrix} = \begin{bmatrix}
15 & 18 \\
21 & 24
\end{bmatrix}
\end{align*}
$$

$$
\begin{align*}
\mathbf A + (\mathbf B + \mathbf C) 
&= \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} + \left( \begin{bmatrix}
5 & 6 \\
7 & 8
\end{bmatrix} + \begin{bmatrix}
9 & 10 \\
11 & 12
\end{bmatrix} \right) = \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} + \begin{bmatrix}
14 & 16 \\
18 & 20
\end{bmatrix} = \begin{bmatrix}
15 & 18 \\
21 & 24
\end{bmatrix}
\end{align*}
$$



</div>

<div class="tab-pane fade" id="English" role="tabpanel" aria-labelledby="English-tab">

## Matrix

A matrix is a rectangular array of elements, usually real numbers, arranged in rows and columns. If $\mathbf{A}$ is an $m \times n$ matrix, it can be represented as:
$$
\begin{bmatrix} 
  a_{11} & a_{12} & \cdots & a_{1n} \\
  a_{21} & a_{22} & \cdots & a_{2n} \\
  \vdots & \vdots & \ddots & \vdots \\
  a_{m1} & a_{m2} & \cdots & a_{mn}
\end{bmatrix} 
$$

where $a_{ij}$ is the element in the $i$-th row and $j$-th column of the matrix $\mathbf{A}$.

## Terminology

### Column Vector

A column vector is a matrix with a single column, typically denoted as $\mathbf{v}$, containing elements arranged vertically. It can be represented as:
$$
\mathbf{v} = \begin{bmatrix} 
  v_1 \\
  v_2 \\
  \vdots \\
  v_n
\end{bmatrix}
$$

where $v_1, v_2, \ldots, v_n$ are the elements of the column vector $\mathbf{v}$.

### Row Vector

A row vector is a matrix with a single row. It can be represented as:

$$
\begin{bmatrix} 
  v_1 & v_2 & \cdots & v_n 
\end{bmatrix}
$$

where $v_1, v_2, ..., v_n$ are the elements of the row vector.


### Elements

The terms "component," "element," and "entry" are used to refer to the individual values within vectors, matrices, or other mathematical objects. While they are often used interchangeably, there can be subtle differences in their specific usage:

* Component: The term "component" is typically used when referring to the individual values within a vector or a tensor. It emphasizes the role of each value as a part of the vector or tensor, contributing to its overall representation. Components are often associated with a **specific position or index** within the vector or tensor.
* Element: The term "element" is more general and can be used to describe the individual values within any mathematical object, including vectors, matrices, sets, or groups. **It implies that the values belong to a larger mathematical structure** and can be operated on or analyzed within that context.
* Entry: The term "entry" is commonly used when discussing matrices or arrays. **It refers to the individual values within a matrix, which are organized into rows and columns. Entries are often identified by their position, specified by row and column indices.**
* An entry in a matrix $\mathbf{A}$, denoted as $a_{ij}$, refers to the element located at the $i$-th row and $j$-th column of the matrix. It represents a specific value within the matrix.
* A diagonal entry in a matrix $\mathbf{A}$, denoted as $a_{ii}$, refers to the element located at the $i$-th row and $i$-th column of the matrix. It represents a value on the main diagonal of the matrix where the row index is equal to the column index.

## Basic Matrix Operations

### Matrix addition 

The sum of two matrices of the same size is a matrix of the **same size** obtained by adding corresponding entries.

Given two $m \times n$ matrices $\mathbf{A}$ and $\mathbf{B}$, their sum $\mathbf{C} = \mathbf{A} + \mathbf{B}$ is defined by:

$$
c_{i,j}=a_{i,j}+b_{i,j}​
$$
for $1 \leq i \leq m$ and $1 \leq j \leq n$.

$$
\begin{bmatrix}
  1 & 2 \\
  3 & 4 \\
  5 & 6
\end{bmatrix} +
\begin{bmatrix}
  -1 & 0 \\
  2 & -3 \\
  -5 & 4
\end{bmatrix} =
\begin{bmatrix}
  0 & 2 \\
  5 & 1 \\
  0 & 10
\end{bmatrix}
$$

### Scalar multiplication 

The product of a scalar and a matrix is a matrix obtained by multiplying each entry of the matrix by the scalar.

Given a scalar $k$ and an $m \times n$ matrix $\mathbf{A}$, their product $k\mathbf{A}$ is defined by:
$$
(k\mathbf{A})_{i,j} = k(a_{i,j})
$$

for $1 \leq i \leq m$ and $1 \leq j \leq n$.

Example:
$$
2\begin{bmatrix}
1 & 2 \\
3 & 4 \\
5 & 6
\end{bmatrix} =
\begin{bmatrix}
2 & 4 \\
6 & 8 \\
10 & 12
\end{bmatrix}
$$

### Isomorphism

Let $A$ and $B$ be two sets with operations defined on them. An isomorphism from $A$ to $B$ is a bijective mapping $\phi: A \to B$ that preserves the structure and properties of the operations in $A$ and $B$. More formally, for any elements $a, a' \in A$ and any operations $\star$ in $A$ and $\diamond$ in $B$, the following properties hold:

1. $\phi(a \star a') = \phi(a) \diamond \phi(a')$ (operation preservation)
2. $\phi^{-1}(b_1 \diamond b_2) = \phi^{-1}(b_1) \star \phi^{-1}(b_2)$ (inverse preservation)

If there exists an isomorphism between $A$ and $B$, we say that $A$ and $B$ are isomorphic and write $A \cong B$.

$$
\begin{align*}
  \exists f : A &\rightarrow B \text{ s.t. } f \text{ is an isomorphism} \\ 
  & \Leftrightarrow A \cong B \\
  & \Leftrightarrow B \cong A \\
  & \Leftrightarrow A \text{ is isomorphic to } B \\
  & \Leftrightarrow B \text{ is isomorphic to } A
\end{align*}
$$

* Matrices and vectors are isomorphic, but only with respect to addition and scalar multiplication.
* Note that an operation, in general, refers to a set operation that is closed within the set. Since the dot product does not result in a vector but in a scalar, it cannot be considered as an operation but rather should be viewed as a function or relation.
  * an operation typically refers to a rule or procedure that combines elements from a set to produce another element from the same set. While addition and scalar multiplication are operations on matrices and vectors, the dot product does not fit the conventional definition of an operation as it yields a scalar rather than a vector. Therefore, it is more appropriately viewed as a function or relation between vectors, rather than an operation.

## Rules for Matrix Operations

You reference some rules of matrix operations in the other blog (See [the basic matrix operation](./02.basic_matrix.qmd)).

### Commutative Law of Matrix Addition

Matrix addition is commutative, which means that changing the order of the matrices being added does not affect the result.

$$
\begin{align*}
\mathbf A + \mathbf B = \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} + \begin{bmatrix}
5 & 6 \\
7 & 8
\end{bmatrix} = \begin{bmatrix}
1 + 5 & 2 + 6 \\
3 + 7 & 4 + 8
\end{bmatrix} = \begin{bmatrix}
6 & 8 \\
10 & 12
\end{bmatrix}
\\
\mathbf B + \mathbf A = \begin{bmatrix}
5 & 6 \\
7 & 8
\end{bmatrix} + \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} = \begin{bmatrix}
5 + 1 & 6 + 2 \\
7 + 3 & 8 + 4
\end{bmatrix} = \begin{bmatrix}
6 & 8 \\
10 & 12
\end{bmatrix}
\end{align*}
$$

### Distributive Law

Matrix addition distributes over matrix multiplication, which means that multiplying a matrix by the sum of two matrices is the same as multiplying the matrix by each individual matrix and then adding the results.

$$
\begin{align*}
\mathbf A (\mathbf B + \mathbf C )
&= \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} \cdot \left( \begin{bmatrix}
5 & 6 \\
7 & 8
\end{bmatrix} + \begin{bmatrix}
9 & 10 \\
11 & 12
\end{bmatrix} \right) = \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} \cdot \begin{bmatrix}
14 & 16 \\
18 & 20
\end{bmatrix} = \begin{bmatrix}
70 & 76 \\
158 & 172
\end{bmatrix}
\end{align*}
$$

$$
\begin{align*}
\mathbf A \mathbf B + \mathbf A \mathbf C 
&= \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} \cdot \begin{bmatrix}
5 & 6 \\
7 & 8
\end{bmatrix} + \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} \cdot \begin{bmatrix}
9 & 10 \\
11 & 12
\end{bmatrix} = \begin{bmatrix}
19 & 22 \\
43 & 50
\end{bmatrix} + \begin{bmatrix}
23 & 26 \\
31 & 34
\end{bmatrix} = \begin{bmatrix}
70 & 76 \\
158 & 172
\end{bmatrix}
\end{align*}
$$


### Associative Law

Matrix addition is associative, which means that changing the grouping of the matrices being added does not affect the result.

$$
\begin{align*}
(\mathbf A + \mathbf B )+ \mathbf C 
&= \left( \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} + \begin{bmatrix}
5 & 6 \\
7 & 8
\end{bmatrix} \right) + \begin{bmatrix}
9 & 10 \\
11 & 12
\end{bmatrix} = \begin{bmatrix}
1 + 5 & 2 + 6 \\
3 + 7 & 4 + 8
\end{bmatrix} + \begin{bmatrix}
9 & 10 \\
11 & 12
\end{bmatrix} = \begin{bmatrix}
6 & 8 \\
10 & 12
\end{bmatrix} + \begin{bmatrix}
9 & 10 \\
11 & 12
\end{bmatrix} = \begin{bmatrix}
15 & 18 \\
21 & 24
\end{bmatrix}
\end{align*}
$$

$$
\begin{align*}
\mathbf A + (\mathbf B + \mathbf C) 
&= \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} + \left( \begin{bmatrix}
5 & 6 \\
7 & 8
\end{bmatrix} + \begin{bmatrix}
9 & 10 \\
11 & 12
\end{bmatrix} \right) = \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix} + \begin{bmatrix}
14 & 16 \\
18 & 20
\end{bmatrix} = \begin{bmatrix}
15 & 18 \\
21 & 24
\end{bmatrix}
\end{align*}
$$



</div>


