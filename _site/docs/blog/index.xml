<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Kwangmin Kim</title>
<link>kmink3225.netlify.app/docs/blog/index.html</link>
<atom:link href="kmink3225.netlify.app/docs/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>blog</description>
<generator>quarto-1.2.335</generator>
<lastBuildDate>Tue, 31 Dec 2999 15:00:00 GMT</lastBuildDate>
<item>
  <title>Blog Content List</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/content_list.html</link>
  <description><![CDATA[ 



<section id="contents" class="level1">
<h1>Contents</h1>
<ul>
<li><a href="../../../docs/blog/posts/DL/guide_map/index.html">Deep Learning</a></li>
<li><a href="../../../docs/blog/posts/ML/guide_map/index.html">Machine Learning</a></li>
<li><a href="../../../docs/blog/posts/Mathmatics/guide_map/index.html">Mathematics</a></li>
<li><a href="../../../docs/blog/posts/statistics/guide_map/index.html">Statistics</a></li>
<li><a href="../../../docs/blog/posts/Engineering/guide_map/index.html">Engineering</a></li>
<li><a href="../../../docs/blog/posts/Patent/guide_map/index.html">Patent</a></li>
<li><a href="../../../docs/blog/posts/Language/guide_map/index.html">Language</a></li>
<li><a href="../../../docs/blog/posts/Surveilance/guide_map/index.html">Surveilance</a></li>
</ul>
</section>
<section id="reference" class="level1">
<h1>Reference</h1>
<ul>
<li>Statistics
<ul>
<li>George Casella &amp; Rogeer L. Berger - Statistcal Inference, 2nd Edition</li>
<li>Dobson and Barnett (2008) An Introduction to Generalized Linear Model. 3rd Ed. Chapman &amp; Hall.</li>
<li>Fitzmaurice, Laird and Ware (2011) Applied Longitudinal Analysis. 2nd Ed. Wiley.</li>
<li>Hosmer, Lemeshow and May (2008) Applied Survival Analysis. 2nd Ed. Wiley.</li>
<li>슬기로운 통계생활 - https://www.youtube.com/<span class="citation" data-cites="statisticsplaybook">@statisticsplaybook</span></li>
<li>슬기로운 통계생활 - https://github.com/statisticsplaybook</li>
<li>Fast Campus, Coursera, Inflearn</li>
<li>그 외 다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Mathematics
<ul>
<li>James Stewart - Calculus Early Transcedentals, 7th Eidition</li>
<li>any James Stewart series</li>
<li>임장환 - 머신러닝, 인공지능, 컴퓨터 비전 전공자를 위한 최적화 이론</li>
<li>Fast Campus, Coursera, Inflearn</li>
<li>다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Machine Learning
<ul>
<li>Gareth M. James, Daniela Witten, Trevor Hastie, Robert Tibshirani - An Introduction to Statistical Learning: With Applications in R 2nd Edition</li>
<li>Trevor Hastie, Robert Tibshirani, Jerome H. Friedman - The Elements of Statistical Learning 2nd Edition</li>
<li>Fast Campus, Coursera, Inflearn</li>
<li>다수의 Youtube, and Documents from Googling<br>
</li>
</ul></li>
<li>Deep Learning
<ul>
<li>Saito Koki - Deep Learning from Scratch 1,2,3 (밑바닥부터 시작하는 딥러닝 1,2,3)</li>
<li>조준우 - 머신러닝·딥러닝에 필요한 기초 수학 with 파이썬</li>
<li>조준우 - https://github.com/metamath1/noviceml</li>
<li>동빈나 - https://www.youtube.com/c/dongbinna</li>
<li>혁펜하임 - https://www.youtube.com/channel/UCcbPAIfCa4q0x7x8yFXmBag</li>
<li>Fast Campus, Coursera, Inflearn</li>
<li>다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Engineering
<ul>
<li>Fast Campus, Coursera, Inflearn</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>All List</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/content_list.html</guid>
  <pubDate>Tue, 31 Dec 2999 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Statistics</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/statistics/guide_map/index.html</link>
  <description><![CDATA[ 



<p><strong>(Draft)</strong></p>
<section id="contents-list" class="level1">
<h1>Contents List</h1>
<section id="basic" class="level2">
<h2 class="anchored" data-anchor-id="basic">Basic</h2>
<section id="probability-theory" class="level3">
<h3 class="anchored" data-anchor-id="probability-theory">Probability Theory</h3>
<ul>
<li>2023-02-05, Set Theory</li>
<li>2023-02-05, [Basics of Probability Theory - Axiomatic Foundations]</li>
<li>2023-02-05, [Basics of Probability Theory - Calculus of Probabilities]</li>
<li>2023-02-05, <a href="../../../../../docs/blog/posts/statistics/2023-02-05_probability/index.html">Basics of Probability Theory - Probability</a></li>
<li>2023-02-05, <a href="../../../../../docs/blog/posts/statistics/2023-02-05_conditional_probability/index.html">Conditional Probability</a></li>
<li>2023-02-05, [Independence]</li>
<li>2023-02-05, <a href="../../../../../docs/blog/posts/statistics/2023-02-05_bayes_rule/index.html">Bayes’ Rule</a></li>
<li>2023-02-05, Random Variable</li>
<li>1111-11-11, Probability Distribution</li>
</ul>
</section>
<section id="transformations-and-expectations" class="level3">
<h3 class="anchored" data-anchor-id="transformations-and-expectations">Transformations and Expectations</h3>
<ul>
<li>2023-02-21, <a href="../../../../../docs/blog/posts/statistics/2023-02-21_transformation/index.html">Transformation of Random Variables</a></li>
<li>1111-11-11, Expected Value vs Realizaed Value</li>
<li>1111-11-11, Variance</li>
<li>1111-11-11, Covariance and Correlation</li>
<li>2023-02-28, <a href="../../../../../docs/blog/posts/statistics/2023-02-28_mgf/index.html">Moment Generating Function, MGF</a></li>
</ul>
</section>
<section id="exponential-family-distributions" class="level3">
<h3 class="anchored" data-anchor-id="exponential-family-distributions">Exponential Family Distributions</h3>
<ul>
<li>Discrete Random Variable
<ul>
<li>2023-02-27,<a href="../../../../../docs/blog/posts/statistics/2023-02-27_exponential_family/discrete_bernoulli.html">Bernoulli Distribution</a></li>
<li>2023-02-28,<a href="../../../../../docs/blog/posts/statistics/2023-02-27_exponential_family/discrete_binomial.html">Binomial Distribution</a></li>
<li>2023-03-01,<a href="../../../../../docs/blog/posts/statistics/2023-02-27_exponential_family/discrete_poisson.html">Poisson Distribution</a></li>
<li>2023-03-01,<a href="../../../../../docs/blog/posts/statistics/2023-02-27_exponential_family/discrete_geometric.html">Geometric Distribution</a></li>
<li>1111-11-11, Hypergeometric Distribution</li>
</ul></li>
<li>Continuous Random Variable
<ul>
<li>1111-11-11, Normal Distribution</li>
<li>1111-11-11, Exponential Distribution</li>
<li>1111-11-11, Beta Distribution</li>
<li>1111-11-11, Chi-squared Distribution</li>
</ul></li>
<li>1111-11-11,</li>
</ul>
</section>
<section id="multiple-random-variables" class="level3">
<h3 class="anchored" data-anchor-id="multiple-random-variables">Multiple Random Variables</h3>
<ul>
<li>1111-11-11, Joint Distribution and Marginal Distribution</li>
</ul>
</section>
<section id="point-estimation" class="level3">
<h3 class="anchored" data-anchor-id="point-estimation">Point Estimation</h3>
<ul>
<li>1111-11-11, Estimation Methods - Method of Moments</li>
<li>2023-03-29, Estimation Methods - <a href="../../../../../docs/blog/posts/statistics/2023-03-25_MLE/index.html">Maximum Likelihood Estimation &amp; Statistical Bias</a></li>
<li>1111-11-11, Estimation Methods - Bayesian Estimation</li>
<li>1111-11-11, Estimation Methods - The EM Algorithm</li>
<li>1111-11-11, Evaluation Methods of Estimators - Mean Squared Error</li>
<li>1111-11-11, Evaluation Methods of Estimators - Best Unbiased Estimators</li>
<li>1111-11-11, Evaluation Methods of Estimators - Sufficiency and Unbiasedness</li>
<li>1111-11-11, Evaluation Methods of Estimators - Loss Function Optimality</li>
</ul>
</section>
</section>
<section id="hypothesis-testing" class="level2">
<h2 class="anchored" data-anchor-id="hypothesis-testing">Hypothesis Testing</h2>
<ul>
<li>1111-11-11, Hypothesis Testing</li>
<li>1111-11-11, Permutation Test</li>
</ul>
<section id="methods-of-finding-tests" class="level3">
<h3 class="anchored" data-anchor-id="methods-of-finding-tests">Methods of Finding Tests</h3>
<ul>
<li>1111-11-11, Likelihood Ratio Tests</li>
<li>1111-11-11, Bayesian Tests</li>
<li>1111-11-11, Union-Intersection and Intersection-Union Tets</li>
</ul>
</section>
<section id="methods-of-evaluating-tests" class="level3">
<h3 class="anchored" data-anchor-id="methods-of-evaluating-tests">Methods of Evaluating Tests</h3>
<ul>
<li>1111-11-11, Power</li>
<li>1111-11-11, Error Proabilities and the Power Function</li>
<li>1111-11-11, Most Powerful Tests</li>
<li>2022-12-28, <a href="../../../../../docs/blog/posts/statistics/2022-12-08-P-value/index.html">p-values</a></li>
<li>1111-11-11, Loss Function Optimality</li>
<li>1111-11-11, Multiple Testing</li>
<li>1111-11-11, Sample Size Calculation</li>
<li>1111-11-11, A/B Testing</li>
<li>2023-01-07, <a href="../../../../../docs/blog/posts/statistics/2023-01-07-anova/index.html">ANOVA</a>
<ul>
<li>2023-01-27, <a href="../2023-01-27_ANCOVA/">ANCOVA</a></li>
<li>2023-01-27, <a href="../2023-01-27_rmANOVA/">repeated measures ANOVA</a></li>
<li>2023-01-28, <a href="../2023-01-28_MANOVA/">MANOVA</a></li>
</ul></li>
</ul>
</section>
</section>
<section id="categorical-data-analysis" class="level2">
<h2 class="anchored" data-anchor-id="categorical-data-analysis">Categorical Data Analysis</h2>
<ul>
<li>1111-11-11, Introduction</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>2022-12-28,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>2023-01-07,</li>
<li>2023-01-27,</li>
<li>2023-01-27,</li>
<li>2023-01-28,</li>
</ul>
</section>
<section id="regression" class="level2">
<h2 class="anchored" data-anchor-id="regression">Regression</h2>
<ul>
<li>1111-11-11, Least Square and Simple Linear Regression</li>
<li>1111-11-11, Multiple Linear Regression</li>
</ul>
<section id="generalized-linear-models" class="level3">
<h3 class="anchored" data-anchor-id="generalized-linear-models">Generalized Linear Models</h3>
<ul>
<li>1111-11-11, Logistic Regression</li>
<li>1111-11-11, Multinomial Regression</li>
<li>1111-11-11, Poisson Regression</li>
<li>1111-11-11, Poisson Regression</li>
<li>1111-11-11, Poisson Regression</li>
</ul>
</section>
</section>
<section id="longitudinal-data-analysis" class="level2">
<h2 class="anchored" data-anchor-id="longitudinal-data-analysis">Longitudinal Data Analysis</h2>
<ul>
<li>2023-03-23, <a href="../../../../../docs/blog/posts/statistics/LDA/1_intro.html">LDA (1) - Intro</a></li>
<li>2023-03-23, <a href="../../../../../docs/blog/posts/statistics/LDA/2_covariance_model.html">LDA (2) - Concepts &amp; Covariance Models</a></li>
<li>2023-03-25, <a href="../LDA/intro.qmd">LDA (3) - WLS &amp; REML</a></li>
<li>2023-03-25, <a href="../LDA/intro.qmd">LDA (4) - Respiratory Infection Data Example</a></li>
<li>2023-03-28, <a href="../LDA/intro.qmd">LDA (5) - Epileptic Seizures Data Example</a></li>
</ul>
<section id="mixed-models" class="level3">
<h3 class="anchored" data-anchor-id="mixed-models">Mixed Models</h3>
<ul>
<li>1111-11-11, Linear Mixed Models</li>
</ul>
</section>
</section>
<section id="generalized-additive-models" class="level2">
<h2 class="anchored" data-anchor-id="generalized-additive-models">Generalized Additive Models</h2>
</section>
<section id="survival-analysis" class="level2">
<h2 class="anchored" data-anchor-id="survival-analysis">Survival Analysis</h2>
<ul>
<li>1111-11-11, Cox-Hazard Model</li>
</ul>


</section>
</section>

 ]]></description>
  <category>Statistics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/statistics/guide_map/index.html</guid>
  <pubDate>Fri, 30 Apr 2100 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Machine Learning</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/ML/guide_map/index.html</link>
  <description><![CDATA[ 



<p><strong>(Draft)</strong></p>
<section id="contents-list" class="level1">
<h1>Contents List</h1>
<section id="basic" class="level2">
<h2 class="anchored" data-anchor-id="basic">Basic</h2>
<section id="r" class="level3">
<h3 class="anchored" data-anchor-id="r">R</h3>
</section>
<section id="python" class="level3">
<h3 class="anchored" data-anchor-id="python">Python</h3>
<section id="tensor-flow-framework" class="level4">
<h4 class="anchored" data-anchor-id="tensor-flow-framework">Tensor Flow Framework</h4>
<ul>
<li>2023-02-03, <a href="../../../../../docs/blog/posts/ML/2023-02-03_tf_introduction/index.html">Tensor Flow Introduction</a></li>
</ul>
</section>
<section id="pytorch-framework" class="level4">
<h4 class="anchored" data-anchor-id="pytorch-framework">Pytorch Framework</h4>
<ul>
<li>2023-02-03, <a href="../../../../../docs/blog/posts/ML/2023-02-03_pytorch_introduction/index.html">Pytorch Introduction</a></li>
</ul>
</section>
</section>
</section>
<section id="machine-learning-methods" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning-methods">Machine Learning Methods</h2>
<section id="supervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="supervised-learning">Supervised Learning</h3>
<ul>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Logistic Regression]</li>
<li>0000-00=00, [Generative Models]
<ul>
<li>0000-00=00, [Linear Discriminant Analysis]</li>
<li>0000-00=00, [Quadratic Discriminant Analysis]</li>
<li>0000-00=00, [Naive Bayes]</li>
</ul></li>
<li>0000-00=00, [Resampling Methods]</li>
<li>0000-00=00, [Regularization]</li>
<li>0000-00=00, [Smoothing]</li>
<li>0000-00=00, [Tree Based Methods]</li>
<li>0000-00=00, [Support Vector Machine]</li>
<li>0000-00=00, [PCR]</li>
<li>0000-00=00, [PLS]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
</ul>
</section>
<section id="unupervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="unupervised-learning">Unupervised Learning</h3>
<ul>
<li>0000-00=00, [PCA]</li>
<li>0000-00=00, [K means clustering]</li>
<li>0000-00=00, [Hierarchical Clustering]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
</ul>


</section>
</section>
</section>

 ]]></description>
  <category>ML</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/ML/guide_map/index.html</guid>
  <pubDate>Wed, 31 Mar 2100 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Mathematics</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/guide_map/index.html</link>
  <description><![CDATA[ 



<section id="contents" class="level1">
<h1>Contents</h1>
<section id="basic" class="level2">
<h2 class="anchored" data-anchor-id="basic">Basic</h2>
<ul>
<li>2023-03-24, <a href="../../../../../docs/blog/posts/Mathmatics/variables/index.html">Variable types</a></li>
<li>1111-11-11, <a href="../../../../../docs/blog/posts/Mathmatics/function/index.html">Function</a>
<ul>
<li>2023-01-31, <a href="../../../../../docs/blog/posts/Mathmatics/function/univariable_scalar_function.html">Function (1) - Univariable Scalar Function (One to One)</a></li>
<li>2023-01-31, <a href="../../../../../docs/blog/posts/Mathmatics/function/multivariable_scalar_function.html">Function (2) - Multi-variable Scalar Function (Many to One)</a></li>
<li>2023-01-31, <a href="../../../../../docs/blog/posts/Mathmatics/function/univariable_vector_function.html">Function (3) - Univariable Vector Function (One to Many)</a></li>
<li>2023-01-31, <a href="../../../../../docs/blog/posts/Mathmatics/function/mutivariable_vector_function.html">Function (4) - Multi-variable Vector Function (Many to Many)</a></li>
<li>2023-02-18, <a href="../../../../../docs/blog/posts/Mathmatics/function/composite_function.html">Function (5) - Composite Function</a></li>
</ul></li>
<li>2023-02-18, <a href="../../../../../docs/blog/posts/Mathmatics/transformation/index.html">Transformations of Functions</a></li>
<li>1111-11-11, Vector &amp; Matrix</li>
<li>2023-03-15, <a href="../epsilon_delta/">Limit, <img src="https://latex.codecogs.com/png.latex?%5Cepsilon-%5Cdelta"> Method</a></li>
<li>Differentiation
<ul>
<li>2023-02-04, <a href="../../../../../docs/blog/posts/Mathmatics/differentiation/2023-02-04_uni_derivative.html">Derivative (1) - Univariable Scalar Funtion</a></li>
<li>1111-11-11, <a href="../../../../../docs/blog/posts/Mathmatics/differentiation/2023-02-10_composite_partial_derivative.html">Derivative (2) - Chain Rule &amp; Partial Derivative</a></li>
<li>1111-11-11, Derivative (3) - Higher Order Derivative</li>
<li>1111-11-11, Derivative (4) - Mean Value Theorem</li>
<li>1111-11-11, Derivative (5) - Gradient</li>
</ul></li>
<li>2023-03-15, <a href="../../../../../docs/blog/posts/Mathmatics/taylor_series/index.html">Talyer’s Series</a></li>
<li>1111-11-11, Gradient Direction</li>
<li>1111-11-11, Random Variable</li>
<li>1111-11-11, Probability Distribution</li>
<li>1111-11-11, Information Theory - Entropy</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
</ul>
</section>
<section id="linear-algebra" class="level2">
<h2 class="anchored" data-anchor-id="linear-algebra">Linear Algebra</h2>
<ul>
<li>1111-11-11, Vector Space</li>
<li>1111-11-11, Subspace</li>
<li>1111-11-11, Inner Product</li>
<li>1111-11-11, Linear Combination</li>
<li>1111-11-11, Quadratic Form</li>
<li>1111-11-11, Linear Independence</li>
<li>1111-11-11, Basis, Dimension, &amp; Rank</li>
<li>1111-11-11, Outer Product</li>
<li>1111-11-11, Eigen Value &amp; Eigen Vector</li>
<li>1111-11-11, Eigen Decomposition</li>
<li>1111-11-11, Singular Value Decomposition (SVD)</li>
<li>1111-11-11, Gram-Schmidt</li>
<li>1111-11-11, Group</li>
<li>1111-11-11, Orthogonal Matrix</li>
<li>1111-11-11, Rotation &amp; Group</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
</ul>
</section>
<section id="optimization" class="level2">
<h2 class="anchored" data-anchor-id="optimization">Optimization</h2>
<ul>
<li>2023-03-23, <a href="../../../../../docs/blog/posts/Mathmatics/optimization/minimizer.html">Minimizer &amp; Minimum</a></li>
<li>1111-11-11, Convex Set</li>
<li>1111-11-11, Convex Function</li>
<li>1111-11-11, Unconstrained Optimization</li>
<li>1111-11-11, Non-linear Least Square</li>
<li>1111-11-11, Largrange Multiplier Method
<ul>
<li>1111-11-11, Largrange Primal Function</li>
<li>1111-11-11, Largrange Dual Function</li>
<li>1111-11-11, KKT conditions</li>
</ul></li>
<li>1111-11-11, Gradient Descent Optimizers</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
</ul>
</section>
<section id="reference" class="level2">
<h2 class="anchored" data-anchor-id="reference">Reference</h2>
<ul>
<li>Statistics
<ul>
<li>George Casella &amp; Rogeer L. Berger - Statistcal Inference, 2nd Edition</li>
<li>슬기로운 통계생활 - https://www.youtube.com/<span class="citation" data-cites="statisticsplaybook">@statisticsplaybook</span></li>
<li>슬기로운 통계생활 - https://github.com/statisticsplaybook</li>
<li>다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Mathematics
<ul>
<li>James Stewart - Calculus Early Transcedentals, 7th Eidition</li>
<li>any James Stewart series</li>
<li>임장환 - 머신러닝, 인공지능, 컴퓨터 비전 전공자를 위한 최적화 이론</li>
<li>다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Deep Learning
<ul>
<li>조준우 - 머신러닝·딥러닝에 필요한 기초 수학 with 파이썬</li>
<li>조준우 - https://github.com/metamath1/noviceml</li>
<li>동빈나 - https://www.youtube.com/c/dongbinna</li>
<li>혁펜하임 - https://www.youtube.com/channel/UCcbPAIfCa4q0x7x8yFXmBag</li>
<li>다수의 Youtube, and Documents from Googling</li>
</ul></li>
</ul>


</section>
</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/guide_map/index.html</guid>
  <pubDate>Sun, 28 Feb 2100 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Deep Learning</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/DL/guide_map/index.html</link>
  <description><![CDATA[ 



<p><strong>(Draft)</strong></p>
<section id="contents-list" class="level1">
<h1>Contents List</h1>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<ul>
<li>1111-11-11, Artificial Intelligence</li>
<li>1111-11-11, Perceptron</li>
<li>1111-11-11, Artificial Neural Netwroks (ANN)
<ul>
<li>1111-11-11, activation functions</li>
<li>1111-11-11, output layer design</li>
</ul></li>
<li>1111-11-11, loss function</li>
<li>1111-11-11, numerical differentiation</li>
<li>1111-11-11, gradient descent</li>
<li>1111-11-11, backpropagation</li>
<li>1111-11-11, optimizer
<ul>
<li>1111-11-11, stochastic gradient descent</li>
<li>1111-11-11, momentum</li>
<li>1111-11-11, adaGrad</li>
<li>1111-11-11, adam</li>
<li>1111-11-11, weight initalization</li>
</ul></li>
<li>1111-11-11, batch normalization</li>
<li>1111-11-11, dropout</li>
<li>1111-11-11, tuning parameter</li>
<li>1111-11-11, auto-encoder</li>
<li>1111-11-11, stacked auto-encoder</li>
<li>1111-11-11, denoising auto-encoder(DAE)</li>
</ul>
<section id="convolutional-neural-network-cnn" class="level3">
<h3 class="anchored" data-anchor-id="convolutional-neural-network-cnn">Convolutional Neural Network (CNN)</h3>
<ul>
<li>2023-03-10, <a href="../../../../../docs/blog/posts/DL/2023-03-10_cnn/index.html">CNN (1) - Concept</a></li>
<li>2023-03-10, <a href="">CNN (2) - Practice</a></li>
</ul>
</section>
<section id="natural-language-process-nlp" class="level3">
<h3 class="anchored" data-anchor-id="natural-language-process-nlp">Natural Language Process (NLP)</h3>
<ul>
<li>1111-11-11, word2vec</li>
<li>1111-11-11, improved word2vec</li>
</ul>
</section>
<section id="recurrent-neural-network-rnn" class="level3">
<h3 class="anchored" data-anchor-id="recurrent-neural-network-rnn">Recurrent Neural Network (RNN)</h3>
</section>
<section id="gate-recurrent-unit-gru" class="level3">
<h3 class="anchored" data-anchor-id="gate-recurrent-unit-gru">Gate Recurrent Unit (GRU)</h3>
</section>
<section id="long-short-term-memory-lstm" class="level3">
<h3 class="anchored" data-anchor-id="long-short-term-memory-lstm">Long Short-Term Memory (LSTM)</h3>
</section>
<section id="attention-transformer" class="level3">
<h3 class="anchored" data-anchor-id="attention-transformer">Attention (Transformer)</h3>
</section>
<section id="bidirectional-encoder-representations-from-transformers-bert" class="level3">
<h3 class="anchored" data-anchor-id="bidirectional-encoder-representations-from-transformers-bert">Bidirectional Encoder Representations from Transformers (BERT)</h3>
</section>
<section id="generative-pre-training-transformer-gpt" class="level3">
<h3 class="anchored" data-anchor-id="generative-pre-training-transformer-gpt">Generative Pre-training Transformer (GPT)</h3>


</section>
</section>
</section>

 ]]></description>
  <category>DL</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/DL/guide_map/index.html</guid>
  <pubDate>Thu, 31 Dec 2099 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Engineering</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Engineering/guide_map/index.html</link>
  <description><![CDATA[ 



<section id="it-terminology" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="it-terminology"><span class="header-section-number">1</span> IT Terminology</h2>
<ul>
<li>0000-00-00, Terminology</li>
</ul>
</section>
<section id="data-structure" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="data-structure"><span class="header-section-number">2</span> Data Structure</h2>
<ul>
<li>2023-01-17, <a href="../2023-01-17_data_structure_overview/">Overview</a></li>
<li>2023-01-18, <a href="../2023-01-18_array/">Array</a></li>
<li>2023-01-18, <a href="../2023-01-18_linked_list/">Linked List</a></li>
<li>2023-01-18, <a href="../2023-01-18_python_list/">Python List</a></li>
<li>2023-01-19, <a href="../2023-01-19_stack/">Stack</a></li>
<li>2023-01-19, <a href="../2023-01-19_queue/">Queue</a></li>
<li>2023-01-26, <a href="../2023-01-19_deque/">Deque</a></li>
<li>2023-01-26, <a href="../2023-01-20_binary_search_tree/">Binary Search Tree</a></li>
<li>2023-01-20, <a href="../2023-01-20_priority_queue/">Priority Queue</a></li>
<li>2023-01-20, <a href="../2023-01-20_graph/">Graph</a></li>
</ul>
</section>
<section id="conda" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="conda"><span class="header-section-number">3</span> Conda</h2>
</section>
<section id="docker" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="docker"><span class="header-section-number">4</span> Docker</h2>
<ul>
<li>2023-01-30, Docker Install</li>
<li>2023-01-31, Docker Compose</li>
<li>2023-02-01, Docker Container</li>
</ul>
</section>
<section id="dynamic-documentation" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="dynamic-documentation"><span class="header-section-number">5</span> Dynamic Documentation</h2>
<ul>
<li>2023-01-19, <a href="https://quarto.org/docs/get-started/">Quarto</a></li>
<li>2023-01-19, <a href="https://github.com/yihui/xaringan">xaringan[R]</a></li>
<li>2023-01-19, <a href="https://bookdown.org/yihui/bookdown/get-started.html">Bookdown[R]</a></li>
<li>2023-01-19, <a href="https://decile-team-distil.readthedocs.io/en/latest/index.html">DISTL</a></li>
<li>2023-01-26, <a href="https://www.sphinx-doc.org/en/master/">Sphinx[Python]</a></li>
</ul>
</section>
<section id="aws-cloud" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="aws-cloud"><span class="header-section-number">6</span> AWS Cloud</h2>
<p>Coursera Course: AWS Fundamentals</p>
<ul>
<li>2023-03-09, <a href="../../../../../docs/blog/posts/Engineering/2023-03-02_aws/computing_networking.html">Computing and Networking</a></li>
<li>2023-03-12, <a href="../../../../../docs/blog/posts/Engineering/2023-03-02_aws/storage_database.html">Storage and Database</a></li>
</ul>
</section>
<section id="azure-cloud" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="azure-cloud"><span class="header-section-number">7</span> Azure Cloud</h2>
</section>
<section id="data-modeling" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="data-modeling"><span class="header-section-number">8</span> Data Modeling</h2>
</section>
<section id="apache-airflow" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="apache-airflow"><span class="header-section-number">9</span> Apache Airflow</h2>
</section>
<section id="apache-spark" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="apache-spark"><span class="header-section-number">10</span> Apache Spark</h2>
</section>
<section id="front-end" class="level2" data-number="11">
<h2 data-number="11" class="anchored" data-anchor-id="front-end"><span class="header-section-number">11</span> Front End</h2>
</section>
<section id="back-end" class="level2" data-number="12">
<h2 data-number="12" class="anchored" data-anchor-id="back-end"><span class="header-section-number">12</span> Back End</h2>


</section>

 ]]></description>
  <category>Engineering</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Engineering/guide_map/index.html</guid>
  <pubDate>Thu, 31 Dec 2099 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Language</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Language/guide_map/index.html</link>
  <description><![CDATA[ 



<p><strong>(Draft)</strong></p>
<section id="contents-list" class="level1">
<h1>Contents List</h1>
<section id="r" class="level2">
<h2 class="anchored" data-anchor-id="r">R</h2>
<ul>
<li>1111-11-11, tidyverse
<ul>
<li>1111-11-11, dplyr</li>
<li>1111-11-11, ggplot2</li>
<li>1111-11-11, tidyr</li>
<li>1111-11-11, readr</li>
<li>1111-11-11, purrr</li>
<li>1111-11-11, tibble</li>
<li>1111-11-11, stringr</li>
<li>1111-11-11, forcats</li>
</ul></li>
<li>1111-11-11, tidymodels</li>
<li>1111-11-11, R shiny</li>
</ul>
</section>
<section id="python" class="level2">
<h2 class="anchored" data-anchor-id="python">Python</h2>
<ul>
<li>1111-11-11, numpy</li>
<li>1111-11-11, pandas</li>
<li>1111-11-11, matplotlib</li>
<li>1111-11-11, seaborn</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
</ul>
</section>
<section id="sql" class="level2">
<h2 class="anchored" data-anchor-id="sql">SQL</h2>
<section id="sqlite" class="level3">
<h3 class="anchored" data-anchor-id="sqlite">SQLite</h3>
</section>
<section id="oracle-sql" class="level3">
<h3 class="anchored" data-anchor-id="oracle-sql">Oracle SQL</h3>
</section>
<section id="ms-sql" class="level3">
<h3 class="anchored" data-anchor-id="ms-sql">MS-SQL</h3>
</section>
<section id="postgre-sql" class="level3">
<h3 class="anchored" data-anchor-id="postgre-sql">Postgre SQL</h3>
</section>
</section>
<section id="linux" class="level2">
<h2 class="anchored" data-anchor-id="linux">Linux</h2>
</section>
<section id="powershell" class="level2">
<h2 class="anchored" data-anchor-id="powershell">Powershell</h2>
</section>
<section id="c" class="level2">
<h2 class="anchored" data-anchor-id="c">C++</h2>
</section>
<section id="javascript" class="level2">
<h2 class="anchored" data-anchor-id="javascript">Javascript</h2>


</section>
</section>

 ]]></description>
  <category>Language</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Language/guide_map/index.html</guid>
  <pubDate>Thu, 31 Dec 2099 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Patent</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Patent/guide_map/index.html</link>
  <description><![CDATA[ 



<p><strong>(Draft)</strong></p>
<section id="contents-list" class="level1">
<h1>Contents List</h1>
<section id="basic" class="level2">
<h2 class="anchored" data-anchor-id="basic">Basic</h2>


</section>
</section>

 ]]></description>
  <category>Patent</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Patent/guide_map/index.html</guid>
  <pubDate>Thu, 31 Dec 2099 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Validation</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Surveilance/guide_map/index.html</link>
  <description><![CDATA[ 



<section id="sgs" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sgs"><span class="header-section-number">1</span> SGS</h2>
<ul>
<li>0000-00-00, EN62304</li>
</ul>
</section>
<section id="fda" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="fda"><span class="header-section-number">2</span> FDA</h2>
<ul>
<li>2023-01-27, <a href="../../../../../docs/blog/posts/Surveilance/2022-12-10_FDA_sw_general_guidance/index.html">General Principles of SW Validation</a></li>
<li>2023-01-27, <a href="../../../../../docs/blog/posts/Surveilance/2023-01-27_FDA_sw_general_guidance_presentation/index.html">General Principles of SW Validation - Diagram Summary</a></li>
<li>1111-11-11, Guidance for the Content of Premarket Submissions for Software Contained in Medical Devices</li>
</ul>
</section>
<section id="dhf" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="dhf"><span class="header-section-number">3</span> DHF</h2>
</section>
<section id="public-health" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="public-health"><span class="header-section-number">4</span> Public Health</h2>
</section>
<section id="wet-lab" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="wet-lab"><span class="header-section-number">5</span> Wet Lab</h2>
<ul>
<li>0000-00-00, PCR (Polymerase Chain Reaction) Experiment</li>
</ul>


</section>

 ]]></description>
  <category>Surveilance</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Surveilance/guide_map/index.html</guid>
  <pubDate>Sat, 31 Dec 2089 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Maximum Likelihood Estimation, Statistical Bias, and Point Estimation</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/statistics/2023-03-25_MLE/index.html</link>
  <description><![CDATA[ 



<section id="definition" class="level3" data-number="0.1">
<h3 data-number="0.1" class="anchored" data-anchor-id="definition"><span class="header-section-number">0.1</span> Definition</h3>
<p>To talk about MLE (Maximum Likelihood Estimation), we need to recap the concepts and definitions of probability and likelihood. They are related but distinct concepts.</p>
<ul>
<li>probability is a measure of the chance that an event will occur, given some prior knowledge or assumptions.</li>
<li>likelihood is a measure of the plausibility or compatibility of a particular set of model parameters, given the observed data.</li>
</ul>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Chance vs Plausibility (personal opinion)
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>chance is a general term but closer term to statistics, which is used in the situation of the probability or likelihood of an event occurring based on randomness or uncertainty.<br>
</li>
<li>plausibility chance is a term more often used in everyday life, which refers to the degree to which something is believable based on the available evidence or information.</li>
</ul>
</div>
</div>
<div id="def-likelihood" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 </strong></span>Let <img src="https://latex.codecogs.com/png.latex?X_1,%20X_2,%20...,%20X_n"> be a set of iid random variables with pdf or pmf <img src="https://latex.codecogs.com/png.latex?f(x_i%20%7C%20%5Ctheta)">, where <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> is a vector of unknown parameters. Then, <strong>the likelihood function is defined as the joint pdf or pmf of the observed data, given the values of the parameters</strong>:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AL(%5Ctheta%20%7C%20x_1,%20x_2,%20...,%20x_n)%20=%20L(%5Ctheta%20%7C%20%5Cmathbf%20x)%20=%20%5Cprod_%7Bi=1%7D%5En%20f(x_i%20%7C%20%5Ctheta)%0A"></p>
</div>
<p>The likelihood function is a function of the parameters <img src="https://latex.codecogs.com/png.latex?%5Ctheta">. The function measures the probability of observing a set of data, given the values of the parameters of a statistical model in order to estimate the values of the parameters by finding the values that maximize the likelihood function. The likelihood function is often used in the maximum likelihood estimation (MLE) method, where the MLE estimator is the set of parameter values that maximize the likelihood function.</p>
<p>The likelihood function is related to the concept of conditional probability. Given a set of observed data <img src="https://latex.codecogs.com/png.latex?x_1,%20x_2,%20...,%20x_n">, the likelihood function measures the probability of observing these data, assuming a particular set of parameter values. The likelihood function is not a probability distribution, but it can be used to derive a probability distribution for the parameters, known as the posterior distribution, using Bayes’ theorem.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Probability
</div>
</div>
<div class="callout-body-container callout-body">
<p>Probability is a measure of the likelihood or chance that an event will occur, which is used to quantify uncertainty and randomness.<br>
probability is a function that maps a real number mapped from a random variable into <img src="https://latex.codecogs.com/png.latex?%5B0,1%5D">. The probability function, denoted by <img src="https://latex.codecogs.com/png.latex?P">, satisfies the following axioms:</p>
<ul>
<li>Non-negativity: For any event <img src="https://latex.codecogs.com/png.latex?A%20%5Cin%20%5COmega">, <img src="https://latex.codecogs.com/png.latex?P(A)%20%5Cgeq%200">.</li>
<li>Normalization: The probability of the entire sample space is 1, i.e., <img src="https://latex.codecogs.com/png.latex?P(%5COmega)%20=%201">.</li>
<li>Additivity: For any two disjoint events <img src="https://latex.codecogs.com/png.latex?A,%20B%20%5Cin%20%5COmega">, or <img src="https://latex.codecogs.com/png.latex?A%20%5Ccap%20B%20=%20%5Cemptyset">, the probability of their union is equal to the sum of their individual probabilities, i.e., <img src="https://latex.codecogs.com/png.latex?P(A%20%5Ccup%20B)%20=%20P(A)%20+%20P(B)">.</li>
</ul>
</div>
</div>
<section id="probability-vs-likelihood" class="level4" data-number="0.1.1">
<h4 data-number="0.1.1" class="anchored" data-anchor-id="probability-vs-likelihood"><span class="header-section-number">0.1.1</span> Probability vs Likelihood</h4>
<p>Probability and likelihood are related but distinct concepts in statistics.</p>
<ul>
<li>Probability refers to the measure of the likelihood that a particular event will occur, scaled on <img src="https://latex.codecogs.com/png.latex?%5B0,1%5D">. It is calculated based on a known probability distribution (= some prior knowledge or assumptions) before the data is observed.</li>
<li>On the other hand, likelihood refers to the probability of observing a set of data given a particular set of parameter values in a statistical model. It is calculated based on the unknown parameters after the data is observed.</li>
</ul>
<p>The likelihood function is used to estimate the values of the parameters by finding the parameter values that maximize the likelihood function.</p>
<p>For instance of a coin flip, the <strong>probability</strong> of getting heads on a coin flip is 0.5, regardless of whether the coin has been flipped or not (i.e., without data). In contrast, the <strong>likelihood</strong> of observing heads after a coin has been flipped depends on the parameter of interest. We need to find the parameter given data, the results of multiple coin flips.</p>
<p>If we want to estimate the probability of heads, we can use the maximum likelihood estimation (MLE) approach, which involves finding the value of the coin bias that maximizes the likelihood of observing the observed sequence of heads and tails. The likelihood of the data is calculated using the binomial distribution, which gives the probability of observing a certain number of heads, given the number of tosses and the coin bias. In this case, the likelihood function is a function of the coin bias, and the probability of heads is the value of the coin bias that maximizes the likelihood function.</p>
</section>
<section id="relation-between-likelihood-and-pmf-or-pdf" class="level4" data-number="0.1.2">
<h4 data-number="0.1.2" class="anchored" data-anchor-id="relation-between-likelihood-and-pmf-or-pdf"><span class="header-section-number">0.1.2</span> Relation between Likelihood and PMF or PDF</h4>
<p>The likelihood function is closely related to pmf or pdf of the data, which is a function that describes the probability of observing a particular value or range of values for the data, given the model parameters. The pmf or pdf is a function of the data, not the parameters, and is often written as <img src="https://latex.codecogs.com/png.latex?f(x%7C%5Ctheta)">. The likelihood function is proportional to the pdf because is a product of pdfs when <img src="https://latex.codecogs.com/png.latex?X_i"> is independent, but with the data fixed and the parameter values treated as variables.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;">library</span>(tidyverse)</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;"># Probability of getting heads on a fair coin flip</span></span>
<span id="cb1-4">prob <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fl" style="color: #AD0000;">0.5</span></span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="co" style="color: #5E5E5E;"># likelihood</span></span>
<span id="cb1-7"><span class="do" style="color: #5E5E5E;
font-style: italic;">## Simulate a coin flip with a biased coin</span></span>
<span id="cb1-8"><span class="fu" style="color: #4758AB;">set.seed</span>(<span class="dv" style="color: #AD0000;">123</span>) <span class="co" style="color: #5E5E5E;"># Set random seed for reproducibility</span></span>
<span id="cb1-9">n <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="dv" style="color: #AD0000;">100</span> <span class="co" style="color: #5E5E5E;"># flipping numbers</span></span>
<span id="cb1-10">p <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fl" style="color: #AD0000;">0.2</span> <span class="co" style="color: #5E5E5E;"># Probability of getting heads</span></span>
<span id="cb1-11">x <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">rbinom</span>(n, <span class="at" style="color: #657422;">size =</span> <span class="dv" style="color: #AD0000;">1</span>, <span class="at" style="color: #657422;">prob =</span> p) <span class="co" style="color: #5E5E5E;"># Simulate n coin flips</span></span>
<span id="cb1-12">x<span class="sc" style="color: #5E5E5E;">%&gt;%</span><span class="fu" style="color: #4758AB;">head</span>(<span class="dv" style="color: #AD0000;">10</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> [1] 0 0 0 1 1 0 0 1 0 0</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="do" style="color: #5E5E5E;
font-style: italic;">## Calculate the likelihood of observing the data given the parameter value p</span></span>
<span id="cb3-2">likelihood <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">prod</span>(<span class="fu" style="color: #4758AB;">dbinom</span>(x, <span class="at" style="color: #657422;">size =</span> <span class="dv" style="color: #AD0000;">1</span>, <span class="at" style="color: #657422;">prob =</span> p))</span>
<span id="cb3-3">likelihood<span class="sc" style="color: #5E5E5E;">%&gt;%</span><span class="fu" style="color: #4758AB;">round</span>()</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
</div>
<p>In this example, <code>prob</code> is the assumed probability of getting heads on a fair coin flip. The probability of getting heads on a fair coin flip is 0.5, which is a fixed value that does not depend on any specific data. On the other hand, <code>p</code> is the probability of getting heads for the biased coin that we are simulating. The likelihood of observing a set of coin flips depends on the parameter value, which is unknown (actually, we know that it was <img src="https://latex.codecogs.com/png.latex?p=0.2">), and the observed data. We simulate a set of 100 coin flips with a biased coin that has a probability of 0.2 of getting heads. We then calculate the likelihood of observing this data given the parameter value of 0.2, which is the product of the probability mass function for each flip.</p>
<p>However, in a real-world scenario, we would not know the true value of <code>p</code> and we would need to estimate it based on the observed data. By finding the Maximum Likelihood Estimation (MLE) of p, we are estimating the value of p that is most likely to have generated the observed data. To find MLE of <code>p</code> that maximizes the likelihood function, we can use numerical optimization methods.</p>
<p>As n increases, the product term in the likelihood function <img src="https://latex.codecogs.com/png.latex?%5Cprod_%7Bi=1%7D%5E%7Bn%7D%20f(x_i;%20%5Ctheta)">, where <img src="https://latex.codecogs.com/png.latex?f"> is the pdf or pmf of the distribution being used, can become very small (since it is a product of values less than 1) and may result in numerical underflow (i.e., the product becomes so small that it rounds down to 0 in computer calculations). In practice, we typically take the logarithm of the likelihood function, called the log-likelihood, to avoid this issue:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clog%20L(%5Ctheta%7Cx_1,%20x_2,%20...,%20x_n)%20=%20%5Csum_%7Bi=1%7D%5E%7Bn%7D%20%5Clog%20f(x_i;%20%5Ctheta)%0A"></p>
<p>Using the logarithm allows us to convert the product of small probabilities into a sum of log-probabilities, which are typically easier to work with numerically and mathematically. In this case, as n increases, the sum term in the log-likelihood can decrease (since it is a sum of negative values), but the decrease may not be as severe as in the product term of the likelihood function because of the log scale converting very small or large values into larger or smaller values .</p>
<div id="def-MLE" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2 </strong></span>The MLE estimator <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Ctheta%7D"> is the value of the parameter vector that maximizes the likelihood function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Ctheta%7D_%7BMLE%7D%20=%20%5Cunderset%7B%5Ctheta%7D%7B%5Coperatorname%7Bargmax%7D%7D%20L(%5Ctheta%20%7C%20x_1,%20x_2,%20...,%20x_n)%0A"></p>
<p>or equivalently, maximizes the log-likelihood function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Ctheta%7D_%7BMLE%7D%20=%20%5Cunderset%7B%5Ctheta%7D%7B%5Coperatorname%7Bargmax%7D%7D%20%5Clog%20L(%5Ctheta%20%7C%20x_1,%20x_2,%20...,%20x_n)%0A"></p>
</div>
<p>The Maximum Likelihood Estimation (MLE) is a method of estimating the parameters of a statistical model by finding the values of the parameters that maximize the likelihood function. The likelihood function is the probability of observing the data, given the parameters of the model. The MLE estimator is the set of parameter values that maximize the likelihood function. In other words, the MLE is the set of parameter values that make the observed data most probable, given the assumed probability distribution. The likelihood function is typically the product or the sum (depending on whether the observations are assumed to be independent or not) of the probabilities or probability densities of the observations, evaluated at the values of the parameters.</p>
<p>The MLE estimator has desirable statistical properties, such as consistency, efficiency, and asymptotic normality, under certain regularity conditions on the likelihood function and the parameter space. However, it is important to note that the MLE is not always the best estimator for a given problem, and other estimation methods may be more appropriate depending on the specific characteristics of the data and the model.</p>
<p>The likelihood function is the joint probability density (or mass) function of the data, viewed as a function of the parameters, and we find the maximum of this function <strong>by differentiating</strong> it with respect to the parameters and setting the derivative to zero.</p>
</section>
</section>
<section id="sec-mle_ols" class="level3" data-number="0.2">
<h3 data-number="0.2" class="anchored" data-anchor-id="sec-mle_ols"><span class="header-section-number">0.2</span> MLE of OLS</h3>
<p>In a linear regression, the maximum likelihood estimate of the ordinary least squares (OLS) coefficients is equivalent to the least squares estimate. To derive this, we assume that <img src="https://latex.codecogs.com/png.latex?%5Cepsilon_i%20%5Csim%20N(0,%5Csigma%5E2)"> and that the observations are independent. Then, the likelihood function for the data <img src="https://latex.codecogs.com/png.latex?Y%20=%20(Y_1,%20Y_2,%20%5Cdots,%20Y_n)"> is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AL(Y%7C%5Ctheta)%20=L(Y%7C%5Cbeta,%5Csigma%5E2)%20=%20(2%5Cpi%5Csigma%5E2)%5E%7B-%5Cfrac%7Bn%7D%7B2%7D%7D%20e%5E%7B-%5Cfrac%7B1%7D%7B2%5Csigma%5E2%7D%20%5Csum_%7Bi=1%7D%5En%20(Y_i%20-%20X_i%5Cbeta)%5E2%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?X_i"> is the <img src="https://latex.codecogs.com/png.latex?i"> th row of the design matrix <img src="https://latex.codecogs.com/png.latex?X"> and <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> is the vector of regression coefficients.</p>
<p>To find the maximum likelihood estimates of <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> and <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">, we maximize the likelihood function with respect to these parameters. Taking the log of the likelihood function and simplifying, we obtain:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clog%20L(Y%7C%5Ctheta)%20=%20%5Clog%20L(Y%7C%5Cbeta,%5Csigma%5E2)%20=%20-%5Cfrac%7Bn%7D%7B2%7D%20%5Clog%20(2%5Cpi)%20-%20%5Cfrac%7Bn%7D%7B2%7D%20%5Clog(%5Csigma%5E2)%20-%20%5Cfrac%7B1%7D%7B2%5Csigma%5E2%7D%20%5Csum_%7Bi=1%7D%5En%20(Y_i%20-%20X_i%5Cbeta)%5E2%0A"></p>
<p>To maximize this function with respect to <img src="https://latex.codecogs.com/png.latex?%5Cbeta">, we differentiate with respect to <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> and set the derivative to zero, <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Ctheta%7D%20%5Clog%20L(Y%7C%5Ctheta)%20=%200">:</p>
<p>Solving for <img src="https://latex.codecogs.com/png.latex?%5Cbeta">, we obtain:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Ctheta%7D%20%5Clog%20L(Y%7C%5Cbeta,%5Csigma%5E2)%20=%20-%5Cfrac%7B1%7D%7B2%5Csigma%5E2%7D%20%5Csum_%7Bi=1%7D%5En%202X_i(Y_i%20-%20X_i%5Cbeta)%20=%200%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Cbeta%7D%20=%20(X%5ET%20X)%5E%7B-1%7D%20X%5ET%20Y%0A"> , which is the OLS estimate of <img src="https://latex.codecogs.com/png.latex?%5Cbeta">.</p>
<p>Solving for <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">, we differentiate with respect to <img src="https://latex.codecogs.com/png.latex?sigma%5E2"> and set the derivative to zero:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial%20%5Csigma%5E2%7D%20log%20L(Y%7C%5Cbeta,%5Csigma%5E2)%20=%20-%5Cfrac%7Bn%7D%7B2%5Csigma%5E2%7D%20+%20%5Cfrac%7B1%7D%7B2%5Csigma%5E4%7D%20%5Csum_%7Bi=1%7D%5En%20(Y_i%20-%20X_i%5Cbeta)%5E2%20=%200%0A"> <img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Csigma%7D%5E2%20=%20%5Cfrac%7B%5Csum_%7Bi=1%7D%5En%20(Y_i%20-%20X_i%5Cbeta)%5E2%7D%7Bn%7D%0A"></p>
<p>which is the OLS estimate of <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">.</p>
<p>Therefore, we see that the maximum likelihood estimates of <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> and <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2"> in linear regression with normally distributed errors are equivalent to the OLS estimates of these parameters.</p>
</section>
<section id="statistical-bias" class="level3" data-number="0.3">
<h3 data-number="0.3" class="anchored" data-anchor-id="statistical-bias"><span class="header-section-number">0.3</span> Statistical Bias</h3>
<p>Statistical bias refers to a systematic error or deviation in the results of a statistical analysis that is caused by factors other than chance. A biased estimator is one that consistently produces estimates that are systematically different from the true value of the parameter being estimated.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
There are 5 Types of bias
</div>
</div>
<div class="callout-body-container callout-body">
<p>The above article discusses five types of statistical bias that analysts, data scientists, and other business professionals should be aware of to minimize their effects on the final results.</p>
<ol type="1">
<li>selection bias: data selection methods are not truly random, leading to unequal representation of the population.</li>
<li>bias in assignment: pre-existing differences between groups in an experiment can affect the outcome, a.k.a allocation bias, treatment assignment bias, or exposure assignment bias.</li>
<li>confounders: additional variables not accounted for in the experimental design can impact the results.</li>
<li>self-serving bias: individuals tend to downplay undesirable qualities and overemphasize desirable ones a.k.a cognitive bias. In other words, people tend to take credit for their successes and blame outside factors for their failures.</li>
<li>experimenter expectations: researchers can unconsciously influence the data through verbal or non-verbal cues.</li>
</ol>
<p>Being aware of these biases can lead to better models and more reliable insights for data-backed business decisions.</p>
<p><a href="https://online.hbs.edu/blog/post/types-of-statistical-bias">Source: Article Written by Jenny Gutbezahl</a></p>
</div>
</div>
<p>It is important to detect and correct for bias in statistical analyses, as biased estimates can lead to incorrect conclusions and decisions. One way to correct for bias is to use an unbiased estimator, which is one that has a zero bias, i.e., its expected value is equal to the true value of the parameter being estimated.</p>
<div id="def-bias" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3 </strong></span>An estimator <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Ctheta%7D"> is said to be biased if</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Coperatorname%7BE%7D(%5Chat%7B%5Ctheta%7D)%5Cne%20%5Ctheta%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Coperatorname%7BE%7D(%5Chat%7B%5Ctheta%7D)"> is the expected value of the estimator <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Ctheta%7D">, and <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> is the true value of the parameter being estimated.</p>
</div>
<p>An estimator is said to be unbiased if <strong>its expected value is equal to the true value of the parameter being estimated</strong>. In other words, an estimator is unbiased if, on average, it gives an estimate that is equal to the true value of the parameter.</p>
<div class="cell" data-evale="false">

</div>


</section>

 ]]></description>
  <category>Statistics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/statistics/2023-03-25_MLE/index.html</guid>
  <pubDate>Tue, 28 Mar 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Tensorflow - Data Input Pipeline</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Language/pipeline.html</link>
  <description><![CDATA[ 



<ul class="nav nav-pills" id="language-tab">
<li class="nav-item">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<section id="input-pipeline" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="input-pipeline"><span class="header-section-number">1</span> Input Pipeline</h2>
<p>Tensorflow 공식 문서 중 Dataset에 대한 기능 및 성능에 대한 비교 자료</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <code>tf.data API</code> makes it possible to handle large amounts of data, read from different data formats, and perform complex transformations. The tf.data API introduces a tf.data.Dataset abstraction that represents a sequence of elements, in which each element consists of one or more components. For example, in an image pipeline, an element might be a single training example, with a pair of tensor components representing the image and its label. <a href="https://www.tensorflow.org/guide/data">Source: https://www.tensorflow.org/guide/data</a></p>
</div>
</div>
<section id="장점" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="장점"><span class="header-section-number">1.1</span> 장점</h3>
<ul>
<li>어떠한 데이터의 형태가 오더라도 Dataset object 자체가 iterative한 interface를 제공해서 for loop 등의 iteration을 이용하여 데이터의 입력 형태가 변경되어도 코드의 일관성을 유지할 수 있음</li>
</ul>
<p>To create an input pipeline, you must start with a data source. For example, to construct a Dataset from data in memory, you can use tf.data.Dataset.from_tensors() or tf.data.Dataset.from_tensor_slices(). Alternatively, if your input data is stored in a file in the recommended TFRecord format, you can use tf.data.TFRecordDataset().</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> tensorflow <span class="im" style="color: #00769E;">as</span> tf</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> pathlib</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-7"></span>
<span id="cb1-8">np.set_printoptions(precision<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>)</span>
<span id="cb1-9"></span>
<span id="cb1-10">dataset <span class="op" style="color: #5E5E5E;">=</span> tf.data.Dataset.from_tensor_slices([<span class="dv" style="color: #AD0000;">8</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">8</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb1-11">dataset</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>&lt;TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)&gt;</code></pre>
</div>
</div>
<p>Once you have a Dataset object, you can transform it into a new Dataset by chaining method calls on the tf.data.Dataset object. For example, you can apply per-element transformations such as Dataset.map, and multi-element transformations such as Dataset.batch. Refer to the documentation for tf.data.Dataset for a complete list of transformations. The Dataset object is a Python iterable. This makes it possible to consume its elements using a for loop:</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="cf" style="color: #003B4F;">for</span> z <span class="kw" style="color: #003B4F;">in</span> dataset:</span>
<span id="cb3-2">    <span class="bu" style="color: null;">print</span>(z.numpy())</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>8
3
0
8
2
1</code></pre>
</div>
</div>
</section>
</section>
<section id="optimize-pipeline-performance" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="optimize-pipeline-performance"><span class="header-section-number">2</span> Optimize pipeline performance</h2>
<ul>
<li>Dataset을 사용은 prefetch 기능과 interleaving 기능에 의한 연산 속도를 향상 시킬수있다.
<ul>
<li>사용할 수 없는 (또는 사용하지 말아야 할) 특별한 이유가 없다면 필수로 사용해야 할 듯</li>
</ul></li>
<li>Pipeline을 쓸 때 연산 처리 속도가 빨리지는 이유 -&gt; cpu architecture 관련
<ul>
<li>X86, ARM 프로세서
<ul>
<li>실행을 위해 D램 올라감 -&gt; cpu에서 하나의 명령이 거치는 step들 fetch(cpu에 로드), decode(해석), execution(수행) -&gt; load (다시 메모리 이동)</li>
<li>각 단계에서 수행 소요 시간 존재</li>
</ul></li>
</ul></li>
<li>파이프라인 구조를 가지면, 한 스텝 수행 시 다음 데이터가 다른 스텝 수행 가능 -&gt; 시간 단축</li>
</ul>
<p><a href="https://www.tensorflow.org/guide/data">Tensor Flow Pipeline</a></p>
<section id="prefetch" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="prefetch"><span class="header-section-number">2.1</span> Prefetch</h3>
<p>앞쪽 데이터 트레이닝 동안 다음 데이터를 미리 읽어옴</p>
</section>
<section id="interleaving" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="interleaving"><span class="header-section-number">2.2</span> Interleaving</h3>
<p>어떤 작업이 끝나기 전에 dependency 없는 다른 작업 수행(async 하게)</p>
</section>
<section id="caching" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="caching"><span class="header-section-number">2.3</span> Caching</h3>
<p>같은 데이터를 반복적으로 사용시 한번 읽은 데이터를 계속 메모리에 가지고 있음</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
floating point 로 인한 error 누적
</div>
</div>
<div class="callout-body-container callout-body">
<p>Tensorflow와 Numpy로 구현한 값에 오차가 발생하는 이유는 Tensorflow를 어떻게 compile 하였느냐에 따른 차이.</p>
<ul>
<li>Floating point (IEEE-754)에서는 값의 표현에 대한 정의만 있고 실제 연산은 processor vendor마다 다르므로 약간의 오차가 있을 수 있으며, 부동소수점 연산기능을 지원하는 명령들 중 어떠한 명령을 사용하도록 compile하였느냐에 따라 계산값에 차이 발생 가능하고 대부분 무시하지만 오차가 누적이 되면 error rate에 영향이 있을 수 있음.</li>
<li>부동소수점의 precision이 낮을수록 overfitting 가능성 저하되어 오히려 학습이 잘될 수도 있으며 모델을 경량화 할 수 있음 <img src="https://latex.codecogs.com/png.latex?%5Crightarrow"> bfloat16 type이 생기게 된 이유.</li>
</ul>
</div>
</div>
</section>
</section>
</div>
</div>
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">

</div>
</div>
<section id="go-to-blog-content-list" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="go-to-blog-content-list"><span class="header-section-number">3</span> Go to Blog Content List</h2>
<p><a href="./docs/blog/posts/content_list.qmd">Blog Content List</a></p>


</section>

</div></ul> ]]></description>
  <category>Language</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Language/pipeline.html</guid>
  <pubDate>Thu, 23 Mar 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>LDA (2) - Concept &amp; Covariance Models</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/statistics/LDA/2_covariance_model.html</link>
  <description><![CDATA[ 



<ul class="nav nav-pills" id="language-tab">
<li class="nav-item">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<section id="notations" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="notations"><span class="header-section-number">1</span> Notations</h2>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?y_%7Bij%7D"> : the univariate response (i.e.&nbsp;scalar) for the <img src="https://latex.codecogs.com/png.latex?i"> th subject at the <img src="https://latex.codecogs.com/png.latex?j"> th occasion or measurement
<ul>
<li>later when I use the vector case, I will re-define this notation, but focus on the scalar case for now.</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?x_%7Bij%7D"> : the predictor at time <img src="https://latex.codecogs.com/png.latex?t_%7Bij%7D">, which is either a scalr or vector.
<ul>
<li>a scalar case: <img src="https://latex.codecogs.com/png.latex?x_%7Bij%7D"> where <img src="https://latex.codecogs.com/png.latex?i"> is the <img src="https://latex.codecogs.com/png.latex?i"> th subject, and <img src="https://latex.codecogs.com/png.latex?j"> is the <img src="https://latex.codecogs.com/png.latex?j"> th measurement.</li>
<li>a vector case: <img src="https://latex.codecogs.com/png.latex?x_%7Bijk%7D"> where <img src="https://latex.codecogs.com/png.latex?i"> is the <img src="https://latex.codecogs.com/png.latex?i"> th subject, <img src="https://latex.codecogs.com/png.latex?j"> is the <img src="https://latex.codecogs.com/png.latex?j"> th measurement, and <img src="https://latex.codecogs.com/png.latex?k%20%5Cin%20%5B1,p%5D"> is the <img src="https://latex.codecogs.com/png.latex?k"> th predictor.</li>
<li>sometimes, covariate for different measurements could be the same. In this case, the notation could be written in <img src="https://latex.codecogs.com/png.latex?x_%7Bi%7D">
<ul>
<li>ex) a gender does not change over time in the most cases.</li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?i=1,%20%5Cdots,%20m"> : i is the index for the <img src="https://latex.codecogs.com/png.latex?i"> th subject</li>
<li><img src="https://latex.codecogs.com/png.latex?j=1,%20%5Cdots,%20n_i"> : j is the index for the <img src="https://latex.codecogs.com/png.latex?j"> th measurement of the <img src="https://latex.codecogs.com/png.latex?i"> th subject
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%7Bn_i%7D"> is the number of measurements of the <img src="https://latex.codecogs.com/png.latex?i"> th subject, each <img src="https://latex.codecogs.com/png.latex?%7Bn_i%7D"> does not have to the same.</li>
<li>balanced desgin: <img src="https://latex.codecogs.com/png.latex?%7Bn_i%7D"> is the same.</li>
<li>unbalanced desgin: <img src="https://latex.codecogs.com/png.latex?%7Bn_i%7D"> is different.</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20y_i"> : a vector (not a matrix), <img src="https://latex.codecogs.com/png.latex?(y_%7Bi1%7D,y_%7Bi2%7D,%5Cdots%20,y_%7Bin_i%7D)"> of the <img src="https://latex.codecogs.com/png.latex?i"> th subject</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20Y"> : the reponse matrix</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20X"> : the predictor matrix</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BE%7D(y_%7Bij%7D)"> : <img src="https://latex.codecogs.com/png.latex?%5Cmu_%7Bij%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BE%7D(%5Cmathbf%20y_i)"> : <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20%5Cmu_%7Bi%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BVar%7D(%5Cmathbf%20y_i)"> : <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BVar%7D(%5Cmathbf%20y_i)"> is a variance-covariance matrix of the different measurement for the <img src="https://latex.codecogs.com/png.latex?i"> th subject
<ul>
<li>for now, we do not care of the variance covariance of the different subjects because we assume that the measurements of different subjects are indpendent. <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%5Ctext%7BVar%7D(y_%7Bi1%7D)%20&amp;%20%5Ctext%7BCov%7D(%20y_%7Bi1%7D,%20y_%7Bi2%7D)%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BCov%7D(%20y_%7Bi1%7D,%20y_%7Bin_i%7D)%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%5Ctext%7BVar%7D(%20y_%7Bi2%7D)%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BCov%7D(%20y_%7Bi2%7D,%20y_%7Bin_i%7D)%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;&amp;%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5Cdots%20&amp;%20%5Ctext%7BVar%7D(%20y_%7Bin_i%7D)%0A%5Cend%7Bbmatrix%7D%0A"></li>
</ul></li>
</ul>
</section>
<section id="assumptions" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="assumptions"><span class="header-section-number">2</span> Assumptions</h2>
<ul>
<li>the measurements for the same subject are not independent.</li>
<li>the measurements for the different subject are independent.</li>
<li>some correlation structures of the different measurements.</li>
</ul>
</section>
<section id="for-continuous-responses" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="for-continuous-responses"><span class="header-section-number">3</span> For Continuous Responses</h2>
<ul>
<li>Marginal Models
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BE%7D(y_%7Bij%7D)%20=%20%5Cmathbf%20x_%7Bij%7D%20%5Cmathbf%20%5Cbeta"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BVar%7D(%5Cmathbf%20y_i)=%20%5Cmathbf%20V_i"></li>
<li>to build a marginal model, we just need info on the 3 things
<ul>
<li>the distribution : a multivariate normal distribution</li>
<li>mean and variance-covariance</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbeta"> is fixed. That’s why we call this marginal models ‘fixed effect’</li>
</ul></li>
</ul>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Recall
</div>
</div>
<div class="callout-body-container callout-body">
<p>We find MLE for the linear regression with the 3 things: the normal distribution (iid), <img src="https://latex.codecogs.com/png.latex?%5Cmu"> and <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2"></p>
</div>
</div>
<ul>
<li>Mixed Effects Models
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BE%7D(y_%7Bij%7D%7C%5Cmathbf%20%5Cbeta_i)%20=%20%5Cmathbf%20x_%7Bij%7D%20%5Cmathbf%20%5Cbeta_i"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20%5Cbeta_i%20=%20%5Cmathbf%20%5Cbeta%20(%5Ctext%7Bfixed%20effect%7D)%20+%20%5Cmathbf%20u_i%20(%5Ctext%7Bsubject-specific%20random%20effect%7D)"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20%5Cbeta_i"> is a random coefficient specific for the <img src="https://latex.codecogs.com/png.latex?i"> th subject, That’s why we call this mixed effect models ‘random effect’</li>
<li>subject-specific random effect: differenct subjects have different <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20%5Cbeta_i"></li>
</ul></li>
<li>Transition Models
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BE%7D(y_%7Bij%7D%7Cy_%7Bi,j-1%7D,%5Cdots,y_%7Bi,1%7D,%5Cmathbf%20x_%7Bij%7D)"></li>
<li>Markov Process: the response variable in the previous time point will affect the measurement in the current time point.</li>
</ul></li>
</ul>
<section id="marginal-models" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="marginal-models"><span class="header-section-number">3.1</span> Marginal Models</h3>
<p>Consider an example of a simple linear model (i.e., a univaiable linear model) <img src="https://latex.codecogs.com/png.latex?%0Ay_%7Bij%7D=%5Cbeta_0+%5Cbeta_1t_%7Bij%7D%20+%20%5Cepsilon_%7Bij%7D%0A"></p>
<ul>
<li>mean part: <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BE%7D(y_%7Bij%7D)"></li>
<li>variance part: <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BVar%7D(%5Cmathbf%20y_%7Bi%7D)=%5Ctext%7BVar%7D(%5Cmathbf%20%5Cepsilon_%7Bi%7D)">
<ul>
<li>more often, a correlation matrix is used in LDA because correlation is more interpretable.</li>
</ul></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BCorr%7D(%5Cmathbf%20y_i)%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%20%5Crho_%7B12%7D&amp;%20%5Cdots%20&amp;%20%5Crho_%7B1n_i%7D%20%5C%5C%0A%5Crho_%7B21%7D%20&amp;%201%20&amp;%20%5Cdots%20&amp;%20%5Crho_%7B2n_i%7D%20%5C%5C%0A%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%20%5C%5C%0A%5Crho_%7Bn_i1%7D%20&amp;%20%5Crho_%7Bn_i2%7D&amp;%20%5Cdots%20&amp;%201%0A%5Cend%7Bbmatrix%7D%0A"></p>
<ul>
<li>in this correlation matrix, there are <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bn(n-1)%7D%7B2%7D"> parameters to estimate</li>
<li>in the mean part, there are 2 parameters, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20%5Cbeta"> to estimate Likewise, the number of the estimators depends on the number of the measurements and the covriates.</li>
</ul>
<p>In LDA, since the responses are multiple, we need to look into the correlation characteristics.</p>
</section>
<section id="empirical-observations" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="empirical-observations"><span class="header-section-number">3.2</span> Empirical Observations</h3>
<p>In empirical observations about the nature of the correlation among repeated measures,</p>
<ul>
<li>correlations among the repeated measures are usually positive</li>
<li>correlations tend to decrease with increasing time separation</li>
<li>correlations among repeated measures rarely approach zero</li>
<li>correlations between any pair of repeated meausres regardless of distance in time is constrained by the reliability of the measurement process.
<ul>
<li>if the measurement process is not very reliable or consistent, then even if two measurements are taken close together in time, their correlation will not be very strong. Similarly, if the measurement process is highly reliable or consistent, then two measurements taken far apart in time may still be highly correlated. Reliability refers to the degree to which a measurement process produces consistent and accurate results over time.</li>
</ul></li>
</ul>
</section>
<section id="modeling-covariance-structure" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="modeling-covariance-structure"><span class="header-section-number">3.3</span> Modeling Covariance Structure</h3>
<p>There are 2 types of covariance structure: unbalanced design and balanced design. For now, let’s focus on the balanced design.</p>
<section id="unbalanced-design" class="level4" data-number="3.3.1">
<h4 data-number="3.3.1" class="anchored" data-anchor-id="unbalanced-design"><span class="header-section-number">3.3.1</span> Unbalanced Design</h4>
<ul>
<li>observations for each subject are not made on the same grid</li>
<li>these observations can be made at different time points and different numbers of observations may be made for each subject.</li>
<li>Missing observations falls into this category.</li>
</ul>
</section>
<section id="balanced-design" class="level4" data-number="3.3.2">
<h4 data-number="3.3.2" class="anchored" data-anchor-id="balanced-design"><span class="header-section-number">3.3.2</span> Balanced Design</h4>
<ul>
<li>observations for each subject are made on the same grid and there is no missing data.
<ul>
<li>number and timing of the repeated measurements are the same for all individuals.</li>
</ul></li>
<li>Then, <img src="https://latex.codecogs.com/png.latex?t_%7Bij%7D"> can be denoted as <img src="https://latex.codecogs.com/png.latex?t_j"> where <img src="https://latex.codecogs.com/png.latex?j%20%5Cin%201,%20%5Cdots,%20n"> because the size of the measurements is the same (<img src="https://latex.codecogs.com/png.latex?n_i"> is the same)</li>
<li>The covariance of the response variable <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20Y_%7Bm%5Ctimes%20n%7D"> :</li>
</ul>
$$
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Baligned%7D%0A%20%20%5Ctext%7BCov%7D(%5Cmathbf%20Y)%0A%20%20&amp;=%5Ctext%7BCov%7D(%5Cmathbf%20y_1,%5Cdots,y_m)%20%5C%5C%0A%20%20&amp;=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%5Ctext%7BVar%7D(%5Cmathbf%20y_1)%20&amp;%200%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%200%20&amp;%20%5Ctext%7BVar%7D(%5Cmathbf%20y_2)%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%20%5C%5C%0A%20%20%20%200%20&amp;%200%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BVar%7D(%5Cmathbf%20y_m)%0A%20%20%5Cend%7Bbmatrix%7D%5C%5C%0A%20%20&amp;=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%5Ctext%7BVar%7D(y_%7B11%7D)%20&amp;%20%5Ctext%7BCov%7D(%20y_%7B11%7D,%20y_%7B12%7D)%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BCov%7D(%20y_%7B11%7D,%20y_%7B1n_1%7D)%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%5Ctext%7BVar%7D(%20y_%7B12%7D)%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BCov%7D(%20y_%7B12%7D,%20y_%7B1n_1%7D)%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;&amp;%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5Cdots%20&amp;%20%5Ctext%7BVar%7D(%20y_%7B1n_1%7D)%0A%5Cend%7Bbmatrix%7D%20&amp;%200%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%200%20&amp;%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%5Ctext%7BVar%7D(y_%7B21%7D)%20&amp;%20%5Ctext%7BCov%7D(%20y_%7B21%7D,%20y_%7B22%7D)%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BCov%7D(%20y_%7B21%7D,%20y_%7Bin_2%7D)%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%5Ctext%7BVar%7D(%20y_%7B22%7D)%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BCov%7D(%20y_%7B22%7D,%20y_%7Bin_2%7D)%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;&amp;%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5Cdots%20&amp;%20%5Ctext%7BVar%7D(%20y_%7B2n_2%7D)%0A%5Cend%7Bbmatrix%7D%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%20%5C%5C%0A%20%20%20%200%20&amp;%200%20&amp;%20%5Cdots%20&amp;%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%5Ctext%7BVar%7D(y_%7Bm1%7D)%20&amp;%20%5Ctext%7BCov%7D(%20y_%7Bm1%7D,%20y_%7Bm2%7D)%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BCov%7D(%20y_%7Bm1%7D,%20y_%7Bmn_m%7D)%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%5Ctext%7BVar%7D(%20y_%7Bm2%7D)%20&amp;%20%5Cdots%20&amp;%20%5Ctext%7BCov%7D(%20y_%7Bm2%7D,%20y_%7Bmn_m%7D)%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;&amp;%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5Cdots%20&amp;%20%5Ctext%7BVar%7D(%20y_%7Bmn_m%7D)%0A%5Cend%7Bbmatrix%7D%0A%0A%20%20%5Cend%7Bbmatrix%7D%20%5C%5C%0A%20%20&amp;=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%5CSigma_1%20&amp;%200%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%200%20&amp;%20%5CSigma_1%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%20%5C%5C%0A%20%20%20%200%20&amp;%200%20&amp;%20%5Cdots%20&amp;%20%5CSigma_m%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Baligned%7D">
<p>$$</p>
<p>If we assume the covariance matrices for different subjects are the same, we can denote <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BCov%7D(%5Cmathbf%20Y)=%5CSigma">.</p>
</section>
</section>
<section id="covariance-structure-pattern-models" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="covariance-structure-pattern-models"><span class="header-section-number">3.4</span> Covariance Structure Pattern Models</h3>
<section id="compound-symmetry-structure" class="level4" data-number="3.4.1">
<h4 data-number="3.4.1" class="anchored" data-anchor-id="compound-symmetry-structure"><span class="header-section-number">3.4.1</span> Compound symmetry Structure</h4>
<p><img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Ctext%7BCov%7D(%5Cmathbf%20y_i)=%0A%20%20%5Csigma%5E2%20%20%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%20%5Crho%20&amp;%20%5Crho%20&amp;%20%5Cdots%20&amp;%20%5Crho%20%5C%5C%0A%20%20%20%20%5Crho%20&amp;%201%20&amp;%20%5Crho%20&amp;%20%5Cdots%20&amp;%20%5Crho%20%5C%5C%0A%20%20%20%20%5Crho%20&amp;%20%5Crho%20&amp;%201%20&amp;%20%5Cdots%20&amp;%20%5Crho%20%5C%5C%0A%20%20%20%20%5Cvdots%20&amp;%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%20%5C%5C%0A%20%20%20%20%5Crho%20&amp;%20%5Crho%20&amp;%20%5Crho%20&amp;%20%5Cdots%20&amp;%201%0A%20%20%5Cend%7Bbmatrix%7D%0A"></p>
<ul>
<li>compound symmetry is a.k.a <strong>Exchangeable</strong></li>
<li>Assume variance is constant across visits (say <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">)</li>
<li>Assume correlation between any two visits are constant (say <img src="https://latex.codecogs.com/png.latex?%5Crho">).</li>
<li>Parsimonious: there are two parameters in the covariance, <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2"> and <img src="https://latex.codecogs.com/png.latex?%5Crho"> (computational benefit)</li>
<li>Without any contraint on <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">, you will get closed form estimate.</li>
<li>Covariance variance matrix is plugged into likelihood function to estimate 3 kinds of parameters <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">, <img src="https://latex.codecogs.com/png.latex?%5Crho">, and <img src="https://latex.codecogs.com/png.latex?%5Cbeta"></li>
<li>This structure is so parsimonuous that it could be unrealistic: not commonly used</li>
</ul>
</section>
<section id="toeplitz-structure" class="level4" data-number="3.4.2">
<h4 data-number="3.4.2" class="anchored" data-anchor-id="toeplitz-structure"><span class="header-section-number">3.4.2</span> Toeplitz Structure</h4>
<p><img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Ctext%7BCov%7D(%5Cmathbf%20y_i)=%0A%20%20%5Csigma%5E2%20%20%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%20%5Crho_1%20&amp;%20%5Crho_2%20&amp;%20%5Cdots%20&amp;%20%5Crho_%7Bn-1%7D%20%5C%5C%0A%20%20%20%20%5Crho_1%20&amp;%201%20&amp;%20%5Crho_1%20&amp;%20%5Cdots%20&amp;%20%5Crho_%7Bn-2%7D%20%5C%5C%0A%20%20%20%20%5Crho_2%20&amp;%20%5Crho_1%20&amp;%201%20&amp;%20%5Cdots%20&amp;%20%5Crho_%7Bn-3%7D%20%5C%5C%0A%20%20%20%20%5Cvdots%20&amp;%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%20%5C%5C%0A%20%20%20%20%5Crho_%7Bn-1%7D%20&amp;%20%5Crho_%7Bn-2%7D%20&amp;%20%5Crho_%7Bn-3%7D%20&amp;%20%5Cdots%20&amp;%201%0A%20%20%5Cend%7Bbmatrix%7D%0A"></p>
<ul>
<li>Toeplitz structure is more flexible than compound symmetry</li>
<li>Assume variance is constant across visits and <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BCorr%7D(y_%7Bij%7D,%20y_%7Bi,j+k%7D)%20=%20%5Crho_k">.</li>
<li>Assume correlation among responses at adjacent measurements is constant.</li>
<li>Only suitable for measurements made at equal intervals of time between different measurement.</li>
<li>Without any contraint on <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2">, you will get closed form estimate.</li>
<li>Toeplitz covariance has free <img src="https://latex.codecogs.com/png.latex?n"> parameters to estimate (<img src="https://latex.codecogs.com/png.latex?1"> for variance and <img src="https://latex.codecogs.com/png.latex?n-1"> correlation parameters)</li>
<li>The larger time differences, the smaller its correlations</li>
</ul>
</section>
<section id="autoregressive-structure" class="level4" data-number="3.4.3">
<h4 data-number="3.4.3" class="anchored" data-anchor-id="autoregressive-structure"><span class="header-section-number">3.4.3</span> Autoregressive Structure</h4>
<p><img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Ctext%7BCov%7D(%5Cmathbf%20y_i)=%0A%20%20%5Csigma%5E2%20%20%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%20%5Crho%5E1%20&amp;%20%5Crho%5E2%20&amp;%20%5Cdots%20&amp;%20%5Crho%5E%7Bn-1%7D%20%5C%5C%0A%20%20%20%20%5Crho%5E1%20&amp;%201%20&amp;%20%5Crho%5E1%20&amp;%20%5Cdots%20&amp;%20%5Crho%5E%7Bn-2%7D%20%5C%5C%0A%20%20%20%20%5Crho%5E2%20&amp;%20%5Crho%5E1%20&amp;%201%20&amp;%20%5Cdots%20&amp;%20%5Crho%5E%7Bn-3%7D%20%5C%5C%0A%20%20%20%20%5Cvdots%20&amp;%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%20%5C%5C%0A%20%20%20%20%5Crho%5E%7Bn-1%7D%20&amp;%20%5Crho%5E%7Bn-2%7D%20&amp;%20%5Crho%5E%7Bn-3%7D%20&amp;%20%5Cdots%20&amp;%201%0A%20%20%5Cend%7Bbmatrix%7D%0A"></p>
<ul>
<li>A special case of toeplitz structure with <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BCorr%7D(y_%7Bij%7D,y_%7Bi,j+k%7D)=%5Crho%5Ek"></li>
<li>simpler than toeplitz, only 2 parameters</li>
<li>Only suitable for measurements made at equal intervals of time between different measurement.</li>
</ul>
</section>
<section id="banded-structure" class="level4" data-number="3.4.4">
<h4 data-number="3.4.4" class="anchored" data-anchor-id="banded-structure"><span class="header-section-number">3.4.4</span> Banded Structure</h4>
<p><img src="https://latex.codecogs.com/png.latex?%0A%20%20%5Ctext%7BCov%7D(%5Cmathbf%20y_i)=%0A%20%20%5Csigma%5E2%20%20%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%20%5Crho%5E1%20&amp;%200%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%20%5Crho%5E1%20&amp;%201%20&amp;%20%5Crho%5E1%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%200%20&amp;%20%5Crho%5E1%20&amp;%201%20&amp;%20%5Cdots%20&amp;%200%20%5C%5C%0A%20%20%20%20%5Cvdots%20&amp;%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%20%5C%5C%0A%20%20%20%200%20&amp;%200%20&amp;%200%20&amp;%20%5Cdots%20&amp;%201%0A%20%20%5Cend%7Bbmatrix%7D%0A"></p>
<p>Look at the more general case of the banded structure in <a href="https://en.wikipedia.org/wiki/Band_matrix">Wiki</a>.</p>
<ul>
<li>Assume correlation is 0 beyond some specified interval.</li>
<li>Can be combined with the previous patterns.</li>
<li>Very strong assumption about how quickly the correlation decays to 0 with increasing time separation.</li>
</ul>
</section>
<section id="exponential-structure" class="level4" data-number="3.4.5">
<h4 data-number="3.4.5" class="anchored" data-anchor-id="exponential-structure"><span class="header-section-number">3.4.5</span> Exponential Structure</h4>
<ul>
<li>A generalization of autoregressive pattern</li>
<li>The most general and reasonable structure</li>
<li>Suitable for unevenly spaced measurements, take actual time points (time difference), the larger time difference the smaller correlation</li>
<li>Assumption that the variance of different measurements over time is the same, which can be easily generalized. You can put different variance on the diagonal.</li>
<li>Let <img src="https://latex.codecogs.com/png.latex?%5C%7Bt_%7Bi1%7D,%5Cdots,t_%7Bin_i%7D%5C%7D"> denote the observation times for the <img src="https://latex.codecogs.com/png.latex?i"> th individual. Then, the correlation is <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BCorr%7D(Y_%7Bij%7D%20,Y_%7Bik%7D)%20=%20%5Crho%5E%7B%7Ct_%7Bij%7D-t_%7Bik%7D%7C%7D"></li>
<li>Correlation decreases exponentially with the time separations between them.</li>
</ul>
</section>
</section>
</section>
</div>
</div>
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">

</div>
</div>
<section id="go-to-blog-content-list" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="go-to-blog-content-list"><span class="header-section-number">4</span> Go to Blog Content List</h2>
<p><a href="../../../../../docs/blog/posts/content_list.html">Blog Content List</a></p>


</section>

</div></ul> ]]></description>
  <category>Statistics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/statistics/LDA/2_covariance_model.html</guid>
  <pubDate>Thu, 23 Mar 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Minimizer &amp; Maximizer</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/minimizer.html</link>
  <description><![CDATA[ 



<ul class="nav nav-pills" id="language-tab">
<li class="nav-item">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<p>A minimizer or a maximizer refer to a point in the domain of a function where the function achieves its minimum or maximum value. More formally, let <img src="https://latex.codecogs.com/png.latex?f:%20X%20%E2%86%92%20%5Cmathbb%20R"> be a real-valued function defined on a set <img src="https://latex.codecogs.com/png.latex?X%20%5Csubset%20%5Cmathbb%20R">.</p>
<div id="def-minimum" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 </strong></span><img src="https://latex.codecogs.com/png.latex?f(x%5E*)"> with a point <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X"> is called a <strong>minimum</strong> if <img src="https://latex.codecogs.com/png.latex?f(x%5E*)%20%5Cle%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20X">. <img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_%7Bx%5Cin%20X%7D%7Bf(x)%7D%0A"> , which means a minimum, <img src="https://latex.codecogs.com/png.latex?f(x)">.</p>
</div>
<div id="def-maximum" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2 </strong></span><img src="https://latex.codecogs.com/png.latex?f(x%5E*)"> with a point <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X"> is called a <strong>maximum</strong> if <img src="https://latex.codecogs.com/png.latex?f(x%5E*)%20%5Cge%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20X">. <img src="https://latex.codecogs.com/png.latex?%0A%5Cmax_%7Bx%5Cin%20X%7D%7Bf(x)%7D%0A"> , which means a maximum, <img src="https://latex.codecogs.com/png.latex?f(x)">.</p>
</div>
<div id="def-minimizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3 </strong></span>A point <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X"> is called a <strong>minimizer</strong> of <img src="https://latex.codecogs.com/png.latex?f"> if <img src="https://latex.codecogs.com/png.latex?f(x%5E*)%20%5Cle%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20X">. <img src="https://latex.codecogs.com/png.latex?%0A%5Carg%5Cmin_%7Bx%5Cin%20X%7D%7Bf(x)%7D%0A"> , which means <img src="https://latex.codecogs.com/png.latex?x"> that mainimizes <img src="https://latex.codecogs.com/png.latex?f(x)">.</p>
</div>
<div id="def-maximizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4 </strong></span>A point <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X"> is called a <strong>maximizer</strong> of <img src="https://latex.codecogs.com/png.latex?f"> if <img src="https://latex.codecogs.com/png.latex?f(x%5E*)%20%5Cge%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20X">. <img src="https://latex.codecogs.com/png.latex?%0A%5Carg%5Cmax_%7Bx%5Cin%20X%7D%7Bf(x)%7D%0A"> , which means <img src="https://latex.codecogs.com/png.latex?x"> that maximizes <img src="https://latex.codecogs.com/png.latex?f(x)">.</p>
</div>
<div id="def-global_minimizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 5 </strong></span>A point <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X"> is called a <strong>global mainimizer</strong> of <img src="https://latex.codecogs.com/png.latex?f"> if <img src="https://latex.codecogs.com/png.latex?f(x%5E*)%20%5Cge%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20%5Cmathbb%20R">. <img src="https://latex.codecogs.com/png.latex?%0A%5Carg%5Cmin_%7Bx%5Cin%20%5Cmathbb%20R%7D%7Bf(x)%7D%0A"> , which means <img src="https://latex.codecogs.com/png.latex?x"> that minimizes <img src="https://latex.codecogs.com/png.latex?f(x)">.</p>
</div>
<div id="def-global_maximizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6 </strong></span>A point <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X"> is called a <strong>global maximizer</strong> of <img src="https://latex.codecogs.com/png.latex?f"> if <img src="https://latex.codecogs.com/png.latex?f(x%5E*)%20%5Cge%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20%5Cmathbb%20R">. <img src="https://latex.codecogs.com/png.latex?%0A%5Carg%5Cmax_%7Bx%5Cin%20%5Cmathbb%20R%7D%7Bf(x)%7D%0A"> , which means <img src="https://latex.codecogs.com/png.latex?x"> that maximizes <img src="https://latex.codecogs.com/png.latex?f(x)">.</p>
</div>
<div id="def-strict_global_maximizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 7 </strong></span>A point <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X"> is called a <strong>strict global maximizer</strong> of <img src="https://latex.codecogs.com/png.latex?f"><br>
if <img src="https://latex.codecogs.com/png.latex?f(x%5E*)%20%3E%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20%5Cmathbb%20R">.</p>
</div>
<div id="def-strict_global_miniimizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 8 </strong></span>A point <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X"> is called a <strong>strict global miniimizer</strong> of <img src="https://latex.codecogs.com/png.latex?f"><br>
if <img src="https://latex.codecogs.com/png.latex?f(x%5E*)%20%3C%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20%5Cmathbb%20R">.</p>
</div>
<div id="def-local_minimizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9 </strong></span>A local minimizer of <img src="https://latex.codecogs.com/png.latex?f"> is a point <img src="https://latex.codecogs.com/png.latex?x*%20%5Cin%20X"> such that there exists a radius, <img src="https://latex.codecogs.com/png.latex?%5Cdelta%3E0"> of a neighborhood of <img src="https://latex.codecogs.com/png.latex?x%5E*"> such that <img src="https://latex.codecogs.com/png.latex?f(x*)%20%5Cle%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20(x%5E*-%5Cdelta,x%5E*+%5Cdelta)"> or <img src="https://latex.codecogs.com/png.latex?%7Cx-x%5E*%7C%3C%5Cdelta"> . A local minimizer is at least best possible solution among nearby points.</p>
</div>
<div id="def-local_maximizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 10 </strong></span>A local maximizer of <img src="https://latex.codecogs.com/png.latex?f"> is a point <img src="https://latex.codecogs.com/png.latex?x*%20%5Cin%20X"> such that there exists a radius, <img src="https://latex.codecogs.com/png.latex?%5Cdelta%3E0"> of a neighborhood of <img src="https://latex.codecogs.com/png.latex?x%5E*"> such that <img src="https://latex.codecogs.com/png.latex?f(x*)%20%5Cge%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20(x%5E*-%5Cdelta,x%5E*+%5Cdelta)"> or <img src="https://latex.codecogs.com/png.latex?%7Cx-x%5E*%7C%3C%5Cdelta"> . A local maximizer is at least best possible solution among nearby points.</p>
</div>
<div id="def-strict_local_minimizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 11 </strong></span>A strict local minimizer of <img src="https://latex.codecogs.com/png.latex?f"> is a point <img src="https://latex.codecogs.com/png.latex?x*%20%5Cin%20X"> such that there exists a radius, <img src="https://latex.codecogs.com/png.latex?%5Cdelta%3E0"> of a neighborhood of <img src="https://latex.codecogs.com/png.latex?x%5E*"> such that <img src="https://latex.codecogs.com/png.latex?f(x*)%20%3C%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20(x%5E*-%5Cdelta,x%5E*+%5Cdelta)"> or <img src="https://latex.codecogs.com/png.latex?%7Cx-x%5E*%7C%3C%5Cdelta"> . A local minimizer is at least best possible solution among nearby points.</p>
</div>
<div id="def-strict_local_maximizer" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 12 </strong></span>A strict local maximizer of <img src="https://latex.codecogs.com/png.latex?f"> is a point <img src="https://latex.codecogs.com/png.latex?x*%20%5Cin%20X"> such that there exists a radius, <img src="https://latex.codecogs.com/png.latex?%5Cdelta%3E0"> of a neighborhood of <img src="https://latex.codecogs.com/png.latex?x%5E*"> such that <img src="https://latex.codecogs.com/png.latex?f(x*)%20%3E%20f(x)"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20(x%5E*-%5Cdelta,x%5E*+%5Cdelta)"> or <img src="https://latex.codecogs.com/png.latex?%7Cx-x%5E*%7C%3C%5Cdelta"> . A local maximizer is at least best possible solution among nearby points.</p>
</div>
<div id="def-critical_point" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13 </strong></span>It is said to be a critical point if <img src="https://latex.codecogs.com/png.latex?f'(x)"> exists and <img src="https://latex.codecogs.com/png.latex?f'(x%5E*)=0"> for <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X">.</p>
</div>
<p>Note that a function may have multiple minimizers, and some functions may not have a minimizer at all. In addition, if a function has multiple minimizers, they may be either global or local minimizers.</p>
<p><strong>Example</strong></p>
<ul>
<li>If <img src="https://latex.codecogs.com/png.latex?f(x)=2(x-3)%5E2+8">, then<br>
the vertex is <img src="https://latex.codecogs.com/png.latex?(2,8)">, the global minimizer is <img src="https://latex.codecogs.com/png.latex?2">, the global minimum is <img src="https://latex.codecogs.com/png.latex?8">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f(x)=x%5E3-3x%5E2+4">, then<br>
<img src="https://latex.codecogs.com/png.latex?f'(x)=3x%5E2-6x=3x(x-2)"> and the critical points are <img src="https://latex.codecogs.com/png.latex?(0,4),%20(2,0)">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f(x)=7x%5E5-35x+4">, then<br>
<img src="https://latex.codecogs.com/png.latex?f'(x)=35x%5E4-35=35(x%5E2+1)(x-1)(x+1)"> critical points are <img src="https://latex.codecogs.com/png.latex?(-1,0),%20(1,32)">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f(x)=%5Cfrac%7B2x%7D%7Bx%5E2+1%7D">, then<br>
<img src="https://latex.codecogs.com/png.latex?f'(x)=%5Cfrac%7B2(1-x)(1+x)%7D%7B(1+x%5E2)%5E2%7D"> the critical points are <img src="https://latex.codecogs.com/png.latex?(-1,-1),%20(1,1)">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f(x)=4x%5E5-%5Cfrac%7B20%7D%7B3%7Dx%5E3+4">, then<br>
<img src="https://latex.codecogs.com/png.latex?f'(x)=20x%5E4-20x%5E2=20(x%5E2)(x-1)(x+1)"> critical points are <img src="https://latex.codecogs.com/png.latex?(-1,%5Cfrac%7B20%7D%7B3%7D),%20(1,%5Cfrac%7B4%7D%7B3%7D)">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f(x)=%5Cfrac%7B(x%5E2-1)%7D%7B(x-2)%7D">, then<br>
<img src="https://latex.codecogs.com/png.latex?f'(x)=%5Cfrac%7B(x%5E2-4x+1)%7D%7B(x-2)%5E2%7D">, critical points are <img src="https://latex.codecogs.com/png.latex?(-1,%5Cfrac%7B20%7D%7B3%7D),%20(1,%5Cfrac%7B4%7D%7B3%7D)">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f(x)=%5Cmathrm%7Be%7D%5E%7B%5Csin%5Cleft(x%5E2+1%5Cright)%7D">, then<br>
<img src="https://latex.codecogs.com/png.latex?f'(x)=2x%5Cmathrm%7Be%7D%5E%7B%5Csin%5Cleft(x%5E2+1%5Cright)%7D%5Ccos%5Cleft(x%5E2+1%5Cright)"> , <img src="https://latex.codecogs.com/png.latex?f''(x)=-2%5Cmathrm%7Be%7D%5E%7B%5Csin%5Cleft(x%5E2+1%5Cright)%7D%5Ccdot%5Cleft(2x%5E2%5Csin%5Cleft(x%5E2+1%5Cright)-2x%5E2%5Ccos%5E2%5Cleft(x%5E2+1%5Cright)-%5Ccos%5Cleft(x%5E2+1%5Cright)%5Cright)">, critical points are <img src="https://latex.codecogs.com/png.latex?(0,e%5E%7B%5Csin(1)%7D),%20(%5Cpm%5Csqrt%7B(2n-1)%5Cfrac%7B%5Cpi%7D%7B2%7D-1%7D%20)"> where <img src="https://latex.codecogs.com/png.latex?n=1,2,%5Cdots">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f(x)=3x%5E4-4x%5E3+1">, then<br>
<img src="https://latex.codecogs.com/png.latex?f'(x)=12x%5E3-12x%5E2=12x%5E2(x-1)"> , <img src="https://latex.codecogs.com/png.latex?f''(x)=36x%5E2-24x=12x(3x-2)">, critical points are <img src="https://latex.codecogs.com/png.latex?(0,1),%20(1,0)">.</li>
</ul>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="kw" style="color: #003B4F;">def</span> f(x):</span>
<span id="cb1-5">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">*</span>(x<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">3</span>)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">8</span></span>
<span id="cb1-6"><span class="kw" style="color: #003B4F;">def</span> f2(x):</span>
<span id="cb1-7">    <span class="cf" style="color: #003B4F;">return</span> x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb1-8"><span class="kw" style="color: #003B4F;">def</span> f3(x):</span>
<span id="cb1-9">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">7</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">5</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">35</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb1-10"><span class="kw" style="color: #003B4F;">def</span> f4(x):</span>
<span id="cb1-11">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">/</span>(x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb1-12"><span class="kw" style="color: #003B4F;">def</span> f5(x):</span>
<span id="cb1-13">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">4</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">5</span><span class="op" style="color: #5E5E5E;">-</span>(<span class="dv" style="color: #AD0000;">20</span><span class="op" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">3</span>)<span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb1-14"><span class="kw" style="color: #003B4F;">def</span> f6(x):</span>
<span id="cb1-15">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">4</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">4</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb1-16"></span>
<span id="cb1-17"><span class="kw" style="color: #003B4F;">def</span> df(x):</span>
<span id="cb1-18">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">4</span><span class="op" style="color: #5E5E5E;">*</span>(x<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">3</span>)</span>
<span id="cb1-19"><span class="kw" style="color: #003B4F;">def</span> df2(x):</span>
<span id="cb1-20">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">6</span><span class="op" style="color: #5E5E5E;">*</span>x</span>
<span id="cb1-21"><span class="kw" style="color: #003B4F;">def</span> df3(x):</span>
<span id="cb1-22">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">35</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">4</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">35</span></span>
<span id="cb1-23"><span class="kw" style="color: #003B4F;">def</span> df4(x):</span>
<span id="cb1-24">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">*</span>(<span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">-</span>x)<span class="op" style="color: #5E5E5E;">*</span>(<span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">+</span>x)<span class="op" style="color: #5E5E5E;">/</span>(<span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">+</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span></span>
<span id="cb1-25"><span class="kw" style="color: #003B4F;">def</span> df5(x):</span>
<span id="cb1-26">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">20</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">4</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">20</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span></span>
<span id="cb1-27"><span class="kw" style="color: #003B4F;">def</span> df6(x):</span>
<span id="cb1-28">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">12</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">*</span>(x<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb1-29"></span>
<span id="cb1-30"><span class="kw" style="color: #003B4F;">def</span> ddf(n):</span>
<span id="cb1-31">    <span class="cf" style="color: #003B4F;">return</span> np.repeat(<span class="dv" style="color: #AD0000;">4</span>,n)</span>
<span id="cb1-32"><span class="kw" style="color: #003B4F;">def</span> ddf2(x):</span>
<span id="cb1-33">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">6</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">6</span></span>
<span id="cb1-34"><span class="kw" style="color: #003B4F;">def</span> ddf3(x):</span>
<span id="cb1-35">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">140</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb1-36"><span class="kw" style="color: #003B4F;">def</span> ddf4(x):</span>
<span id="cb1-37">    <span class="cf" style="color: #003B4F;">return</span> (<span class="dv" style="color: #AD0000;">4</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">*</span>(x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">3</span>))<span class="op" style="color: #5E5E5E;">/</span>(x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb1-38"><span class="kw" style="color: #003B4F;">def</span> ddf5(x):</span>
<span id="cb1-39">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">80</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">40</span><span class="op" style="color: #5E5E5E;">*</span>x</span>
<span id="cb1-40"><span class="kw" style="color: #003B4F;">def</span> ddf6(x):</span>
<span id="cb1-41">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">12</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">*</span>(<span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>)</span></code></pre></div>
</details>
</div>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># Create a range of x values</span></span>
<span id="cb2-2">x <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">8</span>, <span class="dv" style="color: #AD0000;">1000</span>)</span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;"># Plot the function</span></span>
<span id="cb2-5">plt.plot(x, f(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$f(x)=2(x-3)^2+8$'</span>)</span>
<span id="cb2-6">plt.plot(x, df(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$df(x)=4(x-3)$'</span>)</span>
<span id="cb2-7">plt.plot(x, ddf(<span class="bu" style="color: null;">len</span>(x)), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$d^2f(x)=4$'</span>)</span>
<span id="cb2-8">plt.axhline(y<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb2-9">plt.axvline(x<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb2-10"></span>
<span id="cb2-11">plt.legend()</span>
<span id="cb2-12">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/minimizer_files/figure-html/cell-3-output-1.png" width="577" height="411"></p>
</div>
</div>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">x <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">4</span>, <span class="dv" style="color: #AD0000;">1000</span>)</span>
<span id="cb3-2"></span>
<span id="cb3-3">plt.plot(x, f2(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$f(x)=x^3-3x^2+4$'</span>)</span>
<span id="cb3-4">plt.plot(x, df2(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$df(x)=3x^2-6x=3x(x-2)$'</span>)</span>
<span id="cb3-5">plt.plot(x, ddf2(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$d^2f(x)=6x-6=6(x-1)$'</span>)</span>
<span id="cb3-6">plt.axhline(y<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb3-7">plt.axvline(x<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb3-8"></span>
<span id="cb3-9">plt.legend()</span>
<span id="cb3-10">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/minimizer_files/figure-html/cell-4-output-1.png" width="577" height="411"></p>
</div>
</div>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># Create a range of x values</span></span>
<span id="cb4-2">x <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">1.2</span>, <span class="fl" style="color: #AD0000;">1.2</span>, <span class="dv" style="color: #AD0000;">1000</span>)</span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;"># Plot the function</span></span>
<span id="cb4-5">plt.plot(x, f3(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$f(x)=7x^5-35x+4$'</span>)</span>
<span id="cb4-6">plt.plot(x, df3(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$df(x)=35x^4-35=35(x^2+1)(x-1)(x+1)$'</span>)</span>
<span id="cb4-7">plt.plot(x, ddf3(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$d^2f(x)=120x^3$'</span>)</span>
<span id="cb4-8">plt.axhline(y<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb4-9">plt.axvline(x<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb4-10"></span>
<span id="cb4-11">plt.legend()</span>
<span id="cb4-12">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/minimizer_files/figure-html/cell-5-output-1.png" width="586" height="411"></p>
</div>
</div>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">x <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">4</span>, <span class="dv" style="color: #AD0000;">1000</span>)</span>
<span id="cb5-2"></span>
<span id="cb5-3">plt.plot(x, f4(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$\frac</span><span class="sc" style="color: #5E5E5E;">{2x}</span><span class="vs" style="color: #20794D;">{x^2+1}$'</span>)</span>
<span id="cb5-4">plt.plot(x, df4(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$df(x)=\frac{2(1-x)(1+x)}{(1+x^2)^2}$'</span>)</span>
<span id="cb5-5">plt.plot(x, ddf4(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$d^2f(x)=\frac{4x(x^2-3)}{(1+x^2)^3}$'</span>)</span>
<span id="cb5-6">plt.axhline(y<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb5-7">plt.axvline(x<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb5-8"></span>
<span id="cb5-9">plt.legend()</span>
<span id="cb5-10">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/minimizer_files/figure-html/cell-6-output-1.png" width="569" height="411"></p>
</div>
</div>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">x <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">1000</span>)</span>
<span id="cb6-2"></span>
<span id="cb6-3"><span class="co" style="color: #5E5E5E;"># Plot the function</span></span>
<span id="cb6-4">plt.plot(x, f5(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$f(x)=4x^5-\frac</span><span class="sc" style="color: #5E5E5E;">{20}{3}</span><span class="vs" style="color: #20794D;">x^3+4$'</span>)</span>
<span id="cb6-5">plt.plot(x, df5(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$df(x)=20x^4-20x^2=20(x^2)(x-1)(x+1)$'</span>)</span>
<span id="cb6-6">plt.plot(x, ddf5(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$d^2f(x)=80x^3-40x=40x(x-1)(x+1)$'</span>)</span>
<span id="cb6-7"></span>
<span id="cb6-8">plt.axhline(y<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb6-9">plt.axvline(x<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb6-10">plt.axis([<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">20</span>, <span class="dv" style="color: #AD0000;">20</span>])</span>
<span id="cb6-11">plt.legend()</span>
<span id="cb6-12">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/minimizer_files/figure-html/cell-7-output-1.png" width="588" height="416"></p>
</div>
</div>
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/critical_points.PNG" class="img-fluid" alt="https://www.derivative-calculator.net/"><br>
I felt too annoyed to type this latex and make the function…</p>
<div id="thm-theorem" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 </strong></span>For <img src="https://latex.codecogs.com/png.latex?f:X%20%5Crightarrow%20%5Cmathbb%20R">, let <img src="https://latex.codecogs.com/png.latex?f(x)">, <img src="https://latex.codecogs.com/png.latex?f'(x)">, and <img src="https://latex.codecogs.com/png.latex?f''(x)"> be all continuous. For <img src="https://latex.codecogs.com/png.latex?x%5E*%20%5Cin%20X">, <img src="https://latex.codecogs.com/png.latex?f'(x%5E*)=0"></p>
<ol type="1">
<li>If <img src="https://latex.codecogs.com/png.latex?f''(x)%5Cge%200"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20X">, <img src="https://latex.codecogs.com/png.latex?x%5E*"> is a global minimizer</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f''(x)%3E%200"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20X">, <img src="https://latex.codecogs.com/png.latex?x%5E*"> is a strict global minimizer</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f''(x%5E*)%3E%200">, <img src="https://latex.codecogs.com/png.latex?x%5E*"> is a strict local minimizer</li>
</ol>
</div>
<p>the reverse of the stament 1 in Theorem&nbsp;1 is not true.</p>
<p><strong>Counter Example</strong></p>
<p>If <img src="https://latex.codecogs.com/png.latex?f(x)=3x%5E4-4x%5E3+1">, then<br>
<img src="https://latex.codecogs.com/png.latex?f'(x)=12x%5E3-12x%5E2=12x%5E2(x-1)"> , <img src="https://latex.codecogs.com/png.latex?f''(x)=36x%5E2-24x=12x(3x-2)">, critical points are <img src="https://latex.codecogs.com/png.latex?(0,1),%20(1,0)">.</p>
<p><img src="https://latex.codecogs.com/png.latex?x%5E*=1"> is a global minimizer. For <img src="https://latex.codecogs.com/png.latex?x%5Cin%20%5Cmathbb%20R">, <img src="https://latex.codecogs.com/png.latex?f''(x)%5Cge%200"> is not true.</p>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">x <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="fl" style="color: #AD0000;">1.5</span>, <span class="dv" style="color: #AD0000;">1000</span>)</span>
<span id="cb7-2"></span>
<span id="cb7-3"><span class="co" style="color: #5E5E5E;"># Plot the function</span></span>
<span id="cb7-4">plt.plot(x, f6(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$f(x)=3x^4-4x^3+1$'</span>)</span>
<span id="cb7-5">plt.plot(x, df6(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$df(x)=12x^3-12x^2=12x^2(x-1)$'</span>)</span>
<span id="cb7-6">plt.plot(x, ddf6(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$d^2f(x)=36x^2-24x=12x(3x-2)$'</span>)</span>
<span id="cb7-7"></span>
<span id="cb7-8">plt.axhline(y<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb7-9">plt.axvline(x<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb7-10">plt.axis([<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="fl" style="color: #AD0000;">1.5</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">5</span>])</span>
<span id="cb7-11"></span>
<span id="cb7-12">plt.legend()</span>
<span id="cb7-13">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/minimizer_files/figure-html/cell-8-output-1.png" width="580" height="411"></p>
</div>
</div>
</div>
</div>
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">

</div>
</div>
<section id="go-to-blog-content-list" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Go to Blog Content List</h1>
<p><a href="./docs/blog/posts/content_list.qmd">Blog Content List</a></p>


</section>

</div></ul> ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/minimizer.html</guid>
  <pubDate>Wed, 22 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/docs/blog/posts/Mathmatics/optimization/critical_points.PNG" medium="image"/>
</item>
<item>
  <title>Variable Types</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/variables/index.html</link>
  <description><![CDATA[ 



<ul class="nav nav-pills" id="language-tab">
<li class="nav-item">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<section id="variable-types" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Variable Types</h1>
<p>Variable types can be classified with various perspectives depending on research purpose:</p>
<ul>
<li>From the perspective of a data type, variable types are largely divided into two categories:
<ul>
<li>quantitative variable: a variable containing quantitative data that represents quantity</li>
<li>categorical variable: a variable containing qualitative data that represents groups</li>
</ul></li>
<li>From the standpoint of modeling or experiment designs, variable types are largely divided into 3 categories:
<ul>
<li>independent variable: a variable (cause) that might have an effect on a dependent variabe (result).</li>
<li>dependent variable: a variable (result) that might be influenced by independent variables (cause).</li>
<li>control variable: a variable that is fixed to look into a relation between an independent variable in your interest and dependent variable.</li>
</ul></li>
<li>From the point of mathmatical view, variable types are categorized largely into 4 categories:
<ul>
<li>univariable: each subject gives rise to a single measurement of independent variable termed exploratory variable.</li>
<li>univariate: each subject gives rise to a single measurement of dependent variables termed response.</li>
<li>multivariate: each subject gives rise to a vector of measurements of independent variables termed exploratory variables.</li>
<li>multivariable: each subject gives rise to a vector of measurements of dependent variables termed responses.</li>
</ul></li>
</ul>
<section id="from-the-point-of-data-type" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="from-the-point-of-data-type"><span class="header-section-number">1.1</span> From the Point of Data Type</h2>
<section id="quantitative-variable" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="quantitative-variable"><span class="header-section-number">1.1.1</span> Quantitative Variable</h3>
<p>the values of the quantitative variables with which you can conduct arithematic operations. There are two types of quantitative variables: discrete and continuous.</p>
<section id="discrete-variables" class="level4" data-number="1.1.1.1">
<h4 data-number="1.1.1.1" class="anchored" data-anchor-id="discrete-variables"><span class="header-section-number">1.1.1.1</span> Discrete Variables</h4>
<ul>
<li>As integer, count valuess of individual items.</li>
<li>ex: number of people, number of different events, etc.</li>
</ul>
</section>
<section id="continuous-variables" class="level4" data-number="1.1.1.2">
<h4 data-number="1.1.1.2" class="anchored" data-anchor-id="continuous-variables"><span class="header-section-number">1.1.1.2</span> Continuous Variables</h4>
<ul>
<li>As real number, measurement values of continuous or uncountable values.</li>
<li>ex: height, weight, distance, volume, age, etc.</li>
</ul>
</section>
</section>
<section id="categorical-variables" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="categorical-variables"><span class="header-section-number">1.1.2</span> Categorical Variables</h3>
<p>Categorical variables contain grouping values representing categories rather than quantity. There are three types of categorical variables: binary, nominal, and ordinal variables.</p>
<section id="binary-variables" class="level4" data-number="1.1.2.1">
<h4 data-number="1.1.2.1" class="anchored" data-anchor-id="binary-variables"><span class="header-section-number">1.1.2.1</span> Binary Variables</h4>
<ul>
<li>Binary variables a.k.a dichotomous variables contain two types of values, true or false, 1 or 0<br>
</li>
<li>ex: disease/non-disease, heads/tails in flipping a coin, win/lose in a game</li>
</ul>
</section>
<section id="nominal-variables" class="level4" data-number="1.1.2.2">
<h4 data-number="1.1.2.2" class="anchored" data-anchor-id="nominal-variables"><span class="header-section-number">1.1.2.2</span> Nominal Variables</h4>
<ul>
<li>catogories with no rank or order among them.</li>
<li>ex: gender, races, colors, brands, company names</li>
</ul>
</section>
<section id="ordinal-variables" class="level4" data-number="1.1.2.3">
<h4 data-number="1.1.2.3" class="anchored" data-anchor-id="ordinal-variables"><span class="header-section-number">1.1.2.3</span> Ordinal Variables</h4>
<ul>
<li>catogories ranked in a specific order</li>
<li>ex: ranks in a game, places in a line, rating scale responses in a movie review</li>
</ul>
</section>
</section>
</section>
<section id="from-the-perspective-of-modeling" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="from-the-perspective-of-modeling"><span class="header-section-number">1.2</span> From the Perspective of Modeling</h2>
<p>Experiments or models are usually designed or built to discover what effect one variable has on another.</p>
<section id="independent-variables" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="independent-variables"><span class="header-section-number">1.2.1</span> Independent Variables</h3>
<ul>
<li>Independent variable is a variable you can set to observe an effect on the outcome of an experiment.<br>
</li>
<li>By many people, independent Variables are also commonly called predictors, explanatory variables, treatment variables, features, etc.</li>
</ul>
</section>
<section id="dependent-variables" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="dependent-variables"><span class="header-section-number">1.2.2</span> Dependent variables</h3>
<ul>
<li>Dependent variable is a variable that represents the outcome of the experiment.</li>
<li>By many people, dependent variables are also commonly called outcome variables, response variables, targets, etc.</li>
</ul>
</section>
<section id="control-variables" class="level3" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="control-variables"><span class="header-section-number">1.2.3</span> Control variables</h3>
<ul>
<li>Control variable is a variable that is held fixed throughout the experiment.</li>
<li>Positive control: a variable that is set for showing effect on the dependent variable.</li>
<li>Negative control: a variable that is set for showing no effect on the dependent variable.</li>
<li>Internal control: a variable that is set for showing effect on the dependent variable with a researcher’s certain intention.</li>
</ul>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
FYI
</div>
</div>
<div class="callout-body-container callout-body">
<p>Strictly speaking, the synonyms of independent and dependent variables are all slightly different for the different purpose.</p>
<ul>
<li>In association research, the use of the terms “dependent” and “independent” should be avoided because the research does not focus on causality between one another.<br>
</li>
<li>When the before-and-after relationship is clear, there might be cases where one variable clearly precedes the other
<ul>
<li>for example, rainfall leads to mud, rather than the other way around.</li>
<li>In these cases, you may call the rainfall a predictor and the mud an outcome variable.</li>
</ul></li>
</ul>
</div>
</div>
</section>
</section>
<section id="perspective-of-modeling" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="perspective-of-modeling"><span class="header-section-number">1.3</span> Perspective of Modeling</h2>
<p>There are largely 3 types of variables: confounders, latent variables, and composite variables</p>
<section id="confounders" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="confounders"><span class="header-section-number">1.3.1</span> Confounders</h3>
<ul>
<li>Confounding variables or confounders
<ul>
<li>Confounder is a variable that hides the true effect of another variable in an experiment by confounding the association between independent and dependent variables. This can happen when the 3rd variable has effect on both independent variable and dependent variable but the 3rd variable has not been controlled in your experiment. Confounders run a high risk of introducing a variety of research biases to your analysis result, particularly omitted variable bias.</li>
</ul></li>
<li>ex: When conducting a study on muscle mass increase for dumbbells in a gym, if gender is not included in the research model, gender is a confounder. This is because men and women have different innate muscle mass and baseline for lifting dumbbells.</li>
</ul>
</section>
<section id="latent-variables" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="latent-variables"><span class="header-section-number">1.3.2</span> Latent variables</h3>
<ul>
<li>Latent variable is a variable that can’t be measured directly but indirectly via a proxy.</li>
<li>ex: lactose tolerance of a person cannot be measured directly but indirectly inferred from measurements of a person’s can be inferred from measurements of digestion ability with biochemical metrics in a certain designed experiment.</li>
</ul>
</section>
<section id="composite-variable" class="level3" data-number="1.3.3">
<h3 data-number="1.3.3" class="anchored" data-anchor-id="composite-variable"><span class="header-section-number">1.3.3</span> Composite variable</h3>
<ul>
<li>Composite variable is a variable made by combining multiple variables of your data. These variables are created not when you measure it but when you analyze data,</li>
<li>ex: When your academic performance is measured with math, physics, literature, and writing composition, your numerical academic performance can be measured by combining math with physics, and your language academic performance by combining literature with writing composition.</li>
</ul>
</section>
</section>
<section id="from-the-point-of-mathmatical-view" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="from-the-point-of-mathmatical-view"><span class="header-section-number">1.4</span> From the point of mathmatical view</h2>
<ul>
<li>univariable: each subject gives rise to a single measurement of independent variable termed exploratory variable.</li>
<li>univariate: each subject gives rise to a single measurement of dependent variables termed response.</li>
<li>multivariate: each subject gives rise to a vector of measurements of independent variables termed exploratory variables.</li>
<li>multivariable: each subject gives rise to a vector of measurements of dependent variables termed responses.</li>
</ul>
</section>
</section>
<section id="data-type" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Data Type</h1>
<p>Data types can also be classified with various perspectives depending on research purpose:</p>
<ul>
<li>From the perspective of programming or computer science <a href="https://amplitude.com/blog/data-types">data type</a></li>
</ul>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Data Type</th>
<th>Definition</th>
<th>Examples</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Integer (int)</td>
<td>Numeric data type for numbers without fractions</td>
<td>-707, 0, 707</td>
</tr>
<tr class="even">
<td>Floating Point (float)</td>
<td>Numeric data type for numbers with fractions</td>
<td>707.07, 0.7, 707.00</td>
</tr>
<tr class="odd">
<td>Character (char)</td>
<td>Single letter, digit, punctuation mark, symbol, or blank space</td>
<td>a, 1, !</td>
</tr>
<tr class="even">
<td>String (str or text)</td>
<td>Sequence of characters, digits, or symbols—always treated as text</td>
<td>hello, +1-999-666-3333</td>
</tr>
<tr class="odd">
<td>Boolean (bool)</td>
<td>True or false values</td>
<td>0 (false), 1 (true)</td>
</tr>
<tr class="even">
<td>Enumerated type (enum)</td>
<td>Small set of predefined unique values (elements or enumerators) that can be text-based or numerical</td>
<td>rock (0), jazz (1)</td>
</tr>
<tr class="odd">
<td>Array</td>
<td>List with a number of elements in a specific order—typically of the same type</td>
<td>rock (0), jazz (1), blues (2), pop (3)</td>
</tr>
<tr class="even">
<td>Date</td>
<td>Date in the YYYY-MM-DD format (ISO 8601 syntax)</td>
<td>2021-09-28</td>
</tr>
<tr class="odd">
<td>Time</td>
<td>Time in the hh:mm:ss format for the time of day, time since an event, or time interval between events</td>
<td>12:00:59</td>
</tr>
<tr class="even">
<td>Datetime</td>
<td>Date and time together in the YYYY-MM-DD hh:mm:ss format</td>
<td>2021-09-28 12:00:59</td>
</tr>
<tr class="odd">
<td>Timestamp</td>
<td>Number of seconds that have elapsed since midnight (00:00:00 UTC), 1st January 1970 (Unix time)</td>
<td>1632855600</td>
</tr>
</tbody>
</table>
<ul>
<li>From the perspective of data measurement
<ul>
<li>longitudinal (or repeated) data: Each subject gives rise to a vector of measurements, but these represent the same response measured at a sequence of observation times</li>
<li>cross-sectional data : Outcome variable(s) and covariates that are measured at a single time point</li>
</ul></li>
</ul>
<section id="from-the-perspective-of-data-measurement" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="from-the-perspective-of-data-measurement"><span class="header-section-number">2.1</span> From the perspective of data measurement</h2>
<section id="longitudinal-or-repeated-data" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="longitudinal-or-repeated-data"><span class="header-section-number">2.1.1</span> Longitudinal (or repeated) Data</h3>
</section>
<section id="cross-sectional-data" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="cross-sectional-data"><span class="header-section-number">2.1.2</span> Cross-sectional Data</h3>
</section>
</section>
</section>
<section id="refrences" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Refrences</h1>
<ul>
<li><a href="https://www.scribbr.com/methodology/types-of-variables/">Scribbr</a></li>
</ul>
</section>
</div>
</div>
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">

</div>
</div>
<section id="go-to-content-list" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Go to Content List</h1>
<ul>
<li><a href="./docs/projects/index.qmd">Project Content List</a></li>
<li><a href="./docs/blog/posts/content_list.qmd">Blog Content List</a></li>
</ul>


</section>

</div></ul> ]]></description>
  <category>template</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/variables/index.html</guid>
  <pubDate>Wed, 22 Mar 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Storage and Database</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Engineering/2023-03-02_aws/storage_database.html</link>
  <description><![CDATA[ 



<ul class="nav nav-pills" id="language-tab">
<li class="nav-item">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<section id="storage-on-aws" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="storage-on-aws"><span class="header-section-number">1</span> Storage on AWS</h2>
<section id="storage-types-of-aws" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="storage-types-of-aws"><span class="header-section-number">1.1</span> Storage Types of AWS</h3>
<ul>
<li>Storage Types <img src="kmink3225.netlify.app/images/aws/storage_types.PNG" class="img-fluid" alt="Storage Types: Block Storage vs Object Storage">
<ul>
<li>Block Storage: split into fixed size chunk of data
<ul>
<li>easy to change small parts: change only block/piece of the data</li>
<li>for frequently modified data, or data with a high trasaction rate (like app or system files)</li>
</ul></li>
<li>Object Storage: each file = single unit of data
<ul>
<li>to change even small parts: need to update the entire file</li>
<li>for WORM(write once, read many) model
<ul>
<li>accessed often, but modified rarely (like photo)</li>
</ul></li>
</ul></li>
<li>File Storage: tree-like hierarchy (folders → subfolders)
<ul>
<li>similar to windows file explorer or MacOS Finder</li>
<li>for files shared/managed by multiple host computers
<ul>
<li>user home directories, developmental environments</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="amazon-ec2-instance-storage-and-amazon-elastic-block-store" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="amazon-ec2-instance-storage-and-amazon-elastic-block-store"><span class="header-section-number">2</span> Amazon EC2 Instance Storage and Amazon Elastic Block Store</h2>
<ul>
<li>block storage
<ul>
<li>boot volume for OS or data volume</li>
</ul></li>
<li>block storages for EC2 instances</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="kmink3225.netlify.app/images/aws/amazone EC2 Instance.PNG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">block storages for EC2 instances with EBS</figcaption><p></p>
</figure>
</div>
<ul>
<li>EC2 instance store: internal storage, ephemeral storage
<ul>
<li>directly(physically) attached: fast, quick response</li>
<li>life cycle is tied to the instance: lose data when stop/terminate the instance</li>
</ul></li>
<li>Amazon Elastic Block Store(Amazon EBS): external storage, persistent storage
<ul>
<li>separate from EC2, user-configured size</li>
<li>one-to-one with EC2 instances (can’t be shared/attached to multiple instances): secure communication
<ul>
<li>can be detached → attached to another instance in the same AZ</li>
<li>for multiple attachements: need to use Amazon EBS Multi-Attach</li>
</ul></li>
<li>Types of EBS
<ul>
<li>SSD backed volumes: for random I/O</li>
<li>HDD backed volumes: for sequential I/O</li>
</ul></li>
<li>backing up data: (EBS)Snapshot</li>
</ul></li>
</ul>
</section>
<section id="object-storage-with-amazon-s3" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="object-storage-with-amazon-s3"><span class="header-section-number">3</span> Object Storage with Amazon S3</h2>
<ul>
<li>for employee photos: can’t use amazon EBS
<ul>
<li>can’t be attached to instances when the app scales</li>
<li>has size limitations</li>
</ul></li>
<li>amazon simple storage service(Amazon S3)
<ul>
<li>standalone, don’t mount onto EC2 instances</li>
<li>access data through URL: storage for the internet<br>
</li>
<li>size limit for a single object: 5Tb</li>
<li>flat structure: use unique identifiers(?)</li>
<li>distributed storage: store data across multiple different facilities within one AWS region
<ul>
<li>durable storage system</li>
</ul></li>
</ul></li>
<li>S3 buckets: objects is stored in buckets
<ul>
<li>need to create buckets first</li>
<li>can make folders inside</li>
<li>region specific</li>
<li>name: should be globally unique across AWS accounts, DNS compliant (no special characters, spaces, etc.)<br>
</li>
<li>URL will be constructed using the name → should be reached with HTTP/HTTPS
<ul>
<li>bucket URL → append object key to bucket URL</li>
</ul>
<img src="kmink3225.netlify.app/images/aws/bucket URL.PNG" title="fig:" class="img-fluid" alt="Bucket URL"></li>
</ul></li>
<li>Accesss control
<ul>
<li>default: everything in S3 is private → can give public access<br>
</li>
<li>to make object publically access, need to change bucket settings</li>
</ul></li>
<li>policies&nbsp;
<ul>
<li>IAM policies</li>
<li>S3 bucket policies
<ul>
<li>JSON format (like IAM policies)</li>
<li>only placed on buckets (can apply for another AWS accounts or anonymous users)
<ul>
<li>not for folders/objects</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="databases-on-aws" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="databases-on-aws"><span class="header-section-number">4</span> Databases on AWS</h2>
<ul>
<li><p>Relational database(RDB): data를 table 형태로 저장, 서로 다른 table간 data는 relationship으로 연결됨</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="kmink3225.netlify.app/images/aws/RDB.PNG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">RDB</figcaption><p></p>
</figure>
</div>
<ul>
<li>Table은 row와 column으로 구성</li>
<li>row는 record라고도 부르며 특정 개체에 관련된 모든 정보를 담고 있음</li>
<li>column은 attribute라고도 부르며 개체의 각 속성을 나타냄</li>
</ul></li>
<li><p>Schema: 각 table 별 관계 및 column에 들어갈 data type 등을 정의한 것</p>
<ul>
<li>schema는 한 번 설정하고 나면 변경하기 어려움</li>
<li>예시: MySQL, PostgresQL, Oracle, SQL server, Amazon Aurora</li>
<li>일반적으로 SQL query를 사용해서 data 접근 및 수정</li>
</ul></li>
<li><p>장점</p>
<ul>
<li>Joins: table을 join하여 data간 관계를 쉽게 이해 가능</li>
<li>Reduced redundancy: 일부 attribute만 다른 경우 table을 나누어 중복 정보가 저장되는 것을 방지할 수 있음</li>
<li>Familiarity: 오래된 기술이기 때문에 자료가 많아서 적응하기 쉬움</li>
<li>Accuracy: data의 안정성 및 결과 보장 <a href="https://ko.wikipedia.org/wiki/ACID">참고</a><br>
</li>
</ul></li>
<li><p>사용처</p>
<ul>
<li>Schema가 거의 변경되지 않는 application들</li>
<li>작업 및 data의 안정성이 필요한 분야 전반</li>
<li>Enterprise Resource Planning (ERP) applications</li>
<li>Customer Relationship Management (CRM) applications</li>
<li>Commerce and financial applications</li>
</ul></li>
<li><p>RDB on AWS</p>
<ul>
<li><p>Managed database: EC2 or AWS database service</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="kmink3225.netlify.app/images/aws/EC2 or AWS database service.PNG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">EC2 or AWS database service</figcaption><p></p>
</figure>
</div></li>
</ul></li>
<li><p>Amazon RDS: AWS에서 제공하는 RDB service</p>
<ul>
<li><strong>Commercial:</strong> Oracle, SQL Server</li>
<li><strong>Open Source:</strong> MySQL, PostgreSQL, MariaDB</li>
<li><strong>Cloud Native:</strong> Amazon Aurora&nbsp;<strong>Note:</strong> The cloud native option, Amazon Aurora, is a MySQL and PostgreSQL-compatible database built for the cloud. It is more durable, more available, and provides faster performance than the Amazon RDS version of MySQL and PostgreSQL</li>
</ul></li>
<li><p>DB instance type - 아래 type 내에서 size 별 선택지 존재</p>
<ul>
<li><strong>Standard</strong>, which include general-purpose instances</li>
<li><strong>Memory Optimized</strong>, which are optimized for memory-intensive applications</li>
<li><strong>Burstable Performance</strong>, which provides a baseline performance level, with the ability to burst to full CPU usage.</li>
</ul></li>
<li><p>DB storage - the DB instance uses <strong>Amazon Elastic Block Store (EBS)</strong> volumes as its storage layer</p>
<ul>
<li>용량: 20~65536Gb</li>
<li>General purpose (SSD)</li>
<li>Provisioned IOPS (SSD)</li>
<li>Magnetic storage (not recommended)</li>
</ul></li>
<li><p>DB subnet group</p>
<ul>
<li>DB를 사용하기 위해서 <strong>VPC</strong> 및 <strong>subnet</strong> 설정 필요&nbsp;=&gt; availability zone 내 subnet 지정 필요</li>
<li>DB subnet은 <strong>private</strong>해야 됨 - gateway에 직접 연결 금지 for 보안</li>
<li>보안의 경우 ACL 및 security group으로 통제 가능 - network section 참고</li>
</ul></li>
<li><p>IAM policy</p>
<ul>
<li>DB subnet group은 traffic을 조절</li>
<li>IAM policy는 data와 table에 대한 접근 및 수정 권한을 조절</li>
</ul></li>
<li><p>Backup</p>
<ul>
<li>Automatic
<ul>
<li>default로 설정</li>
<li>log 및 DB instance 자체를 백업</li>
<li>주기: 0~35일&nbsp;<strong>0일의 경우 automatic 백업을 disable, 기존 backup도 삭제됨</strong></li>
<li>방식: point-in-time&nbsp;=&gt; 특정 기간 내 일어난 transaction에 대해서 recovery</li>
</ul></li>
<li>Manual snapshot
<ul>
<li>35일보다 긴 기간에 대해 backup할 때 사용</li>
</ul></li>
<li>Backup recovery: 새 instance를 생성</li>
</ul></li>
<li><p>Redundancy</p>
<ul>
<li>Multi-AZ를 허용할 경우, Amazon RDS가 다른 AZ에 redundant copy 생성</li>
<li>Primary copy: 평소에 사용하는 copy</li>
<li>Standby copy: primary copy에 접근이 불가한 경우 사용하는 copy</li>
<li>두 copy간 싱크로는 자동 유지</li>
<li>DB instance 생성시 DNS를 설정하면 AWS가 이를 인식하여 자동으로 failover 수행</li>
<li>Redundant copy는 subnet에 존재해야 됨</li>
</ul></li>
<li><p><strong>Amazon DynamoDB</strong></p>
<ul>
<li>Fully managed NoSQL database service: provides fast and predictable performance with seamless scalability</li>
<li><strong>Serverless</strong>
<ul>
<li>RDB와 달리 size 제한 없음</li>
<li>자동 scale 조절</li>
<li>SSD에 자동 저장되며 replication 또한 자동 수행</li>
<li>No schema</li>
</ul></li>
</ul></li>
<li><p><strong>저장된 데이터 양과 접근 횟수에 따라 과금</strong></p></li>
<li><p>구성 요소</p>
<ul>
<li>Table: RDB와 유사하게 item의 집합으로 구성</li>
<li>Item: 다른 item과 unique하게 구분가능한 data, 개수 제한 없음, attribute의 조합으로 구성됨, RDB와 달리 <strong>각 item의 attribute 개수가 다를 수 있음</strong>&nbsp;RDB의 row에 대응</li>
<li>Attribute: RDB와 달리 같은 attribute라도 <strong>다양한 type</strong>의 정보를 저장할 수 있음?&nbsp;RDB의 column에 대응</li>
</ul></li>
<li><p><strong>AWS Database Services </strong></p></li>
</ul>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Database Type</th>
<th>Use Cases</th>
<th>AWS Service</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Relational</td>
<td>Traditional applications, ERP, CRM, e-commerce</td>
<td>Amazon RDS, Amazon Aurora, Amazon Redshift</td>
</tr>
<tr class="even">
<td>Key-value</td>
<td>High-traffic web apps, e-commerce systems, gaming applications</td>
<td>Amazon DynamoDB</td>
</tr>
<tr class="odd">
<td>In-memory</td>
<td>Caching, session management, gaming leaderboards, geospatial applications</td>
<td>Amazon ElastiCache for Memcached, Amazon ElastiCache for Redis</td>
</tr>
<tr class="even">
<td>Document</td>
<td>Content management, catalogs, user profiles</td>
<td>Amazon DocumentDB (with MongoDB compatibility)</td>
</tr>
<tr class="odd">
<td>Wide column</td>
<td>High-scale industrial apps for equipment maintenance, fleet management, and route optimization</td>
<td>Amazon Keyspaces (for Apache Cassandra)</td>
</tr>
<tr class="even">
<td>Graph</td>
<td>Fraud detection, social networking, recommendation engines</td>
<td>Amazon Neptune</td>
</tr>
<tr class="odd">
<td>Time series</td>
<td>IoT applications, DevOps, industrial telemetry</td>
<td>Amazon Timestream</td>
</tr>
<tr class="even">
<td>Ledger</td>
<td>Systems of record, supply chain, registrations, banking transactions</td>
<td>Amazon QLDB</td>
</tr>
</tbody>
</table>
<ul>
<li>선택 기준
<ul>
<li>RDB: 데이터 간 관계가 복잡하고 별도 관리가 필요한 경우에 사용&nbsp;복잡도에 의해 overhead가 발생하기 때문</li>
<li>Key-value DB: Large scale, low latency 보장, 단순 데이터 저장 및 조회 목적으로 적합&nbsp;=&gt; RDB에서는 여러 table에 나누어 저장해야 되는 정보를 한 table에 저장 가능</li>
<li>Graph: SNS와 같은 관계형 자료구조에 적합</li>
<li>Ledger: 금융과 같은 안정성, 변경 불가가 필요한 자료를 저장하는 경우에 적합</li>
</ul></li>
</ul>
</section>
</div>
</div>
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">

</div>
</div>
<section id="back-to-content-list" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="back-to-content-list"><span class="header-section-number">5</span> Back to Content List</h2>
<ul>
<li><a href="../../../../../docs/blog/posts/content_list.html">Global Blog Content List</a></li>
</ul>


</section>

</div></ul> ]]></description>
  <category>Engineering</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Engineering/2023-03-02_aws/storage_database.html</guid>
  <pubDate>Fri, 17 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/images/aws/storage_types.PNG" medium="image"/>
</item>
<item>
  <title>Differentiation - Higher Order Derivative</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/differentiation/2023-03-18_higher_order_derivative.html</link>
  <description><![CDATA[ 



<ul class="nav nav-pills" id="language-tab">
<li class="nav-item">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<div id="def-second_derivative" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 </strong></span>미분 가능한 함수 <img src="https://latex.codecogs.com/png.latex?f(x)"> 의 <img src="https://latex.codecogs.com/png.latex?f'(x)"> 가 존재할 때, <img src="https://latex.codecogs.com/png.latex?f'(x)"> 의 도함수 <img src="https://latex.codecogs.com/png.latex?(f'(x))'"> 를 <img src="https://latex.codecogs.com/png.latex?%0Af%5E%7B''%7D(x),%20%5Cfrac%7Bd%5E2f(x)%7D%7Bdx%5E2%7D,%20%5Ctext%7B%20or%20%7D%20%5Cfrac%7Bd%5E2y%7D%7Bdx%5E2%7D%0A"> 라 표기하고 <img src="https://latex.codecogs.com/png.latex?f(x)"> 의 2차 도함수 or second derivative라고 한다.</p>
<p>같은 방법으로, <img src="https://latex.codecogs.com/png.latex?n"> 차 도함수 <img src="https://latex.codecogs.com/png.latex?f%5E%7B(n)%7D(x)"> or <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bd%5Enf(x)%7D%7Bdx%5En%7D"> 가 정의 된다.</p>
</div>
</section>
<section id="example" class="level2">
<h2 class="anchored" data-anchor-id="example">Example</h2>
<p>다음의 <img src="https://latex.codecogs.com/png.latex?n"> 차 도함수</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?f(x)=x%5E%7B%5Calpha%7D%20%5Ctext%7B%20%7D%20(x%3E0,%20%5Calpha%20%5Cne%20-1)"></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20f'(x)&amp;=%5Calpha%20x%5E%7B%5Calpha-1%7D%5C%5C%0A%20%20%20%20f%5E%7B''%7D(x)&amp;=%5Calpha(%5Calpha-1)%20x%5E%7B%5Calpha-2%7D%5C%5C%0A%20%20%20%20&amp;%5Cvdots%5C%5C%0A%20%20%20%20f%5E%7Bn%7D(x)&amp;=%5Calpha(%5Calpha-1)%5Ccdots(%5Calpha-(n-1))%20x%5E%7B%5Calpha-n%7D%0A%5Cend%7Baligned%7D%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?f(x)=ln(1+x)"></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20f'(x)&amp;=%5Cfrac%7B1%7D%7B1+x%7D%5C%5C%0A%20%20%20%20f%5E%7B''%7D(x)&amp;=-%5Cfrac%7B1%7D%7B(1+x)%5E2%7D%5C%5C%0A%20%20%20%20f%5E%7B3%7D(x)&amp;=(-1)%5E2%5Cfrac%7B1%20%5Ccdot%202%20%7D%7B(1+x)%5E3%7D%5C%5C%0A%20%20%20%20&amp;%5Cvdots%5C%5C%0A%20%20%20%20f%5E%7Bn%7D(x)&amp;=(-1)%5E%7Bn-1%7D%5Cfrac%7B(n-1)!%7D%7B(1+x)%5En%7D%5C%5C%0A%5Cend%7Baligned%7D%0A"></p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?f(x)=%5Csin(x)"></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20f'(x)&amp;=%5Ccos(x)=%5Csin(x+1%5Ccdot%5Cfrac%7B%5Cpi%7D%7B2%7D)%5C%5C%0A%20%20%20%20f%5E%7B2%7D(x)&amp;=(-1)%5Csin(x)=%5Csin(x+2%5Ccdot%5Cfrac%7B%5Cpi%7D%7B2%7D)%5C%5C%0A%20%20%20%20f%5E%7B3%7D(x)&amp;=-%5Ccos(x)=%5Csin(x+3%5Ccdot%5Cfrac%7B%5Cpi%7D%7B2%7D)%5C%5C%0A%20%20%20%20f%5E%7B4%7D(x)&amp;=(-1)%5E2%5Csin(x)=%5Csin(x+4%5Ccdot%5Cfrac%7B%5Cpi%7D%7B2%7D)%5C%5C%0A%20%20%20%20&amp;%5Cvdots%5C%5C%0A%20%20%20%20f%5E%7Bn%7D(x)&amp;=%5Csin(x+n%5Ccdot%5Cfrac%7B%5Cpi%7D%7B2%7D)%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="mean-value-theorem" class="level2">
<h2 class="anchored" data-anchor-id="mean-value-theorem">Mean Value Theorem</h2>
<div id="thm-mvt" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 </strong></span>If A function <img src="https://latex.codecogs.com/png.latex?f(x)"> is differentiable on <img src="https://latex.codecogs.com/png.latex?%5C%5Ba,b%5C%5D">, then there exists <img src="https://latex.codecogs.com/png.latex?c%20%5Cin%20(a,b)"> such that <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20%5Cfrac%7Bf(b)-f(a)%7D%7Bb-a%7D%20=%20f'(c),%20(a%3Cc%3Cb)%0A%5Cend%7Baligned%7D%0A"></p>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="https://commons.wikimedia.org/w/index.php?curid=1039489" class="img-fluid"></p>
<p></p><figcaption class="figure-caption">By 4C - 자작, based on PNG version, CC BY-SA 3.0</figcaption><p></p>
</figure>
</div>
<section id="example-1" class="level3">
<h3 class="anchored" data-anchor-id="example-1">Example</h3>
</section>
</section>
</div>
</div>
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">

</div>
</div>
<section id="blog-guide-map-link" class="level2">
<h2 class="anchored" data-anchor-id="blog-guide-map-link">Blog Guide Map Link</h2>
<ul>
<li><a href="../../../../../docs/blog/posts/statistics/guide_map/index.html">Statistics Blog</a></li>
<li><a href="../../../../../docs/blog/posts/Engineering/guide_map/index.html">Engineering Blog</a></li>
<li><a href="../../../../../docs/blog/posts/DL/guide_map/index.html">Deep Learning Blog</a></li>
<li><a href="../../../../../docs/blog/posts/ML/guide_map/index.html">Machine Learning Blog</a></li>
<li><a href="../Mathmatics/guide_map/index.qmd">Mathematics Blog</a></li>
<li><a href="../../../../../docs/blog/posts/Patent/guide_map/index.html">Patent Blog</a></li>
<li><a href="../../Validation/guide_map/index.qmd">Validation Blog</a></li>
</ul>


</section>

</div></ul> ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/differentiation/2023-03-18_higher_order_derivative.html</guid>
  <pubDate>Fri, 17 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="https://commons.wikimedia.org/w/index.php?curid=1039489" medium="image"/>
</item>
<item>
  <title>Categorical Data Analysis</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/statistics/categorical_data/2023-03-17_introduction/index.html</link>
  <description><![CDATA[ 



<ul class="nav nav-pills" id="language-tab">
<li class="nav-item">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<section id="goal" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="goal"><span class="header-section-number">1</span> Goal</h2>
<ul>
<li>Visualization Methods
<ul>
<li>for EDA: visualize patterns, trends, anomalies in data</li>
<li>for model diagnostic methods: visualize to assess violations of assumptions</li>
<li>for summary methods: visualize to provide an interpretable summary of data</li>
</ul></li>
<li>apply theory to practice
<ul>
<li>conert research questions into statistical hypotheses and models</li>
<li>look into the difference between non-parametric (ex. fisher exact test) vs parametric (ex. <img src="https://latex.codecogs.com/png.latex?%5Cchi%5E2%20test%20for%20independence">) vs model-based methods (ex. logistic regression)</li>
<li>for summary methods: visualize to provide an interpretable summary of data</li>
</ul></li>
</ul>
</section>
<section id="definition-of-categorical-data" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="definition-of-categorical-data"><span class="header-section-number">2</span> Definition of Categorical Data</h2>
<ul>
<li>categorical (or frequency) data consist of a discrete set of categories, which may be ordered or unordered.
<ul>
<li>unordered
<ul>
<li>gener: {male, female, transgender}</li>
<li>marital status: {never married, married, separated, divorced, widowed}</li>
<li>party preference: {NDP, liberal, conservative, green}</li>
<li>treatment improvement: {none, some, marked}</li>
</ul></li>
<li>ordered
<ul>
<li>age group: {0s,10s,20s,30s, …}</li>
<li>number of children: {0, 1 , 2 ,3, …} ## Structures</li>
</ul></li>
</ul></li>
</ul>
<p>Categorical data appears in various forms like:</p>
<ul>
<li><p>tables</p>
<ul>
<li><p>one way</p></li>
<li><p>two way</p></li>
<li><p>three way</p></li>
</ul></li>
<li><p>matrices</p></li>
<li><p>array</p></li>
<li><p>data frames</p>
<ul>
<li><p>case form</p></li>
<li><p>frequency form</p></li>
</ul></li>
<li></li>
</ul>
</section>
</div>
</div>
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">

</div>
</div>



</div></ul> ]]></description>
  <category>template</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/statistics/categorical_data/2023-03-17_introduction/index.html</guid>
  <pubDate>Thu, 16 Mar 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Taylor’s Series</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/taylor_series/index.html</link>
  <description><![CDATA[ 



<ul class="nav nav-pills" id="language-tab">
<li class="nav-item">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<section id="definition" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="definition"><span class="header-section-number">1</span> Definition</h2>
<div id="def-sequence" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 </strong></span>A <strong>sequence</strong> is a list of numbers written in a definite order: <img src="https://latex.codecogs.com/png.latex?%0Aa_1,%20a_2,%20a_3,%20%5Cdots,%20a_n,%20a_%7Bn+1%7D%20%5Cdots%20%20%0A"></p>
<p>the number <img src="https://latex.codecogs.com/png.latex?a_1">, <img src="https://latex.codecogs.com/png.latex?a_2">, and <img src="https://latex.codecogs.com/png.latex?a_n"> are called the first term, the second term, the nth term. Since for every positive inter <img src="https://latex.codecogs.com/png.latex?n"> there is a corresponding number <img src="https://latex.codecogs.com/png.latex?a_n">, a sequence can be defined as a funtion with domain of the set of positive integers. The notation of the sequence function is <img src="https://latex.codecogs.com/png.latex?a_n"> instead of <img src="https://latex.codecogs.com/png.latex?f(n)"> in convention: <img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BThe%20sequence%20%7D%20%5C%7Ba_1,a_2,a_3,%5Cdots%5C%7D%20%5Ctext%7B%20is%20also%20denoted%20by%20%7D%20%5C%7Ba_n%5C%7D%20%5Ctext%7B%20or%20%7D%20%5C%7Ba_n%5C%7D_%7Bn=1%7D%5E%7B%5Cinfty%7D%0A"> .</p>
</div>
<div id="def-series" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2 </strong></span>A <strong>series or infinite series</strong> is defined as a sum of the terms of an infinite sequence <img src="https://latex.codecogs.com/png.latex?%5C%7Ba_n%5C%7D_%7Bn=1%7D%5E%7B%5Cinfty%7D">: <img src="https://latex.codecogs.com/png.latex?%0Aa_1+%20a_2+%20a_3+%20%5Cdots+%20a_n+%20a_%7Bn+1%7D%20%5Cdots%20%20%0A"></p>
<p>The notation of a series is: <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bn=1%7D%5E%7B%5Cinfty%7D%20a_n"> or <img src="https://latex.codecogs.com/png.latex?%5Csum%20a_n">.</p>
</div>
<div id="def-power_series" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3 </strong></span>A <strong>power series</strong> is a series of the following form: <img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bn=0%7D%5E%7B%5Cinfty%7D%20c_nx%5En%20=%20c_0x%5E0+c_1x%5E1+c_2x%5E2+%20%5Cdots+%20c_nx%5En+c_%7Bn+1%7Dx%5E%7Bn+1%7D+%5Cdots%20%20%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?x"> is a variable and the <img src="https://latex.codecogs.com/png.latex?c_n">’s are constants called the coefficients of the series.</p>
</div>
<div id="def-power_series" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4 </strong></span>A <strong>power series centered at a</strong> is a series of the following form: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20%5Csum_%7Bn=0%7D%5E%7B%5Cinfty%7D%20c_n(x-a)%5En%20&amp;=%20c_0(x-a)%5E0+c_1(x-a)%5E1+c_2(x-a)%5E2+%20%5Cdots+%20c_n(x-a)%5En+c_%7Bn+1%7D(x-a)%5E%7Bn+1%7D+%5Cdots%20%20%5C%5C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20&amp;=%20c_0+c_1(x-a)%5E1+c_2(x-a)%5E2+%20%5Cdots+%20c_n(x-a)%5En+c_%7Bn+1%7D(x-a)%5E%7Bn+1%7D+%5Cdots%20%20%0A%5Cend%7Baligned%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?x"> is a variable and the <img src="https://latex.codecogs.com/png.latex?c_n">’s are constants called the coefficients of the series.</p>
</div>
<div id="thm-power_series_expansion" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 </strong></span><img src="https://latex.codecogs.com/png.latex?f"> is said to be a <strong>expanded power series centered at a</strong> : <img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bif%20%7Df(x)=%5Csum_%7Bn=0%7D%5E%7B%5Cinfty%7D%20c_n(x-a)%5En%20%7Cx-a%7C%3CR,%20%5Ctext%7B%20then,%20its%20coefficients%20are%20given%20by%20the%20formula%20%7D%20c_n=%5Cfrac%7Bf%5E%7B(n)%7D(a)%7D%7Bn!%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?x"> is a variable and the <img src="https://latex.codecogs.com/png.latex?c_n">’s are constants called the coefficients of the series.</p>
</div>
<p>Proof)</p>
<p>Let <img src="https://latex.codecogs.com/png.latex?f"> is any function that can be represented by a powerseries.</p>
$$
<img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Baligned%7D%0A%20%20%20%20%0A%20%20%20%20f(x)%20&amp;=%20c_0+c_1(x-a)%5E1+c_2(x-a)%5E2+%20%5Cdots+%20c_n(x-a)%5En+c_%7Bn+1%7D(x-a)%5E%7Bn+1%7D+%5Cdots%20%5Ctext%7B%20%20%7D%7Cx-a%7C%3CR%5C%5C%0A%20%20%20%20f(a)%20&amp;=%200%5C%5C%0A%20%20%20%20f'(x)%20&amp;=%20c_1+2c_2(x-a)+%203c_3(x-a)%5E2+%20%5Cdots%20%5Ctext%7B%20%20%7D%7Cx-a%7C%3CR%5C%5C%20%5C%5C%0A%20%20%20%20f'(a)%20&amp;=%20c_1%20%5C%5C%0A%20%20%20%20f''(x)%20&amp;=%202c_2(x-a)+%202%5Ctimes%203c_3(x-a)+%203%5Ctimes%204c_4(x-a)%5E2+%20%5Cdots%20%5Ctext%7B%20%20%7D%7Cx-a%7C%3CR%5C%5C%0A%20%20%20%20f''(a)%20&amp;=%202c_2%20%5C%5C%0A%20%20%20%20f'''(x)%20&amp;=%203!c_3%20+%204!%20c_4(x-a)+3%5Ctimes%204%20%5Ctimes%205%20c_4(x-a)%5E2%20%5Cdots%20%5Ctext%7B%20%20%7D%7Cx-a%7C%3CR%5C%5C%0A%20%20%20%20f'''(a)%20&amp;=%203!c_3%20%5C%5C%0A%20%20%20%20%5Cvdots%20%5C%5C%0A%20%20%20%20f%5E%7B(n)%7D(a)%20&amp;=%20n!c_n%20%5C%5C%0A%20%20%20%20c_n&amp;=%5Cfrac%7Bf%5E%7B(n)%7D%7D%7Bn!%7D%0A%5Cend%7Baligned%7D">
<p>$$</p>
<div id="def-taylor_series" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 5 </strong></span><img src="https://latex.codecogs.com/png.latex?f"> is said to be a <strong>Taylor’s series</strong> if f has a expanded power series at a with the following form: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20f(x)&amp;=%5Csum_%7Bn=0%7D%5E%7B%5Cinfty%7D%20%5Cfrac%7Bf%5E%7B(n)%7D(a)%7D%7Bn!%7D(x-a)%5En%20%5C%5C%0A%20%20%20%20%20%20%20%20&amp;=%20%5Cfrac%7Bf%5E%7B(0)%7D(a)%7D%7B0!%7D(x-a)%5E0+%5Cfrac%7Bf%5E%7B(1)%7D(a)%7D%7B1!%7D(x-a)%5E1+%5Cfrac%7Bf%5E%7B(2)%7D(a)%7D%7B2!%7D(x-a)%5E2+%5Cfrac%7Bf%5E%7B(0)%7D(a)%7D%7B0!%7D(x-a)%5E3%20+%20%5Cdots%20%5C%5C%0A%20%20%20%20%20%20%20%20&amp;=%20f(a)+%5Cfrac%7Bf%5E%7B(1)%7D(a)%7D%7B1!%7D(x-a)%5E1+%5Cfrac%7Bf%5E%7B(2)%7D(a)%7D%7B2!%7D(x-a)%5E2+%5Cfrac%7Bf%5E%7B(3)%7D(a)%7D%7B3!%7D(x-a)%5E3%20+%20%5Cdots%0A%5Cend%7Baligned%7D%0A"></p>
</div>
<div id="def-maclaurin_series" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6 </strong></span><img src="https://latex.codecogs.com/png.latex?f"> is said to be a <strong>Maclaurin series</strong> if f has a Taylor’s series with the special case <img src="https://latex.codecogs.com/png.latex?a=0">: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20f(x)&amp;=%5Csum_%7Bn=0%7D%5E%7B%5Cinfty%7D%20%5Cfrac%7Bf%5E%7B(n)%7D(0)%7D%7Bn!%7D(x)%5En%20%5C%5C%0A%20%20%20%20%20%20%20%20&amp;=%20%5Cfrac%7Bf%5E%7B(0)%7D(0)%7D%7B0!%7Dx%5E0+%5Cfrac%7Bf%5E%7B(1)%7D(0)%7D%7B1!%7Dx%5E1+%5Cfrac%7Bf%5E%7B(2)%7D(0)%7D%7B2!%7Dx%5E2+%5Cfrac%7Bf%5E%7B(3)%7D(0)%7D%7B3!%7Dx%5E3%20+%20%5Cdots%20%5C%5C%0A%20%20%20%20%20%20%20%20&amp;=%20f(0)+%5Cfrac%7Bf%5E%7B(1)%7D(0)%7D%7B1!%7Dx%5E1+%5Cfrac%7Bf%5E%7B(2)%7D(0)%7D%7B2!%7Dx%5E2+%5Cfrac%7Bf%5E%7B(3)%7D(0)%7D%7B3!%7Dx%5E3%20+%20%5Cdots%0A%5Cend%7Baligned%7D%0A"></p>
</div>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> math</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-4"></span>
<span id="cb1-5">degrees <span class="op" style="color: #5E5E5E;">=</span> (<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">7</span>)</span>
<span id="cb1-6">ls <span class="op" style="color: #5E5E5E;">=</span> (<span class="st" style="color: #20794D;">'-'</span>, <span class="st" style="color: #20794D;">'--'</span>, <span class="st" style="color: #20794D;">'-.'</span>, <span class="st" style="color: #20794D;">':'</span>)</span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="kw" style="color: #003B4F;">def</span>  taylor_e(x, a, n) :</span>
<span id="cb1-9">    <span class="co" style="color: #5E5E5E;">"""</span></span>
<span id="cb1-10"><span class="co" style="color: #5E5E5E;">    x* = a 에서 전개</span></span>
<span id="cb1-11"><span class="co" style="color: #5E5E5E;">    f(x) = f(a) + f'(a)*(x-a) + (1/2!)f''(a)(x-a)^2 + ... + (1/k!)f^(k)(a)(x-a)^k + R_k</span></span>
<span id="cb1-12"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb1-13">    signs  <span class="op" style="color: #5E5E5E;">=</span> (<span class="dv" style="color: #AD0000;">1</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb1-14">    derivs <span class="op" style="color: #5E5E5E;">=</span> (np.cos, np.sin, np.cos, np.sin)</span>
<span id="cb1-15"></span>
<span id="cb1-16">    fx <span class="op" style="color: #5E5E5E;">=</span>  np.sin(a) </span>
<span id="cb1-17">    </span>
<span id="cb1-18">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">1</span>, n<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>) : </span>
<span id="cb1-19">        fx <span class="op" style="color: #5E5E5E;">+=</span> (signs[(i<span class="op" style="color: #5E5E5E;">%</span><span class="dv" style="color: #AD0000;">4</span>)<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]<span class="op" style="color: #5E5E5E;">*</span>derivs[(i<span class="op" style="color: #5E5E5E;">%</span><span class="dv" style="color: #AD0000;">4</span>)<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>](a)) <span class="op" style="color: #5E5E5E;">/</span> math.factorial(i)<span class="op" style="color: #5E5E5E;">*</span>(x<span class="op" style="color: #5E5E5E;">-</span>a)<span class="op" style="color: #5E5E5E;">**</span>i</span>
<span id="cb1-20">    </span>
<span id="cb1-21">    <span class="cf" style="color: #003B4F;">return</span> fx</span>
<span id="cb1-22">    </span>
<span id="cb1-23">x <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">10</span>, <span class="dv" style="color: #AD0000;">10</span>, <span class="dv" style="color: #AD0000;">100</span>)</span>
<span id="cb1-24">y <span class="op" style="color: #5E5E5E;">=</span> np.sin(x)</span>
<span id="cb1-25"></span>
<span id="cb1-26">fig <span class="op" style="color: #5E5E5E;">=</span> plt.figure(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">12</span>,<span class="dv" style="color: #AD0000;">5</span>))</span>
<span id="cb1-27">ax <span class="op" style="color: #5E5E5E;">=</span> fig.add_subplot(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb1-28"></span>
<span id="cb1-29">ax.xaxis.set_tick_params(labelsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">12</span>)</span>
<span id="cb1-30">ax.yaxis.set_tick_params(labelsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">12</span>)</span>
<span id="cb1-31">ax.set_xlabel(<span class="vs" style="color: #20794D;">r'$x$'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">15</span>)</span>
<span id="cb1-32">ax.set_ylabel(<span class="vs" style="color: #20794D;">r'$x$'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">15</span>)</span>
<span id="cb1-33">ax.grid(<span class="va" style="color: #111111;">False</span>)</span>
<span id="cb1-34"></span>
<span id="cb1-35">taylors <span class="op" style="color: #5E5E5E;">=</span> (taylor_e(x, <span class="dv" style="color: #AD0000;">0</span>, i) <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> degrees)</span>
<span id="cb1-36">ax.plot(x, y , lw<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>, </span>
<span id="cb1-37">        label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r"sin(x)"</span>)</span>
<span id="cb1-38"></span>
<span id="cb1-39"><span class="cf" style="color: #003B4F;">for</span> i, taylor <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(taylors) :</span>
<span id="cb1-40">    ax.plot(x, taylor, lw<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, ls<span class="op" style="color: #5E5E5E;">=</span>ls[i], color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'k'</span>, </span>
<span id="cb1-41">            label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"degree </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">"</span>.<span class="bu" style="color: null;">format</span>(degrees[i]))</span>
<span id="cb1-42"></span>
<span id="cb1-43"></span>
<span id="cb1-44">ax.legend(fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">11</span>)</span>
<span id="cb1-45">ax.set_ylim([<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">5</span>])</span>
<span id="cb1-46"></span>
<span id="cb1-47"><span class="co" style="color: #5E5E5E;"># plt.suptitle("Taylor series, order=1,2,3", fontsize=15)</span></span>
<span id="cb1-48"></span>
<span id="cb1-49"></span>
<span id="cb1-50">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/taylor_series/index_files/figure-html/cell-2-output-1.png" width="970" height="439"></p>
</div>
</div>
<div id="thm-taylor_series_remainder" class="theorem">
<p><span class="theorem-title"><strong>Theorem 2 </strong></span>If <img src="https://latex.codecogs.com/png.latex?f(x)"> is differentiable (and therefore continuous) <img src="https://latex.codecogs.com/png.latex?n"> times on <img src="https://latex.codecogs.com/png.latex?%5Ba,b%5D"> , then there exists <img src="https://latex.codecogs.com/png.latex?c"> such that <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20f(b)&amp;=f(a)+f'(a)(b-a)+%5Cfrac%7Bf%5E%7B(2)%7D(a)%5E2%7D%7B2!%7D(b-a)%5E2+%5Cdots+%5C%5C%0A%20%20%20%20&amp;%5Cfrac%7Bf%5E%7B(n-1)%7D(a)%7D%7B(n-1)!%7D(b-a)%5E%7Bn-1%7D%20+%20%5Cfrac%7Bf%5E%7B(n)%7D(c)%7D%7Bn!%7D(b-a)%5E%7Bn%7D,%20a%3Cc%3Cb%0A%5Cend%7Baligned%7D%0A"> .</p>
</div>
<p>Proof) find <img src="https://latex.codecogs.com/png.latex?k"> such that <img src="https://latex.codecogs.com/png.latex?f(b)-(f(a)+f'(a)(b-a)+%5Cfrac%7Bf%5E%7B(2)%7D(a)%5E2%7D%7B2!%7D(b-a)%5E2+%5Cdots+%5Cfrac%7Bf%5E%7B(n-1)%7D(a)%7D%7B(n-1)!%7D(b-a)%5E%7Bn-1%7D%20+%20k(b-a)%5E%7Bn%7D)=0">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20%5Ctext%7BLet%20%7DF(x)&amp;=f(b)-(f(x)+f'(x)(b-x)+%5Cfrac%7Bf%5E%7B(2)%7D(a)%5E2%7D%7B2!%7D(b-x)%5E2+%5Cdots+%5C%5C%0A%20%20%20%20&amp;%5Cfrac%7Bf%5E%7B(n-1)%7D(x)%7D%7B(n-1)!%7D(b-x)%5E%7Bn-1%7D%20+%20k(b-x)%5E%7Bn%7D)%0A%5Cend%7Baligned%7D%0A"></p>
<p>Then, <img src="https://latex.codecogs.com/png.latex?F(x)"> is differentiable on <img src="https://latex.codecogs.com/png.latex?%5Ba,b%5D">. In addition, since <img src="https://latex.codecogs.com/png.latex?F(a)=F(b)=0">, there exists <img src="https://latex.codecogs.com/png.latex?c"> such that <img src="https://latex.codecogs.com/png.latex?F'(c)=0">, <img src="https://latex.codecogs.com/png.latex?a%3Cc%3Cb"> by the Mean Value Theorem. Thus,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20F'(x)&amp;=-%5Cfrac%7Bf%5E%7B(n)%7D(x)%7D%7B(n-1)!%7D(b-x)%5E%7Bn-1%7D+kn(b-x)%5E%7Bn-1%7D%5C%5C%0A%20%20F'(c)&amp;=-%5Cfrac%7Bf%5E%7B(n)%7D(c)%7D%7B(n-1)!%7D(b-c)%5E%7Bn-1%7D+kn(b-c)%5E%7Bn-1%7D=0%5C%5C%0A%20%20kn&amp;=%5Cfrac%7Bf%5E%7B(n)%7D(c)%7D%7B(n-1)!%7D%5C%5C%0A%20%20%5Ctherefore%20k&amp;=%5Cfrac%7Bf%5E%7B(n)%7D(c)%7D%7Bn!%7D%0A%5Cend%7Baligned%7D%0A"></p>
<div id="thm-taylor_series_remainder2" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3 </strong></span>If <img src="https://latex.codecogs.com/png.latex?f"> is differentiable (and therefore continuous) <img src="https://latex.codecogs.com/png.latex?n"> times on <img src="https://latex.codecogs.com/png.latex?%5Ba,b%5D"> , <img src="https://latex.codecogs.com/png.latex?x%5E*,x%20%5Cin%20%5Ba,b%5D">, and <img src="https://latex.codecogs.com/png.latex?x%5Cne%20x%5E*">, there exists <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> such that <img src="https://latex.codecogs.com/png.latex?0%3C%5Ctheta%3C1"> and<br>
<img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20f(x)&amp;=f(x%5E*)+f'(x%5E*)(x-x%5E*)+%5Cfrac%7Bf%5E%7B(2)%7D(x%5E*)%5E2%7D%7B2!%7D(x-x%5E*)%5E2+%5Cdots+%5C%5C%0A%20%20%20%20&amp;%5Cfrac%7Bf%5E%7B(n-1)%7D(x%5E*)%7D%7B(n-1)!%7D(x-x%5E*)%5E%7Bn-1%7D%20+%20%5Cfrac%7Bf%5E%7B(n)%7D(x%5E*+%5Ctheta(x-x%5E*))%7D%7Bn!%7D(x-x%5E*)%5E%7Bn%7D%0A%5Cend%7Baligned%7D%0A"> .</p>
</div>
<p>In the above expression (Theorem&nbsp;3), <img src="https://latex.codecogs.com/png.latex?f(x)"> can be expressed with finite terms because it is differentiable <img src="https://latex.codecogs.com/png.latex?n"> times. The symbol <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> represents a value between 0 and 1, and it is used in the context of Taylor’s theorem with remainder (see Definition&nbsp;5). The general form of Taylor’s theorem with remainder is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(x)%20=%20f(x%5E*)%20+%20%5Cfrac%7Bf'(x%5E*)%7D%7B1!%7D(x-x%5E*)%20+%20%5Cfrac%7Bf''(x%5E*)%7D%7B2!%7D(x-x%5E*)%5E2%20+%20...%20+%20%5Cfrac%7Bf%5E%7B(n)%7D(x%5E*)%7D%7Bn!%7D(x-x%5E*)%5En%20+%20R_n(x)%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?R_n(x)"> is the remainder term that involves the <img src="https://latex.codecogs.com/png.latex?n+1"> th derivative of f evaluated at some point <img src="https://latex.codecogs.com/png.latex?c"> between <img src="https://latex.codecogs.com/png.latex?x"> and <img src="https://latex.codecogs.com/png.latex?x%5E*">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20R_n(x)&amp;=f(x)-%20(f(x%5E*)%20+%20%5Cfrac%7Bf'(x%5E*)%7D%7B1!%7D(x-x%5E*)%20+%20%5Cfrac%7Bf''(x%5E*)%7D%7B2!%7D(x-a)%5E2%20+%20...%20+%20%5Cfrac%7Bf%5E%7B(n)%7D(x%5E*)%7D%7Bn!%7D(x-x%5E*)%5En)%5C%5C%0A%20%20R_n(x)&amp;=%20%5Cfrac%7Bf%5E%7B(n+1)%7D(c)%7D%7B(n+1)!%7D(x-x%5E*)%5E%7Bn+1%7D%0A%5Cend%7Baligned%7D%0A"></p>
<p>In the given expression, <img src="https://latex.codecogs.com/png.latex?x%5E*+%5Ctheta(x-x%5E*)"> is the value of <img src="https://latex.codecogs.com/png.latex?c"> that lies between <img src="https://latex.codecogs.com/png.latex?x"> and <img src="https://latex.codecogs.com/png.latex?x%5E*">, where <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> is a scalar value between <img src="https://latex.codecogs.com/png.latex?0"> and <img src="https://latex.codecogs.com/png.latex?1">. In other words, <img src="https://latex.codecogs.com/png.latex?c"> is an internally dividing point, <img src="https://latex.codecogs.com/png.latex?i"> that divides the segment <img src="https://latex.codecogs.com/png.latex?%5Coverline%7Bxx%5E*%7D"> in the ratio <img src="https://latex.codecogs.com/png.latex?%5Coverline%7Bx%5E*i%7D:%5Coverline%7Bix%7D=%5Ctheta:(1-%5Ctheta)"> because <img src="https://latex.codecogs.com/png.latex?x%5E*+%5Ctheta(x-x%5E*)=x%5E*(1-%5Ctheta)+%5Ctheta%20x"> .Therefore, <img src="https://latex.codecogs.com/png.latex?x%5E*+%5Ctheta(x-x%5E*)"> of the remainder term in the expression is somewhere between <img src="https://latex.codecogs.com/png.latex?x%20and%20x%5E*">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7Bf%5E%7B(n)%7D(x%5E*+%5Ctheta(x-x%5E*))%7D%7B(n)!%7D(x-x%5E*)%5E%7Bn%7D%0A"></p>
<section id="example" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="example"><span class="header-section-number">1.1</span> Example</h3>
<p><img src="https://latex.codecogs.com/png.latex?f(x)=x%5E3-3x%5E2+4"></p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;">def</span> f(x):</span>
<span id="cb2-2">    <span class="cf" style="color: #003B4F;">return</span> x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb2-3"><span class="kw" style="color: #003B4F;">def</span> df(x):</span>
<span id="cb2-4">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">6</span><span class="op" style="color: #5E5E5E;">*</span>x</span>
<span id="cb2-5"><span class="kw" style="color: #003B4F;">def</span> d2f(x):</span>
<span id="cb2-6">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">6</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">6</span></span>
<span id="cb2-7"><span class="kw" style="color: #003B4F;">def</span> d3f(n):</span>
<span id="cb2-8">    <span class="cf" style="color: #003B4F;">return</span> np.repeat(<span class="dv" style="color: #AD0000;">6</span>,n)</span>
<span id="cb2-9"></span>
<span id="cb2-10"></span>
<span id="cb2-11"></span>
<span id="cb2-12"><span class="co" style="color: #5E5E5E;"># Define the Taylor series expansion up to the 3rd order</span></span>
<span id="cb2-13"><span class="kw" style="color: #003B4F;">def</span> taylor(x):</span>
<span id="cb2-14">    <span class="cf" style="color: #003B4F;">return</span> f(<span class="dv" style="color: #AD0000;">0</span>) <span class="op" style="color: #5E5E5E;">+</span> df(<span class="dv" style="color: #AD0000;">0</span>)<span class="op" style="color: #5E5E5E;">*</span>x <span class="op" style="color: #5E5E5E;">+</span> d2f(<span class="dv" style="color: #AD0000;">0</span>)<span class="op" style="color: #5E5E5E;">*</span>(x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>)<span class="op" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">+</span> d3f(<span class="bu" style="color: null;">len</span>(x))<span class="op" style="color: #5E5E5E;">*</span>(x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">3</span>)<span class="op" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">6</span> </span>
<span id="cb2-15"></span>
<span id="cb2-16"><span class="co" style="color: #5E5E5E;"># Create a range of x values</span></span>
<span id="cb2-17">x <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;">-</span>np.pi, np.pi, <span class="dv" style="color: #AD0000;">100</span>)</span>
<span id="cb2-18"></span>
<span id="cb2-19"><span class="co" style="color: #5E5E5E;"># Calculate the function and its approximation using the Taylor series expansion</span></span>
<span id="cb2-20">y <span class="op" style="color: #5E5E5E;">=</span> f(x)</span>
<span id="cb2-21">y2 <span class="op" style="color: #5E5E5E;">=</span> df(x)</span>
<span id="cb2-22">y3 <span class="op" style="color: #5E5E5E;">=</span> d2f(x)</span>
<span id="cb2-23">y_approx <span class="op" style="color: #5E5E5E;">=</span> taylor(x)</span>
<span id="cb2-24"></span>
<span id="cb2-25"><span class="co" style="color: #5E5E5E;"># Plot the function and its approximation</span></span>
<span id="cb2-26"></span>
<span id="cb2-27">plt.plot(x, y, <span class="st" style="color: #20794D;">'--'</span>,lw<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>, label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$f(x)=x^3-3x^2+4$'</span>)</span>
<span id="cb2-28">plt.plot(x, df(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$f(x)=3x^2-6x$'</span>)</span>
<span id="cb2-29">plt.plot(x, d2f(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$f(x)=6x-6$'</span>)</span>
<span id="cb2-30">plt.plot(x, d3f(<span class="bu" style="color: null;">len</span>(x)), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r'$f(x)=6$'</span>)</span>
<span id="cb2-31">plt.plot(x, y_approx, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Taylor Approximation'</span>)</span>
<span id="cb2-32">plt.legend()</span>
<span id="cb2-33">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/taylor_series/index_files/figure-html/cell-3-output-1.png" width="577" height="411"></p>
</div>
</div>
<p>If <img src="https://latex.codecogs.com/png.latex?f(x)=x%5E3-3x%5E2+4">, then <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bdf(x)%7D%7Bdx%7D=3x%5E2-6x">, <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bd%5E2f(x)%7D%7Bdx%5E2%7D=6x-6">, <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bd%5E3f(x)%7D%7Bdx%5E3%7D=6">, <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bd%5Enf(x)%7D%7Bdx%5En%7D=0,%20n%5Cge%204">.</p>
<p>For <img src="https://latex.codecogs.com/png.latex?x%5Cne%20x%5E*">,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20f(x)&amp;=f(x%5E*)+f'(x%5E*)(x-x%5E*)+%5Cfrac%7Bf%5E%7B(2)%7D(x%5E*)%5E2%7D%7B2!%7D(x-x%5E*)%5E2+%5Cfrac%7Bf%5E%7B(3)%7D(x%5E*+%5Ctheta(x-x%5E*))%5E3%7D%7B3!%7D(x-x%5E*)%5E3%5C%5C%0A%20%20f(x)&amp;=f(x%5E*)+(3x%5E2-6x)(x-x%5E*)+%5Cfrac%7B(6x-6)%7D%7B2!%7D(x-x%5E*)%5E2+%5Cfrac%7B6%7D%7B3!%7D(x-x%5E*)%5E3%5C%5C%0A%20%20f(x)&amp;=f(0)+(3x%5E2-6x)(x)+%5Cfrac%7B(6x-6)%7D%7B2!%7D(x)%5E2+%5Cfrac%7B6%7D%7B3!%7D(x)%5E3%20%5Ctext%7B%20%7D%20(x%5E*=0)%5C%5C%0A%20%20f(x)&amp;=x%5E3-3x%5E2+4%0A%5Cend%7Baligned%7D%20%20%20%20%20%0A"></p>
<p>If f is differentated 3 times, f is expressed with <img src="https://latex.codecogs.com/png.latex?%5Ctheta">. But, if differentiated more than 4 times, the <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> disappears.</p>
</section>
<section id="second-derivative-test" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="second-derivative-test"><span class="header-section-number">1.2</span> Second Derivative Test</h3>
<p>The second derivative test is a method used to determine whether a critical point of a function is a local maximum, local minimum, or a saddle point. The test uses the sign of the second derivative of the function at the critical point to determine its nature. In other words, the second derivative test uses the sign of the second derivative to determine the concavity of the function at a critical point, which in turn determines whether the critical point is a local maximum, local minimum, or a saddle point.</p>
<div id="def-2nd_derivative" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 7 </strong></span>Let <img src="https://latex.codecogs.com/png.latex?f"> be a function with a critical point at <img src="https://latex.codecogs.com/png.latex?x%5E*">. If <img src="https://latex.codecogs.com/png.latex?f"> is twice differentiable at <img src="https://latex.codecogs.com/png.latex?x%5E*">, then:</p>
<ul>
<li>If <img src="https://latex.codecogs.com/png.latex?f''(x%5E*)%20%3E%200">, then <img src="https://latex.codecogs.com/png.latex?f"> has a local minimum at <img src="https://latex.codecogs.com/png.latex?x%5E*">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f''(x%5E*)%20%3C%200">, then <img src="https://latex.codecogs.com/png.latex?f"> has a local maximum at <img src="https://latex.codecogs.com/png.latex?x%5E*">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f''(x%5E*)%20=%200"> and there exist values of <img src="https://latex.codecogs.com/png.latex?x"> close to <img src="https://latex.codecogs.com/png.latex?x%5E*"> such that <img src="https://latex.codecogs.com/png.latex?f''(x)%20%3C%200"> and <img src="https://latex.codecogs.com/png.latex?f''(x)%20%3E%200">, then <img src="https://latex.codecogs.com/png.latex?f"> has a saddle point at <img src="https://latex.codecogs.com/png.latex?x%5E*">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f''(x%5E*)%20=%200"> and there do not exist values of <img src="https://latex.codecogs.com/png.latex?x"> close to <img src="https://latex.codecogs.com/png.latex?x%5E*"> such that <img src="https://latex.codecogs.com/png.latex?f''(x)%20%3C%200"> and <img src="https://latex.codecogs.com/png.latex?f''(x)%20%3E%200">, then the test is inconclusive and we may need to use other methods to determine the nature of the critical point.</li>
</ul>
</div>
<p>The second derivative test is a method used to determine the nature of a critical point of a function by examining the concavity of the function at that point.</p>
<p>If the second derivative of the function is positive at a critical point, then the function is concave up at that point, and the critical point is a local minimum. If the second derivative is negative, then the function is concave down, and the critical point is a local maximum. If the second derivative is zero, the test is inconclusive, and the other methods should be tried to determine the nature of the critical point. If there exist values of <img src="https://latex.codecogs.com/png.latex?x"> close to <img src="https://latex.codecogs.com/png.latex?x%5E*"> such that <img src="https://latex.codecogs.com/png.latex?f''(x)%20%3C%200"> and <img src="https://latex.codecogs.com/png.latex?f''(x)%20%3E%200">, then <img src="https://latex.codecogs.com/png.latex?f"> has a saddle point at <img src="https://latex.codecogs.com/png.latex?x%5E*"> (see Figure&nbsp;1).</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
What Is a Saddle Point?
</div>
</div>
<div class="callout-body-container callout-body">
<p>A saddle point is a type of critical point of a function where the first-order partial derivatives of the function are zero, but the behavior of the function around the point is neither a local maximum nor a local minimum. Instead, the behavior is like a saddle shape, hence the name “saddle point” (see Figure&nbsp;1).</p>
<p>At a saddle point, the function changes concavity in different directions, meaning that the function is concave up in some directions and concave down in other directions. In other words, the Hessian matrix of the function (the matrix of second-order partial derivatives) evaluated at the saddle point has both positive and negative eigenvalues, indicating that the curvature of the function changes in different directions.</p>
<p>Saddle points are important in optimization and machine learning because they can cause difficulties in finding the global minimum of a function. At a saddle point, gradient-based optimization algorithms can get stuck because the gradient is zero but the curvature of the function prevents the algorithm from moving in a direction that decreases the function value. This can result in slow convergence or even convergence to a suboptimal solution.</p>
</div>
</div>
<div id="fig-saddle" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/taylor_series/saddle_point.PNG" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Saddle Point Example</figcaption><p></p>
</figure>
</div>
<p><a href="https://commons.wikimedia.org/w/index.php?curid=20570051">Sourced from Wiki By Nicoguaro - Own work, CC BY 3.0</a></p>
<p>Thus, for the problem of finding the maximum and minimum, it is usually sufficient for <img src="https://latex.codecogs.com/png.latex?f"> to be differentiable twice in a taylor series.</p>
<p><span id="eq-second_derivative"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20f(x)&amp;=f(x%5E*)+f'(x%5E*)(x-x%5E*)+%5Cfrac%7Bf%5E%7B(2)%7D(x%5E*+%5Ctheta(x-x%5E*))%7D%7B2!%7D(x-x%5E*)%5E%7B2%7D%20,%5Ctext%7B%20%7D%200%3C%5Ctheta%3C1%0A%5Cend%7Baligned%7D%0A%5Ctag%7B1%7D"></span></p>
<p>It is the case that <img src="https://latex.codecogs.com/png.latex?f'(x%5E*)=0"> to find <img src="https://latex.codecogs.com/png.latex?x%5E*"> that makes the extrema (minimum or maximum) of <img src="https://latex.codecogs.com/png.latex?f">. So, we can set <img src="https://latex.codecogs.com/png.latex?f'(x%5E*)"> in Equation&nbsp;1 as <img src="https://latex.codecogs.com/png.latex?0">. Then,</p>
<p><span id="eq-second_derivative2"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20f(x)&amp;=f(x%5E*)+%5Cfrac%7Bf%5E%7B(2)%7D(x%5E*+%5Ctheta(x-x%5E*))%7D%7B2!%7D(x-x%5E*)%5E%7B2%7D%20,%5Ctext%7B%20%7D%200%3C%5Ctheta%3C1%0A%5Cend%7Baligned%7D%0A%5Ctag%7B2%7D"></span></p>
<p>In Equation&nbsp;2, we can make a certain conclusion on the second derivative test depending on the sign of the variable (not a constant because of <img src="https://latex.codecogs.com/png.latex?%5Ctheta">), <img src="https://latex.codecogs.com/png.latex?f%5E%7B(2)%7D(x%5E*+%5Ctheta(x-x%5E*))"> because <img src="https://latex.codecogs.com/png.latex?(x-x%5E*)%5E%7B2%7D%3E0">:</p>
<ul>
<li>If <img src="https://latex.codecogs.com/png.latex?f'(x%5E*)=0">, <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20%5Ba,b%5D">, and <img src="https://latex.codecogs.com/png.latex?f''(x)%3E0">, then <img src="https://latex.codecogs.com/png.latex?f(x)=f(x%5E*)+d,%20%5Ctext%7B%20%7D%20(d%3E0)"><br>
<img src="https://latex.codecogs.com/png.latex?%5Ctherefore%20f(x)%3Ef(x%5E*)">, which means that <img src="https://latex.codecogs.com/png.latex?f(x)"> has a minimum at <img src="https://latex.codecogs.com/png.latex?x%5E*">.</li>
<li>If <img src="https://latex.codecogs.com/png.latex?f'(x%5E*)=0">, <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20%5Ba,b%5D">, and <img src="https://latex.codecogs.com/png.latex?f''(x)%3C0">, then <img src="https://latex.codecogs.com/png.latex?f(x)=f(x%5E*)-d,%20%5Ctext%7B%20%7D%20(d%3E0)"><br>
<img src="https://latex.codecogs.com/png.latex?%5Ctherefore%20f(x)%3Cf(x%5E*)">, which means that <img src="https://latex.codecogs.com/png.latex?f(x)"> has a maximum at <img src="https://latex.codecogs.com/png.latex?x%5E*">.</li>
</ul>
<section id="example-1" class="level4" data-number="1.2.1">
<h4 data-number="1.2.1" class="anchored" data-anchor-id="example-1"><span class="header-section-number">1.2.1</span> Example</h4>
<p>If <img src="https://latex.codecogs.com/png.latex?f(x)=e%5E%7Bx%5E2%7D,%20f'(x)=2xe%5E%7Bx%5E2%7D,%20%5Ctext%7B%20and%20%7D%20f%5E%7B''%7D(x)=(2+4x%5E2)e%5E%7Bx%5E2%7D">, the case <img src="https://latex.codecogs.com/png.latex?f'(x%5E*)=0"> is when <img src="https://latex.codecogs.com/png.latex?x%5E*=0">. Since <img src="https://latex.codecogs.com/png.latex?f%5E%7B''%7D(x)%3E0"> for all <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20%5Cmathbb%7BR%7D">, <img src="https://latex.codecogs.com/png.latex?f(0)=1"> is a minimum at <img src="https://latex.codecogs.com/png.latex?x%5E*">.</p>
<p><img src="https://latex.codecogs.com/png.latex?f(x)=e%5E%7Bx%5E2%7D"></p>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;">def</span> f(x):</span>
<span id="cb3-2">    <span class="cf" style="color: #003B4F;">return</span> np.exp(x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb3-3"><span class="kw" style="color: #003B4F;">def</span> df(x):</span>
<span id="cb3-4">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">*</span>np.exp(x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb3-5"><span class="kw" style="color: #003B4F;">def</span> d2f(x):</span>
<span id="cb3-6">    <span class="cf" style="color: #003B4F;">return</span> (<span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">4</span><span class="op" style="color: #5E5E5E;">*</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>)<span class="op" style="color: #5E5E5E;">*</span>np.exp(x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="co" style="color: #5E5E5E;"># Create a range of x values</span></span>
<span id="cb3-9">x <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">100</span>)</span>
<span id="cb3-10"></span>
<span id="cb3-11"><span class="co" style="color: #5E5E5E;"># Calculate the function and its approximation using the Taylor series expansion</span></span>
<span id="cb3-12">y <span class="op" style="color: #5E5E5E;">=</span> f(x)</span>
<span id="cb3-13">y2 <span class="op" style="color: #5E5E5E;">=</span> df(x)</span>
<span id="cb3-14">y3 <span class="op" style="color: #5E5E5E;">=</span> d2f(x)</span>
<span id="cb3-15">y_approx <span class="op" style="color: #5E5E5E;">=</span> taylor(x)</span>
<span id="cb3-16"></span>
<span id="cb3-17"><span class="co" style="color: #5E5E5E;"># Plot the function and its approximation</span></span>
<span id="cb3-18"></span>
<span id="cb3-19">plt.plot(x, y, label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r"$f(x)=e^{x^2}$"</span>)</span>
<span id="cb3-20">plt.plot(x, df(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r"$f'(x)=2xe^{x^2}$"</span>)</span>
<span id="cb3-21">plt.plot(x, d2f(x), label<span class="op" style="color: #5E5E5E;">=</span><span class="vs" style="color: #20794D;">r"$f^{''}(x)=(2+4x^2)e^{x^2}$"</span>)</span>
<span id="cb3-22">plt.axhline(y<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb3-23">plt.axvline(x<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gray'</span>)</span>
<span id="cb3-24"></span>
<span id="cb3-25">plt.plot(x, y_approx, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Taylor Approximation'</span>)</span>
<span id="cb3-26">plt.legend()</span>
<span id="cb3-27">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/taylor_series/index_files/figure-html/cell-4-output-1.png" width="569" height="411"></p>
</div>
</div>
</section>
</section>
</section>
</div>
</div>
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">

</div>
</div>



</div></ul> ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/taylor_series/index.html</guid>
  <pubDate>Wed, 15 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/docs/blog/posts/Mathmatics/taylor_series/saddle_point.PNG" medium="image"/>
</item>
<item>
  <title>\(\epsilon - \delta\) Method</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/epsilon_delta/index.html</link>
  <description><![CDATA[ 



<ul class="nav nav-pills" id="language-tab">
<li class="nav-item">
<button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" aria-controls="Korean" aria-selected="true">
Korean
</button>
</li>
<li class="nav-item">
<button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" aria-controls="knitr" aria-selected="false">
English
</button>
</li>
<div class="tab-content" id="language-tabcontent">

<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<div id="Korean" class="tab-pane fade show active" aria-labelledby="Korean-tab">
<section id="definition" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="definition"><span class="header-section-number">1</span> Definition</h2>
<div id="def-function_limit" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1 </strong></span>Let <img src="https://latex.codecogs.com/png.latex?f"> be a function defined on some open interval that contains the number <img src="https://latex.codecogs.com/png.latex?a">, exccept possibly at <img src="https://latex.codecogs.com/png.latex?a"> itself. Then, <img src="https://latex.codecogs.com/png.latex?f"> is said to converge to the real number <img src="https://latex.codecogs.com/png.latex?L"> provided that for every number <img src="https://latex.codecogs.com/png.latex?%5Cepsilon%3E0">, there is a number <img src="https://latex.codecogs.com/png.latex?%5Cdelta%3E0"> such that <img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bif%20%7D%200%3C%7Cx-a%7C%3C%5Cdelta%20%5Ctext%7B%20then%20%7D%20%7Cf(x)-L%7C%3C%5Cepsilon%0A"></p>
<p>If <img src="https://latex.codecogs.com/png.latex?f(x)"> converges to <img src="https://latex.codecogs.com/png.latex?L">, then <img src="https://latex.codecogs.com/png.latex?L"> is called the <strong>limit</strong> of <img src="https://latex.codecogs.com/png.latex?f(x)"> as <img src="https://latex.codecogs.com/png.latex?x"> approaches <img src="https://latex.codecogs.com/png.latex?a"> , and we write <img src="https://latex.codecogs.com/png.latex?%0A%5Clim_%7Bx%20%5Cto%20a%7D%20f(x)%20=L%0A"></p>
<p>If a function does not coverge to a real number, it is said to diverge.</p>
</div>
<p>먼저, 위의 정의를 하나씩 곱 씹어보면,</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bif%20%7D%200%3C%7Cx-a%7C%3C%5Cdelta%20%5Ctext%7B%20then%20%7D%20%7Cf(x)-L%7C%3C%5Cepsilon"> 에서 <img src="https://latex.codecogs.com/png.latex?%7Cx-a%7C"> 와 <img src="https://latex.codecogs.com/png.latex?%7Cf(x)-L%7C"> 가 절대값으로 표기가 되어 있기 때문에 거리(distance)로 해석이 된다.</li>
<li>또한, <img src="https://latex.codecogs.com/png.latex?%7Cx-a%7C"> 는 임의의 충분히 작은 수 <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> 와 대응이 되고 <img src="https://latex.codecogs.com/png.latex?%7Cf(x)-L%7C"> 는 임의의 충분히 작은 수 <img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> 와 대응이 되는 것을 숙지해야한다.</li>
<li>그리고 <img src="https://latex.codecogs.com/png.latex?%5Cepsilon%20-%20%5Cdelta"> Method 라는 표현에서도 이해에 대한 실마리를 얻을 수 있는데 <img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> 이 먼저 정해지면 <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> 를 그 후에 결정할 수 있다. 좀 더 자세히 말하면, 궁극적으로 <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> 를 <img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> 의 함수 <img src="https://latex.codecogs.com/png.latex?%5Cdelta(%5Cepsilon)"> 로 표현하여 함수의 수렴성을 증명하게 된다.</li>
</ul>
<p>그럼 본격적으로 limit의 notation, <img src="https://latex.codecogs.com/png.latex?%5Clim_%7Bx%20%5Cto%20a%7D%20f(x)%20=L"> 을 해석하면,</p>
<ul>
<li>고등학교 때 우리는 이 표현을 <img src="https://latex.codecogs.com/png.latex?x"> 가 <img src="https://latex.codecogs.com/png.latex?a"> 로 한없이 가까워질 때 <img src="https://latex.codecogs.com/png.latex?f(x)"> 의 limit은 <img src="https://latex.codecogs.com/png.latex?L"> 이다 라고 배웠다.</li>
<li>이를 조금 더 정밀하게 해석하면, <img src="https://latex.codecogs.com/png.latex?x"> 와 <img src="https://latex.codecogs.com/png.latex?a"> 사이의 거리가 만족할 만큼 충분히 작아질 때, (하지만 <img src="https://latex.codecogs.com/png.latex?x%5Cne%20a">), <img src="https://latex.codecogs.com/png.latex?f(x)"> 와 <img src="https://latex.codecogs.com/png.latex?L"> 사이의 거리가 임의대로 작아 질수 있다는 것을 의미한다.</li>
</ul>
<p>하지만 두 번째 표현 역시 수학적이지 않다. 왜냐하면 위의 문장은 <strong>만족할 만큼 충분히 작아질 때</strong> 라는 표현 때문에 명제(statement)가 될 수 없기 때문이다. 사람의 주관마다 어떤 사람은 거리가 1 일 때 충분히 작다고 말 할 수 있고 좀 더 정밀한 사람의 경우 0.0001 이 충분히 작다고 말할 수 있기 때문이다. 또 어떤 사람은 100이 충분히 작은 거리라고 표현할 수 있는 모호성이 존재한다.</p>
<p>여기서, <img src="https://latex.codecogs.com/png.latex?%5Clim_%7Bx%20%5Cto%20a%7D%20f(x)%20=L"> 의 해석을 분석해보고 수식화 시켜보자.</p>
<p>‘<img src="https://latex.codecogs.com/png.latex?x"> 와 <img src="https://latex.codecogs.com/png.latex?a"> 사이의 거리가 만족할 만큼 충분히 작아질 때, (하지만 <img src="https://latex.codecogs.com/png.latex?x%5Cne%20a">), <img src="https://latex.codecogs.com/png.latex?f(x)"> 와 <img src="https://latex.codecogs.com/png.latex?L"> 사이의 거리가 임의대로 작아 질수 있다.’ 는</p>
<ul>
<li>조건절: ’<img src="https://latex.codecogs.com/png.latex?x"> 와 <img src="https://latex.codecogs.com/png.latex?a"> 사이의 거리가 만족할 만큼 충분히 작아질 때, (하지만 <img src="https://latex.codecogs.com/png.latex?x%5Cne%20a">),</li>
<li>결과절: <img src="https://latex.codecogs.com/png.latex?f(x)"> 와 <img src="https://latex.codecogs.com/png.latex?L"> 사이의 거리가 임의대로 작아 질수 있다.’</li>
</ul>
<p>와 같이 조건절과 결과절로 나눌 수 있다.<br>
이를 수식으로 표현하면, 거리의 의미는 수학에서 절대값으로 표현될 수 있기 때문에</p>
<ul>
<li>조건절: <img src="https://latex.codecogs.com/png.latex?%7Cx-a%7C"> 가 만족할 만큼 충분히 작아질 때, (하지만 <img src="https://latex.codecogs.com/png.latex?x%5Cne%20a">),</li>
<li>결과절: <img src="https://latex.codecogs.com/png.latex?%7Cf(x)-L%7C"> 가 임의대로 작아 질수 있다.’</li>
</ul>
<p>와 같이 표현 될 수 있다.</p>
<p>위의 정의 Definition&nbsp;1 의 <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bif%20%7D%200%3C%7Cx-a%7C%3C%5Cdelta%20%5Ctext%7B%20then%20%7D%20%7Cf(x)-L%7C%3C%5Cepsilon"> 를 유심히 보면 애매한 표현을 수학적으로 표현하기 위해 <strong>누구나 만족할만한 충분히 작은 수</strong> 를 <strong>임의의 양수 (every number <img src="https://latex.codecogs.com/png.latex?%5Cepsilon%3E0"> or any number <img src="https://latex.codecogs.com/png.latex?%5Cepsilon%3E0">)</strong>라고 표현하여 명제화 시키는 것을 볼 수 있다.</p>
<p>부등식으로 표현된 명제, <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bif%20%7D%200%3C%7Cx-a%7C%3C%5Cdelta%20%5Ctext%7B%20then%20%7D%20%7Cf(x)-L%7C%3C%5Cepsilon"> 를 대수적으로 변형시켜 분석해보자.</p>
<ul>
<li>조건절: <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bif%20%7D%200%3C%7Cx-a%7C%3C%5Cdelta"></li>
</ul>
<p><span id="eq-first"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20%7C&amp;x-a%7C%3C%5Cdelta%20%5C%5C%0A%20%20%20%20-%5Cdelta%3C&amp;x-a%3C%5Cdelta%20%5Ctext%7B%20%20%7D(%5Cbecause%20%5Cdelta%3E0)%5C%5C%0A%20%20%20%20a-%5Cdelta%3C&amp;x%3Ca+%5Cdelta%0A%5Cend%7Baligned%7D%0A%5Ctag%7B1%7D"></span></p>
<p><span id="eq-second"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%200%3C%7C&amp;x-a%7C%5Ctext%7B%20%20%7D(%5Cbecause%20x%20%5Cne%20a)%0A%5Cend%7Baligned%7D%0A%5Ctag%7B2%7D"></span></p>
<ul>
<li>결과절: <img src="https://latex.codecogs.com/png.latex?%5Ctext%7B%20then%20%7D%20%7Cf(x)-L%7C%3C%5Cepsilon"> <span id="eq-third"><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%7C&amp;f(x)-L%7C%3C%5Cepsilon%20%5C%5C%0A%20%20-%5Cepsilon%3C&amp;f(x)-L%3C%5Cepsilon%20%5Ctext%7B%20%20%7D(%5Cbecause%20%5Cepsilon%3E0)%5C%5C%0A%20%20L-%5Cepsilon%3C&amp;f(x)%3CL+%5Cepsilon%5C%5C%0A%5Cend%7Baligned%7D%0A%5Ctag%7B3%7D"></span></li>
</ul>
<p>위의 간단한 부등식 조작으로 3가지 사실을 재정리했다.</p>
<ol type="1">
<li><img src="https://latex.codecogs.com/png.latex?x"> 의 범위 (see Equation&nbsp;1) : <img src="https://latex.codecogs.com/png.latex?a-%5Cdelta%3Cx%3Ca+%5Cdelta"></li>
<li><img src="https://latex.codecogs.com/png.latex?%7Cx-a%7C"> 의 범위 (see Equation&nbsp;2): <img src="https://latex.codecogs.com/png.latex?0%3C%7Cx-a%7C"></li>
<li><img src="https://latex.codecogs.com/png.latex?f(x)"> 의 범위 (see Equation&nbsp;3): <img src="https://latex.codecogs.com/png.latex?L-%5Cepsilon%3Cf(x)%3CL+%5Cepsilon%5C%5C"></li>
</ol>
<p>이 3가지 사실을 기반으로 limit의 정의 (Definition&nbsp;1)를 다시 해석해보면,</p>
<p><em><img src="https://latex.codecogs.com/png.latex?lim_%7Bx%5Cto%20a%7Df(x)=L"> 은 모든 임의의 양수 <img src="https://latex.codecogs.com/png.latex?%5Cepsilon%3E0"> 에 대해서,<img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20(a-%5Cdelta,a-%5Cdelta)"> (i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?x"> 가 <img src="https://latex.codecogs.com/png.latex?(a-%5Cdelta,a-%5Cdelta)"> 범위안에 있다) 이고 <img src="https://latex.codecogs.com/png.latex?x%5Cne%20a"> 라면 <img src="https://latex.codecogs.com/png.latex?f(x)%20%5Cin%20(L-%5Cepsilon,L+%5Cepsilon)"> 을 만족시키는 임의의 양수 <img src="https://latex.codecogs.com/png.latex?%5Cdelta%3E0"> 가 존재한다</em></p>
<p>라고하는 좀 더 쉬운 해석이 가능해진다. 다른 방식으로 표현하면,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Ctext%7BIf%20%7D%20f(x)%20%5Cin%20(L-%5Cepsilon,L+%5Cepsilon),%20&amp;%5Ctext%7Bthen%20%7D%20%5Cexists%20%5Ctext%7B%20%7D%20x%20%5Cin%20(a-%5Cdelta,a+%5Cdelta)%20%20%5Cni%20%5C%5C%0Af:(a-%5Cdelta,a+%5Cdelta)%20&amp;%5Crightarrow%20(L-%5Cepsilon,L+%5Cepsilon)%0A%5Cend%7Baligned%7D%0A"></p>
<p>여기서, <img src="https://latex.codecogs.com/png.latex?f(x)%5Cin%20(L-%5Cepsilon,L+%5Cepsilon)"> 은 <img src="https://latex.codecogs.com/png.latex?f(x)"> 를 <img src="https://latex.codecogs.com/png.latex?L"> 의 근방 <img src="https://latex.codecogs.com/png.latex?(%5Ctext%7Bi.e.%20%7D%20L-%5Ctext%7Bneighborhood%7D)"> 으로 한정시켰다고 표현한다. 같은 방식으로, <img src="https://latex.codecogs.com/png.latex?x%20%5Cin%20(a-%5Cdelta,a+%5Cdelta)"> 은 <img src="https://latex.codecogs.com/png.latex?x"> 를 <img src="https://latex.codecogs.com/png.latex?a"> 의 근방 <img src="https://latex.codecogs.com/png.latex?(%5Ctext%7Bi.e.%20%7D%20a-%5Ctext%7Bneighborhood%7D)"> 한정시켰다고 표현한다. 여기서, neighborhood는 <img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> 과 <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> 가 정해져야 결정될 수 있는 것을 볼 수 있다. 그리고 if 조건문에 의해 <img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> 에 의해 <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> 가 정해진다는 것을 미루어 짐작할 수 있다.</p>
<p>이를 또 다르게 해석할 수 있는데,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Ctext%7BIf%20%7D%20%5Clim_%7Bx%20%5Cto%20a%7Df(x)=L,%20&amp;%5Ctext%7B%20then%20%7D%20%5Cexists%20%5Cdelta%20%3E%200%20%5Cni%5C%5C%0A%5Ctext%7Bif%20%7D%20x%20%5Cin%20(a-%5Cdelta,a+%5Cdelta),%20&amp;%5Ctext%7B%20then%20%7D%20f(x)%20%5Cin%20(L-%5Cepsilon,L+%5Cepsilon)%0A%5Cend%7Baligned%7D%0A"></p>
<p>위의 표현을 해석해보면, <img src="https://latex.codecogs.com/png.latex?x"> 가 <img src="https://latex.codecogs.com/png.latex?a"> 로 한없이 다가가서 <img src="https://latex.codecogs.com/png.latex?L"> 에 수렴한다면, <img src="https://latex.codecogs.com/png.latex?x"> 를 <img src="https://latex.codecogs.com/png.latex?a"> 근방에 한정시켜 <img src="https://latex.codecogs.com/png.latex?f(x)"> 가 <img src="https://latex.codecogs.com/png.latex?L"> 근방에 한정되는 임의의 양수 <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> 가 존재한다 라고 해석할 수 있다.</p>
<section id="example" class="level4" data-number="1.0.1">
<h4 data-number="1.0.1" class="anchored" data-anchor-id="example"><span class="header-section-number">1.0.1</span> Example</h4>
<ul>
<li>find <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> corresponding to <img src="https://latex.codecogs.com/png.latex?%5Cepsilon=0.5"> in the definition of a limit for <img src="https://latex.codecogs.com/png.latex?f(x)=x+5"> with <img src="https://latex.codecogs.com/png.latex?a=1"> and <img src="https://latex.codecogs.com/png.latex?L=6">. <img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bif%20%7D%20%7Cx-1%7C%3C%5Cdelta%20%5Ctext%7B%20then%7D%20%7C(x+5)-6%7C%3C0.5%0A"></li>
</ul>
<p>Solution)</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20-0.5%3C&amp;(x+5)-6%3C0.5%20%5C%5C%0A%20%20%20%205.5%20%3C&amp;x+5%3C6.5%20%5C%5C%0A%20%20%20%200.5%20%3C&amp;x%3C1.5%20%5C%5C%0A%5Ctext%7BIf%20%7D%200.5%20%3Cx%3C1.5,%20&amp;%5Ctext%7B%20then%20%7D%205.5%20%3Cx+5%3C6.5%20%5C%5C%0A%5Ctherefore%20%5Ctext%7BIf%20%7D%7Cx-1%7C%3C0.5,%20&amp;%5Ctext%7B%20then%20%7D%20%7C(x+5)-6%7C%3C0.5%20(%5Cbecause%20(0.5.1.5)%20%5Ctext%7B%20is%20symmetric%20about%20%7Dx=1)%0A%5Cend%7Baligned%7D%0A"></p>
<p>If the interval of <img src="https://latex.codecogs.com/png.latex?x"> is not symmetric about x=a, the smaller number is chosed as <img src="https://latex.codecogs.com/png.latex?%5Cdelta">. 만약 <img src="https://latex.codecogs.com/png.latex?x"> 의 구간이 <img src="https://latex.codecogs.com/png.latex?a"> 를 기준으로 대칭이 아니라면 더 짧은 근방을 <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> 로 설정한다.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BIf%20%7D%7Cx-1%7C%3C0.5,%20%5Ctext%7B%20then%20%7D%20%7C(x+5)-6%7C%3C0.5"> 을 해석하면</p>
<p><img src="https://latex.codecogs.com/png.latex?a=1"> 을 중심으로 <img src="https://latex.codecogs.com/png.latex?0.5(=%5Cdelta)"> 근방의 <img src="https://latex.codecogs.com/png.latex?x"> 를 설정하면, <img src="https://latex.codecogs.com/png.latex?L=6"> 을 중심으로 한 <img src="https://latex.codecogs.com/png.latex?0.5%20(=%5Cepsilon)"> 근방의 <img src="https://latex.codecogs.com/png.latex?f(x)"> 를 얻을 수 있다.</p>
<ul>
<li>Prove that <img src="https://latex.codecogs.com/png.latex?%5Clim_%7Bx%20%5Cto%203%7D%20(4x-5)=7"></li>
</ul>
<p>Proof)</p>
<p>The 1st step is to find <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> : <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20%5Ctext%7BIf%20%7D%20%7Cx-3%7C%3C%5Cdelta,%20&amp;%5Ctext%7B%20then%20%7D%20%7C4x-5%7C-7%3C%5Cepsilon%20%5C%5C%0A%20%20%20%20%7C4x-5%7C-7&amp;=%7C4x-12%7C=4%7Cx-3%7C%20%5C%5C%0A%20%20%20%204%7Cx-3%7C%3C%5Cepsilon%20%5C%5C%0A%20%20%20%20%5Ctext%7BIf%20%7D%20%7Cx-3%7C%3C%5Cdelta,%20&amp;%5Ctext%7B%20then%20%7D%204%7Cx-3%7C%3C%5Cepsilon%20%5C%5C%0A%20%20%20%20%5Ctext%7BIf%20%7D%20%7Cx-3%7C%3C%5Cdelta,%20&amp;%5Ctext%7B%20then%20%7D%20%7Cx-3%7C%3C%5Cfrac%7B%5Cepsilon%7D%7B4%7D%20%5C%5C%0A%20%20%20%20%5Ctherefore%20%5Cdelta%20=%20%5Cfrac%7B%5Cepsilon%7D%7B4%7D%0A%5Cend%7Baligned%7D%0A"></p>
<p>The 2nd step is to prove that the <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> works:</p>
<p>Given <img src="https://latex.codecogs.com/png.latex?%5Cepsilon%3E0">, choose <img src="https://latex.codecogs.com/png.latex?%5Cdelta=%5Cfrac%7B%5Cepsilon%7D%7B4%7D"> <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20%20%20%5Ctext%7BIf%20%7D%200%3C%7Cx-3%7C%3C%5Cdelta,%20&amp;%5Ctext%7B%20then%20%7D%204%7Cx-3%7C%3C4%5Cdelta=4%5Cfrac%7B%5Cepsilon%7D%7B4%7D=%5Cepsilon%20%5C%5C%0A%20%20%20%20%5Ctext%7BThus,%20%7D%20%5Ctext%7BIf%20%7D%200%3C%7Cx-3%7C%3C%5Cdelta,%20&amp;%5Ctext%7B%20then%20%7D%20%7C(4x-5)-7%7C%3C%5Cepsilon%20%5C%5C%0A%20%20%20%20%5Ctherefore%20%5Clim_%7Bx%20%5Cto%203%7D(4x-5)=7%0A%5Cend%7Baligned%7D%0A"></p>
</section>
</section>
</div>
</div>
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">
<div id="English" class="tab-pane fade" aria-labelledby="English-tab">

</div>
<p>reference : james steward, Calculus</p>
</div>



</div></ul> ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/epsilon_delta/index.html</guid>
  <pubDate>Mon, 13 Mar 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>CNN</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/DL/2023-03-10_cnn/index.html</link>
  <description><![CDATA[ 



<section id="introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<section id="fully-connected-layer-mlp의-문제점" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="fully-connected-layer-mlp의-문제점"><span class="header-section-number">1.1</span> Fully Connected Layer (MLP)의 문제점</h2>
<p>Affine Layer는 인접하는 Layers의 nodes가 모두 연결되고 출력의 수가 임의로 정해지는 특징을 갖는데 이 때 data shape가 무시가 되는 단점이 있다. 이미지 데이터는 보통 (weight, height, color channel) 형태의 shape를 갖지만 MLP에서 이 3차원 구조가 1차원으로 flatten된다. 다시 말해서, 3차원의 이미지 pixels이라는 여러 독립 변수의 위치적 상관성이 1차원화 되면서 무시가 된다.</p>
<p>많은 일반 머신러닝 모델이나 통계 분석 모델은 독립 변수가 독립이라는 가정이 고려되어야 하지만 이미지의 독립 변수들이 서로 독립이 아니다. 픽셀값은 그 위치에 따라서 서로 상관성이 존재한다. 초기엔 독립 변수인 픽셀을 일렬로 늘어뜨려 input으로 사용했지만 위치 기반 픽셀의 상관성 정도를 자세히 반영하진 못했다. 이를 보완하기 위해 CNN에서는 <strong>region feature</strong>가 고안됐다. 이처럼, CNN은 이미지 인식 분야에서 독보적인 영역을 갖고 있다.</p>
</section>
<section id="region-feature" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="region-feature"><span class="header-section-number">1.2</span> Region Feature</h2>
<p>Region Feature 또는 Graphic Feature라고도 한다. 픽셀의 지역 정보를 학습할 수 있는 신경망 구조가 CNN이다.</p>
</section>
</section>
<section id="cnn" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> CNN</h1>
<div id="fig-CNN_structure" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="kmink3225.netlify.app/images/cnn/figure1.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: CNN Structure Example</figcaption><p></p>
</figure>
</div>
<p><strong>Convolutional Neural Network</strong> (CNN)은 합성곱(convolution)으로 이루어진 인공신경망으로 Region Feature를 학습하기 위한 모형이다. CNN은</p>
<ul>
<li>region feature를 추출하기 위한 convolution layer,</li>
<li>activation function,</li>
<li>feature dimension을 위한 pooling layer</li>
<li>fully connected layer (Multi Layer Perceptron (MLP) or Affine Transformation)</li>
<li>Softmax function</li>
</ul>
<p>로 구성되어 있다 (See Figure&nbsp;1).</p>
<section id="convolution-layer-conv" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="convolution-layer-conv"><span class="header-section-number">2.1</span> Convolution Layer (Conv)</h2>
<p>kernel 또는 filter라고 불리는 특징 추출기(Feature detector)를 사용하여 데이터의 특징을 추출하는 CNN 모델의 핵심 부분이다. kernel 를 정의해 입력 층의 이미지의 feature를 추출한다. kernel는 region feature의 크기와 weight을 정의하게 된다. 예를 들어, kernel을 (3x3)으로 정하면 9칸에 가중치를 설정하여 이미지 픽셀값 (a part of input feature map)과 kernel의 weight의 선형결합으로 conv layer를 구성하는 하나의 값을 얻어낸다 (See Figure&nbsp;1 의 노란색 사각형).</p>
<p>convolution layer의 input/output은 보통 feature map이라고 부르며 input data를 input feature map, output data를 output feature map로 부르기도 한다. 즉, feature map 과 input/output data는 같은 의미로 사용되고 feature map = input data + kernel (= receptive field = filter)로 구성된다.</p>
<section id="convolution-operation" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="convolution-operation"><span class="header-section-number">2.1.1</span> Convolution Operation</h3>
<p>Convolution Operation (합성곱 연산)은 filter operation (filter 연산)이라고도 불린다. Figure&nbsp;2 을 보면 입력 데이터 (이미지의 pixels)와 filter의 가중치가 element-wise 별로 곱해져 더해진다. 이 연산을 fused-multiply-add (FMA) or multiply-accumulate operation 라고도 부른다. 예를 들어, input data의 4, 5, 2, 9, 6, 4, 2, 2, 5와 filter1 의 1, 1, 1, 0, 0, 0, -1, -1, -1 가 곱해지고 더해져 4, 5, 2, 0, 0, 0, -2, -2, -5의 결과가 Conv Layer의 output data의 한 칸을 구성하게 된다.</p>
<div id="fig-conv_operation" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="kmink3225.netlify.app/images/cnn/figure2.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;2: Convolution Operation Example</figcaption><p></p>
</figure>
</div>
<p>이렇게, 2차원 입력에 대한 convolution (conv) operation은 Figure&nbsp;3 과 같이 동작한다. Sharpen filter라고 쓰여진 3x3 행렬은 kernel로서 입력 데이터의 특징을 추출하는데, 입력 데이터의 전체를 보는 것이 아닌 kernel size 만큼의 일부분만을 보며 특징을 추출한다. feature map은 kernel의 개수만큼 생성되는데 일반적으로 다양한 특징을 추출하기 위해 하나의 conv layer에서 여러개의 kernel을 사용한다. kernel size에 정해진 규칙은 없으나 주로 3*3 많이 사용하며 대게 conv layer마다 다른 kernel size를 적용한다. Fully connected layer에서의 weight는 CNN에서 filter의 weight과 대응되고 CNN에서의 bias는 항상 scalar로 주어진다.</p>
<div id="fig-conv-operation-process" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="kmink3225.netlify.app/images/cnn/figure3.gif" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3: Convolution Operation Process Example</figcaption><p></p>
</figure>
</div>
</section>
<section id="합성곱-연산을-위한-설정-사항" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="합성곱-연산을-위한-설정-사항"><span class="header-section-number">2.1.2</span> 합성곱 연산을 위한 설정 사항</h3>
<ul>
<li>padding : 입력 데이터의 테두리를 0으로 채워 데이터의 크기를 늘려준다
<ul>
<li><strong>왜 padding을 사용하는가?</strong> padding이 없을 경우 합성곱은 입력 데이터의 1행 1열부터 시작된다. 그런데 합성곱은 입력 데이터에서 kernel size만큼의 영역을 하나로 축소하여 특징을 추출하기 때문에 이 경우 입력 데이터의 가장자리, edge 부분의 특징을 추출하기 어렵다. edge의 특징까지 추출하고자 하면 적어도 0행 0열부터 kernel을 적용해야 하는데 허공에서 element-wise 계산을 할 수 없으니 0을 추가해준다. 다시 말해서, padding은 output data size를 조정할 목적으로 사용된다. <img src="kmink3225.netlify.app/docs/blog/posts/DL/2023-03-10_cnn/output_featuremap.png" id="fig-output_featuremap" class="img-fluid" alt="Output Feature Map"></li>
</ul></li>
<li>stride : kernel이 얼만큼씩 이동하면서 합성곱 계산을 할 것인지를 의미한다.
<ul>
<li>stride를 키우게 되면 output data size가 작아지기 때문에 일반적으로 한 칸씩 이동한다. <img src="kmink3225.netlify.app/images/cnn/stride.PNG" id="fig-stride" class="img-fluid" alt="Stride Example"></li>
</ul></li>
<li>weight sharing:<br>
</li>
<li>kernel size : kernel의 행과 열 개수
<ul>
<li>사이즈가 작을수록 국소 단위의 특징을 추출한다.</li>
</ul></li>
<li>kernel 개수 또는 channel 개수 : 몇 개의 feature map을 추출하고 싶은지에 따라 kernel 개수를 정한다. <img src="kmink3225.netlify.app/images/cnn/channel number.PNG" id="fig-channel_number" class="img-fluid" alt="Channel Number"></li>
<li>이미지 데이터에서의 channel 예시
<ul>
<li>고양이 이미지와 같이 컬러 이미지 데이터는 하나의 이미지에 대해 Red, Green, Blue (RGB) 3개의 색상으로 이루어져 있다 <img src="kmink3225.netlify.app/images/cnn/image_featuremap.png" id="fig-img_featuremap" class="img-fluid" alt="RGB 이미지를 red, green, blue channel 별 분리하여 표시"> <img src="kmink3225.netlify.app/images/cnn/image_featuremap_convolution.png" id="fig-img_featuremap_conv" class="img-fluid" alt="이미지 데이터의 RGB channel에 대한 convolution 계산 예시"></li>
</ul></li>
</ul>
</section>
<section id="feature-map의-shape-계산-방법" class="level3" data-number="2.1.3">
<h3 data-number="2.1.3" class="anchored" data-anchor-id="feature-map의-shape-계산-방법"><span class="header-section-number">2.1.3</span> feature map의 shape 계산 방법</h3>
<p>feature map은 다음 레이어의 입력 데이터가 되기 때문에 feature map의 shape을 계산할 수 있어야한다.</p>
<section id="dimension-input-data-size" class="level4" data-number="2.1.3.1">
<h4 data-number="2.1.3.1" class="anchored" data-anchor-id="dimension-input-data-size"><span class="header-section-number">2.1.3.1</span> 2 Dimension Input Data Size</h4>
<p>다음과 같이 output data size계산을 위한 notation을 정의할 때,</p>
<ul>
<li>input data size : <img src="https://latex.codecogs.com/png.latex?(H,W)"></li>
<li>filter size : <img src="https://latex.codecogs.com/png.latex?(FH,%20FW)"></li>
<li>output data size : <img src="https://latex.codecogs.com/png.latex?(OH,%20OW)"></li>
<li>padding : <img src="https://latex.codecogs.com/png.latex?P"> (width number)</li>
<li>stride : <img src="https://latex.codecogs.com/png.latex?S"></li>
<li>a function to make the calculation result an integer
<ul>
<li>floor function : <img src="https://latex.codecogs.com/png.latex?%5Clfloor%20%5Ctext%7B%20%7D%20%5Crfloor"></li>
<li>ceiling : <img src="https://latex.codecogs.com/png.latex?%5Clceil%20%5Ctext%7B%20%7D%20%5Crceil"></li>
<li>rounding to the nearest integer: <img src="https://latex.codecogs.com/png.latex?%5Clfloor%20%5Ctext%7B%20%7D%20%5Crceil"></li>
</ul></li>
</ul>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%20%20OH=&amp;%5Clfloor%5Cfrac%7BH+2P-FH%7D%7BS%7D+1%5Crfloor%5C%5C%0A%20%20OW=&amp;%5Clfloor%5Cfrac%7BW+2P-FW%7D%7BS%7D+1%5Crfloor%0A%5Cend%7Baligned%7D%0A"></p>
<p>의 관계식을 따르게 된다.</p>
<ul>
<li>예시1- input size: (4x4), P:1, S:1, filter size : (3x3)일 때, <img src="https://latex.codecogs.com/png.latex?(OH,OW)=(4,4)"></li>
<li>예시2- input size: (7x7), P:0, S:2, filter size : (3x3)일 때, <img src="https://latex.codecogs.com/png.latex?(OH,OW)=(3,3)"></li>
<li>예시3- input size: (28x31), P:2, S:3, filter size : (5x5)일 때, <img src="https://latex.codecogs.com/png.latex?(OH,OW)=(10,11)"></li>
</ul>
</section>
<section id="dimension-input-data-size-1" class="level4" data-number="2.1.3.2">
<h4 data-number="2.1.3.2" class="anchored" data-anchor-id="dimension-input-data-size-1"><span class="header-section-number">2.1.3.2</span> 3 Dimension Input Data Size</h4>
<p>길이 또는 채널 방향으로 feature map이 늘어나기 때문에 그 결과는 Figure&nbsp;2 과 같이 나온다. 반드시 input data의 channel 수와 output data channel수가 같아야한다. 채널이 3개면 filter 당 3장의 feature map이 나오게 된다. filter의 종류의 수 weight의 종류의 수로 output data의 길이를 늘리려면 (즉, 다수의 채널로 만드려면) filter의 수 (=weight의 종류)를 늘리면 된다. FN: Flter Number일 때 filter의 가중치 데이터 크기는 (output data channel, input data channel, height, width)로 표현한다. Bias는 <img src="https://latex.codecogs.com/png.latex?(FN,1,1)"> 로 표현하여 채널 하나에 값 하나씩 할당되게 디자인한다. Output data size는 <img src="https://latex.codecogs.com/png.latex?(FN,OH,OW)"> 로 표현된다.</p>
<p>참고) <img src="https://latex.codecogs.com/png.latex?%0A(FN,1,1)%20+%20(FN,OH,OW)%20%5Coverset%7B%5Ctext%7Bbroadcasting%7D%7D%20%5Crightarrow%20(FN,OH,OW)%0A"></p>
<ul>
<li>예시- 채널=3, (FH,FW)=(4,4), <img src="https://latex.codecogs.com/png.latex?FN=20"> 이면 <img src="https://latex.codecogs.com/png.latex?(20,3,4,4)"> 로 표현</li>
</ul>
</section>
</section>
</section>
<section id="batch-processing" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="batch-processing"><span class="header-section-number">2.2</span> Batch Processing</h2>
<p>데이터를 (데이터수, 채널 수, 높이, 너비) <img src="https://latex.codecogs.com/png.latex?=%20(N,C,H,W)"> 순으로 저장하여 처리하여 NN에 4차원 데이터가 하나가 흐를 때마다 데이터 N개의 합성곱 연산이 발생한다. N번의 처리를 한번에 수행한다.</p>
</section>
<section id="pooling-layer" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="pooling-layer"><span class="header-section-number">2.3</span> Pooling Layer</h2>
</section>
<section id="fully-connected-layer" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="fully-connected-layer"><span class="header-section-number">2.4</span> Fully Connected Layer</h2>


</section>
</section>

 ]]></description>
  <category>DL</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/DL/2023-03-10_cnn/index.html</guid>
  <pubDate>Thu, 09 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/docs/blog/posts/DL/2023-03-10_cnn/output_featuremap.png" medium="image" type="image/png" height="95" width="144"/>
</item>
</channel>
</rss>
