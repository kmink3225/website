<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Kwangmin Kim</title>
<link>kmink3225.netlify.app/docs/blog/index.html</link>
<atom:link href="kmink3225.netlify.app/docs/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>blog</description>
<generator>quarto-1.2.313</generator>
<lastBuildDate>Tue, 31 Dec 2999 15:00:00 GMT</lastBuildDate>
<item>
  <title>Blog Content List</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/content_list.html</link>
  <description><![CDATA[ 



<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Scalars are denoted with a lower-case letter (ex a ) or a non-bolded lower-case Greek letter (ex <img src="https://latex.codecogs.com/png.latex?%5Calpha"> ).</li>
<li>Vectors are denoted using a bold-faced lower-case letter (ex <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20a">).</li>
<li>Matrices are denoted using a bold-faced upper-case letter (ex <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20%5Cphi">) or a bold-faced upper-case Greek letter (ex <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20%5CPhi">).</li>
<li>Tensors are denoted using a bold-faced upper-case letter with multiple subscripts or superscripts, indicating the number of indices and the dimensions of the tensor along each axis.
<ul>
<li>A second-order tensor (also known as a matrix) <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> with dimensions <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20m"> can be represented as: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A_%7Bij%7D"> where <img src="https://latex.codecogs.com/png.latex?i%20=%201,%5Cdots,m"> and <img src="https://latex.codecogs.com/png.latex?j%20=%201,%5Cdots,n">, which are the indices that run over the rows and columns of the matrix, respectively.</li>
<li>A third-order tensor <img src="https://latex.codecogs.com/png.latex?T"> with dimensions <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20m%20%5Ctimes%20p"> can be represented as: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A_%7Bijk%7D"> where <img src="https://latex.codecogs.com/png.latex?i%20=%201,%5Cdots,m">, <img src="https://latex.codecogs.com/png.latex?j%20=%201,%5Cdots,n">, which are <img src="https://latex.codecogs.com/png.latex?i">, and <img src="https://latex.codecogs.com/png.latex?k%20=%201,%5Cdots,p"> <img src="https://latex.codecogs.com/png.latex?j">, and <img src="https://latex.codecogs.com/png.latex?k">, which are the indices that run over the three dimensions of the tensor.</li>
</ul></li>
</ul>
</div>
</div>
<section id="contents" class="level1">
<h1>Contents</h1>
<ul>
<li><a href="../../../docs/blog/posts/DL/guide_map/index.html">Deep Learning</a></li>
<li><a href="../../../docs/blog/posts/ML/guide_map/index.html">Machine Learning</a></li>
<li><a href="../../../docs/blog/posts/Mathmatics/guide_map/index.html">Mathematics</a></li>
<li><a href="../../../docs/blog/posts/statistics/guide_map/index.html">Statistics</a></li>
<li><a href="../../../docs/blog/posts/Engineering/guide_map/index.html">Engineering</a></li>
<li><a href="../../../docs/blog/posts/Patent/guide_map/index.html">Patent</a></li>
<li><a href="../../../docs/blog/posts/Language/guide_map/index.html">Language</a></li>
<li><a href="../../../docs/blog/posts/Surveilance/guide_map/index.html">Surveilance</a></li>
</ul>
</section>
<section id="reference" class="level1">
<h1>Reference</h1>
<ul>
<li>Statistics
<ul>
<li>George Casella &amp; Rogeer L. Berger - Statistcal Inference, 2nd Edition</li>
<li>Dobson and Barnett (2008) An Introduction to Generalized Linear Model. 3rd Ed. Chapman &amp; Hall.</li>
<li>Fitzmaurice, Laird and Ware (2011) Applied Longitudinal Analysis. 2nd Ed. Wiley.</li>
<li>Hosmer, Lemeshow and May (2008) Applied Survival Analysis. 2nd Ed. Wiley.</li>
<li>슬기로운 통계생활 - https://www.youtube.com/<span class="citation" data-cites="statisticsplaybook">@statisticsplaybook</span></li>
<li>슬기로운 통계생활 - https://github.com/statisticsplaybook</li>
<li>Fast Campus, Coursera, Inflearn</li>
<li>그 외 다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Mathematics
<ul>
<li>James Stewart - Calculus Early Transcedentals, 7th Eidition &amp; any James Stewart series</li>
<li>GILBERT STRANG - Introduction to Linear Algebra, 4th Edition.</li>
<li>임장환 - 머신러닝, 인공지능, 컴퓨터 비전 전공자를 위한 최적화 이론</li>
<li>Fast Campus, Coursera, Inflearn</li>
<li><a href="https://www.youtube.com/playlist?list=PLaqQvlCBe8vIkIEb4GX2ZZ1A4tFYeXR5W">8일간의 선형대수학 기초(이상준 경희대 교수)</a></li>
<li><a href="https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/">Linear Algebra(Prof.&nbsp;Gilbert Strang, MIT Open Courseware)</a></li>
<li><a href="https://github.com/fastai/numerical-linear-algebra/blob/master/README.md">Computational Linear Algebra for Coders</a></li>
<li><a href="http://immersivemath.com/ila/">Immersive linear Algebra</a></li>
<li><a href="https://www.3blue1brown.com/topics/linear-algebra">3blue1brown</a></li>
<li>그 외 다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Machine Learning
<ul>
<li>Gareth M. James, Daniela Witten, Trevor Hastie, Robert Tibshirani - An Introduction to Statistical Learning: With Applications in R 2nd Edition</li>
<li>Trevor Hastie, Robert Tibshirani, Jerome H. Friedman - The Elements of Statistical Learning 2nd Edition</li>
<li>Fast Campus, Coursera, Inflearn</li>
<li>그 외 다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Deep Learning
<ul>
<li>Saito Koki - Deep Learning from Scratch 1,2,3 (밑바닥부터 시작하는 딥러닝 1,2,3)</li>
<li>조준우 - 머신러닝·딥러닝에 필요한 기초 수학 with 파이썬</li>
<li>조준우 - https://github.com/metamath1/noviceml</li>
<li>동빈나 - https://www.youtube.com/c/dongbinna</li>
<li>혁펜하임 - https://www.youtube.com/channel/UCcbPAIfCa4q0x7x8yFXmBag</li>
<li>Fast Campus, Coursera, Inflearn</li>
<li>다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Engineering
<ul>
<li>Fast Campus, Coursera, Inflearn</li>
<li>그 외 다수의 Youtube, and Documents from Googling</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>All List</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/content_list.html</guid>
  <pubDate>Tue, 31 Dec 2999 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Statistics</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/statistics/guide_map/index.html</link>
  <description><![CDATA[ 



<p><strong>(Draft)</strong></p>
<section id="contents-list" class="level1">
<h1>Contents List</h1>
<section id="basic" class="level2">
<h2 class="anchored" data-anchor-id="basic">Basic</h2>
<section id="probability-theory" class="level3">
<h3 class="anchored" data-anchor-id="probability-theory">Probability Theory</h3>
<ul>
<li>2023-02-05, Set Theory</li>
<li>2023-02-05, [Basics of Probability Theory - Axiomatic Foundations]</li>
<li>2023-02-05, [Basics of Probability Theory - Calculus of Probabilities]</li>
<li>2023-02-05, <a href="../../../../../docs/blog/posts/statistics/2023-02-05_probability/index.html">Basics of Probability Theory - Probability</a></li>
<li>2023-02-05, <a href="../../../../../docs/blog/posts/statistics/2023-02-05_conditional_probability/index.html">Conditional Probability</a></li>
<li>2023-02-05, [Independence]</li>
<li>2023-02-05, <a href="../../../../../docs/blog/posts/statistics/2023-02-05_bayes_rule/index.html">Bayes’ Rule</a></li>
<li>2023-02-05, Random Variable</li>
<li>1111-11-11, Probability Distribution</li>
</ul>
</section>
<section id="transformations-and-expectations" class="level3">
<h3 class="anchored" data-anchor-id="transformations-and-expectations">Transformations and Expectations</h3>
<ul>
<li>2023-02-21, <a href="../../../../../docs/blog/posts/statistics/2023-02-21_transformation/index.html">Transformation of Random Variables</a></li>
<li>1111-11-11, Expected Value vs Realizaed Value</li>
<li>1111-11-11, Variance</li>
<li>1111-11-11, Covariance and Correlation</li>
<li>2023-02-28, <a href="../../../../../docs/blog/posts/statistics/2023-02-28_mgf/index.html">Moment Generating Function, MGF</a></li>
</ul>
</section>
<section id="exponential-family-distributions" class="level3">
<h3 class="anchored" data-anchor-id="exponential-family-distributions">Exponential Family Distributions</h3>
<ul>
<li>Discrete Random Variable
<ul>
<li>2023-02-27,<a href="../../../../../docs/blog/posts/statistics/2023-02-27_exponential_family/discrete_bernoulli.html">Bernoulli Distribution</a></li>
<li>2023-02-28,<a href="../../../../../docs/blog/posts/statistics/2023-02-27_exponential_family/discrete_binomial.html">Binomial Distribution</a></li>
<li>2023-03-01,<a href="../../../../../docs/blog/posts/statistics/2023-02-27_exponential_family/discrete_poisson.html">Poisson Distribution</a></li>
<li>2023-03-01,<a href="../../../../../docs/blog/posts/statistics/2023-02-27_exponential_family/discrete_geometric.html">Geometric Distribution</a></li>
<li>1111-11-11, Hypergeometric Distribution</li>
</ul></li>
<li>Continuous Random Variable
<ul>
<li>1111-11-11, Normal Distribution</li>
<li>1111-11-11, Exponential Distribution</li>
<li>1111-11-11, Beta Distribution</li>
<li>1111-11-11, Chi-squared Distribution</li>
</ul></li>
<li>1111-11-11,</li>
</ul>
</section>
<section id="multiple-random-variables" class="level3">
<h3 class="anchored" data-anchor-id="multiple-random-variables">Multiple Random Variables</h3>
<ul>
<li>1111-11-11, Joint Distribution and Marginal Distribution</li>
</ul>
</section>
<section id="point-estimation" class="level3">
<h3 class="anchored" data-anchor-id="point-estimation">Point Estimation</h3>
<ul>
<li>1111-11-11, Estimation Methods - Method of Moments</li>
<li>2023-03-29, Estimation Methods - <a href="../../../../../docs/blog/posts/statistics/2023-03-25_MLE/index.html">Maximum Likelihood Estimation &amp; Statistical Bias</a></li>
<li>1111-11-11, Estimation Methods - Bayesian Estimation</li>
<li>1111-11-11, Estimation Methods - The EM Algorithm</li>
<li>1111-11-11, Evaluation Methods of Estimators - Mean Squared Error</li>
<li>1111-11-11, Evaluation Methods of Estimators - Best Unbiased Estimators</li>
<li>1111-11-11, Evaluation Methods of Estimators - Sufficiency and Unbiasedness</li>
<li>1111-11-11, Evaluation Methods of Estimators - Loss Function Optimality</li>
</ul>
</section>
</section>
<section id="hypothesis-testing" class="level2">
<h2 class="anchored" data-anchor-id="hypothesis-testing">Hypothesis Testing</h2>
<ul>
<li>1111-11-11, Hypothesis Testing</li>
<li>1111-11-11, Permutation Test</li>
</ul>
<section id="methods-of-finding-tests" class="level3">
<h3 class="anchored" data-anchor-id="methods-of-finding-tests">Methods of Finding Tests</h3>
<ul>
<li>1111-11-11, Likelihood Ratio Tests</li>
<li>1111-11-11, Bayesian Tests</li>
<li>1111-11-11, Union-Intersection and Intersection-Union Tets</li>
</ul>
</section>
<section id="methods-of-evaluating-tests" class="level3">
<h3 class="anchored" data-anchor-id="methods-of-evaluating-tests">Methods of Evaluating Tests</h3>
<ul>
<li>1111-11-11, Power</li>
<li>1111-11-11, Error Proabilities and the Power Function</li>
<li>1111-11-11, Most Powerful Tests</li>
<li>2022-12-28, <a href="../../../../../docs/blog/posts/statistics/2022-12-08-P-value/index.html">p-values</a></li>
<li>1111-11-11, Loss Function Optimality</li>
<li>1111-11-11, Multiple Testing</li>
<li>1111-11-11, Sample Size Calculation</li>
<li>1111-11-11, A/B Testing</li>
<li>2023-01-07, <a href="../../../../../docs/blog/posts/statistics/2023-01-07-anova/index.html">ANOVA</a>
<ul>
<li>2023-01-27, <a href="../2023-01-27_ANCOVA/">ANCOVA</a></li>
<li>2023-01-27, <a href="../2023-01-27_rmANOVA/">repeated measures ANOVA</a></li>
<li>2023-01-28, <a href="../2023-01-28_MANOVA/">MANOVA</a></li>
</ul></li>
</ul>
</section>
</section>
<section id="categorical-data-analysis" class="level2">
<h2 class="anchored" data-anchor-id="categorical-data-analysis">Categorical Data Analysis</h2>
<ul>
<li>1111-11-11, Introduction</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>2022-12-28,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>2023-01-07,</li>
<li>2023-01-27,</li>
<li>2023-01-27,</li>
<li>2023-01-28,</li>
</ul>
</section>
<section id="regression" class="level2">
<h2 class="anchored" data-anchor-id="regression">Regression</h2>
<ul>
<li>1111-11-11, Least Square and Simple Linear Regression</li>
<li>1111-11-11, Multiple Linear Regression</li>
</ul>
<section id="generalized-linear-models" class="level3">
<h3 class="anchored" data-anchor-id="generalized-linear-models">Generalized Linear Models</h3>
<ul>
<li>1111-11-11, Logistic Regression</li>
<li>1111-11-11, Multinomial Regression</li>
<li>1111-11-11, Poisson Regression</li>
<li>1111-11-11, Poisson Regression</li>
<li>1111-11-11, Poisson Regression</li>
</ul>
</section>
</section>
<section id="longitudinal-data-analysis" class="level2">
<h2 class="anchored" data-anchor-id="longitudinal-data-analysis">Longitudinal Data Analysis</h2>
<ul>
<li>2023-03-23, <a href="../../../../../docs/blog/posts/statistics/LDA/1_intro.html">LDA (1) - Intro</a></li>
<li>2023-03-23, <a href="../../../../../docs/blog/posts/statistics/LDA/2_covariance_model.html">LDA (2) - Concepts &amp; Covariance Models</a></li>
<li>2023-03-25, <a href="../LDA/intro.qmd">LDA (3) - WLS &amp; REML</a></li>
<li>2023-03-25, <a href="../LDA/intro.qmd">LDA (4) - Respiratory Infection Data Example</a></li>
<li>2023-03-28, <a href="../LDA/intro.qmd">LDA (5) - Epileptic Seizures Data Example</a></li>
</ul>
<section id="mixed-models" class="level3">
<h3 class="anchored" data-anchor-id="mixed-models">Mixed Models</h3>
<ul>
<li>1111-11-11, Linear Mixed Models</li>
</ul>
</section>
</section>
<section id="generalized-additive-models" class="level2">
<h2 class="anchored" data-anchor-id="generalized-additive-models">Generalized Additive Models</h2>
</section>
<section id="survival-analysis" class="level2">
<h2 class="anchored" data-anchor-id="survival-analysis">Survival Analysis</h2>
<ul>
<li>1111-11-11, Cox-Hazard Model</li>
</ul>


</section>
</section>

 ]]></description>
  <category>Statistics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/statistics/guide_map/index.html</guid>
  <pubDate>Fri, 30 Apr 2100 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Machine Learning</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/ML/guide_map/index.html</link>
  <description><![CDATA[ 



<p><strong>(Draft)</strong></p>
<section id="contents-list" class="level1">
<h1>Contents List</h1>
<section id="basic" class="level2">
<h2 class="anchored" data-anchor-id="basic">Basic</h2>
<section id="r" class="level3">
<h3 class="anchored" data-anchor-id="r">R</h3>
</section>
<section id="python" class="level3">
<h3 class="anchored" data-anchor-id="python">Python</h3>
<section id="tensor-flow-framework" class="level4">
<h4 class="anchored" data-anchor-id="tensor-flow-framework">Tensor Flow Framework</h4>
<ul>
<li>2023-02-03, <a href="../../../../../docs/blog/posts/ML/2023-02-03_tf_introduction/index.html">Tensor Flow Introduction</a></li>
</ul>
</section>
<section id="pytorch-framework" class="level4">
<h4 class="anchored" data-anchor-id="pytorch-framework">Pytorch Framework</h4>
<ul>
<li>2023-02-03, <a href="../../../../../docs/blog/posts/ML/2023-02-03_pytorch_introduction/index.html">Pytorch Introduction</a></li>
</ul>
</section>
</section>
</section>
<section id="machine-learning-methods" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning-methods">Machine Learning Methods</h2>
<section id="supervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="supervised-learning">Supervised Learning</h3>
<ul>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Logistic Regression]</li>
<li>0000-00=00, [Generative Models]
<ul>
<li>0000-00=00, [Linear Discriminant Analysis]</li>
<li>0000-00=00, [Quadratic Discriminant Analysis]</li>
<li>0000-00=00, [Naive Bayes]</li>
</ul></li>
<li>0000-00=00, [Resampling Methods]</li>
<li>0000-00=00, [Regularization]</li>
<li>0000-00=00, [Smoothing]</li>
<li>0000-00=00, [Tree Based Methods]</li>
<li>0000-00=00, [Support Vector Machine]</li>
<li>0000-00=00, [PCR]</li>
<li>0000-00=00, [PLS]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
</ul>
</section>
<section id="unupervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="unupervised-learning">Unupervised Learning</h3>
<ul>
<li>0000-00=00, [PCA]</li>
<li>0000-00=00, [K means clustering]</li>
<li>0000-00=00, [Hierarchical Clustering]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
<li>0000-00=00, [Linear Regression]</li>
</ul>


</section>
</section>
</section>

 ]]></description>
  <category>ML</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/ML/guide_map/index.html</guid>
  <pubDate>Wed, 31 Mar 2100 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Mathematics</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/guide_map/index.html</link>
  <description><![CDATA[ 



<section id="contents" class="level1">
<h1>Contents</h1>
<section id="basic" class="level2">
<h2 class="anchored" data-anchor-id="basic">Basic</h2>
<ul>
<li>2023-03-24, <a href="../../../../../docs/blog/posts/Mathmatics/variables/index.html">Variable types</a></li>
<li>1111-11-11, <a href="../../../../../docs/blog/posts/Mathmatics/function/index.html">Function</a>
<ul>
<li>2023-01-31, <a href="../../../../../docs/blog/posts/Mathmatics/function/univariable_scalar_function.html">Function (1) - Univariable Scalar Function (One to One)</a></li>
<li>2023-01-31, <a href="../../../../../docs/blog/posts/Mathmatics/function/multivariable_scalar_function.html">Function (2) - Multi-variable Scalar Function (Many to One)</a></li>
<li>2023-01-31, <a href="../../../../../docs/blog/posts/Mathmatics/function/univariable_vector_function.html">Function (3) - Univariable Vector Function (One to Many)</a></li>
<li>2023-01-31, <a href="../../../../../docs/blog/posts/Mathmatics/function/mutivariable_vector_function.html">Function (4) - Multi-variable Vector Function (Many to Many)</a></li>
<li>2023-02-18, <a href="../../../../../docs/blog/posts/Mathmatics/function/composite_function.html">Function (5) - Composite Function</a></li>
</ul></li>
<li>2023-02-18, <a href="../../../../../docs/blog/posts/Mathmatics/transformation/index.html">Transformations of Functions</a></li>
<li>1111-11-11, Vector &amp; Matrix</li>
<li>2023-03-15, <a href="../epsilon_delta/">Limit, <img src="https://latex.codecogs.com/png.latex?%5Cepsilon-%5Cdelta"> Method</a></li>
<li>Differentiation
<ul>
<li>2023-02-04, <a href="../../../../../docs/blog/posts/Mathmatics/differentiation/2023-02-04_uni_derivative.html">Derivative (1) - Univariable Scalar Funtion</a></li>
<li>1111-11-11, <a href="../../../../../docs/blog/posts/Mathmatics/differentiation/2023-02-10_composite_partial_derivative.html">Derivative (2) - Chain Rule &amp; Partial Derivative</a></li>
<li>1111-11-11, Derivative (3) - Higher Order Derivative</li>
<li>1111-11-11, Derivative (4) - Mean Value Theorem</li>
<li>1111-11-11, Derivative (5) - Gradient</li>
</ul></li>
<li>2023-03-15, <a href="../../../../../docs/blog/posts/Mathmatics/taylor_series/index.html">Talyer’s Series</a></li>
<li>1111-11-11, Gradient Direction</li>
<li>1111-11-11, Random Variable</li>
<li>1111-11-11, Probability Distribution</li>
<li>1111-11-11, Information Theory - Entropy</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
</ul>
</section>
<section id="linear-algebra" class="level2">
<h2 class="anchored" data-anchor-id="linear-algebra">Linear Algebra</h2>
<ul>
<li>2023-03-30, <a href="../../../../../docs/blog/posts/Mathmatics/linear_algebra/01.basic_vector.html">Basics (1) - Vector Operations</a></li>
<li>2023-03-30, <a href="../../../../../docs/blog/posts/Mathmatics/linear_algebra/02.basic_matrix.html">Basics (2) - Matrix Operations</a></li>
<li>2023-03-30, <a href="../../../../../docs/blog/posts/Mathmatics/linear_algebra/03.basic_special_matrix.html">Basics (3) - Special Matrix</a></li>
<li>1111-11-11, Inner Product</li>
<li>1111-11-11, Linear Combination</li>
<li>1111-11-11,</li>
<li>1111-11-11, Linear Independence</li>
<li>1111-11-11, Basis, Dimension, &amp; Rank</li>
<li>1111-11-11, Outer Product</li>
<li>1111-11-11, Eigen Value &amp; Eigen Vector</li>
<li>1111-11-11, Eigen Decomposition</li>
<li>1111-11-11, Singular Value Decomposition (SVD)</li>
<li>1111-11-11, Gram-Schmidt</li>
<li>1111-11-11, Group</li>
<li>1111-11-11, Orthogonal Matrix</li>
<li>1111-11-11, Rotation &amp; Group</li>
<li>2023-04-02, <a href="../../../../../docs/blog/posts/Mathmatics/linear_algebra/quadratic_form.html">Matrix Transformation (5) - Quadratic Form</a></li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
</ul>
</section>
<section id="optimization" class="level2">
<h2 class="anchored" data-anchor-id="optimization">Optimization</h2>
<ul>
<li>2023-03-23, <a href="../../../../../docs/blog/posts/Mathmatics/optimization/minimizer.html">Minimizer &amp; Minimum</a></li>
<li>1111-11-11, Convex Set</li>
<li>1111-11-11, Convex Function</li>
<li>1111-11-11, Unconstrained Optimization</li>
<li>1111-11-11, Non-linear Least Square</li>
<li>1111-11-11, Largrange Multiplier Method
<ul>
<li>1111-11-11, Largrange Primal Function</li>
<li>1111-11-11, Largrange Dual Function</li>
<li>1111-11-11, KKT conditions</li>
</ul></li>
<li>1111-11-11, Gradient Descent Optimizers</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
</ul>
</section>
<section id="reference" class="level2">
<h2 class="anchored" data-anchor-id="reference">Reference</h2>
<ul>
<li>Statistics
<ul>
<li>George Casella &amp; Rogeer L. Berger - Statistcal Inference, 2nd Edition</li>
<li>슬기로운 통계생활 - https://www.youtube.com/<span class="citation" data-cites="statisticsplaybook">@statisticsplaybook</span></li>
<li>슬기로운 통계생활 - https://github.com/statisticsplaybook</li>
<li>다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Mathematics
<ul>
<li>James Stewart - Calculus Early Transcedentals, 7th Eidition</li>
<li>any James Stewart series</li>
<li>임장환 - 머신러닝, 인공지능, 컴퓨터 비전 전공자를 위한 최적화 이론</li>
<li>다수의 Youtube, and Documents from Googling</li>
</ul></li>
<li>Deep Learning
<ul>
<li>조준우 - 머신러닝·딥러닝에 필요한 기초 수학 with 파이썬</li>
<li>조준우 - https://github.com/metamath1/noviceml</li>
<li>동빈나 - https://www.youtube.com/c/dongbinna</li>
<li>혁펜하임 - https://www.youtube.com/channel/UCcbPAIfCa4q0x7x8yFXmBag</li>
<li>다수의 Youtube, and Documents from Googling</li>
</ul></li>
</ul>


</section>
</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/guide_map/index.html</guid>
  <pubDate>Sun, 28 Feb 2100 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Deep Learning</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/DL/guide_map/index.html</link>
  <description><![CDATA[ 



<p><strong>(Draft)</strong></p>
<section id="contents-list" class="level1">
<h1>Contents List</h1>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<ul>
<li>1111-11-11, Artificial Intelligence</li>
<li>1111-11-11, Perceptron</li>
<li>1111-11-11, Artificial Neural Netwroks (ANN)
<ul>
<li>1111-11-11, activation functions</li>
<li>1111-11-11, output layer design</li>
</ul></li>
<li>1111-11-11, loss function</li>
<li>1111-11-11, numerical differentiation</li>
<li>1111-11-11, gradient descent</li>
<li>1111-11-11, backpropagation</li>
<li>1111-11-11, optimizer
<ul>
<li>1111-11-11, stochastic gradient descent</li>
<li>1111-11-11, momentum</li>
<li>1111-11-11, adaGrad</li>
<li>1111-11-11, adam</li>
<li>1111-11-11, weight initalization</li>
</ul></li>
<li>1111-11-11, batch normalization</li>
<li>1111-11-11, dropout</li>
<li>1111-11-11, tuning parameter</li>
<li>1111-11-11, auto-encoder</li>
<li>1111-11-11, stacked auto-encoder</li>
<li>1111-11-11, denoising auto-encoder(DAE)</li>
</ul>
<section id="convolutional-neural-network-cnn" class="level3">
<h3 class="anchored" data-anchor-id="convolutional-neural-network-cnn">Convolutional Neural Network (CNN)</h3>
<ul>
<li>2023-03-10, <a href="../../../../../docs/blog/posts/DL/2023-03-10_cnn/index.html">CNN (1) - Concept</a></li>
<li>2023-03-10, <a href="">CNN (2) - Practice</a></li>
</ul>
</section>
<section id="natural-language-process-nlp" class="level3">
<h3 class="anchored" data-anchor-id="natural-language-process-nlp">Natural Language Process (NLP)</h3>
<ul>
<li>1111-11-11, word2vec</li>
<li>1111-11-11, improved word2vec</li>
</ul>
</section>
<section id="recurrent-neural-network-rnn" class="level3">
<h3 class="anchored" data-anchor-id="recurrent-neural-network-rnn">Recurrent Neural Network (RNN)</h3>
</section>
<section id="gate-recurrent-unit-gru" class="level3">
<h3 class="anchored" data-anchor-id="gate-recurrent-unit-gru">Gate Recurrent Unit (GRU)</h3>
</section>
<section id="long-short-term-memory-lstm" class="level3">
<h3 class="anchored" data-anchor-id="long-short-term-memory-lstm">Long Short-Term Memory (LSTM)</h3>
</section>
<section id="attention-transformer" class="level3">
<h3 class="anchored" data-anchor-id="attention-transformer">Attention (Transformer)</h3>
</section>
<section id="bidirectional-encoder-representations-from-transformers-bert" class="level3">
<h3 class="anchored" data-anchor-id="bidirectional-encoder-representations-from-transformers-bert">Bidirectional Encoder Representations from Transformers (BERT)</h3>
</section>
<section id="generative-pre-training-transformer-gpt" class="level3">
<h3 class="anchored" data-anchor-id="generative-pre-training-transformer-gpt">Generative Pre-training Transformer (GPT)</h3>


</section>
</section>
</section>

 ]]></description>
  <category>DL</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/DL/guide_map/index.html</guid>
  <pubDate>Thu, 31 Dec 2099 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Engineering</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Engineering/guide_map/index.html</link>
  <description><![CDATA[ 



<section id="it-terminology" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="it-terminology"><span class="header-section-number">1</span> IT Terminology</h2>
<ul>
<li>0000-00-00, Terminology</li>
</ul>
</section>
<section id="data-structure" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="data-structure"><span class="header-section-number">2</span> Data Structure</h2>
<ul>
<li>2023-01-17, <a href="../2023-01-17_data_structure_overview/">Overview</a></li>
<li>2023-01-18, <a href="../2023-01-18_array/">Array</a></li>
<li>2023-01-18, <a href="../2023-01-18_linked_list/">Linked List</a></li>
<li>2023-01-18, <a href="../2023-01-18_python_list/">Python List</a></li>
<li>2023-01-19, <a href="../2023-01-19_stack/">Stack</a></li>
<li>2023-01-19, <a href="../2023-01-19_queue/">Queue</a></li>
<li>2023-01-26, <a href="../2023-01-19_deque/">Deque</a></li>
<li>2023-01-26, <a href="../2023-01-20_binary_search_tree/">Binary Search Tree</a></li>
<li>2023-01-20, <a href="../2023-01-20_priority_queue/">Priority Queue</a></li>
<li>2023-01-20, <a href="../2023-01-20_graph/">Graph</a></li>
</ul>
</section>
<section id="conda" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="conda"><span class="header-section-number">3</span> Conda</h2>
</section>
<section id="docker" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="docker"><span class="header-section-number">4</span> Docker</h2>
<ul>
<li>2023-01-30, Docker Install</li>
<li>2023-01-31, Docker Compose</li>
<li>2023-02-01, Docker Container</li>
</ul>
</section>
<section id="dynamic-documentation" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="dynamic-documentation"><span class="header-section-number">5</span> Dynamic Documentation</h2>
<ul>
<li>2023-01-19, <a href="https://quarto.org/docs/get-started/">Quarto</a></li>
<li>2023-01-19, <a href="https://github.com/yihui/xaringan">xaringan[R]</a></li>
<li>2023-01-19, <a href="https://bookdown.org/yihui/bookdown/get-started.html">Bookdown[R]</a></li>
<li>2023-01-19, <a href="https://decile-team-distil.readthedocs.io/en/latest/index.html">DISTL</a></li>
<li>2023-01-26, <a href="https://www.sphinx-doc.org/en/master/">Sphinx[Python]</a></li>
</ul>
</section>
<section id="aws-cloud" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="aws-cloud"><span class="header-section-number">6</span> AWS Cloud</h2>
<p>Coursera Course: AWS Fundamentals</p>
<ul>
<li>2023-03-09, <a href="../../../../../docs/blog/posts/Engineering/2023-03-02_aws/computing_networking.html">Computing and Networking</a></li>
<li>2023-03-12, <a href="../../../../../docs/blog/posts/Engineering/2023-03-02_aws/storage_database.html">Storage and Database</a></li>
</ul>
</section>
<section id="azure-cloud" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="azure-cloud"><span class="header-section-number">7</span> Azure Cloud</h2>
</section>
<section id="data-modeling" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="data-modeling"><span class="header-section-number">8</span> Data Modeling</h2>
</section>
<section id="apache-airflow" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="apache-airflow"><span class="header-section-number">9</span> Apache Airflow</h2>
</section>
<section id="apache-spark" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="apache-spark"><span class="header-section-number">10</span> Apache Spark</h2>
</section>
<section id="front-end" class="level2" data-number="11">
<h2 data-number="11" class="anchored" data-anchor-id="front-end"><span class="header-section-number">11</span> Front End</h2>
</section>
<section id="back-end" class="level2" data-number="12">
<h2 data-number="12" class="anchored" data-anchor-id="back-end"><span class="header-section-number">12</span> Back End</h2>


</section>

 ]]></description>
  <category>Engineering</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Engineering/guide_map/index.html</guid>
  <pubDate>Thu, 31 Dec 2099 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Language</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Language/guide_map/index.html</link>
  <description><![CDATA[ 



<p><strong>(Draft)</strong></p>
<section id="contents-list" class="level1">
<h1>Contents List</h1>
<section id="r" class="level2">
<h2 class="anchored" data-anchor-id="r">R</h2>
<ul>
<li>1111-11-11, tidyverse
<ul>
<li>1111-11-11, dplyr</li>
<li>1111-11-11, ggplot2</li>
<li>1111-11-11, tidyr</li>
<li>1111-11-11, readr</li>
<li>1111-11-11, purrr</li>
<li>1111-11-11, tibble</li>
<li>1111-11-11, stringr</li>
<li>1111-11-11, forcats</li>
</ul></li>
<li>1111-11-11, tidymodels</li>
<li>1111-11-11, R shiny</li>
</ul>
</section>
<section id="python" class="level2">
<h2 class="anchored" data-anchor-id="python">Python</h2>
<ul>
<li>1111-11-11, numpy</li>
<li>1111-11-11, pandas</li>
<li>1111-11-11, matplotlib</li>
<li>1111-11-11, seaborn</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
<li>1111-11-11,</li>
</ul>
</section>
<section id="sql" class="level2">
<h2 class="anchored" data-anchor-id="sql">SQL</h2>
<section id="sqlite" class="level3">
<h3 class="anchored" data-anchor-id="sqlite">SQLite</h3>
</section>
<section id="oracle-sql" class="level3">
<h3 class="anchored" data-anchor-id="oracle-sql">Oracle SQL</h3>
</section>
<section id="ms-sql" class="level3">
<h3 class="anchored" data-anchor-id="ms-sql">MS-SQL</h3>
</section>
<section id="postgre-sql" class="level3">
<h3 class="anchored" data-anchor-id="postgre-sql">Postgre SQL</h3>
</section>
</section>
<section id="linux" class="level2">
<h2 class="anchored" data-anchor-id="linux">Linux</h2>
</section>
<section id="powershell" class="level2">
<h2 class="anchored" data-anchor-id="powershell">Powershell</h2>
</section>
<section id="c" class="level2">
<h2 class="anchored" data-anchor-id="c">C++</h2>
</section>
<section id="javascript" class="level2">
<h2 class="anchored" data-anchor-id="javascript">Javascript</h2>


</section>
</section>

 ]]></description>
  <category>Language</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Language/guide_map/index.html</guid>
  <pubDate>Thu, 31 Dec 2099 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Patent</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Patent/guide_map/index.html</link>
  <description><![CDATA[ 



<p><strong>(Draft)</strong></p>
<section id="contents-list" class="level1">
<h1>Contents List</h1>
<section id="basic" class="level2">
<h2 class="anchored" data-anchor-id="basic">Basic</h2>


</section>
</section>

 ]]></description>
  <category>Patent</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Patent/guide_map/index.html</guid>
  <pubDate>Thu, 31 Dec 2099 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Content List, Validation</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Surveilance/guide_map/index.html</link>
  <description><![CDATA[ 



<section id="sgs" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sgs"><span class="header-section-number">1</span> SGS</h2>
<ul>
<li>0000-00-00, EN62304</li>
</ul>
</section>
<section id="fda" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="fda"><span class="header-section-number">2</span> FDA</h2>
<ul>
<li>2023-01-27, <a href="../../../../../docs/blog/posts/Surveilance/2022-12-10_FDA_sw_general_guidance/index.html">General Principles of SW Validation</a></li>
<li>2023-01-27, <a href="../../../../../docs/blog/posts/Surveilance/2023-01-27_FDA_sw_general_guidance_presentation/index.html">General Principles of SW Validation - Diagram Summary</a></li>
<li>1111-11-11, Guidance for the Content of Premarket Submissions for Software Contained in Medical Devices</li>
</ul>
</section>
<section id="dhf" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="dhf"><span class="header-section-number">3</span> DHF</h2>
</section>
<section id="public-health" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="public-health"><span class="header-section-number">4</span> Public Health</h2>
</section>
<section id="wet-lab" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="wet-lab"><span class="header-section-number">5</span> Wet Lab</h2>
<ul>
<li>0000-00-00, PCR (Polymerase Chain Reaction) Experiment</li>
</ul>


</section>

 ]]></description>
  <category>Surveilance</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Surveilance/guide_map/index.html</guid>
  <pubDate>Sat, 31 Dec 2089 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Matrix Transformation (4) - Biinear Form</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/11.bilinear_form.html</link>
  <description><![CDATA[ 



<section id="binear-form" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="binear-form"><span class="header-section-number">1</span> Binear Form</h2>
<p>A bilinear form of a matrix is a function that extends the linear form and takes two vectors as inputs and produces a scalar as output. It is linear in both of its arguments, meaning that it satisfies the following properties:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AB(%5Cmathbf%20u+%5Cmathbf%20v)&amp;=B(%5Cmathbf%20u+%5Cmathbf%20w)+B(%5Cmathbf%20v+%5Cmathbf%20w)%5C%5C%0AB(%5Cmathbf%20u,%5Calpha%20%5Cmathbf%20v)&amp;=%5Calpha%20B(%5Cmathbf%20u,%5Cmathbf%20v)%5C%5C%0AB(%5Calpha%5Cmathbf%20u,%5Cmathbf%20v)&amp;=%5Calpha%20B(%5Cmathbf%20u,%5Cmathbf%20v)%0A%5Cend%7Baligned%7D%0A"></p>
<p>for all vectors <img src="https://latex.codecogs.com/png.latex?u">, <img src="https://latex.codecogs.com/png.latex?v">, <img src="https://latex.codecogs.com/png.latex?w"> and scalars <img src="https://latex.codecogs.com/png.latex?%5Calpha">.</p>
<p>A bilinear form can be represented by a matrix <img src="https://latex.codecogs.com/png.latex?B"> such that <img src="https://latex.codecogs.com/png.latex?B_%7Bi,j%7D"> is the coefficient of the product <img src="https://latex.codecogs.com/png.latex?u_i%20v_j"> in the expansion of <img src="https://latex.codecogs.com/png.latex?B(u,v)">. The bilinear form can then be written as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AB(%5Cmathbf%20u,%5Cmathbf%20v)=%5Cmathbf%20u%5ET%20B%20%5Cmathbf%20v%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20u"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20v"> are column vectors and <img src="https://latex.codecogs.com/png.latex?B"> is a matrix.</p>
<p>For example, consider the bilinear form <img src="https://latex.codecogs.com/png.latex?B(%5Cmathbf%20u,%5Cmathbf%20v)%20=%20u_1%20v_1%20+%20u_2%20v_2">. This bilinear form can be represented by the matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AB=%5Cbegin%7Bbmatrix%7D1&amp;0%5C%5C0&amp;1%5Cend%7Bbmatrix%7D%0A"></p>
<p>and written as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AB(%5Cmathbf%20u,%5Cmathbf%20v)=%5Cbegin%7Bbmatrix%7Du_1&amp;%20u_2%5Cend%7Bbmatrix%7D%5Cbegin%7Bbmatrix%7D1&amp;0%5C%5C0&amp;1%5Cend%7Bbmatrix%7D%5Cbegin%7Bbmatrix%7Dv_1%5C%5Cv_2%5Cend%7Bbmatrix%7D=u_1v_1+u_2v_2%0A"></p>
<p>This bilinear form computes the dot product of <img src="https://latex.codecogs.com/png.latex?u"> and <img src="https://latex.codecogs.com/png.latex?v">, which measures the similarity between the two vectors. Bilinear forms are commonly used in applications such as optimization, geometry, and physics, where they capture the interaction between two quantities or variables.</p>
<p>The covariance matrix can be represented as a bilinear form using matrix multiplication. Let’s say we have a random vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20%5Bx_1,%20x_2,%20%5Cldots,%20x_n%5D%5ET"> with mean vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5Cmu%7D%20=%20%5B%5Cmu_1,%20%5Cmu_2,%20%5Cldots,%20%5Cmu_n%5D%5ET"> and covariance matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D">. Then, we can represent the covariance matrix as a bilinear form in the following way:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5CSigma&amp;=%5Coperatorname%7BE%7D%5B(%5Cmathbf%20x-%5Cmathbf%20%5Cmu)(%5Cmathbf%20x-%5Cmathbf%20%5Cmu)%5ET%5D%5C%5C%0A&amp;=%5Cfrac%7B1%7D%7Bn-1%7D%5Csum_%7Bi=1%7D%5E%7Bn%7D(x_i-%5Cbar%7Bx%7D)(x_i-%5Cbar%7Bx%7D)%5ET%0A%5Cend%7Baligned%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BE%7D"> denotes the expectation operator. We can expand this expression as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5CSigma&amp;=%5Coperatorname%7BE%7D%5B%5Cmathbf%20x%5Cmathbf%20x%5ET%5D-%5Cmathbf%20%5Cmu%5Cmathbf%20%5Cmu%5ET%0A%5Cend%7Baligned%7D%0A"></p>
<p>Now, we can represent the covariance matrix as a bilinear form using matrix multiplication as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5CSigma&amp;=%5Coperatorname%7BE%7D%5B(%5Cmathbf%20x-%5Cmathbf%20%5Cmu)(%5Cmathbf%20x-%5Cmathbf%20%5Cmu)%5ET%5D%5C%5C%0A&amp;=%5Csum_%7Bi=1%7D%5E%7Bn%7D%5Csum_%7Bj=1%7D%5E%7Bn%7D(%5Cmathbf%20x_i-%5Cmathbf%5Cmu_i)(%5Cmathbf%20x_i-%5Cmathbf%20%5Cmu_j)%0A%5Cend%7Baligned%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5B%5Cmathbf%7Bx%7D-%5Cmathbf%7B%5Cmu%7D%5D"> is the deviation of the random vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> from its mean vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5Cmu%7D">.</p>
<p>covariance matrix, and correlation matrix</p>
<p>One of the most famous examples is the use of bilinear forms in convolutional neural networks (CNNs), which are a type of deep learning model used for image and video recognition tasks.</p>
<p>In a CNN, a bilinear form is used to compute the similarity between a filter and a local region of an input image. This similarity measure is used to determine how much the filter “matches” the local region of the image, and is used to produce an output feature map.</p>
<p>More specifically, the bilinear form used in a CNN takes the form:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Az_%7Bi,j%7D%20=%20%5Csum_%7Bm=1%7D%5E%7BM%7D%5Csum_%7Bn=1%7D%5E%7BN%7D%20w_%7Bm,n%7Dx_%7Bi+m-1,j+n-1%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?z_%7Bi,j%7D"> is the output feature map at location <img src="https://latex.codecogs.com/png.latex?(i,j)">, <img src="https://latex.codecogs.com/png.latex?x_%7Bi+m-1,j+n-1%7D"> is the input image pixel at location <img src="https://latex.codecogs.com/png.latex?(i+m-1,j+n-1)">, and <img src="https://latex.codecogs.com/png.latex?w_%7Bm,n%7D"> is the weight of the filter at position <img src="https://latex.codecogs.com/png.latex?(m,n)">. This computation is performed for each location <img src="https://latex.codecogs.com/png.latex?(i,j)"> in the output feature map.</p>
<p>The bilinear form used in CNNs is a type of convolution operation, and is used to learn features such as edges, corners, and other patterns in the input image. CNNs with bilinear forms have achieved state-of-the-art performance on many image recognition tasks, including object detection, face recognition, and scene classification.</p>
<p>Bilinear forms also have applications in other areas of machine learning, such as natural language processing (NLP). In NLP, bilinear forms can be used to compute the similarity between two word embeddings, which are vector representations of words. This similarity measure can be used for tasks such as sentiment analysis, text classification, and machine translation.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AB(%5Cmathbf%7Bu%7D,%5Cmathbf%7Bv%7D)=%5Cmathbf%7Bu%7D%5ET%20%5Cmathbf%7BW%7D%5Cmathbf%7Bv%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bu%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> are word embeddings, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BW%7D"> is a weight matrix, and <img src="https://latex.codecogs.com/png.latex?B(%5Cmathbf%7Bu%7D,%5Cmathbf%7Bv%7D)"> represents the bilinear form used to compute the similarity between the two embeddings.</p>
<p>Overall, bilinear forms are a powerful tool for learning features from complex data such as images and text, and have many applications in deep learning and machine learning.</p>


</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/11.bilinear_form.html</guid>
  <pubDate>Sat, 01 Apr 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Matrix Transformation (3) - Linear Form</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/11.linear_form.html</link>
  <description><![CDATA[ 



<section id="linear-form" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="linear-form"><span class="header-section-number">1</span> Linear Form</h2>
<p>A linear form is a linear function that maps a vector space to its underlying field. Let <img src="https://latex.codecogs.com/png.latex?V"> be a vector space over a field <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BF%7D">, and let <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D(V,%5Cmathbb%7BF%7D)"> denote the set of all linear functions from <img src="https://latex.codecogs.com/png.latex?V"> to <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BF%7D">. A linear form on <img src="https://latex.codecogs.com/png.latex?V"> is an element of <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D(V,%5Cmathbb%7BF%7D)">.</p>
<p>A linear form <img src="https://latex.codecogs.com/png.latex?%5Cvarphi"> can be represented by a row vector of dimension <img src="https://latex.codecogs.com/png.latex?1%5Ctimes%20n">, where <img src="https://latex.codecogs.com/png.latex?n"> is the dimension of <img src="https://latex.codecogs.com/png.latex?V">. Let <img src="https://latex.codecogs.com/png.latex?%7B%5Cmathbf%7Be%7D_1,%20%5Cmathbf%7Be%7D_2,%20%5Cdots,%20%5Cmathbf%7Be%7D_n%7D"> be a basis for <img src="https://latex.codecogs.com/png.latex?V">, and let <img src="https://latex.codecogs.com/png.latex?%7B%5Calpha_1,%20%5Calpha_2,%20%5Cdots,%20%5Calpha_n%7D"> be the corresponding dual basis for <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D(V,%5Cmathbb%7BF%7D)">, such that <img src="https://latex.codecogs.com/png.latex?%5Calpha_i(%5Cmathbf%7Be%7Dj)%20=%20%5Cdelta%7Bij%7D"> (the Kronecker delta). Then, any linear form <img src="https://latex.codecogs.com/png.latex?%5Cvarphi%5Cin%5Cmathcal%7BL%7D(V,%5Cmathbb%7BF%7D)"> can be written as: <img src="https://latex.codecogs.com/png.latex?%0A%5Cvarphi(x)=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_ix_i=%5Cmathbf%20a%20%5Cmathbf%20x%5ET=%5Cmathbf%20x%20%5Cmathbf%20a%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%5Cin%20V"> is a column vector of dimension <img src="https://latex.codecogs.com/png.latex?n%5Ctimes%201">, <img src="https://latex.codecogs.com/png.latex?%5B%5Cmathbf%7Ba%7D%5D"> is the row vector representing <img src="https://latex.codecogs.com/png.latex?%5Cvarphi">, and <img src="https://latex.codecogs.com/png.latex?%5B%5Cmathbf%7Bx%7D%5D"> is the column vector representing <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?V%20=%20%5Cmathbb%7BR%7D%5E2"> be the vector space of 2-dimensional column vectors, and let <img src="https://latex.codecogs.com/png.latex?%5Cvarphi%5Cin%5Cmathcal%7BL%7D(V,%5Cmathbb%7BR%7D)"> be the linear form defined by <img src="https://latex.codecogs.com/png.latex?%5Cvarphi(%5Cbegin%7Bbmatrix%7Dx%5Cy%5Cend%7Bbmatrix%7D)%20=%203x%20-%202y">. Then, we can represent <img src="https://latex.codecogs.com/png.latex?%5Cvarphi"> as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5B%5Cmathbf%20a%5D=%5Cbegin%7Bbmatrix%7D%203%20&amp;%20-2%5Cend%7Bbmatrix%7D%20%5B%5Cmathbf%20x%5D=%5Cbegin%7Bbmatrix%7D%20x_1%20%5C%5C%20x_2%20%5Cend%7Bbmatrix%7D%20%5Cvarphi(x)=%5Csum_%7Bi=1%7D%5E%7Bn%7D%5Cmathbf%20a%5Cmathbf%20x%5ET=3x_1-2x_2%0A"></p>
<p>which shows that <img src="https://latex.codecogs.com/png.latex?%5Cvarphi"> is a linear form on <img src="https://latex.codecogs.com/png.latex?V">.</p>
<p>consider a linear regression model that predicts the price of a house based on its size and location. The model can be represented by the linear form:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cvarphi(x)=%5Cmathbf%20w%5Cmathbf%20x%5ET=%5Csum_%7Bi=1%7D%5E%7Bn%7Dw_ix_i=w_0+w_1x_1+w_2x_2%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cvarphi(%5Cmathbf%7Bx%7D)"> is the predicted price, <img src="https://latex.codecogs.com/png.latex?x_1"> is the size of the house, <img src="https://latex.codecogs.com/png.latex?x_2"> is a measure of the location (such as the distance from the city center), and <img src="https://latex.codecogs.com/png.latex?w_0">, <img src="https://latex.codecogs.com/png.latex?w_1">, and <img src="https://latex.codecogs.com/png.latex?w_2"> are the model parameters that control the intercept and the weights of the features. This linear form can be written in matrix form as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cvarphi(x)=%5Cmathbf%20x%5Cmathbf%20w=%5Cmathbf%20w%20%5Cmathbf%20x%5ET%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5B%5Cmathbf%7Bw%7D%5D"> is a row vector of the model parameters and <img src="https://latex.codecogs.com/png.latex?%5B%5Cmathbf%7Bx%7D%5D"> is a row vector of the features.</p>
<p>Linear forms can also be used in deep learning and machine learning models that involve linear transformations, such as fully connected layers in neural networks or linear classifiers. For example, consider a simple linear classifier that classifies images of digits into one of 10 classes. The classifier can be represented by the linear form:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cvarphi(x)=%5Cmathbf%20x%5Cmathbf%20w%20+%20b%20=%5Cmathbf%20w%20%5Cmathbf%20x%5ET%20+b%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cvarphi(%5Cmathbf%7Bx%7D)"> is the predicted class score, <img src="https://latex.codecogs.com/png.latex?%5B%5Cmathbf%7Bx%7D%5D"> is a row vector of the pixel values of the image, <img src="https://latex.codecogs.com/png.latex?%5B%5Cmathbf%7Bw%7D%5D"> is a row vector of the weights of the classifier, and <img src="https://latex.codecogs.com/png.latex?b"> is the bias term. This linear form can be used to classify the image by selecting the class with the highest score.</p>
<p>In both of these examples, linear forms are used to represent linear relationships between variables or features, and the model parameters are learned through training on a set of labeled examples.</p>


</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/11.linear_form.html</guid>
  <pubDate>Sat, 01 Apr 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Matrix Transformation (5) - Quadratic Form</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/11.matrix_transformation.html</link>
  <description><![CDATA[ 



<section id="matrix" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="matrix"><span class="header-section-number">1</span> Matrix</h2>
<p>A matrix is a rectangular array of elements, usually real numbers, arranged in rows and columns. If <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix, it can be represented as: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%20a_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B1n%7D%20%5C%5C%0A%20%20a_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B2n%7D%20%5C%5C%0A%20%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20a_%7Bm1%7D%20&amp;%20a_%7Bm2%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7Bmn%7D%0A%5Cend%7Bbmatrix%7D%0A"> where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of the matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
</section>
<section id="basic-matrix-operations" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="basic-matrix-operations"><span class="header-section-number">2</span> Basic Matrix Operations</h2>
<section id="matrix-addition" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="matrix-addition"><span class="header-section-number">2.1</span> Matrix addition</h3>
<p>The sum of two matrices of the same size is a matrix of the same size obtained by adding corresponding entries.</p>
<p>Given two <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">, their sum <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BA%7D%20+%20%5Cmathbf%7BB%7D"> is defined by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D=a_%7Bi,j%7D+b_%7Bi,j%7D%E2%80%8B%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%201%20&amp;%202%20%5C%5C%0A%20%203%20&amp;%204%20%5C%5C%0A%20%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20+%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-1%20&amp;%200%20%5C%5C%0A%20%202%20&amp;%20-3%20%5C%5C%0A%20%20-5%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%200%20&amp;%202%20%5C%5C%0A%20%205%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%2010%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="scalar-multiplication" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="scalar-multiplication"><span class="header-section-number">2.2</span> Scalar multiplication</h3>
<p>The product of a scalar and a matrix is a matrix obtained by multiplying each entry of the matrix by the scalar.</p>
<p>Given a scalar <img src="https://latex.codecogs.com/png.latex?k"> and an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, their product <img src="https://latex.codecogs.com/png.latex?k%5Cmathbf%7BA%7D"> is defined by: <img src="https://latex.codecogs.com/png.latex?%0A(k%5Cmathbf%7BA%7D)_%7Bi,j%7D%20=%20k(a_%7Bi,j%7D)%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A2%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A2%20&amp;%204%20%5C%5C%0A6%20&amp;%208%20%5C%5C%0A10%20&amp;%2012%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="matrix-multiplication" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="matrix-multiplication"><span class="header-section-number">2.3</span> Matrix multiplication</h3>
<p>The product of two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> is a matrix obtained by multiplying the rows of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> by the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">.</p>
<p>Given two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> with dimensions <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> and <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20p">, respectively, their product <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BAB%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20p"> matrix defined by: <img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D%20=%20%5Csum_%7Bk=1%7D%5En%20a_%7Bi,k%7Db_%7Bk,j%7D%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20p">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%0A-1%20&amp;%200%20&amp;%202%20%5C%5C%0A2%20&amp;%20-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A3%20&amp;%20-6%20&amp;%204%20%5C%5C%0A5%20&amp;%20-12%20&amp;%2010%20%5C%5C%0A7%20&amp;%20-18%20&amp;%2016%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="transpose" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="transpose"><span class="header-section-number">2.4</span> Transpose</h3>
<p>The transpose of an <img src="https://latex.codecogs.com/png.latex?m%20x%20n"> matrix A, denoted by <img src="https://latex.codecogs.com/png.latex?A%5ET">, is the <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix obtained by interchanging the rows and columns of A. Formally, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Ba_%7Bij%7D%5D"> is an m x n matrix, then its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET%20=%20%5Bb_%7Bij%7D%5D"> is an <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix where <img src="https://latex.codecogs.com/png.latex?b_%7Bij%7D"> = <img src="https://latex.codecogs.com/png.latex?a_%7Bji%7D"> for all <img src="https://latex.codecogs.com/png.latex?i"> and <img src="https://latex.codecogs.com/png.latex?j">. In other words, the element in the <img src="https://latex.codecogs.com/png.latex?i"> th row and <img src="https://latex.codecogs.com/png.latex?j"> th column of <img src="https://latex.codecogs.com/png.latex?A%5ET"> is equal to the element in the <img src="https://latex.codecogs.com/png.latex?j"> th row and ith column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>Given an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20m"> matrix defined by: $$ <em>{i,j}^T = </em>{j,i}</p>
<p>$$</p>
<ul>
<li>When <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is transposed, diagnoal entries(<img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D">) do not change but off-diagnoal elements(<img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D%20%5C;%20i%20%5Cneq%20j">) change.</li>
<li>A column vector is tranposed into a row vector, and vice versa.</li>
<li>symmetric matrix: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5ET"></li>
</ul>
<p>Example:</p>
<p>Let A be the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%5C%5C%0A4%20&amp;%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"> The transpose of A, denoted by A^T, is the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5ET%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%204%5C%5C%0A2%20&amp;%205%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="determinant" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="determinant"><span class="header-section-number">2.5</span> Determinant</h3>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> square matrix. The determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C"> or <img src="https://latex.codecogs.com/png.latex?%5Cdet(%5Cmathbf%7BA%7D)">, is a scalar value calculated as the sum of the products of the elements in any row or column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> with their corresponding cofactors, that is,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D=%5Csum_%7Bj=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column, and <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D"> is the cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">. The cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D">, is given by <img src="https://latex.codecogs.com/png.latex?(-1)%5E%7Bi+j%7D"> times the determinant of the <img src="https://latex.codecogs.com/png.latex?(n-1)%20%5Ctimes%20(n-1)"> matrix obtained by deleting the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>The determinant of an <img src="https://latex.codecogs.com/png.latex?n%20x%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is a scalar value denoted as <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C">. It is defined as the sum of all possible products of n elements taken one from each row and one from each column, where the sign of each product alternates according to the position of the element in the matrix. For example, the determinant of a <img src="https://latex.codecogs.com/png.latex?3%20x%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20="> <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%20a_%7B11%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B32%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A-%20a_%7B12%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A+%20a_%7B13%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%0A%5Cend%7Bvmatrix%7D%0A"></p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?3%20%5Ctimes%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%204%20&amp;%205%20&amp;%206%20%5C%5C%207%20&amp;%208%20&amp;%209%20%5Cend%7Bbmatrix%7D">. We can calculate the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> using any row or column. Let’s use the first column:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%201%0A%5Cbegin%7Bvmatrix%7D%0A5%20&amp;%206%20%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A-%204%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%203%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A+%207%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%205%20%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bvmatrix%7D%20=%200%0A"></p>
<p>Therefore, the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is zero.</p>
</section>
<section id="inverse" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="inverse"><span class="header-section-number">2.6</span> Inverse</h3>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?A"> of size <img src="https://latex.codecogs.com/png.latex?n"> is a matrix <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> such that the product of <img src="https://latex.codecogs.com/png.latex?A"> and <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> is the identity matrix <img src="https://latex.codecogs.com/png.latex?I_n">, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I_n">. If such a matrix exists, then <img src="https://latex.codecogs.com/png.latex?A"> is said to be invertible or non-singular.</p>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D"> and is defined as the unique matrix that satisfies the following equation: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BI%7D"> is the identity matrix. Not all matrices have an inverse, and a matrix that has an inverse is called invertible or nonsingular. A matrix that does not have an inverse is called singular.</p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?2%5Ctimes%202"> matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D.%0A"> The inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cfrac%7B1%7D%7B-2%7D%0A%5Cbegin%7Bbmatrix%7D%0A4%20&amp;%20-2%20%5C%5C%0A-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>We can verify that <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BI%7D"> by computing:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%20-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>Let me give another example and A be a <img src="https://latex.codecogs.com/png.latex?3x3"> square matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D">, is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B%5Ctext%7Bdet%7D(%5Cmathbf%7BA%7D)%7D%5Cbegin%7Bbmatrix%7D%0Aa_%7B22%7Da_%7B33%7D-a_%7B23%7Da_%7B32%7D%20&amp;%20a_%7B13%7Da_%7B32%7D-a_%7B12%7Da_%7B33%7D%20&amp;%20a_%7B12%7Da_%7B23%7D-a_%7B13%7Da_%7B22%7D%20%5C%5C%0Aa_%7B23%7Da_%7B31%7D-a_%7B21%7Da_%7B33%7D%20&amp;%20a_%7B11%7Da_%7B33%7D-a_%7B13%7Da_%7B31%7D%20&amp;%20a_%7B13%7Da_%7B21%7D-a_%7B11%7Da_%7B23%7D%20%5C%5C%0Aa_%7B21%7Da_%7B32%7D-a_%7B22%7Da_%7B31%7D%20&amp;%20a_%7B12%7Da_%7B31%7D-a_%7B11%7Da_%7B32%7D%20&amp;%20a_%7B11%7Da_%7B22%7D-a_%7B12%7Da_%7B21%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?det(%5Cmathbf%7BA%7D)"> is the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%20%5C%5C%0A0%20&amp;%201%20&amp;%204%20%5C%5C%0A5%20&amp;%206%20&amp;%200%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, <img src="https://latex.codecogs.com/png.latex?det(A)"> = -57, and the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B-57%7D%5Cbegin%7Bbmatrix%7D%0A-24%20&amp;%2018%20&amp;%205%20%5C%5C%0A20%20&amp;%20-15%20&amp;%20-4%20%5C%5C%0A-3%20&amp;%202%20&amp;%201%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>There are several formulas for finding the inverse of a matrix such as Gauss-Jordan Elimination, Adjoint method, Cramer’s rule, Inverse formula, etc. This topic is going to be handled in the other blogs.</p>
</section>
<section id="rank" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="rank"><span class="header-section-number">2.7</span> Rank</h3>
<p>The rank of a matrix is the dimension of the vector space spanned by its columns (or rows). It is denoted by <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Brank%7D(%5Cmathbf%7BA%7D)">.</p>
<p>For example, consider the following matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%20%20%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%20&amp;%203%5C%5C%0A%20%20%20%204%20&amp;%205%20&amp;%206%20%5C%5C%0A%20%20%20%207%20&amp;%208%20&amp;%209%5C%5C%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are linearly dependent since the third column is equal to the sum of the first two columns. Therefore, the dimension of the vector space spanned by the columns is 2, so the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is 2.</p>
</section>
<section id="trace" class="level3" data-number="2.8">
<h3 data-number="2.8" class="anchored" data-anchor-id="trace"><span class="header-section-number">2.8</span> Trace</h3>
<p>The trace of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)">, is defined as the sum of the diagonal elements of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">. In other words, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> matrix, then its trace is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D"> denotes the <img src="https://latex.codecogs.com/png.latex?i"> th diagonal element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%202%20&amp;%203%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%205%20&amp;%202%20%5C%5C%0A%20%201%20&amp;%201%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>Then, the trace of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)%20=%202%20+%205%20+%204%20=%2011"></p>
</section>
<section id="eigenvalues-and-eigenvectors" class="level3" data-number="2.9">
<h3 data-number="2.9" class="anchored" data-anchor-id="eigenvalues-and-eigenvectors"><span class="header-section-number">2.9</span> Eigenvalues and Eigenvectors</h3>
<p>Let A be an <img src="https://latex.codecogs.com/png.latex?n%20%C3%97%20n"> square matrix. A scalar <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is called an eigenvalue of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> if there exists a non-zero vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> such that <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BAv%7D=%5Clambda%5Cmathbf%7Bv%7D%0A"></p>
<p>Such a vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> is called an eigenvector corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda">.</p>
<p>Example:</p>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> be the matrix</p>
<p>To find the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">, we solve the characteristic equation <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%20=%200">, where I is the n × n identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%0A%20%20&amp;=%0A%20%20%20%20%5Cbegin%7Bvmatrix%7D%0A%20%20%20%203%20-%20%5Clambda%20&amp;%201%20%5C%5C%0A%20%20%20%201%20&amp;%203%20-%20%5Clambda%0A%20%20%20%20%5Cend%7Bvmatrix%7D%20%5C%5C%0A%20%20&amp;=%0A%20%20(3%20-%20%5Clambda)(3%20-%20%5Clambda)%20-%201%20%5C%5C%0A%20%20&amp;=%20%5Clambda%5E2%20-%206%5Clambda%20+%208%20=%200%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this quadratic equation gives us the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">: <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202"> and <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">.</p>
<p>To find the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%20%5Cmathbf%7B0%7D">, where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20I"> is the <img src="https://latex.codecogs.com/png.latex?2%20%5Ctimes%202"> identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%0A%20%20%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%20%201%20&amp;%201%20%5C%5C%0A%20%20%20%20%20%201%20&amp;%201%0A%20%20%20%20%5Cend%7Bbmatrix%7D%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20x%20%5C%5C%0A%20%20%20%20y%0A%20%20%5Cend%7Bbmatrix%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%200%20%5C%5C%0A%20%20%20%200%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this system of equations gives us the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D%20=%20%5Cbegin%7Bbmatrix%7D%20-1%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
<p>Similarly, for <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%204%5Cmathbf%20I)%5Cmathbf%7Bv%7D"> = <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D"> to get the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
</section>
<section id="singular-value-and-singluar-vectors" class="level3" data-number="2.10">
<h3 data-number="2.10" class="anchored" data-anchor-id="singular-value-and-singluar-vectors"><span class="header-section-number">2.10</span> Singular value and Singluar Vectors</h3>
<p>The singular value decomposition (SVD) of a matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> is a factorization of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> into the product of three matrices as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20m"> orthogonal matrix, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> rectangular diagonal matrix with non-negative real numbers on the diagonal, and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> orthogonal matrix.</p>
<p>The diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> are called the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Csigma_1,%20%5Csigma_2,%20%5Cldots,%20%5Csigma_r"> (where <img src="https://latex.codecogs.com/png.latex?r"> is the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">), and are arranged in descending order. The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> are called the left and right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, respectively, and are orthonormal vectors.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be a 3 by 2 matrix given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%5C%5C%0A%20%20%20%203%20&amp;%204%5C%5C%0A%20%20%20%205%20&amp;%206%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The SVD of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.23%20&amp;%20-0.53%20&amp;%20-0.81%5C%5C%0A%20%20-0.53%20&amp;%20-0.72%20&amp;%200.45%5C%5C%0A%20%20-0.81%20&amp;%200.45%20&amp;%20-0.38%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%209.53%20&amp;%200%5C%5C%0A%20%200%20&amp;%200.90%5C%5C%0A%20%200%20&amp;%200%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.62%20&amp;%20-0.78%5C%5C%0A%20%20-0.78%20&amp;%200.62%0A%5Cend%7Bbmatrix%7D%5ET%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where the left singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D">, the right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D">, and the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5CSigma%7D">.</p>
<ul>
<li>연립 방정식을 행렬의 곱으로 나타내보기 <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bmatrix%7Dx_1+2y_1=4%5C%5C2x_1+5y_1=9%5Cend%7Bmatrix%7D%20%5Cquad%20%5Cquad%20%5Cquad%20%5Cbegin%7Bmatrix%7Dx_2+2y_2=3%5C%5C2x_2+5y_2=7%5Cend%7Bmatrix%7D"> <img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20%5C%5C%202%20&amp;%205%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20%5C%5C%20y_1%20&amp;%20y_2%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%204%20&amp;%209%20%5C%5C%203%20&amp;%207%20%5Cend%7Bbmatrix%7D"></li>
<li>중요한 사실(….당연한 사실?)
<ul>
<li>곱셈의 왼쪽 행렬의 열 수와, 오른쪽 행렬의 행 수가 같아야 가능함
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20B_%7Bo%20%5Ctimes%20p%7D"> 에서 <img src="https://latex.codecogs.com/png.latex?n%20=%20o"> 여야 곱셈 성립</li>
</ul></li>
<li>곱셈의 결과 행렬의 크기 = 곱셈의 왼쪽 행렬의 행 수 <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> 곱셈의 오른쪽 행렬의 열 수
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20B_%7Bo%20%5Ctimes%20p%7D%20=%20C_%7Bm%20%5Ctimes%20p%7D"></li>
</ul></li>
<li>교환법칙(Commutative property)이 성립하지 않음
<ul>
<li><img src="https://latex.codecogs.com/png.latex?AB%20%5Cneq%20BA"></li>
</ul></li>
</ul></li>
<li>행렬 곱셈의 여러가지 관점
<ul>
<li>내적으로 바라보기 <img src="https://latex.codecogs.com/png.latex?%20A%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20"> <img src="https://latex.codecogs.com/png.latex?%20AB%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%7D%20&amp;%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_1%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_1%5ET%20b_m%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_2%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_2%5ET%20b_m%7D%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_m%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%5ET%20b_m%7D%20%5Cend%7Bbmatrix%7D"></li>
<li>rank-1 matrix의 합 (또 안가르쳐준 개념 먼저 사용중…..-_-) <img src="https://latex.codecogs.com/png.latex?AB%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%7D%20&amp;%20%5Cmathbf%7Ba_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Bb_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Bb_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7Ba_1%20b_1%5ET%7D%20+%20%5Cmathbf%7Ba_2%20b_2%5ET%7D%20+%20%5Ccdots%20+%20%5Cmathbf%7Ba_m%20b_m%5ET%7D"></li>
<li>column space로 바라보기 <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%7D%20&amp;%20%5Cmathbf%7Ba_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20%5C%5C%20x_2%20%5C%5C%20%5Cvdots%20%5C%5C%20x_m%20%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7Ba_1%7D%20x_1%20+%20%5Cmathbf%7Ba_2%7D%20x_2%20+%20%5Ccdots%20+%20%5Cmathbf%7Ba_m%7D%20x_m%20"> (스칼라배의 합)
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20%5C%5C%200%20&amp;%201%20%5Cend%7Bbmatrix%7D"> 는 2차원 좌표평면의 모든 점을, <img src="https://latex.codecogs.com/png.latex?A=%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%200%20%5C%5C%200%20&amp;%201%20&amp;%200%20%5C%5C%200%20&amp;%200%20&amp;%201%20%5Cend%7Bbmatrix%7D">은 3차원 좌표평면의 모든 점 표현 가능</li>
<li><img src="https://latex.codecogs.com/png.latex?AB%20=%20A%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%7D%20&amp;%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20A%20%5Cmathbf%7Bb_1%7D%20&amp;%20A%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20A%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D"></li>
<li>column space: A의 column vector로 만들 수 있는 부분 공간</li>
</ul></li>
<li>row space로 바라보기 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%5ET%7DA%20=%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20&amp;%20%5Ccdots%20&amp;%20x_m%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20=%20x_1%20%5Cmathbf%7Ba_1%5ET%7D%20+%20x_2%20%5Cmathbf%7Ba_2%5ET%7D%20+%20%5Ccdots%20+%20x_m%20%5Cmathbf%7Ba_m%5ET%7D%20"></li>
</ul></li>
</ul>
</section>
</section>
<section id="열공간column-space" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="열공간column-space"><span class="header-section-number">3</span> 열공간(Column Space)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/g0eaDeVRdZk" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>column space: column vector 들이 span 하는 space
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A">의 column space = <img src="https://latex.codecogs.com/png.latex?C(A)"> 또는 <img src="https://latex.codecogs.com/png.latex?range(A)"></li>
</ul></li>
<li>span: vector들의 linear combination 으로 나타낼 수 있는 모든 vector를 모은 집합
<ul>
<li>vector에 따라, 점일수도 선일수도 평면일 수도 있음</li>
<li>vector space를 이 vector들이 span하는 space → column space는 행렬의 열들이 span하는 space</li>
</ul></li>
<li>vector의 선형 결합(linear combination): vector에 스칼라배를 해서 더하는 것
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D"> 과 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D">의 linear combination으로 2차원 좌표평면 나타내기 <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" class="img-fluid"></li>
</ul></li>
</ul>
</section>
<section id="선형-독립linear-independent" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="선형-독립linear-independent"><span class="header-section-number">4</span> 선형 독립(Linear Independent)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/mOOI4-BfjGQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>…and also see</p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/9F4PZ_1orF0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>선형 독립(linearly independent)인 vectors: (선형 결합을 통해) 더 고차원을 span할 수 있게 해줌</li>
<li>orthogonal 하면 independent
<ul>
<li>but independent해도 항상 orthogonal하지는 않음 (Independent &gt; Orthogonal)</li>
</ul></li>
<li>definition: <img src="https://latex.codecogs.com/png.latex?a_1%20%5Cmathbf%7Bv_1%7D%20+%20a_2%20%5Cmathbf%7Bv_2%7D%20+%20a_3%20%5Cmathbf%7Bv_3%7D%20%5Ccdots%20a_n%20%5Cmathbf%7Bv_n%7D%20=%20%5Cmathbf%7B0%7D"> 를 만족하는 <img src="https://latex.codecogs.com/png.latex?a_1,%20a_2,%20a_3,%20%5Ccdots%20a_n"> 이 <img src="https://latex.codecogs.com/png.latex?a_1%20=%20a_2%20=%20a_3%20=%20%5Ccdots%20=%20a_n%20=%200"> 밖에 없을때
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D">는 모든 elements가 <img src="https://latex.codecogs.com/png.latex?0">인 벡터</li>
<li>예: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%202%20%5Cend%7Bbmatrix%7D"> 는 <img src="https://latex.codecogs.com/png.latex?-2%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D%20+%201%20%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%202%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> 이 되므로, linearly independent 하지 않음</li>
<li>independent한 vector 들의 수 = 표현할 수 있는 차원의 dimension</li>
</ul></li>
</ul>
</section>
<section id="기저basis" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="기저basis"><span class="header-section-number">5</span> 기저(basis)</h2>
<ul>
<li>주어진 vector space를 span하는 linearly independent한 vectors</li>
<li>어떤 공간을 이루는 필수적인 구성요소</li>
<li>orthogonal 하면 orthogonal basis</li>
<li>예: 2차원 좌표평면에 대해
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"> : orthogonal basis</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"> : orthogonal 하지 않은 basis</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> : linearly independent 하지 않으므로 basis 아님</li>
</ul></li>
</ul>
</section>
<section id="항등행렬identity-matrix-역행렬inverse-matrix-대각행렬diagonal-matrix-직교행렬orthogonal-matrix" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="항등행렬identity-matrix-역행렬inverse-matrix-대각행렬diagonal-matrix-직교행렬orthogonal-matrix"><span class="header-section-number">6</span> 항등행렬(identity matrix), 역행렬(inverse matrix), 대각행렬(Diagonal Matrix), 직교행렬(orthogonal matrix)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/XqOvyfMUAwA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="identity-matrix항등행렬" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="identity-matrix항등행렬"><span class="header-section-number">6.1</span> Identity matrix(항등행렬)</h3>
<ul>
<li>항등원: 임의의 원소에 대해 연산하면 자기 자신이 나오게 하는 원소 (by namu.wiki)
<ul>
<li>실수에서 곱셈의 항등원은 1</li>
</ul></li>
<li>행렬의 항등원: 항등행렬(<img src="https://latex.codecogs.com/png.latex?I">) <img src="https://latex.codecogs.com/png.latex?I%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%200%20&amp;%201%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%200%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%201%20%5Cend%7Bbmatrix%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20I_%7Bn%20%5Ctimes%20n%20=%20n%7D%20=%20A_%7Bm%20%5Ctimes%20n%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?I_%7Bm%20%5Ctimes%20m%20=%20m%7D%20%5Ctimes%20A_%7Bm%20%5Ctimes%20n%7D%20=%20A_%7Bm%20%5Ctimes%20n%7D"></li>
</ul></li>
</ul>
</section>
<section id="sec-inv" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="sec-inv"><span class="header-section-number">6.2</span> Inverse matrix(역행렬)</h3>
<ul>
<li>역원: 연산 결과 항등원이 나오게 하는 연소
<ul>
<li>실수에서 곱셈의 역원은 지수의 부호가 반대인 역수 (by namu.wiki): <img src="https://latex.codecogs.com/png.latex?a%20%5Ctimes%20a%5E%7B-1%7D%20=%201"></li>
</ul></li>
<li>행렬의 역원: 역행렬(<img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D">) <img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I%20,%20A%5E%7B-1%7D%20%5Ctimes%20A%20=%20I">
<ul>
<li>존재하지 않는 경우도 있음</li>
<li>존재하면 Invertible(nonsingular, nondegenerate) matrix라고 불림
<ul>
<li>존재하지 않으면 singular, degenerate라고 불림</li>
</ul></li>
<li>square matrix(정사각행렬, <img src="https://latex.codecogs.com/png.latex?m%20=%20n">)은 특수한 경우를 제외하면 역행렬이 항상 존재
<ul>
<li>역행렬이 존재하지 않는특수한 경우: (나중에 배울) determinant가 0인 경우</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?m%20%5Cneq%20n">인 행렬의 경우에는 역행렬이 존재하지 않음
<ul>
<li>다만, 경우에 따라 <img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I"> 를 만족하거나(right inverse), <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D%20%5Ctimes%20A%20=%20I">를 만족하는(left inverse)는 <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D">이 존재함</li>
</ul></li>
<li>연립 방정식을 matrix로 나타냈을 때, 역행렬을 이용해서 해를 찾을 수 있음 <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cmathbf%7Bb%7D%20%5CRightarrow%20A%5E%7B-1%7DA%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D%20%5CRightarrow%20I%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D%20%5CRightarrow%20%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D"></li>
</ul></li>
</ul>
</section>
<section id="diagonal-matrix대각행렬" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="diagonal-matrix대각행렬"><span class="header-section-number">6.3</span> Diagonal Matrix(대각행렬)</h3>
<ul>
<li>diagonal element(대각 원소)외의 모든 elements(off-diagonal elements)가 0인 matrix <img src="https://latex.codecogs.com/png.latex?%20D%20=%20Diag(%5Cmathbf%7Ba%7D)%20=%20%5Cbegin%7Bbmatrix%7D%20a_%7B1,1%7D%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%200%20&amp;%20a_%7B2,2%7D%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%200%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%20a_%7Bn,n%7D%20%5Cend%7Bbmatrix%7D">
<ul>
<li>identity matrix는 diagonal matrix</li>
<li>diagnomal matrix는 symmetric matrix 이기도 함</li>
<li>보통은 square matrix에서 주로 사용됨
<ul>
<li>square matrix가 아니면서 diagonal matrix인 경우: rectangular diagonal matrix</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="orthogonal-matrix직교행렬-orthonomal-matrix" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="orthogonal-matrix직교행렬-orthonomal-matrix"><span class="header-section-number">6.4</span> Orthogonal matrix(직교행렬, orthonomal matrix)</h3>
<ul>
<li>행렬의 각 columns들이 orthonomal vectors (서로 수직하면서 unit vectors) <img src="https://latex.codecogs.com/png.latex?A%20A%5ET%20=%20A%5ET%20A%20=%20I"></li>
<li>identity matrix는 orthogonal matrix</li>
<li>square matrix에서만 정의됨</li>
<li>Orthogonal matrix인 <img src="https://latex.codecogs.com/png.latex?A">이면 <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D%20=%20A%5E%7BT%7D">
<ul>
<li>각 columns에서 자기 자신과의 내적 = 1, 다른 column과의 내적 = 0임</li>
</ul></li>
<li>complex matrix(복소수 행렬)에서는 unitary matrix라고 부름</li>
</ul>
</section>
</section>
<section id="계수rank" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="계수rank"><span class="header-section-number">7</span> 계수(Rank)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/HMST0Yc7EXE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>rank: 행렬이 가지는 independent한 columns의 수 = column space의 dimension = row space의 dimension</li>
<li>independent한 column의 수 = independent한 행의 수: <img src="https://latex.codecogs.com/png.latex?rank(A)%20=%20rank(A%5ET)">
<ul>
<li>proof: <a href="https://en.wikipedia.org/wiki/Rank_%28linear_algebra%29#Proofs_that_column_rank_=_row_rank">Wikipedia</a></li>
</ul></li>
<li>예: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%200%20&amp;%200%20&amp;%200%20%5Cend%7Bbmatrix%7D%20%5CRightarrow%20rank=1"> <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%201%20%5C%5C%200%20&amp;%201%20&amp;%201%20%5Cend%7Bbmatrix%7D%20%5CRightarrow%20rank=2"></li>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D"> 의 최대 랭크는 <img src="https://latex.codecogs.com/png.latex?min%5C%7Bm,n%5C%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?rank(A)%20%3C%20min%5C%7Bm,n%5C%7D"> 면 rank-deficient, <img src="https://latex.codecogs.com/png.latex?rank(A)%20=%20min%5C%7Bm,n%5C%7D">면 full (row/column) rank</li>
</ul></li>
</ul>
</section>
<section id="영공간null-space" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="영공간null-space"><span class="header-section-number">8</span> 영공간(Null space)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/Eizc9TSRYMQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%20%5Cmathbf%7B0%7D"> 을 만족하는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">의 집합
<ul>
<li>column space 관점에서 보기: <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20x_1%20%5Cmathbf%7Ba_1%7D%20+%20x_2%20%5Cmathbf%7Ba_2%7D%20+%20%5Ccdots%20+%20x_n%20%5Cmathbf%7Ba_n%7D%20=%20%5Cmathbf%7B0%7D"></li>
<li>null space에 항상 들어가는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%200%20%5C%5C%20%5Cvdots%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> : trivial solution
<ul>
<li>모든 columns이 다 lienarly independent 하면, null space에는 위의 벡터 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D">하나 밖에 없음</li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D"> 가 아닌 vector가 null space에 있으면, 스칼라배(constant <img src="https://latex.codecogs.com/png.latex?c">에 대해 <img src="https://latex.codecogs.com/png.latex?c%20%5Cmathbf%7Bx%7D">) 역시 null space에 포함됨</li>
<li>혼동 주의! null space는 column space의 일부가 아님
<ul>
<li>row vector의 차원이 null space가 존재하는 공간</li>
</ul></li>
<li>rank와 null space의 dimension의 합은 항상 matrix의 column의 수
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D">에 대해, <img src="https://latex.codecogs.com/png.latex?dim(N(A))%20=%20n%20-%20r">
<ul>
<li>모든 columns이 다 lienarly independent 하면 null space는 0차원(점)</li>
</ul></li>
<li>null space는 row space와 수직한 space
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%20%5Cmathbf%7B0%7D"> : 각각 모든 행과 내적해서 0, → 행들의 linear combination과 내적해도 0</li>
<li>rank는 row space의 dimension → row space의 dimension(<img src="https://latex.codecogs.com/png.latex?dim(R(A))">)과 null space의 dimension(<img src="https://latex.codecogs.com/png.latex?dim(N(A))">)의 합이 <img src="https://latex.codecogs.com/png.latex?n"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%5En%7D"> 공간에 표현: <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_10.PNG" class="img-fluid">
<ul>
<li>겹친 점: 영벡터</li>
</ul></li>
</ul></li>
</ul></li>
<li>left null space: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%5ET%7D%20A%20=%20%5Cmathbf%7B0%5ET%7D"> 인 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">
<ul>
<li>위의 성질을 row에 대해 적용
<ul>
<li>m 차원에 놓인 벡터</li>
<li>dimension: <img src="https://latex.codecogs.com/png.latex?dim(N_L(A))%20=%20m%20-%20r"></li>
<li>column space와 수직: <img src="https://latex.codecogs.com/png.latex?dim(N_L(A))%20+dim(C(A))%20=%20m"></li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?R(A)">에 있는 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_r%7D"> 와 <img src="https://latex.codecogs.com/png.latex?N(A)">에 있는 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 대해:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_r%7D">에 <img src="https://latex.codecogs.com/png.latex?A">를 곱하면 column space로 감</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 <img src="https://latex.codecogs.com/png.latex?A">를 곱하면 $</li>
<li><img src="https://latex.codecogs.com/png.latex?A(%5Cmathbf%7Bx_r%7D%20+%5Cmathbf%7Bx_n%7D)%20=%20A%5Cmathbf%7Bx_r%7D%20+%20A%5Cmathbf%7Bx_n%7D%20=%20A%5Cmathbf%7Bx_r%7D%20=%20%5Cmathbf%7Bb%7D"></li>
</ul></li>
</ul>
</section>
<section id="ax-b의-해의-수" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="ax-b의-해의-수"><span class="header-section-number">9</span> Ax = b의 해의 수</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/nNI2TlD598c" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><p>full column rank 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 있으면 해가 하나</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 없으면 해가 없음 <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_11.PNG" class="img-fluid"></li>
</ul></li>
<li><p>full row rank 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">는 항상 column space 안에 있음: 무한의 해를 가짐</li>
<li>임의의 특정한 해(particular solution) <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_p%7D">와 null space의 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 대해, <img src="https://latex.codecogs.com/png.latex?A(%5Cmathbf%7Bx_p%7D%20+%5Cmathbf%7Bx_n%7D)=%5Cmathbf%7Bb%7D">
<ul>
<li>즉, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_p%7D%20+%5Cmathbf%7Bx_n%7D"> 도 해가 됨: complete solution
<ul>
<li>null space는 무한하므로, 해도 무한함</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>full rank 일때(square matrix): 해가 하나 존재 (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D">$)</p></li>
<li><p>rank-deficient 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 있으면 무한한 해를 가짐</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 없으면 해가 없음</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/11.matrix_transformation.html</guid>
  <pubDate>Sat, 01 Apr 2023 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" medium="image"/>
</item>
<item>
  <title>Matrix Transformation (5) - Quadratic Form</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/quadratic_form.html</link>
  <description><![CDATA[ 



<section id="quadratic-form" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="quadratic-form"><span class="header-section-number">1</span> Quadratic Form</h2>
<p>For a vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20%5Bx_1,x_2,%5Cldots,x_n%5D%5ET">, the quadratic form is defined as</p>
<p><img src="https://latex.codecogs.com/png.latex?Q(%5Cmathbf%7Bx%7D)%20=%20%5Cmathbf%7Bx%7D%5ET%20%5Cmathbf%7BA%7D%20%5Cmathbf%7Bx%7D"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> symmetric matrix.</p>
<p>Here, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%5ET"> represents the transpose of the vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%5ET%20%5Cmathbf%7BA%7D%20%5Cmathbf%7Bx%7D"> represents the dot product of the vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> with itself after the transformation by the matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20%5Bx_1,x_2%5D%5ET"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be a <img src="https://latex.codecogs.com/png.latex?2%20%5Ctimes%202"> symmetric matrix given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20A%20=%20%5Cbegin%7Bbmatrix%7D%202&amp;1%20%5C%5C%201&amp;3%20%5Cend%7Bbmatrix%7D%0A"></p>
<p>Then, the quadratic form <img src="https://latex.codecogs.com/png.latex?Q(%5Cmathbf%7Bx%7D)"> can be written as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20Q(%5Cmathbf%20x)%20=%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20%5Cend%7Bbmatrix%7D%5Cbegin%7Bbmatrix%7D%202&amp;1%20%5C%5C%201&amp;3%20%5Cend%7Bbmatrix%7D%5Cbegin%7Bbmatrix%7D%20x_1%20%5C%5C%20x_2%20%5Cend%7Bbmatrix%7D=2x_1%5E2+4x_1x_2+3x_2%5E2%0A"></p>
<p>Here, we can see that the quadratic form can be represented as a polynomial function of degree 2 in the variables <img src="https://latex.codecogs.com/png.latex?x_1"> and <img src="https://latex.codecogs.com/png.latex?x_2"> with the coefficients given by the entries of the symmetric matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>a quadratic form can be expressed as a bilinear form. In other words, a quadratic form can be written in terms of a bilinear form by defining a new matrix that is the sum of the matrix representing the quadratic form and its transpose.</p>
<p>More formally, suppose we have a quadratic form defined as:</p>
<p><img src="https://latex.codecogs.com/png.latex?q(%5Cmathbf%7Bx%7D)%20=%20%5Cmathbf%7Bx%7D%5ET%20%5Cmathbf%7BA%7D%20%5Cmathbf%7Bx%7D"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is a symmetric matrix. Then, we can define a bilinear form as:</p>
<p><img src="https://latex.codecogs.com/png.latex?b(%5Cmathbf%7Bx%7D,%20%5Cmathbf%7By%7D)%20=%20%5Cfrac%7B1%7D%7B2%7D(%5Cmathbf%7Bx%7D%5ET%20%5Cmathbf%7BA%7D%20%5Cmathbf%7By%7D%20+%20%5Cmathbf%7By%7D%5ET%20%5Cmathbf%7BA%7D%20%5Cmathbf%7Bx%7D)"></p>
<p>Note that the factor of <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7B2%7D"> is introduced to avoid double-counting. It can be shown that the two forms are equivalent, in the sense that for any <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">, <img src="https://latex.codecogs.com/png.latex?q(%5Cmathbf%7Bx%7D)%20=%20b(%5Cmathbf%7Bx%7D,%20%5Cmathbf%7Bx%7D)">.</p>
<p>In other words, every quadratic form can be expressed as a bilinear form, and every symmetric bilinear form can be expressed as a quadratic form.</p>
</section>
<section id="examples" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="examples"><span class="header-section-number">2</span> Examples</h2>
<section id="sum-of-squares" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="sum-of-squares"><span class="header-section-number">2.1</span> Sum of Squares</h3>
<p>The sum of squares of a vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20%5Bx_1,%20x_2,%20%5Cldots,%20x_n%5D%5ET"> can be represented as a quadratic form <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%5ET%5Cmathbf%7Bx%7D">. To see this, consider the sum of squares:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi=1%7D%5E%7Bn%7D%20x_i%5E2%20=%20x_1%5E2%20+%20x_2%5E2%20+%20%5Cdots%20+x_n%5E2%0A"></p>
<p>Now, we can write this in vector form as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20x%5ET%20%5Cmathbf%20x%20=%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20&amp;%20%5Cdots%20&amp;%20x_n%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20%5C%5C%20x_2%20%5C%5C%20%5Cvdots%20%5C%5C%20x_n%20%5Cend%7Bbmatrix%7D%0A"></p>
<p>Therefore, the sum of squares can be represented as a quadratic form <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%5ET%5Cmathbf%7Bx%7D">.</p>
</section>
<section id="covariance-matrix" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="covariance-matrix"><span class="header-section-number">2.2</span> Covariance Matrix</h3>
<p>The covariance matrix of a random vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> can be represented as a quadratic form in terms of the vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> and the matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D"> as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20x%5ET%20%5Cmathbf%20C%20%5Cmathbf%20x%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D"> is the covariance matrix. This expression is a quadratic form because it involves a quadratic polynomial in the elements of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">.</p>
<p>In this representation, the diagonal elements of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D"> correspond to the variances of the individual components of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">, and the off-diagonal elements correspond to the covariances between the components. The expression <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%5ET%20%5Cmathbf%7BC%7D%20%5Cmathbf%7Bx%7D"> measures the variability of the random vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> in all possible directions, weighted by the covariances between the components.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The covariance matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D"> measures the covariance between each pair of components of the random vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">. It is a matrix that summarizes the <strong>pairwise covariances</strong> between the components of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">.</p>
<p>On the other hand, the quadratic form <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%5ET%20%5Cmathbf%7BC%7D%20%5Cmathbf%7Bx%7D"> measures the total variability of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">, taking into account the covariances between <strong>all possible pairs of components</strong>.</p>
<p>It does this by weighting the contribution of each component to the overall variability by its covariance with every other component. So, while the covariance matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D"> captures the pairwise covariances between the components of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">, the quadratic form <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%5ET%20%5Cmathbf%7BC%7D%20%5Cmathbf%7Bx%7D"> captures the total variability of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> in all directions.</p>
</div>
</div>
<p>Let’s take a simple example with a 2-dimensional random vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Bx_1,%20x_2%5D%5ET">. We can think of this random vector as representing data points in a 2D space. The covariance matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D"> will capture the covariances between <img src="https://latex.codecogs.com/png.latex?x_1"> and <img src="https://latex.codecogs.com/png.latex?x_2">. Let’s say that the covariance matrix is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20C%20=%5Cbegin%7Bbmatrix%7D%20%5Csigma_%7Bx_1%7D%20&amp;%20%5Coperatorname%7BCov%7D(x_1,x_2)%20%5C%5C%20%5Coperatorname%7BCov%7D(x_2,x_1)%20&amp;%20%5Csigma_%7Bx_2%7D%20%5Cend%7Bbmatrix%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Csigma_%7Bx_1%7D%5E2"> and <img src="https://latex.codecogs.com/png.latex?%5Csigma_%7Bx_2%7D%5E2"> are the variances of <img src="https://latex.codecogs.com/png.latex?x_1"> and <img src="https://latex.codecogs.com/png.latex?x_2">, respectively, and <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BCov%7D(x_1,x_2)"> is their covariance.</p>
<p>Now, let’s consider the quadratic form <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%5ET%20%5Cmathbf%7BC%7D%20%5Cmathbf%7Bx%7D">. This expression gives us a scalar value that measures the variability of the random vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> in all possible directions, weighted by the covariances between the components. We can see this geometrically by plotting the data points in the 2D space and drawing an ellipse that captures the variability of the data. The shape of the ellipse is determined by the eigenvalues and eigenvectors of the covariance matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D">.</p>
<p>To see this, let’s first rewrite the quadratic form as: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20x%5ET%20%5Cmathbf%20C%20%5Cmathbf%20x%20=%20%5Csigma_%7Bx_1%7D%5E2x_1%5E2%20+2%5Coperatorname%7BCov%7D(x_1,x_2)x_1x_2+%5Csigma_%7Bx_2%7D%5E2%0A"></p>
<p>This is a quadratic equation in <img src="https://latex.codecogs.com/png.latex?x_1"> and <img src="https://latex.codecogs.com/png.latex?x_2"> and can be thought of as the equation of an ellipse centered at the origin by the determinant of the conic equation. The shape of the ellipse is determined by the coefficients of the quadratic terms, which are the variances and covariances in the covariance matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D">.</p>
<p>Now, let’s find the eigenvectors and eigenvalues of the covariance matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D">. The eigenvectors are the directions along which the data has the most variance, and the corresponding eigenvalues are the variances of the data along those directions.</p>
<p>Let’s assume that the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D"> are ordered such that <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20%5Cgeq%20%5Clambda_2">. Then, the eigenvectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_1"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_2"> satisfy:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20C%20%5Cmathbf%20v_1%20=%5Clambda_1%5Cmathbf%20v_1%20%5Ctext%7B%20%20%7D%0A%5Cmathbf%20C%20%5Cmathbf%20v_2%20=%5Clambda_2%5Cmathbf%20v_2%0A"></p>
<p>These equations can be rewritten as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%20%5Csigma_%7Bx_1%7D%5E2%20&amp;%20%5Ctext%7BCov%7D(x_1,x_2)%5C%5C%0A%20%20%5Ctext%7BCov%7D(x_1,x_2)%20&amp;%20%5Csigma_%7Bx_2%7D%5E2%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%20v_%7B11%7D%5C%5C%0A%20%20v_%7B21%7D%0A%5Cend%7Bbmatrix%7D%0A=%20%5Clambda_1%0A%5Cbegin%7Bbmatrix%7D%0Av_%7B11%7D%5C%5C%0Av_%7B21%7D%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation%7D%0A"></p>
<p>This equation can be expanded as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Csigma_%7Bx_1%7D%5E2%20v_%7B11%7D%20+%20%5Ctext%7BCov%7D(x_1,x_2)%20v_%7B21%7D%20=%20%5Clambda_1%20v_%7B11%7D"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BCov%7D(x_1,x_2)%20v_%7B11%7D%20+%20%5Csigma_%7Bx_2%7D%5E2%20v_%7B21%7D%20=%20%5Clambda_1%20v_%7B21%7D"></p>
<p>Now, let’s multiply the first equation by <img src="https://latex.codecogs.com/png.latex?v_%7B11%7D"> and the second equation by <img src="https://latex.codecogs.com/png.latex?v_%7B21%7D">, and then subtract the second equation from the first:</p>
<p><img src="https://latex.codecogs.com/png.latex?(%5Csigma_%7Bx_1%7D%5E2%20-%20%5Clambda_1)v_%7B11%7Dv_%7B21%7D%20+%20%5Ctext%7BCov%7D(x_1,x_2)(v_%7B21%7D%5E2%20-%20v_%7B11%7D%5E2)%20=%200"></p>
<p>This can be rewritten as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Bv_%7B21%7D%7D%7Bv_%7B11%7D%7D%20=%20%5Cfrac%7B%5Csigma_%7Bx_1%7D%5E2%20-%20%5Clambda_1%7D%7B%5Ctext%7BCov%7D(x_1,x_2)%7D%20-%20%5Cfrac%7Bv_%7B11%7D%7D%7Bv_%7B21%7D%7D"></p>
<p>Let <img src="https://latex.codecogs.com/png.latex?t%20=%20%5Cfrac%7Bv_%7B21%7D%7D%7Bv_%7B11%7D%7D">. Then, we have:</p>
<p><img src="https://latex.codecogs.com/png.latex?t%5E2%20-%20%5Cleft(%5Cfrac%7B%5Csigma_%7Bx_1%7D%5E2%20+%20%5Csigma_%7Bx_2%7D%5E2%7D%7B%5Ctext%7BCov%7D(x_1,x_2)%7D%5Cright)t%20+%20%5Cfrac%7B%5Clambda_1%7D%7B%5Ctext%7BCov%7D(x_1,x_2)%7D%20=%200"></p>
<p>This is a quadratic equation in <img src="https://latex.codecogs.com/png.latex?t">, and its roots can be solved using the quadratic formula. The roots are:</p>
<p><img src="https://latex.codecogs.com/png.latex?t_1%20=%20%5Cfrac%7B%5Csigma_%7Bx_1%7D%5E2%20-%20%5Csigma_%7Bx_2%7D%5E2%20+%20%5Csqrt%7B(%5Csigma_%7Bx_1%7D%5E2%20-%20%5Csigma_%7Bx_2%7D%5E2)%5E2%20+%204%5Ctext%7BCov%7D(x_1,x_2)%5E2%7D%7D%7B2%5Ctext%7BCov%7D(x_1,x_2)%7D"></p>
<p><img src="https://latex.codecogs.com/png.latex?t_2%20=%20%5Cfrac%7B%5Csigma_%7Bx_1%7D%5E2%20-%20%5Csigma_%7Bx_2%7D%5E2%20-%20%5Csqrt%7B(%5Csigma_%7Bx_1%7D%5E2%20-%20%5Csigma_%7Bx_2%7D%5E2)%5E2%20+%204%5Ctext%7BCov%7D(x_1,x_2)%5E2%7D%7D%7B2%5Ctext%7BCov%7D(x_1,x_2)%7D"></p>
<p>Finally, the eigenvectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_1"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_2"> are given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7Bv%7D_1%20=%20%5Cbegin%7Bbmatrix%7D1%20%5C%5C%20t_1%20%5Cend%7Bbmatrix%7D%20%5Ctext%7B%20%20%7D%0A%5Cmathbf%7Bv%7D_2%20=%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%20t_2%20%5Cend%7Bbmatrix%7D%0A"></p>
<p>These eigenvectors define the principal components of the data, which are the orthogonal directions in the feature space along which the data varies the most.</p>
<p>Let’s apply this difference between <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20C=%20%5Coperatorname%7BCov(%5Cmathbf%20X)%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20x%5ET%20%5Cmathbf%7BC%7D%20%5Cmathbf%20x"> or PCA to Iris dataset:</p>
<div class="cell" data-execution_count="1">
<div class="cell-output cell-output-stdout">
<pre><code>C=Cov(X) =
[[ 1.00671141 -0.11835884  0.87760447  0.82343066]
 [-0.11835884  1.00671141 -0.43131554 -0.36858315]
 [ 0.87760447 -0.43131554  1.00671141  0.96932762]
 [ 0.82343066 -0.36858315  0.96932762  1.00671141]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/quadratic_form_files/figure-html/cell-2-output-2.png" width="587" height="449"></p>
</div>
</div>
<p>This representation is useful in many statistical and machine learning applications, where the covariance matrix provides information about the variability and dependencies between different features or variables. For example, in principal component analysis (PCA), the covariance matrix is used to identify the directions of maximum variability in a dataset, which can be used to reduce the dimensionality of the data while retaining as much information as possible.</p>
</section>
<section id="pca" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="pca"><span class="header-section-number">2.3</span> PCA</h3>
<p>The principal components of a dataset can be obtained by finding the eigenvectors of the covariance matrix. In other words, we can express the covariance matrix as a quadratic form:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20C%20=%20%5Cmathbf%20x%5ET%20%5Cmathbf%20A%20%5Cmathbf%20x%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> is a column vector of centered data, and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is a symmetric positive semi-definite matrix (the covariance matrix). Diagonalizing <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> gives us the eigenvalues and eigenvectors, which are used to transform the original data into a new coordinate system, where the first axis (the first principal component) corresponds to the direction of greatest variance, the second axis (the second principal component) corresponds to the direction of second greatest variance, and so on. This new coordinate system is called the principal component space.</p>
<p>In summary, PCA can be seen as a method for finding the principal components of a dataset by diagonalizing the covariance matrix, which can be expressed as a quadratic form.</p>
</section>
<section id="positive-definit-matrix" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="positive-definit-matrix"><span class="header-section-number">2.4</span> Positive Definit Matrix</h3>
<p>a symmetric matrix <img src="https://latex.codecogs.com/png.latex?A"> is positive definite if and only if the quadratic form <img src="https://latex.codecogs.com/png.latex?f(%5Cmathbf%7Bx%7D)=%5Cmathbf%7Bx%7D%5ET%20A%20%5Cmathbf%7Bx%7D"> is positive for all nonzero vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">.</p>
<p>To see why this is true, consider the eigenvalue decomposition of <img src="https://latex.codecogs.com/png.latex?A">, which can be written as <img src="https://latex.codecogs.com/png.latex?A%20=%20Q%20%5CLambda%20Q%5ET">, where <img src="https://latex.codecogs.com/png.latex?Q"> is an orthogonal matrix and <img src="https://latex.codecogs.com/png.latex?%5CLambda"> is a diagonal matrix containing the eigenvalues of <img src="https://latex.codecogs.com/png.latex?A">. Then, for any nonzero vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">,</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Diagonalization
</div>
</div>
<div class="callout-body-container callout-body">
<p>Diagonalization is a process of finding a diagonal matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20D"> and an invertible matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20P"> such that <img src="https://latex.codecogs.com/png.latex?P%5E%7B-1%7DAP%20=%20D">, where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> is a square matrix. In other words, diagonalization is a way of representing a matrix as a diagonal matrix, which is a matrix with non-zero values only on its main diagonal.</p>
</div>
</div>
<p>we have</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Cmathbf%20x%5ET%20%5Cmathbf%20A%20%5Cmathbf%20x&amp;=%5Cmathbf%20x%5ET%20%5Cmathbf%20Q%20%5Cmathbf%20%5CLambda%20%5Cmathbf%20Q%5ET%20%5Cmathbf%20x%5C%5C%0A&amp;=(%5Cmathbf%20x%5ET%20%5Cmathbf%20Q)%5Cmathbf%20%5CLambda%20(%20%5Cmathbf%20Q%5ET%5Cmathbf%20x)%5C%5C%0A&amp;=%5Csum_%7Bi=1%7D%5E%7Bn%7D%20%5Clambda_iy_i%5E2%0A%5Cend%7Baligned%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?y_i%20=%20(%5Cmathbf%7Bx%7D%5ET%20Q)_i"> is the <img src="https://latex.codecogs.com/png.latex?i">th coordinate (i.e., a scalar value that represents the position of a point or a vector relative to a chosen basis) of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%5ET%20Q"> and <img src="https://latex.codecogs.com/png.latex?n"> is the dimension of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> and <img src="https://latex.codecogs.com/png.latex?A">. Note that since <img src="https://latex.codecogs.com/png.latex?Q"> is orthogonal, we have <img src="https://latex.codecogs.com/png.latex?Q%5ET%20Q%20=%20I">, so <img src="https://latex.codecogs.com/png.latex?y_i%20=%20%5Cmathbf%7Bq%7D_i%5ET%20%5Cmathbf%7Bx%7D">, where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bq%7D_i"> is the <img src="https://latex.codecogs.com/png.latex?i">th column of <img src="https://latex.codecogs.com/png.latex?Q">. Therefore, the quadratic form <img src="https://latex.codecogs.com/png.latex?f(%5Cmathbf%7Bx%7D)%20=%20%5Cmathbf%7Bx%7D%5ET%20A%20%5Cmathbf%7Bx%7D"> can be written in terms of the eigenvalues of <img src="https://latex.codecogs.com/png.latex?A"> and the coordinates of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> with respect to the eigenvectors of <img src="https://latex.codecogs.com/png.latex?A">.</p>
<p>Since <img src="https://latex.codecogs.com/png.latex?A"> is positive definite, we have <img src="https://latex.codecogs.com/png.latex?%5Clambda_i%20%3E%200"> for all <img src="https://latex.codecogs.com/png.latex?i">, and so <img src="https://latex.codecogs.com/png.latex?%5Csum_%7Bi=1%7D%5En%20%5Clambda_i%20y_i%5E2%20%3E%200"> for all nonzero vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">. Therefore, the quadratic form <img src="https://latex.codecogs.com/png.latex?f(%5Cmathbf%7Bx%7D)=%5Cmathbf%7Bx%7D%5ET%20A%20%5Cmathbf%7Bx%7D"> is positive for all nonzero vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">, which implies that <img src="https://latex.codecogs.com/png.latex?A"> is positive definite.</p>
<p>In other words, the positive definiteness of a symmetric matrix <img src="https://latex.codecogs.com/png.latex?A"> is equivalent to the positivity of the associated quadratic form <img src="https://latex.codecogs.com/png.latex?f(%5Cmathbf%7Bx%7D)=%5Cmathbf%7Bx%7D%5ET%20A%20%5Cmathbf%7Bx%7D"> for all nonzero vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">.</p>
<p>Therefore, a symmetric matrix, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> is said to be positive definite if all of its eigenvalues are positive or equivalently, a symmetric matrix, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> is positive definite if left-multiplying and right-multiplying it by the same vector, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20x"> always gives a positive number if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20x%5ET%20%5Cmathbf%20A%20%5Cmathbf%20x"></p>


</section>
</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/quadratic_form.html</guid>
  <pubDate>Sat, 01 Apr 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Basics (2) - Matrix Operations</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/02.basic_matrix.html</link>
  <description><![CDATA[ 



<section id="matrix" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="matrix"><span class="header-section-number">1</span> Matrix</h2>
<p>A matrix is a rectangular array of elements, usually real numbers, arranged in rows and columns. If <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix, it can be represented as: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%20a_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B1n%7D%20%5C%5C%0A%20%20a_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B2n%7D%20%5C%5C%0A%20%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20a_%7Bm1%7D%20&amp;%20a_%7Bm2%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7Bmn%7D%0A%5Cend%7Bbmatrix%7D%0A"> where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of the matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
</section>
<section id="basic-matrix-operations" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="basic-matrix-operations"><span class="header-section-number">2</span> Basic Matrix Operations</h2>
<section id="matrix-with-combinations-of-vectors" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="matrix-with-combinations-of-vectors"><span class="header-section-number">2.1</span> Matrix with Combinations of Vectors</h3>
<p>A matrix with combinations of vectors is a matrix that can be written as a linear combination of column vectors. Given column vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_1,%20%5Cmathbf%7Bv%7D_2,%20%5Cdots,%20%5Cmathbf%7Bv%7D_n%20%5Cin%20%5Cmathbb%7BR%7D%5Em"> and scalars <img src="https://latex.codecogs.com/png.latex?a_1,%20a_2,%20%5Cdots,%20a_n%20%5Cin%20%5Cmathbb%7BR%7D">, the matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> can be written as: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20A%20=%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bv_1%7D&amp;%5Cmathbf%7Bv_2%7D&amp;%20%5Cdots%20&amp;%5Cmathbf%7Bv_n%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20a_1%20%5C%5C%20a_2%20%5C%5C%20%5Cvdots%20%5C%5C%20a_n%20%5Cend%7Bbmatrix%7D%20=a_1%5Cmathbf%20v_1%20+a_2%5Cmathbf%20v_2%20+%5Cdots+a_n%20%5Cmathbf%20v_n%0A"></p>
<p>In other words, the columns of the matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are linear combinations of the column vectors <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D_1,%20%5Cmathbf%7Bv%7D_2,%20%5Cdots,%20%5Cmathbf%7Bv%7D_n">. This can be written more compactly as: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20A%20=%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bv_1%7D&amp;%5Cmathbf%7Bv_2%7D&amp;%20%5Cdots%20&amp;%5Cmathbf%7Bv_n%7D%20%5Cend%7Bbmatrix%7D%20%5Cmathbf%20a%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Ba%7D%20=%20%5Cbegin%7Bbmatrix%7D%20a_1%20&amp;%20a_2%20&amp;%20%5Cdots%20&amp;%20a_n%20%5Cend%7Bbmatrix%7D%5ET"> is a column vector of scalars.</p>
<p>An example of a matrix with combinations of vectors is: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20A%20=%0A%5Cbegin%7Bbmatrix%7D%0A1&amp;4&amp;7%5C%5C%0A2&amp;5&amp;8%5C%5C%0A3&amp;6&amp;9%5C%5C%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%5C%5C%0A2%5C%5C%0A3%5C%5C%0A%5Cend%7Bbmatrix%7D%5Cmathbf%7Be%7D_1%5E%5Ctext%7BT%7D+%0A%5Cbegin%7Bbmatrix%7D%0A4%5C%5C%0A5%5C%5C%0A6%5C%5C%0A%5Cend%7Bbmatrix%7D%5Cmathbf%7Be%7D_2%5E%5Ctext%7BT%7D+%0A%5Cbegin%7Bbmatrix%7D%0A7%5C%5C%0A8%5C%5C%0A9%5C%5C%0A%5Cend%7Bbmatrix%7D%5Cmathbf%7Be%7D_3%5E%5Ctext%7BT%7D%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Be%7D_1,%20%5Cmathbf%7Be%7D_2,%20%5Cmathbf%7Be%7D_3"> are the standard basis vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5E3">.</p>
</section>
<section id="matrix-addition" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="matrix-addition"><span class="header-section-number">2.2</span> Matrix addition</h3>
<p>The sum of two matrices of the same size is a matrix of the same size obtained by adding corresponding entries.</p>
<p>Given two <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">, their sum <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BA%7D%20+%20%5Cmathbf%7BB%7D"> is defined by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D=a_%7Bi,j%7D+b_%7Bi,j%7D%E2%80%8B%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%201%20&amp;%202%20%5C%5C%0A%20%203%20&amp;%204%20%5C%5C%0A%20%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20+%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-1%20&amp;%200%20%5C%5C%0A%20%202%20&amp;%20-3%20%5C%5C%0A%20%20-5%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%200%20&amp;%202%20%5C%5C%0A%20%205%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%2010%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="scalar-multiplication" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="scalar-multiplication"><span class="header-section-number">2.3</span> Scalar multiplication</h3>
<p>The product of a scalar and a matrix is a matrix obtained by multiplying each entry of the matrix by the scalar.</p>
<p>Given a scalar <img src="https://latex.codecogs.com/png.latex?k"> and an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, their product <img src="https://latex.codecogs.com/png.latex?k%5Cmathbf%7BA%7D"> is defined by: <img src="https://latex.codecogs.com/png.latex?%0A(k%5Cmathbf%7BA%7D)_%7Bi,j%7D%20=%20k(a_%7Bi,j%7D)%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A2%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A2%20&amp;%204%20%5C%5C%0A6%20&amp;%208%20%5C%5C%0A10%20&amp;%2012%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="matrix-multiplication" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="matrix-multiplication"><span class="header-section-number">2.4</span> Matrix multiplication</h3>
<p>The product of two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> is a matrix obtained by multiplying the rows of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> by the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">.</p>
<p>Given two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> with dimensions <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> and <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20p">, respectively, their product <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BAB%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20p"> matrix defined by: <img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D%20=%20%5Csum_%7Bk=1%7D%5En%20a_%7Bi,k%7Db_%7Bk,j%7D%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20p">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%0A-1%20&amp;%200%20&amp;%202%20%5C%5C%0A2%20&amp;%20-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A3%20&amp;%20-6%20&amp;%204%20%5C%5C%0A5%20&amp;%20-12%20&amp;%2010%20%5C%5C%0A7%20&amp;%20-18%20&amp;%2016%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="matrix-multiplication-with-a-vector" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="matrix-multiplication-with-a-vector"><span class="header-section-number">2.5</span> Matrix Multiplication with a Vector</h3>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D"> be a <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%201"> column vector. The matrix-vector product <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BAx%7D"> is defined as:</p>
<p>$$ <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bequation%7D%0A%5Cmathbf%7BAx%7D=%0A%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20%5Cdots%20&amp;%20a_%7B1n%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20%5Cdots%20&amp;%20a_%7B2n%7D%20%5C%5C%0A%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0Aa_%7Bm1%7D%20&amp;%20a_%7Bm2%7D%20&amp;%20%5Cdots%20&amp;%20a_%7Bmn%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%0Ax_1%20%5C%5C%20x_2%20%5C%5C%20%5Cvdots%20%5C%5C%20x_n%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7Dx_1%20&amp;%20a_%7B12%7Dx_2%20&amp;%20%5Cdots%20&amp;%20a_%7B1n%7Dx_n%20%5C%5C%0Aa_%7B21%7Dx_1%20&amp;%20a_%7B22%7Dx_2%20&amp;%20%5Cdots%20&amp;%20a_%7B2n%7Dx_n%20%5C%5C%0A%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cvdots%20%5C%5C%0Aa_%7Bm1%7Dx_1%20&amp;%20a_%7Bm2%7Dx_2%20&amp;%20%5Cdots%20&amp;%20a_%7Bmn%7Dx_n%0A%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation%7D"> $$</p>
<p>In other words, each entry of the resulting column vector is the dot product of the corresponding row of the matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and the column vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">.</p>
<p>For example, let</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20A%20=%0A%5Cbegin%7Bbmatrix%7D%0A2%20&amp;%201%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A1%20&amp;%202%0A%5Cend%7Bbmatrix%7D%20%5Ctext%7B%20%20%7D%0A%5Cmathbf%20x=%0A%5Cbegin%7Bbmatrix%7D%0A%20%201%5C%5C-1%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>Then we have</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BAx%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A2%20&amp;%201%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A1%20&amp;%202%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%201%5C%5C-1%0A%5Cend%7Bbmatrix%7D%0A=%0A%5Cbegin%7Bbmatrix%7D%0A%20%201%5C%5C-5%5C%5C-1%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="transpose" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="transpose"><span class="header-section-number">2.6</span> Transpose</h3>
<p>The transpose of an <img src="https://latex.codecogs.com/png.latex?m%20x%20n"> matrix A, denoted by <img src="https://latex.codecogs.com/png.latex?A%5ET">, is the <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix obtained by interchanging the rows and columns of A. Formally, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Ba_%7Bij%7D%5D"> is an m x n matrix, then its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET%20=%20%5Bb_%7Bij%7D%5D"> is an <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix where <img src="https://latex.codecogs.com/png.latex?b_%7Bij%7D"> = <img src="https://latex.codecogs.com/png.latex?a_%7Bji%7D"> for all <img src="https://latex.codecogs.com/png.latex?i"> and <img src="https://latex.codecogs.com/png.latex?j">. In other words, the element in the <img src="https://latex.codecogs.com/png.latex?i"> th row and <img src="https://latex.codecogs.com/png.latex?j"> th column of <img src="https://latex.codecogs.com/png.latex?A%5ET"> is equal to the element in the <img src="https://latex.codecogs.com/png.latex?j"> th row and ith column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>Given an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20m"> matrix defined by: $$ <em>{i,j}^T = </em>{j,i}</p>
<p>$$</p>
<ul>
<li>When <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is transposed, diagnoal entries(<img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D">) do not change but off-diagnoal elements(<img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D%20%5C;%20i%20%5Cneq%20j">) change.</li>
<li>A column vector is tranposed into a row vector, and vice versa.</li>
<li>symmetric matrix: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5ET"></li>
</ul>
<p>Example:</p>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> be the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%5C%5C%0A4%20&amp;%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"> The transpose of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">, denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A%5ET">, is the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5ET%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%204%5C%5C%0A2%20&amp;%205%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="linear-equations-of-a-matrix" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="linear-equations-of-a-matrix"><span class="header-section-number">2.7</span> Linear Equations of a Matrix</h3>
<p>Given an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> and an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%201"> vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">, the matrix-vector product <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A%5Cmathbf%7Bx%7D"> is a linear combination of the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> with coefficients given by the entries of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">. The system of linear equations represented by <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A%5Cmathbf%7Bx%7D=%5Cmathbf%7Bb%7D"> has a unique solution if and only if the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> are linearly independent.</p>
<p>A system of linear equations can be written in matrix form as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B1n%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B2n%7D%20%5C%5C%0A%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0Aa_%7Bm1%7D%20&amp;%20a_%7Bm2%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7Bmn%7D%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0Ax_1%20%5C%5C%0Ax_2%20%5C%5C%0A%5Cvdots%20%5C%5C%0Ax_n%0A%5Cend%7Bbmatrix%7D=%0A%5Cbegin%7Bbmatrix%7D%0Ab_1%20%5C%5C%0Ab_2%20%5C%5C%0A%5Cvdots%20%5C%5C%0Ab_m%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Baligned%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> are the coefficients of the system, <img src="https://latex.codecogs.com/png.latex?x_i"> are the variables, and <img src="https://latex.codecogs.com/png.latex?b_j"> are the constants.</p>
<p>Here’s an example of a system of linear equations represented by a matrix: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A2x_1%20+%203x_2%20&amp;=%208%20%5C%5C%0A4x_1%20+%205x_2%20&amp;=%2013%0A%5Cend%7Balign*%7D%0A"></p>
<p>This can be written as the matrix equation <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%5Cmathbf%7Bb%7D">, where $$ <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bequation%7D%0A%20%20%5Cmathbf%7BA%7D%20=%0A%20%20%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%202%20&amp;%203%5C%5C%0A%20%20%20%204%20&amp;%205%0A%20%20%20%20%5Cend%7Bbmatrix%7D%0A%20%20%5Cmathbf%7Bx%7D%20=%0A%20%20%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20x_1%5C%5C%0A%20%20%20%20x_2%0A%20%20%20%20%5Cend%7Bbmatrix%7D%0A%0A%20%20%5Cmathbf%7Bb%7D%20=%0A%20%20%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%208%5C%5C%0A%20%20%20%2013%0A%20%20%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation%7D"> $$</p>
<p>The solution to this system can be found by computing the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> (if it exists) and multiplying both sides of the equation by it:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7Bx%7D%20=%20%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7Bb%7D%0A"></p>
<p>If <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> does not have an inverse, then the system of equations may have either no solutions or infinitely many solutions.</p>
<p>Consider the following system of equations:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A2x_1%20+%203x_2%20&amp;=%205%20%5C%5C%0A4x_1%20-%20x_2%20&amp;=%202%0A%5Cend%7Baligned%7D%0A"></p>
<p>This can be written in matrix form as: $$</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bequation%7D%0A%5Cbegin%7Bbmatrix%7D%0A2%20&amp;%203%20%5C%5C%0A4%20&amp;%20-1%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0Ax_1%20%5C%5C%0Ax_2%0A%5Cend%7Bbmatrix%7D=%0A%5Cbegin%7Bbmatrix%7D%0A5%20%5C%5C%0A2%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation%7D"> $$ where <img src="https://latex.codecogs.com/png.latex?a_%7B11%7D%20=%202,%20a_%7B12%7D%20=%203,%20a_%7B21%7D%20=%204,%20a_%7B22%7D%20=%20-1,%20x_1"> and <img src="https://latex.codecogs.com/png.latex?x_2"> are the variables, and <img src="https://latex.codecogs.com/png.latex?b_1%20=%205,%20b_2%20=%202"> are the constants.</p>
</section>
<section id="determinant" class="level3" data-number="2.8">
<h3 data-number="2.8" class="anchored" data-anchor-id="determinant"><span class="header-section-number">2.8</span> Determinant</h3>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> square matrix. The determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C"> or <img src="https://latex.codecogs.com/png.latex?%5Cdet(%5Cmathbf%7BA%7D)">, is a scalar value calculated as the sum of the products of the elements in any row or column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> with their corresponding cofactors, that is,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D=%5Csum_%7Bj=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column, and <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D"> is the cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">. The cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D">, is given by <img src="https://latex.codecogs.com/png.latex?(-1)%5E%7Bi+j%7D"> times the determinant of the <img src="https://latex.codecogs.com/png.latex?(n-1)%20%5Ctimes%20(n-1)"> matrix obtained by deleting the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>The determinant of an <img src="https://latex.codecogs.com/png.latex?n%20x%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is a scalar value denoted as <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C">. It is defined as the sum of all possible products of n elements taken one from each row and one from each column, where the sign of each product alternates according to the position of the element in the matrix. For example, the determinant of a <img src="https://latex.codecogs.com/png.latex?3%20x%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20="> <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%20a_%7B11%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B32%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A-%20a_%7B12%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A+%20a_%7B13%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%0A%5Cend%7Bvmatrix%7D%0A"></p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?3%20%5Ctimes%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%204%20&amp;%205%20&amp;%206%20%5C%5C%207%20&amp;%208%20&amp;%209%20%5Cend%7Bbmatrix%7D">. We can calculate the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> using any row or column. Let’s use the first column:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%201%0A%5Cbegin%7Bvmatrix%7D%0A5%20&amp;%206%20%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A-%204%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%203%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A+%207%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%205%20%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bvmatrix%7D%20=%200%0A"></p>
<p>Therefore, the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is zero.</p>
</section>
<section id="inverse" class="level3" data-number="2.9">
<h3 data-number="2.9" class="anchored" data-anchor-id="inverse"><span class="header-section-number">2.9</span> Inverse</h3>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?A"> of size <img src="https://latex.codecogs.com/png.latex?n"> is a matrix <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> such that the product of <img src="https://latex.codecogs.com/png.latex?A"> and <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> is the identity matrix <img src="https://latex.codecogs.com/png.latex?I_n">, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I_n">. If such a matrix exists, then <img src="https://latex.codecogs.com/png.latex?A"> is said to be invertible or non-singular.</p>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D"> and is defined as the unique matrix that satisfies the following equation: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BI%7D"> is the identity matrix. Not all matrices have an inverse, and a matrix that has an inverse is called invertible or nonsingular. A matrix that does not have an inverse is called singular.</p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?2%5Ctimes%202"> matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D.%0A"> The inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cfrac%7B1%7D%7B-2%7D%0A%5Cbegin%7Bbmatrix%7D%0A4%20&amp;%20-2%20%5C%5C%0A-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>We can verify that <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BI%7D"> by computing:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%20-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>Let me give another example and A be a <img src="https://latex.codecogs.com/png.latex?3x3"> square matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D">, is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B%5Ctext%7Bdet%7D(%5Cmathbf%7BA%7D)%7D%5Cbegin%7Bbmatrix%7D%0Aa_%7B22%7Da_%7B33%7D-a_%7B23%7Da_%7B32%7D%20&amp;%20a_%7B13%7Da_%7B32%7D-a_%7B12%7Da_%7B33%7D%20&amp;%20a_%7B12%7Da_%7B23%7D-a_%7B13%7Da_%7B22%7D%20%5C%5C%0Aa_%7B23%7Da_%7B31%7D-a_%7B21%7Da_%7B33%7D%20&amp;%20a_%7B11%7Da_%7B33%7D-a_%7B13%7Da_%7B31%7D%20&amp;%20a_%7B13%7Da_%7B21%7D-a_%7B11%7Da_%7B23%7D%20%5C%5C%0Aa_%7B21%7Da_%7B32%7D-a_%7B22%7Da_%7B31%7D%20&amp;%20a_%7B12%7Da_%7B31%7D-a_%7B11%7Da_%7B32%7D%20&amp;%20a_%7B11%7Da_%7B22%7D-a_%7B12%7Da_%7B21%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?det(%5Cmathbf%7BA%7D)"> is the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%20%5C%5C%0A0%20&amp;%201%20&amp;%204%20%5C%5C%0A5%20&amp;%206%20&amp;%200%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, <img src="https://latex.codecogs.com/png.latex?det(A)"> = -57, and the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B-57%7D%5Cbegin%7Bbmatrix%7D%0A-24%20&amp;%2018%20&amp;%205%20%5C%5C%0A20%20&amp;%20-15%20&amp;%20-4%20%5C%5C%0A-3%20&amp;%202%20&amp;%201%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>There are several formulas for finding the inverse of a matrix such as Gauss-Jordan Elimination, Adjoint method, Cramer’s rule, Inverse formula, etc. This topic is going to be handled in the other blogs.</p>
</section>
<section id="rank" class="level3" data-number="2.10">
<h3 data-number="2.10" class="anchored" data-anchor-id="rank"><span class="header-section-number">2.10</span> Rank</h3>
<p>The rank of a matrix is the dimension of the vector space spanned by its columns (or rows). It is denoted by <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Brank%7D(%5Cmathbf%7BA%7D)">.</p>
<p>For example, consider the following matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%20%20%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%20&amp;%203%5C%5C%0A%20%20%20%204%20&amp;%205%20&amp;%206%20%5C%5C%0A%20%20%20%207%20&amp;%208%20&amp;%209%5C%5C%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are linearly dependent since the third column is equal to the sum of the first two columns. Therefore, the dimension of the vector space spanned by the columns is 2, so the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is 2.</p>
</section>
<section id="trace" class="level3" data-number="2.11">
<h3 data-number="2.11" class="anchored" data-anchor-id="trace"><span class="header-section-number">2.11</span> Trace</h3>
<p>The trace of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)">, is defined as the sum of the diagonal elements of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">. In other words, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> matrix, then its trace is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D"> denotes the <img src="https://latex.codecogs.com/png.latex?i"> th diagonal element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%202%20&amp;%203%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%205%20&amp;%202%20%5C%5C%0A%20%201%20&amp;%201%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>Then, the trace of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)%20=%202%20+%205%20+%204%20=%2011"></p>
</section>
<section id="eigenvalues-and-eigenvectors" class="level3" data-number="2.12">
<h3 data-number="2.12" class="anchored" data-anchor-id="eigenvalues-and-eigenvectors"><span class="header-section-number">2.12</span> Eigenvalues and Eigenvectors</h3>
<p>Let A be an <img src="https://latex.codecogs.com/png.latex?n%20%C3%97%20n"> square matrix. A scalar <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is called an eigenvalue of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> if there exists a non-zero vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> such that <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BAv%7D=%5Clambda%5Cmathbf%7Bv%7D%0A"></p>
<p>Such a vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> is called an eigenvector corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda">.</p>
<p>Example:</p>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> be the matrix</p>
<p>To find the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">, we solve the characteristic equation <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%20=%200">, where I is the n × n identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%0A%20%20&amp;=%0A%20%20%20%20%5Cbegin%7Bvmatrix%7D%0A%20%20%20%203%20-%20%5Clambda%20&amp;%201%20%5C%5C%0A%20%20%20%201%20&amp;%203%20-%20%5Clambda%0A%20%20%20%20%5Cend%7Bvmatrix%7D%20%5C%5C%0A%20%20&amp;=%0A%20%20(3%20-%20%5Clambda)(3%20-%20%5Clambda)%20-%201%20%5C%5C%0A%20%20&amp;=%20%5Clambda%5E2%20-%206%5Clambda%20+%208%20=%200%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this quadratic equation gives us the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">: <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202"> and <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">.</p>
<p>To find the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%20%5Cmathbf%7B0%7D">, where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20I"> is the <img src="https://latex.codecogs.com/png.latex?2%20%5Ctimes%202"> identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%0A%20%20%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%20%201%20&amp;%201%20%5C%5C%0A%20%20%20%20%20%201%20&amp;%201%0A%20%20%20%20%5Cend%7Bbmatrix%7D%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20x%20%5C%5C%0A%20%20%20%20y%0A%20%20%5Cend%7Bbmatrix%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%200%20%5C%5C%0A%20%20%20%200%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this system of equations gives us the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D%20=%20%5Cbegin%7Bbmatrix%7D%20-1%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
<p>Similarly, for <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%204%5Cmathbf%20I)%5Cmathbf%7Bv%7D"> = <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D"> to get the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
</section>
<section id="singular-value-and-singluar-vectors" class="level3" data-number="2.13">
<h3 data-number="2.13" class="anchored" data-anchor-id="singular-value-and-singluar-vectors"><span class="header-section-number">2.13</span> Singular value and Singluar Vectors</h3>
<p>The singular value decomposition (SVD) of a matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> is a factorization of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> into the product of three matrices as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20m"> orthogonal matrix, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> rectangular diagonal matrix with non-negative real numbers on the diagonal, and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> orthogonal matrix.</p>
<p>The diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> are called the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Csigma_1,%20%5Csigma_2,%20%5Cldots,%20%5Csigma_r"> (where <img src="https://latex.codecogs.com/png.latex?r"> is the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">), and are arranged in descending order. The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> are called the left and right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, respectively, and are orthonormal vectors.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be a 3 by 2 matrix given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%5C%5C%0A%20%20%20%203%20&amp;%204%5C%5C%0A%20%20%20%205%20&amp;%206%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The SVD of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.23%20&amp;%20-0.53%20&amp;%20-0.81%5C%5C%0A%20%20-0.53%20&amp;%20-0.72%20&amp;%200.45%5C%5C%0A%20%20-0.81%20&amp;%200.45%20&amp;%20-0.38%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%209.53%20&amp;%200%5C%5C%0A%20%200%20&amp;%200.90%5C%5C%0A%20%200%20&amp;%200%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.62%20&amp;%20-0.78%5C%5C%0A%20%20-0.78%20&amp;%200.62%0A%5Cend%7Bbmatrix%7D%5ET%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where the left singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D">, the right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D">, and the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5CSigma%7D">.</p>
<div class="cell">

</div>


</section>
</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/02.basic_matrix.html</guid>
  <pubDate>Thu, 30 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" medium="image"/>
</item>
<item>
  <title>Basics (3) - Special Matrices</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/03.basic_special_matrix.html</link>
  <description><![CDATA[ 



<section id="matrix" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="matrix"><span class="header-section-number">1</span> Matrix</h2>
<p>A matrix is a rectangular array of elements, usually real numbers, arranged in rows and columns. If <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix, it can be represented as: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%20a_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B1n%7D%20%5C%5C%0A%20%20a_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B2n%7D%20%5C%5C%0A%20%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20a_%7Bm1%7D%20&amp;%20a_%7Bm2%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7Bmn%7D%0A%5Cend%7Bbmatrix%7D%0A"> where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of the matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
</section>
<section id="basic-matrix-operations" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="basic-matrix-operations"><span class="header-section-number">2</span> Basic Matrix Operations</h2>
<section id="matrix-addition" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="matrix-addition"><span class="header-section-number">2.1</span> Matrix addition</h3>
<p>The sum of two matrices of the same size is a matrix of the same size obtained by adding corresponding entries.</p>
<p>Given two <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">, their sum <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BA%7D%20+%20%5Cmathbf%7BB%7D"> is defined by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D=a_%7Bi,j%7D+b_%7Bi,j%7D%E2%80%8B%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%201%20&amp;%202%20%5C%5C%0A%20%203%20&amp;%204%20%5C%5C%0A%20%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20+%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-1%20&amp;%200%20%5C%5C%0A%20%202%20&amp;%20-3%20%5C%5C%0A%20%20-5%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%200%20&amp;%202%20%5C%5C%0A%20%205%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%2010%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="scalar-multiplication" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="scalar-multiplication"><span class="header-section-number">2.2</span> Scalar multiplication</h3>
<p>The product of a scalar and a matrix is a matrix obtained by multiplying each entry of the matrix by the scalar.</p>
<p>Given a scalar <img src="https://latex.codecogs.com/png.latex?k"> and an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, their product <img src="https://latex.codecogs.com/png.latex?k%5Cmathbf%7BA%7D"> is defined by: <img src="https://latex.codecogs.com/png.latex?%0A(k%5Cmathbf%7BA%7D)_%7Bi,j%7D%20=%20k(a_%7Bi,j%7D)%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A2%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A2%20&amp;%204%20%5C%5C%0A6%20&amp;%208%20%5C%5C%0A10%20&amp;%2012%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="matrix-multiplication" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="matrix-multiplication"><span class="header-section-number">2.3</span> Matrix multiplication</h3>
<p>The product of two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> is a matrix obtained by multiplying the rows of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> by the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">.</p>
<p>Given two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> with dimensions <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> and <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20p">, respectively, their product <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BAB%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20p"> matrix defined by: <img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D%20=%20%5Csum_%7Bk=1%7D%5En%20a_%7Bi,k%7Db_%7Bk,j%7D%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20p">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%0A-1%20&amp;%200%20&amp;%202%20%5C%5C%0A2%20&amp;%20-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A3%20&amp;%20-6%20&amp;%204%20%5C%5C%0A5%20&amp;%20-12%20&amp;%2010%20%5C%5C%0A7%20&amp;%20-18%20&amp;%2016%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="transpose" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="transpose"><span class="header-section-number">2.4</span> Transpose</h3>
<p>The transpose of an <img src="https://latex.codecogs.com/png.latex?m%20x%20n"> matrix A, denoted by <img src="https://latex.codecogs.com/png.latex?A%5ET">, is the <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix obtained by interchanging the rows and columns of A. Formally, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Ba_%7Bij%7D%5D"> is an m x n matrix, then its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET%20=%20%5Bb_%7Bij%7D%5D"> is an <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix where <img src="https://latex.codecogs.com/png.latex?b_%7Bij%7D"> = <img src="https://latex.codecogs.com/png.latex?a_%7Bji%7D"> for all <img src="https://latex.codecogs.com/png.latex?i"> and <img src="https://latex.codecogs.com/png.latex?j">. In other words, the element in the <img src="https://latex.codecogs.com/png.latex?i"> th row and <img src="https://latex.codecogs.com/png.latex?j"> th column of <img src="https://latex.codecogs.com/png.latex?A%5ET"> is equal to the element in the <img src="https://latex.codecogs.com/png.latex?j"> th row and ith column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>Given an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20m"> matrix defined by: $$ <em>{i,j}^T = </em>{j,i}</p>
<p>$$</p>
<ul>
<li>When <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is transposed, diagnoal entries(<img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D">) do not change but off-diagnoal elements(<img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D%20%5C;%20i%20%5Cneq%20j">) change.</li>
<li>A column vector is tranposed into a row vector, and vice versa.</li>
<li>symmetric matrix: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5ET"></li>
</ul>
<p>Example:</p>
<p>Let A be the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%5C%5C%0A4%20&amp;%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"> The transpose of A, denoted by A^T, is the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5ET%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%204%5C%5C%0A2%20&amp;%205%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="determinant" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="determinant"><span class="header-section-number">2.5</span> Determinant</h3>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> square matrix. The determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C"> or <img src="https://latex.codecogs.com/png.latex?%5Cdet(%5Cmathbf%7BA%7D)">, is a scalar value calculated as the sum of the products of the elements in any row or column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> with their corresponding cofactors, that is,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D=%5Csum_%7Bj=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column, and <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D"> is the cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">. The cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D">, is given by <img src="https://latex.codecogs.com/png.latex?(-1)%5E%7Bi+j%7D"> times the determinant of the <img src="https://latex.codecogs.com/png.latex?(n-1)%20%5Ctimes%20(n-1)"> matrix obtained by deleting the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>The determinant of an <img src="https://latex.codecogs.com/png.latex?n%20x%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is a scalar value denoted as <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C">. It is defined as the sum of all possible products of n elements taken one from each row and one from each column, where the sign of each product alternates according to the position of the element in the matrix. For example, the determinant of a <img src="https://latex.codecogs.com/png.latex?3%20x%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20="> <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%20a_%7B11%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B32%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A-%20a_%7B12%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A+%20a_%7B13%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%0A%5Cend%7Bvmatrix%7D%0A"></p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?3%20%5Ctimes%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%204%20&amp;%205%20&amp;%206%20%5C%5C%207%20&amp;%208%20&amp;%209%20%5Cend%7Bbmatrix%7D">. We can calculate the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> using any row or column. Let’s use the first column:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%201%0A%5Cbegin%7Bvmatrix%7D%0A5%20&amp;%206%20%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A-%204%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%203%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A+%207%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%205%20%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bvmatrix%7D%20=%200%0A"></p>
<p>Therefore, the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is zero.</p>
</section>
<section id="inverse" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="inverse"><span class="header-section-number">2.6</span> Inverse</h3>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?A"> of size <img src="https://latex.codecogs.com/png.latex?n"> is a matrix <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> such that the product of <img src="https://latex.codecogs.com/png.latex?A"> and <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> is the identity matrix <img src="https://latex.codecogs.com/png.latex?I_n">, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I_n">. If such a matrix exists, then <img src="https://latex.codecogs.com/png.latex?A"> is said to be invertible or non-singular.</p>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D"> and is defined as the unique matrix that satisfies the following equation: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BI%7D"> is the identity matrix. Not all matrices have an inverse, and a matrix that has an inverse is called invertible or nonsingular. A matrix that does not have an inverse is called singular.</p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?2%5Ctimes%202"> matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D.%0A"> The inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cfrac%7B1%7D%7B-2%7D%0A%5Cbegin%7Bbmatrix%7D%0A4%20&amp;%20-2%20%5C%5C%0A-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>We can verify that <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BI%7D"> by computing:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%20-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>Let me give another example and A be a <img src="https://latex.codecogs.com/png.latex?3x3"> square matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D">, is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B%5Ctext%7Bdet%7D(%5Cmathbf%7BA%7D)%7D%5Cbegin%7Bbmatrix%7D%0Aa_%7B22%7Da_%7B33%7D-a_%7B23%7Da_%7B32%7D%20&amp;%20a_%7B13%7Da_%7B32%7D-a_%7B12%7Da_%7B33%7D%20&amp;%20a_%7B12%7Da_%7B23%7D-a_%7B13%7Da_%7B22%7D%20%5C%5C%0Aa_%7B23%7Da_%7B31%7D-a_%7B21%7Da_%7B33%7D%20&amp;%20a_%7B11%7Da_%7B33%7D-a_%7B13%7Da_%7B31%7D%20&amp;%20a_%7B13%7Da_%7B21%7D-a_%7B11%7Da_%7B23%7D%20%5C%5C%0Aa_%7B21%7Da_%7B32%7D-a_%7B22%7Da_%7B31%7D%20&amp;%20a_%7B12%7Da_%7B31%7D-a_%7B11%7Da_%7B32%7D%20&amp;%20a_%7B11%7Da_%7B22%7D-a_%7B12%7Da_%7B21%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?det(%5Cmathbf%7BA%7D)"> is the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%20%5C%5C%0A0%20&amp;%201%20&amp;%204%20%5C%5C%0A5%20&amp;%206%20&amp;%200%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, <img src="https://latex.codecogs.com/png.latex?det(A)"> = -57, and the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B-57%7D%5Cbegin%7Bbmatrix%7D%0A-24%20&amp;%2018%20&amp;%205%20%5C%5C%0A20%20&amp;%20-15%20&amp;%20-4%20%5C%5C%0A-3%20&amp;%202%20&amp;%201%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>There are several formulas for finding the inverse of a matrix such as Gauss-Jordan Elimination, Adjoint method, Cramer’s rule, Inverse formula, etc. This topic is going to be handled in the other blogs.</p>
</section>
<section id="rank" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="rank"><span class="header-section-number">2.7</span> Rank</h3>
<p>The rank of a matrix is the dimension of the vector space spanned by its columns (or rows). It is denoted by <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Brank%7D(%5Cmathbf%7BA%7D)">.</p>
<p>For example, consider the following matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%20%20%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%20&amp;%203%5C%5C%0A%20%20%20%204%20&amp;%205%20&amp;%206%20%5C%5C%0A%20%20%20%207%20&amp;%208%20&amp;%209%5C%5C%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are linearly dependent since the third column is equal to the sum of the first two columns. Therefore, the dimension of the vector space spanned by the columns is 2, so the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is 2.</p>
</section>
<section id="trace" class="level3" data-number="2.8">
<h3 data-number="2.8" class="anchored" data-anchor-id="trace"><span class="header-section-number">2.8</span> Trace</h3>
<p>The trace of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)">, is defined as the sum of the diagonal elements of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">. In other words, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> matrix, then its trace is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D"> denotes the <img src="https://latex.codecogs.com/png.latex?i"> th diagonal element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%202%20&amp;%203%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%205%20&amp;%202%20%5C%5C%0A%20%201%20&amp;%201%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>Then, the trace of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)%20=%202%20+%205%20+%204%20=%2011"></p>
</section>
<section id="eigenvalues-and-eigenvectors" class="level3" data-number="2.9">
<h3 data-number="2.9" class="anchored" data-anchor-id="eigenvalues-and-eigenvectors"><span class="header-section-number">2.9</span> Eigenvalues and Eigenvectors</h3>
<p>Let A be an <img src="https://latex.codecogs.com/png.latex?n%20%C3%97%20n"> square matrix. A scalar <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is called an eigenvalue of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> if there exists a non-zero vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> such that <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BAv%7D=%5Clambda%5Cmathbf%7Bv%7D%0A"></p>
<p>Such a vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> is called an eigenvector corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda">.</p>
<p>Example:</p>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> be the matrix</p>
<p>To find the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">, we solve the characteristic equation <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%20=%200">, where I is the n × n identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%0A%20%20&amp;=%0A%20%20%20%20%5Cbegin%7Bvmatrix%7D%0A%20%20%20%203%20-%20%5Clambda%20&amp;%201%20%5C%5C%0A%20%20%20%201%20&amp;%203%20-%20%5Clambda%0A%20%20%20%20%5Cend%7Bvmatrix%7D%20%5C%5C%0A%20%20&amp;=%0A%20%20(3%20-%20%5Clambda)(3%20-%20%5Clambda)%20-%201%20%5C%5C%0A%20%20&amp;=%20%5Clambda%5E2%20-%206%5Clambda%20+%208%20=%200%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this quadratic equation gives us the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">: <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202"> and <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">.</p>
<p>To find the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%20%5Cmathbf%7B0%7D">, where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20I"> is the <img src="https://latex.codecogs.com/png.latex?2%20%5Ctimes%202"> identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%0A%20%20%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%20%201%20&amp;%201%20%5C%5C%0A%20%20%20%20%20%201%20&amp;%201%0A%20%20%20%20%5Cend%7Bbmatrix%7D%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20x%20%5C%5C%0A%20%20%20%20y%0A%20%20%5Cend%7Bbmatrix%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%200%20%5C%5C%0A%20%20%20%200%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this system of equations gives us the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D%20=%20%5Cbegin%7Bbmatrix%7D%20-1%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
<p>Similarly, for <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%204%5Cmathbf%20I)%5Cmathbf%7Bv%7D"> = <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D"> to get the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
</section>
<section id="singular-value-and-singluar-vectors" class="level3" data-number="2.10">
<h3 data-number="2.10" class="anchored" data-anchor-id="singular-value-and-singluar-vectors"><span class="header-section-number">2.10</span> Singular value and Singluar Vectors</h3>
<p>The singular value decomposition (SVD) of a matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> is a factorization of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> into the product of three matrices as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20m"> orthogonal matrix, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> rectangular diagonal matrix with non-negative real numbers on the diagonal, and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> orthogonal matrix.</p>
<p>The diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> are called the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Csigma_1,%20%5Csigma_2,%20%5Cldots,%20%5Csigma_r"> (where <img src="https://latex.codecogs.com/png.latex?r"> is the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">), and are arranged in descending order. The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> are called the left and right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, respectively, and are orthonormal vectors.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be a 3 by 2 matrix given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%5C%5C%0A%20%20%20%203%20&amp;%204%5C%5C%0A%20%20%20%205%20&amp;%206%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The SVD of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.23%20&amp;%20-0.53%20&amp;%20-0.81%5C%5C%0A%20%20-0.53%20&amp;%20-0.72%20&amp;%200.45%5C%5C%0A%20%20-0.81%20&amp;%200.45%20&amp;%20-0.38%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%209.53%20&amp;%200%5C%5C%0A%20%200%20&amp;%200.90%5C%5C%0A%20%200%20&amp;%200%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.62%20&amp;%20-0.78%5C%5C%0A%20%20-0.78%20&amp;%200.62%0A%5Cend%7Bbmatrix%7D%5ET%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where the left singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D">, the right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D">, and the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5CSigma%7D">.</p>
<ul>
<li>연립 방정식을 행렬의 곱으로 나타내보기 <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bmatrix%7Dx_1+2y_1=4%5C%5C2x_1+5y_1=9%5Cend%7Bmatrix%7D%20%5Cquad%20%5Cquad%20%5Cquad%20%5Cbegin%7Bmatrix%7Dx_2+2y_2=3%5C%5C2x_2+5y_2=7%5Cend%7Bmatrix%7D"> <img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20%5C%5C%202%20&amp;%205%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20%5C%5C%20y_1%20&amp;%20y_2%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%204%20&amp;%209%20%5C%5C%203%20&amp;%207%20%5Cend%7Bbmatrix%7D"></li>
<li>중요한 사실(….당연한 사실?)
<ul>
<li>곱셈의 왼쪽 행렬의 열 수와, 오른쪽 행렬의 행 수가 같아야 가능함
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20B_%7Bo%20%5Ctimes%20p%7D"> 에서 <img src="https://latex.codecogs.com/png.latex?n%20=%20o"> 여야 곱셈 성립</li>
</ul></li>
<li>곱셈의 결과 행렬의 크기 = 곱셈의 왼쪽 행렬의 행 수 <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> 곱셈의 오른쪽 행렬의 열 수
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20B_%7Bo%20%5Ctimes%20p%7D%20=%20C_%7Bm%20%5Ctimes%20p%7D"></li>
</ul></li>
<li>교환법칙(Commutative property)이 성립하지 않음
<ul>
<li><img src="https://latex.codecogs.com/png.latex?AB%20%5Cneq%20BA"></li>
</ul></li>
</ul></li>
<li>행렬 곱셈의 여러가지 관점
<ul>
<li>내적으로 바라보기 <img src="https://latex.codecogs.com/png.latex?%20A%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20"> <img src="https://latex.codecogs.com/png.latex?%20AB%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%7D%20&amp;%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_1%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_1%5ET%20b_m%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_2%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_2%5ET%20b_m%7D%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_m%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%5ET%20b_m%7D%20%5Cend%7Bbmatrix%7D"></li>
<li>rank-1 matrix의 합 (또 안가르쳐준 개념 먼저 사용중…..-_-) <img src="https://latex.codecogs.com/png.latex?AB%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%7D%20&amp;%20%5Cmathbf%7Ba_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Bb_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Bb_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7Ba_1%20b_1%5ET%7D%20+%20%5Cmathbf%7Ba_2%20b_2%5ET%7D%20+%20%5Ccdots%20+%20%5Cmathbf%7Ba_m%20b_m%5ET%7D"></li>
<li>column space로 바라보기 <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%7D%20&amp;%20%5Cmathbf%7Ba_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20%5C%5C%20x_2%20%5C%5C%20%5Cvdots%20%5C%5C%20x_m%20%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7Ba_1%7D%20x_1%20+%20%5Cmathbf%7Ba_2%7D%20x_2%20+%20%5Ccdots%20+%20%5Cmathbf%7Ba_m%7D%20x_m%20"> (스칼라배의 합)
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20%5C%5C%200%20&amp;%201%20%5Cend%7Bbmatrix%7D"> 는 2차원 좌표평면의 모든 점을, <img src="https://latex.codecogs.com/png.latex?A=%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%200%20%5C%5C%200%20&amp;%201%20&amp;%200%20%5C%5C%200%20&amp;%200%20&amp;%201%20%5Cend%7Bbmatrix%7D">은 3차원 좌표평면의 모든 점 표현 가능</li>
<li><img src="https://latex.codecogs.com/png.latex?AB%20=%20A%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%7D%20&amp;%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20A%20%5Cmathbf%7Bb_1%7D%20&amp;%20A%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20A%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D"></li>
<li>column space: A의 column vector로 만들 수 있는 부분 공간</li>
</ul></li>
<li>row space로 바라보기 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%5ET%7DA%20=%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20&amp;%20%5Ccdots%20&amp;%20x_m%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20=%20x_1%20%5Cmathbf%7Ba_1%5ET%7D%20+%20x_2%20%5Cmathbf%7Ba_2%5ET%7D%20+%20%5Ccdots%20+%20x_m%20%5Cmathbf%7Ba_m%5ET%7D%20"></li>
</ul></li>
</ul>
</section>
</section>
<section id="열공간column-space" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="열공간column-space"><span class="header-section-number">3</span> 열공간(Column Space)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/g0eaDeVRdZk" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>column space: column vector 들이 span 하는 space
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A">의 column space = <img src="https://latex.codecogs.com/png.latex?C(A)"> 또는 <img src="https://latex.codecogs.com/png.latex?range(A)"></li>
</ul></li>
<li>span: vector들의 linear combination 으로 나타낼 수 있는 모든 vector를 모은 집합
<ul>
<li>vector에 따라, 점일수도 선일수도 평면일 수도 있음</li>
<li>vector space를 이 vector들이 span하는 space → column space는 행렬의 열들이 span하는 space</li>
</ul></li>
<li>vector의 선형 결합(linear combination): vector에 스칼라배를 해서 더하는 것
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D"> 과 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D">의 linear combination으로 2차원 좌표평면 나타내기 <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" class="img-fluid"></li>
</ul></li>
</ul>
</section>
<section id="선형-독립linear-independent" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="선형-독립linear-independent"><span class="header-section-number">4</span> 선형 독립(Linear Independent)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/mOOI4-BfjGQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>…and also see</p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/9F4PZ_1orF0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>선형 독립(linearly independent)인 vectors: (선형 결합을 통해) 더 고차원을 span할 수 있게 해줌</li>
<li>orthogonal 하면 independent
<ul>
<li>but independent해도 항상 orthogonal하지는 않음 (Independent &gt; Orthogonal)</li>
</ul></li>
<li>definition: <img src="https://latex.codecogs.com/png.latex?a_1%20%5Cmathbf%7Bv_1%7D%20+%20a_2%20%5Cmathbf%7Bv_2%7D%20+%20a_3%20%5Cmathbf%7Bv_3%7D%20%5Ccdots%20a_n%20%5Cmathbf%7Bv_n%7D%20=%20%5Cmathbf%7B0%7D"> 를 만족하는 <img src="https://latex.codecogs.com/png.latex?a_1,%20a_2,%20a_3,%20%5Ccdots%20a_n"> 이 <img src="https://latex.codecogs.com/png.latex?a_1%20=%20a_2%20=%20a_3%20=%20%5Ccdots%20=%20a_n%20=%200"> 밖에 없을때
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D">는 모든 elements가 <img src="https://latex.codecogs.com/png.latex?0">인 벡터</li>
<li>예: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%202%20%5Cend%7Bbmatrix%7D"> 는 <img src="https://latex.codecogs.com/png.latex?-2%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D%20+%201%20%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%202%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> 이 되므로, linearly independent 하지 않음</li>
<li>independent한 vector 들의 수 = 표현할 수 있는 차원의 dimension</li>
</ul></li>
</ul>
</section>
<section id="기저basis" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="기저basis"><span class="header-section-number">5</span> 기저(basis)</h2>
<ul>
<li>주어진 vector space를 span하는 linearly independent한 vectors</li>
<li>어떤 공간을 이루는 필수적인 구성요소</li>
<li>orthogonal 하면 orthogonal basis</li>
<li>예: 2차원 좌표평면에 대해
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"> : orthogonal basis</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"> : orthogonal 하지 않은 basis</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> : linearly independent 하지 않으므로 basis 아님</li>
</ul></li>
</ul>
</section>
<section id="항등행렬identity-matrix-역행렬inverse-matrix-대각행렬diagonal-matrix-직교행렬orthogonal-matrix" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="항등행렬identity-matrix-역행렬inverse-matrix-대각행렬diagonal-matrix-직교행렬orthogonal-matrix"><span class="header-section-number">6</span> 항등행렬(identity matrix), 역행렬(inverse matrix), 대각행렬(Diagonal Matrix), 직교행렬(orthogonal matrix)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/XqOvyfMUAwA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="identity-matrix항등행렬" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="identity-matrix항등행렬"><span class="header-section-number">6.1</span> Identity matrix(항등행렬)</h3>
<ul>
<li>항등원: 임의의 원소에 대해 연산하면 자기 자신이 나오게 하는 원소 (by namu.wiki)
<ul>
<li>실수에서 곱셈의 항등원은 1</li>
</ul></li>
<li>행렬의 항등원: 항등행렬(<img src="https://latex.codecogs.com/png.latex?I">) <img src="https://latex.codecogs.com/png.latex?I%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%200%20&amp;%201%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%200%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%201%20%5Cend%7Bbmatrix%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20I_%7Bn%20%5Ctimes%20n%20=%20n%7D%20=%20A_%7Bm%20%5Ctimes%20n%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?I_%7Bm%20%5Ctimes%20m%20=%20m%7D%20%5Ctimes%20A_%7Bm%20%5Ctimes%20n%7D%20=%20A_%7Bm%20%5Ctimes%20n%7D"></li>
</ul></li>
</ul>
</section>
<section id="sec-inv" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="sec-inv"><span class="header-section-number">6.2</span> Inverse matrix(역행렬)</h3>
<ul>
<li>역원: 연산 결과 항등원이 나오게 하는 연소
<ul>
<li>실수에서 곱셈의 역원은 지수의 부호가 반대인 역수 (by namu.wiki): <img src="https://latex.codecogs.com/png.latex?a%20%5Ctimes%20a%5E%7B-1%7D%20=%201"></li>
</ul></li>
<li>행렬의 역원: 역행렬(<img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D">) <img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I%20,%20A%5E%7B-1%7D%20%5Ctimes%20A%20=%20I">
<ul>
<li>존재하지 않는 경우도 있음</li>
<li>존재하면 Invertible(nonsingular, nondegenerate) matrix라고 불림
<ul>
<li>존재하지 않으면 singular, degenerate라고 불림</li>
</ul></li>
<li>square matrix(정사각행렬, <img src="https://latex.codecogs.com/png.latex?m%20=%20n">)은 특수한 경우를 제외하면 역행렬이 항상 존재
<ul>
<li>역행렬이 존재하지 않는특수한 경우: (나중에 배울) determinant가 0인 경우</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?m%20%5Cneq%20n">인 행렬의 경우에는 역행렬이 존재하지 않음
<ul>
<li>다만, 경우에 따라 <img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I"> 를 만족하거나(right inverse), <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D%20%5Ctimes%20A%20=%20I">를 만족하는(left inverse)는 <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D">이 존재함</li>
</ul></li>
<li>연립 방정식을 matrix로 나타냈을 때, 역행렬을 이용해서 해를 찾을 수 있음 <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cmathbf%7Bb%7D%20%5CRightarrow%20A%5E%7B-1%7DA%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D%20%5CRightarrow%20I%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D%20%5CRightarrow%20%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D"></li>
</ul></li>
</ul>
</section>
<section id="diagonal-matrix대각행렬" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="diagonal-matrix대각행렬"><span class="header-section-number">6.3</span> Diagonal Matrix(대각행렬)</h3>
<ul>
<li>diagonal element(대각 원소)외의 모든 elements(off-diagonal elements)가 0인 matrix <img src="https://latex.codecogs.com/png.latex?%20D%20=%20Diag(%5Cmathbf%7Ba%7D)%20=%20%5Cbegin%7Bbmatrix%7D%20a_%7B1,1%7D%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%200%20&amp;%20a_%7B2,2%7D%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%200%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%20a_%7Bn,n%7D%20%5Cend%7Bbmatrix%7D">
<ul>
<li>identity matrix는 diagonal matrix</li>
<li>diagnomal matrix는 symmetric matrix 이기도 함</li>
<li>보통은 square matrix에서 주로 사용됨
<ul>
<li>square matrix가 아니면서 diagonal matrix인 경우: rectangular diagonal matrix</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="orthogonal-matrix직교행렬-orthonomal-matrix" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="orthogonal-matrix직교행렬-orthonomal-matrix"><span class="header-section-number">6.4</span> Orthogonal matrix(직교행렬, orthonomal matrix)</h3>
<ul>
<li>행렬의 각 columns들이 orthonomal vectors (서로 수직하면서 unit vectors) <img src="https://latex.codecogs.com/png.latex?A%20A%5ET%20=%20A%5ET%20A%20=%20I"></li>
<li>identity matrix는 orthogonal matrix</li>
<li>square matrix에서만 정의됨</li>
<li>Orthogonal matrix인 <img src="https://latex.codecogs.com/png.latex?A">이면 <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D%20=%20A%5E%7BT%7D">
<ul>
<li>각 columns에서 자기 자신과의 내적 = 1, 다른 column과의 내적 = 0임</li>
</ul></li>
<li>complex matrix(복소수 행렬)에서는 unitary matrix라고 부름</li>
</ul>
</section>
</section>
<section id="계수rank" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="계수rank"><span class="header-section-number">7</span> 계수(Rank)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/HMST0Yc7EXE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>rank: 행렬이 가지는 independent한 columns의 수 = column space의 dimension = row space의 dimension</li>
<li>independent한 column의 수 = independent한 행의 수: <img src="https://latex.codecogs.com/png.latex?rank(A)%20=%20rank(A%5ET)">
<ul>
<li>proof: <a href="https://en.wikipedia.org/wiki/Rank_%28linear_algebra%29#Proofs_that_column_rank_=_row_rank">Wikipedia</a></li>
</ul></li>
<li>예: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%200%20&amp;%200%20&amp;%200%20%5Cend%7Bbmatrix%7D%20%5CRightarrow%20rank=1"> <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%201%20%5C%5C%200%20&amp;%201%20&amp;%201%20%5Cend%7Bbmatrix%7D%20%5CRightarrow%20rank=2"></li>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D"> 의 최대 랭크는 <img src="https://latex.codecogs.com/png.latex?min%5C%7Bm,n%5C%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?rank(A)%20%3C%20min%5C%7Bm,n%5C%7D"> 면 rank-deficient, <img src="https://latex.codecogs.com/png.latex?rank(A)%20=%20min%5C%7Bm,n%5C%7D">면 full (row/column) rank</li>
</ul></li>
</ul>
</section>
<section id="영공간null-space" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="영공간null-space"><span class="header-section-number">8</span> 영공간(Null space)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/Eizc9TSRYMQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%20%5Cmathbf%7B0%7D"> 을 만족하는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">의 집합
<ul>
<li>column space 관점에서 보기: <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20x_1%20%5Cmathbf%7Ba_1%7D%20+%20x_2%20%5Cmathbf%7Ba_2%7D%20+%20%5Ccdots%20+%20x_n%20%5Cmathbf%7Ba_n%7D%20=%20%5Cmathbf%7B0%7D"></li>
<li>null space에 항상 들어가는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%200%20%5C%5C%20%5Cvdots%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> : trivial solution
<ul>
<li>모든 columns이 다 lienarly independent 하면, null space에는 위의 벡터 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D">하나 밖에 없음</li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D"> 가 아닌 vector가 null space에 있으면, 스칼라배(constant <img src="https://latex.codecogs.com/png.latex?c">에 대해 <img src="https://latex.codecogs.com/png.latex?c%20%5Cmathbf%7Bx%7D">) 역시 null space에 포함됨</li>
<li>혼동 주의! null space는 column space의 일부가 아님
<ul>
<li>row vector의 차원이 null space가 존재하는 공간</li>
</ul></li>
<li>rank와 null space의 dimension의 합은 항상 matrix의 column의 수
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D">에 대해, <img src="https://latex.codecogs.com/png.latex?dim(N(A))%20=%20n%20-%20r">
<ul>
<li>모든 columns이 다 lienarly independent 하면 null space는 0차원(점)</li>
</ul></li>
<li>null space는 row space와 수직한 space
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%20%5Cmathbf%7B0%7D"> : 각각 모든 행과 내적해서 0, → 행들의 linear combination과 내적해도 0</li>
<li>rank는 row space의 dimension → row space의 dimension(<img src="https://latex.codecogs.com/png.latex?dim(R(A))">)과 null space의 dimension(<img src="https://latex.codecogs.com/png.latex?dim(N(A))">)의 합이 <img src="https://latex.codecogs.com/png.latex?n"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%5En%7D"> 공간에 표현: <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_10.PNG" class="img-fluid">
<ul>
<li>겹친 점: 영벡터</li>
</ul></li>
</ul></li>
</ul></li>
<li>left null space: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%5ET%7D%20A%20=%20%5Cmathbf%7B0%5ET%7D"> 인 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">
<ul>
<li>위의 성질을 row에 대해 적용
<ul>
<li>m 차원에 놓인 벡터</li>
<li>dimension: <img src="https://latex.codecogs.com/png.latex?dim(N_L(A))%20=%20m%20-%20r"></li>
<li>column space와 수직: <img src="https://latex.codecogs.com/png.latex?dim(N_L(A))%20+dim(C(A))%20=%20m"></li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?R(A)">에 있는 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_r%7D"> 와 <img src="https://latex.codecogs.com/png.latex?N(A)">에 있는 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 대해:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_r%7D">에 <img src="https://latex.codecogs.com/png.latex?A">를 곱하면 column space로 감</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 <img src="https://latex.codecogs.com/png.latex?A">를 곱하면 $</li>
<li><img src="https://latex.codecogs.com/png.latex?A(%5Cmathbf%7Bx_r%7D%20+%5Cmathbf%7Bx_n%7D)%20=%20A%5Cmathbf%7Bx_r%7D%20+%20A%5Cmathbf%7Bx_n%7D%20=%20A%5Cmathbf%7Bx_r%7D%20=%20%5Cmathbf%7Bb%7D"></li>
</ul></li>
</ul>
</section>
<section id="ax-b의-해의-수" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="ax-b의-해의-수"><span class="header-section-number">9</span> Ax = b의 해의 수</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/nNI2TlD598c" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><p>full column rank 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 있으면 해가 하나</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 없으면 해가 없음 <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_11.PNG" class="img-fluid"></li>
</ul></li>
<li><p>full row rank 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">는 항상 column space 안에 있음: 무한의 해를 가짐</li>
<li>임의의 특정한 해(particular solution) <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_p%7D">와 null space의 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 대해, <img src="https://latex.codecogs.com/png.latex?A(%5Cmathbf%7Bx_p%7D%20+%5Cmathbf%7Bx_n%7D)=%5Cmathbf%7Bb%7D">
<ul>
<li>즉, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_p%7D%20+%5Cmathbf%7Bx_n%7D"> 도 해가 됨: complete solution
<ul>
<li>null space는 무한하므로, 해도 무한함</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>full rank 일때(square matrix): 해가 하나 존재 (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D">$)</p></li>
<li><p>rank-deficient 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 있으면 무한한 해를 가짐</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 없으면 해가 없음</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/03.basic_special_matrix.html</guid>
  <pubDate>Thu, 30 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" medium="image"/>
</item>
<item>
  <title>Basics (4) - Tensor</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/04.basic_tensor.html</link>
  <description><![CDATA[ 



<section id="tensor" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="tensor"><span class="header-section-number">1</span> Tensor</h2>
<p>A tensor is a mathematical object that generalizes vectors and matrices to higher dimensions. A tensor of order <img src="https://latex.codecogs.com/png.latex?n"> is an object that can be represented by a multidimensional array of <img src="https://latex.codecogs.com/png.latex?n"> indices. Each index can take on a range of values, which determine the dimensionality of the tensor along that axis.</p>
<p>For example, a rank-2 tensor (i.e., a matrix) can be represented as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20A_%7Bij%7D%20%5Ctext%7B%20,%20%7D%20i=1,%5Cdots%20m%20%5Ctext%7B,%20%7D%20j=1,%5Cdots,n%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> is the tensor, <img src="https://latex.codecogs.com/png.latex?i"> and <img src="https://latex.codecogs.com/png.latex?j"> are the indices, and <img src="https://latex.codecogs.com/png.latex?m"> and <img src="https://latex.codecogs.com/png.latex?n"> are the dimensions of the tensor along each axis. The entries of the tensor are given by <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">.</p>
<p>A rank-3 tensor can be represented as: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%20A_%7Bijk%7D%20%5Ctext%7B%20,%20%7D%20i=1,%5Cdots%20m%20%5Ctext%7B,%20%7D%20j=1,%5Cdots,n%5Ctext%7B,%20%7D%20k=1,%5Cdots,p%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> is the tensor, <img src="https://latex.codecogs.com/png.latex?i">, <img src="https://latex.codecogs.com/png.latex?j">, and <img src="https://latex.codecogs.com/png.latex?k"> are the indices, and <img src="https://latex.codecogs.com/png.latex?m">, <img src="https://latex.codecogs.com/png.latex?n">, and <img src="https://latex.codecogs.com/png.latex?p"> are the dimensions of the tensor along each axis. The entries of the tensor are given by <img src="https://latex.codecogs.com/png.latex?A_%7Bijk%7D">.</p>
</section>
<section id="basic-tensor-operations" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="basic-tensor-operations"><span class="header-section-number">2</span> Basic Tensor Operations</h2>
<section id="section" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="section"><span class="header-section-number">2.1</span> </h3>


</section>
</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/04.basic_tensor.html</guid>
  <pubDate>Thu, 30 Mar 2023 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Basics (3) - Special Matrices</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/04.linear_transformation.html</link>
  <description><![CDATA[ 



<section id="matrix" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="matrix"><span class="header-section-number">1</span> Matrix</h2>
<p>A matrix is a rectangular array of elements, usually real numbers, arranged in rows and columns. If <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix, it can be represented as: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%20a_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B1n%7D%20%5C%5C%0A%20%20a_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B2n%7D%20%5C%5C%0A%20%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20a_%7Bm1%7D%20&amp;%20a_%7Bm2%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7Bmn%7D%0A%5Cend%7Bbmatrix%7D%0A"> where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of the matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
</section>
<section id="basic-matrix-operations" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="basic-matrix-operations"><span class="header-section-number">2</span> Basic Matrix Operations</h2>
<section id="matrix-addition" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="matrix-addition"><span class="header-section-number">2.1</span> Matrix addition</h3>
<p>The sum of two matrices of the same size is a matrix of the same size obtained by adding corresponding entries.</p>
<p>Given two <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">, their sum <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BA%7D%20+%20%5Cmathbf%7BB%7D"> is defined by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D=a_%7Bi,j%7D+b_%7Bi,j%7D%E2%80%8B%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%201%20&amp;%202%20%5C%5C%0A%20%203%20&amp;%204%20%5C%5C%0A%20%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20+%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-1%20&amp;%200%20%5C%5C%0A%20%202%20&amp;%20-3%20%5C%5C%0A%20%20-5%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%200%20&amp;%202%20%5C%5C%0A%20%205%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%2010%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="scalar-multiplication" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="scalar-multiplication"><span class="header-section-number">2.2</span> Scalar multiplication</h3>
<p>The product of a scalar and a matrix is a matrix obtained by multiplying each entry of the matrix by the scalar.</p>
<p>Given a scalar <img src="https://latex.codecogs.com/png.latex?k"> and an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, their product <img src="https://latex.codecogs.com/png.latex?k%5Cmathbf%7BA%7D"> is defined by: <img src="https://latex.codecogs.com/png.latex?%0A(k%5Cmathbf%7BA%7D)_%7Bi,j%7D%20=%20k(a_%7Bi,j%7D)%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A2%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A2%20&amp;%204%20%5C%5C%0A6%20&amp;%208%20%5C%5C%0A10%20&amp;%2012%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="matrix-multiplication" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="matrix-multiplication"><span class="header-section-number">2.3</span> Matrix multiplication</h3>
<p>The product of two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> is a matrix obtained by multiplying the rows of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> by the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">.</p>
<p>Given two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> with dimensions <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> and <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20p">, respectively, their product <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BAB%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20p"> matrix defined by: <img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D%20=%20%5Csum_%7Bk=1%7D%5En%20a_%7Bi,k%7Db_%7Bk,j%7D%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20p">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%0A-1%20&amp;%200%20&amp;%202%20%5C%5C%0A2%20&amp;%20-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A3%20&amp;%20-6%20&amp;%204%20%5C%5C%0A5%20&amp;%20-12%20&amp;%2010%20%5C%5C%0A7%20&amp;%20-18%20&amp;%2016%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="transpose" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="transpose"><span class="header-section-number">2.4</span> Transpose</h3>
<p>The transpose of an <img src="https://latex.codecogs.com/png.latex?m%20x%20n"> matrix A, denoted by <img src="https://latex.codecogs.com/png.latex?A%5ET">, is the <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix obtained by interchanging the rows and columns of A. Formally, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Ba_%7Bij%7D%5D"> is an m x n matrix, then its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET%20=%20%5Bb_%7Bij%7D%5D"> is an <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix where <img src="https://latex.codecogs.com/png.latex?b_%7Bij%7D"> = <img src="https://latex.codecogs.com/png.latex?a_%7Bji%7D"> for all <img src="https://latex.codecogs.com/png.latex?i"> and <img src="https://latex.codecogs.com/png.latex?j">. In other words, the element in the <img src="https://latex.codecogs.com/png.latex?i"> th row and <img src="https://latex.codecogs.com/png.latex?j"> th column of <img src="https://latex.codecogs.com/png.latex?A%5ET"> is equal to the element in the <img src="https://latex.codecogs.com/png.latex?j"> th row and ith column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>Given an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20m"> matrix defined by: $$ <em>{i,j}^T = </em>{j,i}</p>
<p>$$</p>
<ul>
<li>When <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is transposed, diagnoal entries(<img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D">) do not change but off-diagnoal elements(<img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D%20%5C;%20i%20%5Cneq%20j">) change.</li>
<li>A column vector is tranposed into a row vector, and vice versa.</li>
<li>symmetric matrix: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5ET"></li>
</ul>
<p>Example:</p>
<p>Let A be the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%5C%5C%0A4%20&amp;%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"> The transpose of A, denoted by A^T, is the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5ET%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%204%5C%5C%0A2%20&amp;%205%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="determinant" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="determinant"><span class="header-section-number">2.5</span> Determinant</h3>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> square matrix. The determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C"> or <img src="https://latex.codecogs.com/png.latex?%5Cdet(%5Cmathbf%7BA%7D)">, is a scalar value calculated as the sum of the products of the elements in any row or column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> with their corresponding cofactors, that is,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D=%5Csum_%7Bj=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column, and <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D"> is the cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">. The cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D">, is given by <img src="https://latex.codecogs.com/png.latex?(-1)%5E%7Bi+j%7D"> times the determinant of the <img src="https://latex.codecogs.com/png.latex?(n-1)%20%5Ctimes%20(n-1)"> matrix obtained by deleting the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>The determinant of an <img src="https://latex.codecogs.com/png.latex?n%20x%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is a scalar value denoted as <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C">. It is defined as the sum of all possible products of n elements taken one from each row and one from each column, where the sign of each product alternates according to the position of the element in the matrix. For example, the determinant of a <img src="https://latex.codecogs.com/png.latex?3%20x%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20="> <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%20a_%7B11%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B32%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A-%20a_%7B12%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A+%20a_%7B13%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%0A%5Cend%7Bvmatrix%7D%0A"></p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?3%20%5Ctimes%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%204%20&amp;%205%20&amp;%206%20%5C%5C%207%20&amp;%208%20&amp;%209%20%5Cend%7Bbmatrix%7D">. We can calculate the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> using any row or column. Let’s use the first column:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%201%0A%5Cbegin%7Bvmatrix%7D%0A5%20&amp;%206%20%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A-%204%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%203%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A+%207%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%205%20%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bvmatrix%7D%20=%200%0A"></p>
<p>Therefore, the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is zero.</p>
</section>
<section id="inverse" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="inverse"><span class="header-section-number">2.6</span> Inverse</h3>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?A"> of size <img src="https://latex.codecogs.com/png.latex?n"> is a matrix <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> such that the product of <img src="https://latex.codecogs.com/png.latex?A"> and <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> is the identity matrix <img src="https://latex.codecogs.com/png.latex?I_n">, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I_n">. If such a matrix exists, then <img src="https://latex.codecogs.com/png.latex?A"> is said to be invertible or non-singular.</p>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D"> and is defined as the unique matrix that satisfies the following equation: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BI%7D"> is the identity matrix. Not all matrices have an inverse, and a matrix that has an inverse is called invertible or nonsingular. A matrix that does not have an inverse is called singular.</p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?2%5Ctimes%202"> matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D.%0A"> The inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cfrac%7B1%7D%7B-2%7D%0A%5Cbegin%7Bbmatrix%7D%0A4%20&amp;%20-2%20%5C%5C%0A-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>We can verify that <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BI%7D"> by computing:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%20-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>Let me give another example and A be a <img src="https://latex.codecogs.com/png.latex?3x3"> square matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D">, is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B%5Ctext%7Bdet%7D(%5Cmathbf%7BA%7D)%7D%5Cbegin%7Bbmatrix%7D%0Aa_%7B22%7Da_%7B33%7D-a_%7B23%7Da_%7B32%7D%20&amp;%20a_%7B13%7Da_%7B32%7D-a_%7B12%7Da_%7B33%7D%20&amp;%20a_%7B12%7Da_%7B23%7D-a_%7B13%7Da_%7B22%7D%20%5C%5C%0Aa_%7B23%7Da_%7B31%7D-a_%7B21%7Da_%7B33%7D%20&amp;%20a_%7B11%7Da_%7B33%7D-a_%7B13%7Da_%7B31%7D%20&amp;%20a_%7B13%7Da_%7B21%7D-a_%7B11%7Da_%7B23%7D%20%5C%5C%0Aa_%7B21%7Da_%7B32%7D-a_%7B22%7Da_%7B31%7D%20&amp;%20a_%7B12%7Da_%7B31%7D-a_%7B11%7Da_%7B32%7D%20&amp;%20a_%7B11%7Da_%7B22%7D-a_%7B12%7Da_%7B21%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?det(%5Cmathbf%7BA%7D)"> is the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%20%5C%5C%0A0%20&amp;%201%20&amp;%204%20%5C%5C%0A5%20&amp;%206%20&amp;%200%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, <img src="https://latex.codecogs.com/png.latex?det(A)"> = -57, and the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B-57%7D%5Cbegin%7Bbmatrix%7D%0A-24%20&amp;%2018%20&amp;%205%20%5C%5C%0A20%20&amp;%20-15%20&amp;%20-4%20%5C%5C%0A-3%20&amp;%202%20&amp;%201%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>There are several formulas for finding the inverse of a matrix such as Gauss-Jordan Elimination, Adjoint method, Cramer’s rule, Inverse formula, etc. This topic is going to be handled in the other blogs.</p>
</section>
<section id="rank" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="rank"><span class="header-section-number">2.7</span> Rank</h3>
<p>The rank of a matrix is the dimension of the vector space spanned by its columns (or rows). It is denoted by <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Brank%7D(%5Cmathbf%7BA%7D)">.</p>
<p>For example, consider the following matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%20%20%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%20&amp;%203%5C%5C%0A%20%20%20%204%20&amp;%205%20&amp;%206%20%5C%5C%0A%20%20%20%207%20&amp;%208%20&amp;%209%5C%5C%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are linearly dependent since the third column is equal to the sum of the first two columns. Therefore, the dimension of the vector space spanned by the columns is 2, so the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is 2.</p>
</section>
<section id="trace" class="level3" data-number="2.8">
<h3 data-number="2.8" class="anchored" data-anchor-id="trace"><span class="header-section-number">2.8</span> Trace</h3>
<p>The trace of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)">, is defined as the sum of the diagonal elements of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">. In other words, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> matrix, then its trace is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D"> denotes the <img src="https://latex.codecogs.com/png.latex?i"> th diagonal element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%202%20&amp;%203%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%205%20&amp;%202%20%5C%5C%0A%20%201%20&amp;%201%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>Then, the trace of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)%20=%202%20+%205%20+%204%20=%2011"></p>
</section>
<section id="eigenvalues-and-eigenvectors" class="level3" data-number="2.9">
<h3 data-number="2.9" class="anchored" data-anchor-id="eigenvalues-and-eigenvectors"><span class="header-section-number">2.9</span> Eigenvalues and Eigenvectors</h3>
<p>Let A be an <img src="https://latex.codecogs.com/png.latex?n%20%C3%97%20n"> square matrix. A scalar <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is called an eigenvalue of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> if there exists a non-zero vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> such that <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BAv%7D=%5Clambda%5Cmathbf%7Bv%7D%0A"></p>
<p>Such a vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> is called an eigenvector corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda">.</p>
<p>Example:</p>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> be the matrix</p>
<p>To find the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">, we solve the characteristic equation <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%20=%200">, where I is the n × n identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%0A%20%20&amp;=%0A%20%20%20%20%5Cbegin%7Bvmatrix%7D%0A%20%20%20%203%20-%20%5Clambda%20&amp;%201%20%5C%5C%0A%20%20%20%201%20&amp;%203%20-%20%5Clambda%0A%20%20%20%20%5Cend%7Bvmatrix%7D%20%5C%5C%0A%20%20&amp;=%0A%20%20(3%20-%20%5Clambda)(3%20-%20%5Clambda)%20-%201%20%5C%5C%0A%20%20&amp;=%20%5Clambda%5E2%20-%206%5Clambda%20+%208%20=%200%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this quadratic equation gives us the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">: <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202"> and <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">.</p>
<p>To find the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%20%5Cmathbf%7B0%7D">, where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20I"> is the <img src="https://latex.codecogs.com/png.latex?2%20%5Ctimes%202"> identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%0A%20%20%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%20%201%20&amp;%201%20%5C%5C%0A%20%20%20%20%20%201%20&amp;%201%0A%20%20%20%20%5Cend%7Bbmatrix%7D%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20x%20%5C%5C%0A%20%20%20%20y%0A%20%20%5Cend%7Bbmatrix%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%200%20%5C%5C%0A%20%20%20%200%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this system of equations gives us the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D%20=%20%5Cbegin%7Bbmatrix%7D%20-1%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
<p>Similarly, for <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%204%5Cmathbf%20I)%5Cmathbf%7Bv%7D"> = <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D"> to get the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
</section>
<section id="singular-value-and-singluar-vectors" class="level3" data-number="2.10">
<h3 data-number="2.10" class="anchored" data-anchor-id="singular-value-and-singluar-vectors"><span class="header-section-number">2.10</span> Singular value and Singluar Vectors</h3>
<p>The singular value decomposition (SVD) of a matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> is a factorization of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> into the product of three matrices as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20m"> orthogonal matrix, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> rectangular diagonal matrix with non-negative real numbers on the diagonal, and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> orthogonal matrix.</p>
<p>The diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> are called the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Csigma_1,%20%5Csigma_2,%20%5Cldots,%20%5Csigma_r"> (where <img src="https://latex.codecogs.com/png.latex?r"> is the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">), and are arranged in descending order. The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> are called the left and right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, respectively, and are orthonormal vectors.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be a 3 by 2 matrix given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%5C%5C%0A%20%20%20%203%20&amp;%204%5C%5C%0A%20%20%20%205%20&amp;%206%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The SVD of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.23%20&amp;%20-0.53%20&amp;%20-0.81%5C%5C%0A%20%20-0.53%20&amp;%20-0.72%20&amp;%200.45%5C%5C%0A%20%20-0.81%20&amp;%200.45%20&amp;%20-0.38%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%209.53%20&amp;%200%5C%5C%0A%20%200%20&amp;%200.90%5C%5C%0A%20%200%20&amp;%200%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.62%20&amp;%20-0.78%5C%5C%0A%20%20-0.78%20&amp;%200.62%0A%5Cend%7Bbmatrix%7D%5ET%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where the left singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D">, the right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D">, and the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5CSigma%7D">.</p>
<ul>
<li>연립 방정식을 행렬의 곱으로 나타내보기 <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bmatrix%7Dx_1+2y_1=4%5C%5C2x_1+5y_1=9%5Cend%7Bmatrix%7D%20%5Cquad%20%5Cquad%20%5Cquad%20%5Cbegin%7Bmatrix%7Dx_2+2y_2=3%5C%5C2x_2+5y_2=7%5Cend%7Bmatrix%7D"> <img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20%5C%5C%202%20&amp;%205%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20%5C%5C%20y_1%20&amp;%20y_2%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%204%20&amp;%209%20%5C%5C%203%20&amp;%207%20%5Cend%7Bbmatrix%7D"></li>
<li>중요한 사실(….당연한 사실?)
<ul>
<li>곱셈의 왼쪽 행렬의 열 수와, 오른쪽 행렬의 행 수가 같아야 가능함
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20B_%7Bo%20%5Ctimes%20p%7D"> 에서 <img src="https://latex.codecogs.com/png.latex?n%20=%20o"> 여야 곱셈 성립</li>
</ul></li>
<li>곱셈의 결과 행렬의 크기 = 곱셈의 왼쪽 행렬의 행 수 <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> 곱셈의 오른쪽 행렬의 열 수
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20B_%7Bo%20%5Ctimes%20p%7D%20=%20C_%7Bm%20%5Ctimes%20p%7D"></li>
</ul></li>
<li>교환법칙(Commutative property)이 성립하지 않음
<ul>
<li><img src="https://latex.codecogs.com/png.latex?AB%20%5Cneq%20BA"></li>
</ul></li>
</ul></li>
<li>행렬 곱셈의 여러가지 관점
<ul>
<li>내적으로 바라보기 <img src="https://latex.codecogs.com/png.latex?%20A%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20"> <img src="https://latex.codecogs.com/png.latex?%20AB%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%7D%20&amp;%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_1%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_1%5ET%20b_m%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_2%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_2%5ET%20b_m%7D%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_m%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%5ET%20b_m%7D%20%5Cend%7Bbmatrix%7D"></li>
<li>rank-1 matrix의 합 (또 안가르쳐준 개념 먼저 사용중…..-_-) <img src="https://latex.codecogs.com/png.latex?AB%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%7D%20&amp;%20%5Cmathbf%7Ba_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Bb_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Bb_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7Ba_1%20b_1%5ET%7D%20+%20%5Cmathbf%7Ba_2%20b_2%5ET%7D%20+%20%5Ccdots%20+%20%5Cmathbf%7Ba_m%20b_m%5ET%7D"></li>
<li>column space로 바라보기 <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%7D%20&amp;%20%5Cmathbf%7Ba_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20%5C%5C%20x_2%20%5C%5C%20%5Cvdots%20%5C%5C%20x_m%20%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7Ba_1%7D%20x_1%20+%20%5Cmathbf%7Ba_2%7D%20x_2%20+%20%5Ccdots%20+%20%5Cmathbf%7Ba_m%7D%20x_m%20"> (스칼라배의 합)
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20%5C%5C%200%20&amp;%201%20%5Cend%7Bbmatrix%7D"> 는 2차원 좌표평면의 모든 점을, <img src="https://latex.codecogs.com/png.latex?A=%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%200%20%5C%5C%200%20&amp;%201%20&amp;%200%20%5C%5C%200%20&amp;%200%20&amp;%201%20%5Cend%7Bbmatrix%7D">은 3차원 좌표평면의 모든 점 표현 가능</li>
<li><img src="https://latex.codecogs.com/png.latex?AB%20=%20A%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%7D%20&amp;%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20A%20%5Cmathbf%7Bb_1%7D%20&amp;%20A%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20A%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D"></li>
<li>column space: A의 column vector로 만들 수 있는 부분 공간</li>
</ul></li>
<li>row space로 바라보기 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%5ET%7DA%20=%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20&amp;%20%5Ccdots%20&amp;%20x_m%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20=%20x_1%20%5Cmathbf%7Ba_1%5ET%7D%20+%20x_2%20%5Cmathbf%7Ba_2%5ET%7D%20+%20%5Ccdots%20+%20x_m%20%5Cmathbf%7Ba_m%5ET%7D%20"></li>
</ul></li>
</ul>
</section>
</section>
<section id="열공간column-space" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="열공간column-space"><span class="header-section-number">3</span> 열공간(Column Space)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/g0eaDeVRdZk" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>column space: column vector 들이 span 하는 space
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A">의 column space = <img src="https://latex.codecogs.com/png.latex?C(A)"> 또는 <img src="https://latex.codecogs.com/png.latex?range(A)"></li>
</ul></li>
<li>span: vector들의 linear combination 으로 나타낼 수 있는 모든 vector를 모은 집합
<ul>
<li>vector에 따라, 점일수도 선일수도 평면일 수도 있음</li>
<li>vector space를 이 vector들이 span하는 space → column space는 행렬의 열들이 span하는 space</li>
</ul></li>
<li>vector의 선형 결합(linear combination): vector에 스칼라배를 해서 더하는 것
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D"> 과 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D">의 linear combination으로 2차원 좌표평면 나타내기 <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" class="img-fluid"></li>
</ul></li>
</ul>
</section>
<section id="선형-독립linear-independent" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="선형-독립linear-independent"><span class="header-section-number">4</span> 선형 독립(Linear Independent)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/mOOI4-BfjGQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>…and also see</p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/9F4PZ_1orF0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>선형 독립(linearly independent)인 vectors: (선형 결합을 통해) 더 고차원을 span할 수 있게 해줌</li>
<li>orthogonal 하면 independent
<ul>
<li>but independent해도 항상 orthogonal하지는 않음 (Independent &gt; Orthogonal)</li>
</ul></li>
<li>definition: <img src="https://latex.codecogs.com/png.latex?a_1%20%5Cmathbf%7Bv_1%7D%20+%20a_2%20%5Cmathbf%7Bv_2%7D%20+%20a_3%20%5Cmathbf%7Bv_3%7D%20%5Ccdots%20a_n%20%5Cmathbf%7Bv_n%7D%20=%20%5Cmathbf%7B0%7D"> 를 만족하는 <img src="https://latex.codecogs.com/png.latex?a_1,%20a_2,%20a_3,%20%5Ccdots%20a_n"> 이 <img src="https://latex.codecogs.com/png.latex?a_1%20=%20a_2%20=%20a_3%20=%20%5Ccdots%20=%20a_n%20=%200"> 밖에 없을때
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D">는 모든 elements가 <img src="https://latex.codecogs.com/png.latex?0">인 벡터</li>
<li>예: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%202%20%5Cend%7Bbmatrix%7D"> 는 <img src="https://latex.codecogs.com/png.latex?-2%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D%20+%201%20%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%202%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> 이 되므로, linearly independent 하지 않음</li>
<li>independent한 vector 들의 수 = 표현할 수 있는 차원의 dimension</li>
</ul></li>
</ul>
</section>
<section id="기저basis" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="기저basis"><span class="header-section-number">5</span> 기저(basis)</h2>
<ul>
<li>주어진 vector space를 span하는 linearly independent한 vectors</li>
<li>어떤 공간을 이루는 필수적인 구성요소</li>
<li>orthogonal 하면 orthogonal basis</li>
<li>예: 2차원 좌표평면에 대해
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"> : orthogonal basis</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"> : orthogonal 하지 않은 basis</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> : linearly independent 하지 않으므로 basis 아님</li>
</ul></li>
</ul>
</section>
<section id="항등행렬identity-matrix-역행렬inverse-matrix-대각행렬diagonal-matrix-직교행렬orthogonal-matrix" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="항등행렬identity-matrix-역행렬inverse-matrix-대각행렬diagonal-matrix-직교행렬orthogonal-matrix"><span class="header-section-number">6</span> 항등행렬(identity matrix), 역행렬(inverse matrix), 대각행렬(Diagonal Matrix), 직교행렬(orthogonal matrix)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/XqOvyfMUAwA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="identity-matrix항등행렬" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="identity-matrix항등행렬"><span class="header-section-number">6.1</span> Identity matrix(항등행렬)</h3>
<ul>
<li>항등원: 임의의 원소에 대해 연산하면 자기 자신이 나오게 하는 원소 (by namu.wiki)
<ul>
<li>실수에서 곱셈의 항등원은 1</li>
</ul></li>
<li>행렬의 항등원: 항등행렬(<img src="https://latex.codecogs.com/png.latex?I">) <img src="https://latex.codecogs.com/png.latex?I%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%200%20&amp;%201%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%200%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%201%20%5Cend%7Bbmatrix%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20I_%7Bn%20%5Ctimes%20n%20=%20n%7D%20=%20A_%7Bm%20%5Ctimes%20n%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?I_%7Bm%20%5Ctimes%20m%20=%20m%7D%20%5Ctimes%20A_%7Bm%20%5Ctimes%20n%7D%20=%20A_%7Bm%20%5Ctimes%20n%7D"></li>
</ul></li>
</ul>
</section>
<section id="sec-inv" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="sec-inv"><span class="header-section-number">6.2</span> Inverse matrix(역행렬)</h3>
<ul>
<li>역원: 연산 결과 항등원이 나오게 하는 연소
<ul>
<li>실수에서 곱셈의 역원은 지수의 부호가 반대인 역수 (by namu.wiki): <img src="https://latex.codecogs.com/png.latex?a%20%5Ctimes%20a%5E%7B-1%7D%20=%201"></li>
</ul></li>
<li>행렬의 역원: 역행렬(<img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D">) <img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I%20,%20A%5E%7B-1%7D%20%5Ctimes%20A%20=%20I">
<ul>
<li>존재하지 않는 경우도 있음</li>
<li>존재하면 Invertible(nonsingular, nondegenerate) matrix라고 불림
<ul>
<li>존재하지 않으면 singular, degenerate라고 불림</li>
</ul></li>
<li>square matrix(정사각행렬, <img src="https://latex.codecogs.com/png.latex?m%20=%20n">)은 특수한 경우를 제외하면 역행렬이 항상 존재
<ul>
<li>역행렬이 존재하지 않는특수한 경우: (나중에 배울) determinant가 0인 경우</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?m%20%5Cneq%20n">인 행렬의 경우에는 역행렬이 존재하지 않음
<ul>
<li>다만, 경우에 따라 <img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I"> 를 만족하거나(right inverse), <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D%20%5Ctimes%20A%20=%20I">를 만족하는(left inverse)는 <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D">이 존재함</li>
</ul></li>
<li>연립 방정식을 matrix로 나타냈을 때, 역행렬을 이용해서 해를 찾을 수 있음 <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cmathbf%7Bb%7D%20%5CRightarrow%20A%5E%7B-1%7DA%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D%20%5CRightarrow%20I%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D%20%5CRightarrow%20%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D"></li>
</ul></li>
</ul>
</section>
<section id="diagonal-matrix대각행렬" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="diagonal-matrix대각행렬"><span class="header-section-number">6.3</span> Diagonal Matrix(대각행렬)</h3>
<ul>
<li>diagonal element(대각 원소)외의 모든 elements(off-diagonal elements)가 0인 matrix <img src="https://latex.codecogs.com/png.latex?%20D%20=%20Diag(%5Cmathbf%7Ba%7D)%20=%20%5Cbegin%7Bbmatrix%7D%20a_%7B1,1%7D%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%200%20&amp;%20a_%7B2,2%7D%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%200%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%20a_%7Bn,n%7D%20%5Cend%7Bbmatrix%7D">
<ul>
<li>identity matrix는 diagonal matrix</li>
<li>diagnomal matrix는 symmetric matrix 이기도 함</li>
<li>보통은 square matrix에서 주로 사용됨
<ul>
<li>square matrix가 아니면서 diagonal matrix인 경우: rectangular diagonal matrix</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="orthogonal-matrix직교행렬-orthonomal-matrix" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="orthogonal-matrix직교행렬-orthonomal-matrix"><span class="header-section-number">6.4</span> Orthogonal matrix(직교행렬, orthonomal matrix)</h3>
<ul>
<li>행렬의 각 columns들이 orthonomal vectors (서로 수직하면서 unit vectors) <img src="https://latex.codecogs.com/png.latex?A%20A%5ET%20=%20A%5ET%20A%20=%20I"></li>
<li>identity matrix는 orthogonal matrix</li>
<li>square matrix에서만 정의됨</li>
<li>Orthogonal matrix인 <img src="https://latex.codecogs.com/png.latex?A">이면 <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D%20=%20A%5E%7BT%7D">
<ul>
<li>각 columns에서 자기 자신과의 내적 = 1, 다른 column과의 내적 = 0임</li>
</ul></li>
<li>complex matrix(복소수 행렬)에서는 unitary matrix라고 부름</li>
</ul>
</section>
</section>
<section id="계수rank" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="계수rank"><span class="header-section-number">7</span> 계수(Rank)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/HMST0Yc7EXE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>rank: 행렬이 가지는 independent한 columns의 수 = column space의 dimension = row space의 dimension</li>
<li>independent한 column의 수 = independent한 행의 수: <img src="https://latex.codecogs.com/png.latex?rank(A)%20=%20rank(A%5ET)">
<ul>
<li>proof: <a href="https://en.wikipedia.org/wiki/Rank_%28linear_algebra%29#Proofs_that_column_rank_=_row_rank">Wikipedia</a></li>
</ul></li>
<li>예: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%200%20&amp;%200%20&amp;%200%20%5Cend%7Bbmatrix%7D%20%5CRightarrow%20rank=1"> <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%201%20%5C%5C%200%20&amp;%201%20&amp;%201%20%5Cend%7Bbmatrix%7D%20%5CRightarrow%20rank=2"></li>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D"> 의 최대 랭크는 <img src="https://latex.codecogs.com/png.latex?min%5C%7Bm,n%5C%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?rank(A)%20%3C%20min%5C%7Bm,n%5C%7D"> 면 rank-deficient, <img src="https://latex.codecogs.com/png.latex?rank(A)%20=%20min%5C%7Bm,n%5C%7D">면 full (row/column) rank</li>
</ul></li>
</ul>
</section>
<section id="영공간null-space" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="영공간null-space"><span class="header-section-number">8</span> 영공간(Null space)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/Eizc9TSRYMQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%20%5Cmathbf%7B0%7D"> 을 만족하는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">의 집합
<ul>
<li>column space 관점에서 보기: <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20x_1%20%5Cmathbf%7Ba_1%7D%20+%20x_2%20%5Cmathbf%7Ba_2%7D%20+%20%5Ccdots%20+%20x_n%20%5Cmathbf%7Ba_n%7D%20=%20%5Cmathbf%7B0%7D"></li>
<li>null space에 항상 들어가는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%200%20%5C%5C%20%5Cvdots%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> : trivial solution
<ul>
<li>모든 columns이 다 lienarly independent 하면, null space에는 위의 벡터 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D">하나 밖에 없음</li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D"> 가 아닌 vector가 null space에 있으면, 스칼라배(constant <img src="https://latex.codecogs.com/png.latex?c">에 대해 <img src="https://latex.codecogs.com/png.latex?c%20%5Cmathbf%7Bx%7D">) 역시 null space에 포함됨</li>
<li>혼동 주의! null space는 column space의 일부가 아님
<ul>
<li>row vector의 차원이 null space가 존재하는 공간</li>
</ul></li>
<li>rank와 null space의 dimension의 합은 항상 matrix의 column의 수
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D">에 대해, <img src="https://latex.codecogs.com/png.latex?dim(N(A))%20=%20n%20-%20r">
<ul>
<li>모든 columns이 다 lienarly independent 하면 null space는 0차원(점)</li>
</ul></li>
<li>null space는 row space와 수직한 space
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%20%5Cmathbf%7B0%7D"> : 각각 모든 행과 내적해서 0, → 행들의 linear combination과 내적해도 0</li>
<li>rank는 row space의 dimension → row space의 dimension(<img src="https://latex.codecogs.com/png.latex?dim(R(A))">)과 null space의 dimension(<img src="https://latex.codecogs.com/png.latex?dim(N(A))">)의 합이 <img src="https://latex.codecogs.com/png.latex?n"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%5En%7D"> 공간에 표현: <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_10.PNG" class="img-fluid">
<ul>
<li>겹친 점: 영벡터</li>
</ul></li>
</ul></li>
</ul></li>
<li>left null space: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%5ET%7D%20A%20=%20%5Cmathbf%7B0%5ET%7D"> 인 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">
<ul>
<li>위의 성질을 row에 대해 적용
<ul>
<li>m 차원에 놓인 벡터</li>
<li>dimension: <img src="https://latex.codecogs.com/png.latex?dim(N_L(A))%20=%20m%20-%20r"></li>
<li>column space와 수직: <img src="https://latex.codecogs.com/png.latex?dim(N_L(A))%20+dim(C(A))%20=%20m"></li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?R(A)">에 있는 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_r%7D"> 와 <img src="https://latex.codecogs.com/png.latex?N(A)">에 있는 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 대해:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_r%7D">에 <img src="https://latex.codecogs.com/png.latex?A">를 곱하면 column space로 감</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 <img src="https://latex.codecogs.com/png.latex?A">를 곱하면 $</li>
<li><img src="https://latex.codecogs.com/png.latex?A(%5Cmathbf%7Bx_r%7D%20+%5Cmathbf%7Bx_n%7D)%20=%20A%5Cmathbf%7Bx_r%7D%20+%20A%5Cmathbf%7Bx_n%7D%20=%20A%5Cmathbf%7Bx_r%7D%20=%20%5Cmathbf%7Bb%7D"></li>
</ul></li>
</ul>
</section>
<section id="ax-b의-해의-수" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="ax-b의-해의-수"><span class="header-section-number">9</span> Ax = b의 해의 수</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/nNI2TlD598c" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><p>full column rank 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 있으면 해가 하나</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 없으면 해가 없음 <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_11.PNG" class="img-fluid"></li>
</ul></li>
<li><p>full row rank 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">는 항상 column space 안에 있음: 무한의 해를 가짐</li>
<li>임의의 특정한 해(particular solution) <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_p%7D">와 null space의 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 대해, <img src="https://latex.codecogs.com/png.latex?A(%5Cmathbf%7Bx_p%7D%20+%5Cmathbf%7Bx_n%7D)=%5Cmathbf%7Bb%7D">
<ul>
<li>즉, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_p%7D%20+%5Cmathbf%7Bx_n%7D"> 도 해가 됨: complete solution
<ul>
<li>null space는 무한하므로, 해도 무한함</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>full rank 일때(square matrix): 해가 하나 존재 (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D">$)</p></li>
<li><p>rank-deficient 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 있으면 무한한 해를 가짐</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 없으면 해가 없음</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/04.linear_transformation.html</guid>
  <pubDate>Thu, 30 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" medium="image"/>
</item>
<item>
  <title>Basics (3) - Special Matrices</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/05.vector_space.html</link>
  <description><![CDATA[ 



<section id="matrix" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="matrix"><span class="header-section-number">1</span> Matrix</h2>
<p>A matrix is a rectangular array of elements, usually real numbers, arranged in rows and columns. If <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix, it can be represented as: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%20a_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B1n%7D%20%5C%5C%0A%20%20a_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B2n%7D%20%5C%5C%0A%20%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20a_%7Bm1%7D%20&amp;%20a_%7Bm2%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7Bmn%7D%0A%5Cend%7Bbmatrix%7D%0A"> where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of the matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
</section>
<section id="basic-matrix-operations" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="basic-matrix-operations"><span class="header-section-number">2</span> Basic Matrix Operations</h2>
<section id="matrix-addition" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="matrix-addition"><span class="header-section-number">2.1</span> Matrix addition</h3>
<p>The sum of two matrices of the same size is a matrix of the same size obtained by adding corresponding entries.</p>
<p>Given two <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">, their sum <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BA%7D%20+%20%5Cmathbf%7BB%7D"> is defined by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D=a_%7Bi,j%7D+b_%7Bi,j%7D%E2%80%8B%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%201%20&amp;%202%20%5C%5C%0A%20%203%20&amp;%204%20%5C%5C%0A%20%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20+%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-1%20&amp;%200%20%5C%5C%0A%20%202%20&amp;%20-3%20%5C%5C%0A%20%20-5%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%200%20&amp;%202%20%5C%5C%0A%20%205%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%2010%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="scalar-multiplication" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="scalar-multiplication"><span class="header-section-number">2.2</span> Scalar multiplication</h3>
<p>The product of a scalar and a matrix is a matrix obtained by multiplying each entry of the matrix by the scalar.</p>
<p>Given a scalar <img src="https://latex.codecogs.com/png.latex?k"> and an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, their product <img src="https://latex.codecogs.com/png.latex?k%5Cmathbf%7BA%7D"> is defined by: <img src="https://latex.codecogs.com/png.latex?%0A(k%5Cmathbf%7BA%7D)_%7Bi,j%7D%20=%20k(a_%7Bi,j%7D)%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A2%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A2%20&amp;%204%20%5C%5C%0A6%20&amp;%208%20%5C%5C%0A10%20&amp;%2012%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="matrix-multiplication" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="matrix-multiplication"><span class="header-section-number">2.3</span> Matrix multiplication</h3>
<p>The product of two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> is a matrix obtained by multiplying the rows of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> by the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">.</p>
<p>Given two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> with dimensions <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> and <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20p">, respectively, their product <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BAB%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20p"> matrix defined by: <img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D%20=%20%5Csum_%7Bk=1%7D%5En%20a_%7Bi,k%7Db_%7Bk,j%7D%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20p">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%0A-1%20&amp;%200%20&amp;%202%20%5C%5C%0A2%20&amp;%20-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A3%20&amp;%20-6%20&amp;%204%20%5C%5C%0A5%20&amp;%20-12%20&amp;%2010%20%5C%5C%0A7%20&amp;%20-18%20&amp;%2016%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="transpose" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="transpose"><span class="header-section-number">2.4</span> Transpose</h3>
<p>The transpose of an <img src="https://latex.codecogs.com/png.latex?m%20x%20n"> matrix A, denoted by <img src="https://latex.codecogs.com/png.latex?A%5ET">, is the <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix obtained by interchanging the rows and columns of A. Formally, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Ba_%7Bij%7D%5D"> is an m x n matrix, then its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET%20=%20%5Bb_%7Bij%7D%5D"> is an <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix where <img src="https://latex.codecogs.com/png.latex?b_%7Bij%7D"> = <img src="https://latex.codecogs.com/png.latex?a_%7Bji%7D"> for all <img src="https://latex.codecogs.com/png.latex?i"> and <img src="https://latex.codecogs.com/png.latex?j">. In other words, the element in the <img src="https://latex.codecogs.com/png.latex?i"> th row and <img src="https://latex.codecogs.com/png.latex?j"> th column of <img src="https://latex.codecogs.com/png.latex?A%5ET"> is equal to the element in the <img src="https://latex.codecogs.com/png.latex?j"> th row and ith column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>Given an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20m"> matrix defined by: $$ <em>{i,j}^T = </em>{j,i}</p>
<p>$$</p>
<ul>
<li>When <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is transposed, diagnoal entries(<img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D">) do not change but off-diagnoal elements(<img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D%20%5C;%20i%20%5Cneq%20j">) change.</li>
<li>A column vector is tranposed into a row vector, and vice versa.</li>
<li>symmetric matrix: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5ET"></li>
</ul>
<p>Example:</p>
<p>Let A be the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%5C%5C%0A4%20&amp;%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"> The transpose of A, denoted by A^T, is the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5ET%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%204%5C%5C%0A2%20&amp;%205%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="determinant" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="determinant"><span class="header-section-number">2.5</span> Determinant</h3>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> square matrix. The determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C"> or <img src="https://latex.codecogs.com/png.latex?%5Cdet(%5Cmathbf%7BA%7D)">, is a scalar value calculated as the sum of the products of the elements in any row or column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> with their corresponding cofactors, that is,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D=%5Csum_%7Bj=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column, and <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D"> is the cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">. The cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D">, is given by <img src="https://latex.codecogs.com/png.latex?(-1)%5E%7Bi+j%7D"> times the determinant of the <img src="https://latex.codecogs.com/png.latex?(n-1)%20%5Ctimes%20(n-1)"> matrix obtained by deleting the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>The determinant of an <img src="https://latex.codecogs.com/png.latex?n%20x%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is a scalar value denoted as <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C">. It is defined as the sum of all possible products of n elements taken one from each row and one from each column, where the sign of each product alternates according to the position of the element in the matrix. For example, the determinant of a <img src="https://latex.codecogs.com/png.latex?3%20x%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20="> <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%20a_%7B11%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B32%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A-%20a_%7B12%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A+%20a_%7B13%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%0A%5Cend%7Bvmatrix%7D%0A"></p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?3%20%5Ctimes%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%204%20&amp;%205%20&amp;%206%20%5C%5C%207%20&amp;%208%20&amp;%209%20%5Cend%7Bbmatrix%7D">. We can calculate the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> using any row or column. Let’s use the first column:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%201%0A%5Cbegin%7Bvmatrix%7D%0A5%20&amp;%206%20%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A-%204%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%203%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A+%207%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%205%20%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bvmatrix%7D%20=%200%0A"></p>
<p>Therefore, the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is zero.</p>
</section>
<section id="inverse" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="inverse"><span class="header-section-number">2.6</span> Inverse</h3>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?A"> of size <img src="https://latex.codecogs.com/png.latex?n"> is a matrix <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> such that the product of <img src="https://latex.codecogs.com/png.latex?A"> and <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> is the identity matrix <img src="https://latex.codecogs.com/png.latex?I_n">, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I_n">. If such a matrix exists, then <img src="https://latex.codecogs.com/png.latex?A"> is said to be invertible or non-singular.</p>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D"> and is defined as the unique matrix that satisfies the following equation: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BI%7D"> is the identity matrix. Not all matrices have an inverse, and a matrix that has an inverse is called invertible or nonsingular. A matrix that does not have an inverse is called singular.</p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?2%5Ctimes%202"> matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D.%0A"> The inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cfrac%7B1%7D%7B-2%7D%0A%5Cbegin%7Bbmatrix%7D%0A4%20&amp;%20-2%20%5C%5C%0A-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>We can verify that <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BI%7D"> by computing:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%20-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>Let me give another example and A be a <img src="https://latex.codecogs.com/png.latex?3x3"> square matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D">, is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B%5Ctext%7Bdet%7D(%5Cmathbf%7BA%7D)%7D%5Cbegin%7Bbmatrix%7D%0Aa_%7B22%7Da_%7B33%7D-a_%7B23%7Da_%7B32%7D%20&amp;%20a_%7B13%7Da_%7B32%7D-a_%7B12%7Da_%7B33%7D%20&amp;%20a_%7B12%7Da_%7B23%7D-a_%7B13%7Da_%7B22%7D%20%5C%5C%0Aa_%7B23%7Da_%7B31%7D-a_%7B21%7Da_%7B33%7D%20&amp;%20a_%7B11%7Da_%7B33%7D-a_%7B13%7Da_%7B31%7D%20&amp;%20a_%7B13%7Da_%7B21%7D-a_%7B11%7Da_%7B23%7D%20%5C%5C%0Aa_%7B21%7Da_%7B32%7D-a_%7B22%7Da_%7B31%7D%20&amp;%20a_%7B12%7Da_%7B31%7D-a_%7B11%7Da_%7B32%7D%20&amp;%20a_%7B11%7Da_%7B22%7D-a_%7B12%7Da_%7B21%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?det(%5Cmathbf%7BA%7D)"> is the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%20%5C%5C%0A0%20&amp;%201%20&amp;%204%20%5C%5C%0A5%20&amp;%206%20&amp;%200%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, <img src="https://latex.codecogs.com/png.latex?det(A)"> = -57, and the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B-57%7D%5Cbegin%7Bbmatrix%7D%0A-24%20&amp;%2018%20&amp;%205%20%5C%5C%0A20%20&amp;%20-15%20&amp;%20-4%20%5C%5C%0A-3%20&amp;%202%20&amp;%201%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>There are several formulas for finding the inverse of a matrix such as Gauss-Jordan Elimination, Adjoint method, Cramer’s rule, Inverse formula, etc. This topic is going to be handled in the other blogs.</p>
</section>
<section id="rank" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="rank"><span class="header-section-number">2.7</span> Rank</h3>
<p>The rank of a matrix is the dimension of the vector space spanned by its columns (or rows). It is denoted by <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Brank%7D(%5Cmathbf%7BA%7D)">.</p>
<p>For example, consider the following matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%20%20%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%20&amp;%203%5C%5C%0A%20%20%20%204%20&amp;%205%20&amp;%206%20%5C%5C%0A%20%20%20%207%20&amp;%208%20&amp;%209%5C%5C%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are linearly dependent since the third column is equal to the sum of the first two columns. Therefore, the dimension of the vector space spanned by the columns is 2, so the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is 2.</p>
</section>
<section id="trace" class="level3" data-number="2.8">
<h3 data-number="2.8" class="anchored" data-anchor-id="trace"><span class="header-section-number">2.8</span> Trace</h3>
<p>The trace of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)">, is defined as the sum of the diagonal elements of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">. In other words, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> matrix, then its trace is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D"> denotes the <img src="https://latex.codecogs.com/png.latex?i"> th diagonal element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%202%20&amp;%203%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%205%20&amp;%202%20%5C%5C%0A%20%201%20&amp;%201%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>Then, the trace of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)%20=%202%20+%205%20+%204%20=%2011"></p>
</section>
<section id="eigenvalues-and-eigenvectors" class="level3" data-number="2.9">
<h3 data-number="2.9" class="anchored" data-anchor-id="eigenvalues-and-eigenvectors"><span class="header-section-number">2.9</span> Eigenvalues and Eigenvectors</h3>
<p>Let A be an <img src="https://latex.codecogs.com/png.latex?n%20%C3%97%20n"> square matrix. A scalar <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is called an eigenvalue of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> if there exists a non-zero vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> such that <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BAv%7D=%5Clambda%5Cmathbf%7Bv%7D%0A"></p>
<p>Such a vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> is called an eigenvector corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda">.</p>
<p>Example:</p>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> be the matrix</p>
<p>To find the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">, we solve the characteristic equation <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%20=%200">, where I is the n × n identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%0A%20%20&amp;=%0A%20%20%20%20%5Cbegin%7Bvmatrix%7D%0A%20%20%20%203%20-%20%5Clambda%20&amp;%201%20%5C%5C%0A%20%20%20%201%20&amp;%203%20-%20%5Clambda%0A%20%20%20%20%5Cend%7Bvmatrix%7D%20%5C%5C%0A%20%20&amp;=%0A%20%20(3%20-%20%5Clambda)(3%20-%20%5Clambda)%20-%201%20%5C%5C%0A%20%20&amp;=%20%5Clambda%5E2%20-%206%5Clambda%20+%208%20=%200%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this quadratic equation gives us the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">: <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202"> and <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">.</p>
<p>To find the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%20%5Cmathbf%7B0%7D">, where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20I"> is the <img src="https://latex.codecogs.com/png.latex?2%20%5Ctimes%202"> identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%0A%20%20%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%20%201%20&amp;%201%20%5C%5C%0A%20%20%20%20%20%201%20&amp;%201%0A%20%20%20%20%5Cend%7Bbmatrix%7D%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20x%20%5C%5C%0A%20%20%20%20y%0A%20%20%5Cend%7Bbmatrix%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%200%20%5C%5C%0A%20%20%20%200%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this system of equations gives us the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D%20=%20%5Cbegin%7Bbmatrix%7D%20-1%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
<p>Similarly, for <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%204%5Cmathbf%20I)%5Cmathbf%7Bv%7D"> = <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D"> to get the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
</section>
<section id="singular-value-and-singluar-vectors" class="level3" data-number="2.10">
<h3 data-number="2.10" class="anchored" data-anchor-id="singular-value-and-singluar-vectors"><span class="header-section-number">2.10</span> Singular value and Singluar Vectors</h3>
<p>The singular value decomposition (SVD) of a matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> is a factorization of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> into the product of three matrices as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20m"> orthogonal matrix, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> rectangular diagonal matrix with non-negative real numbers on the diagonal, and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> orthogonal matrix.</p>
<p>The diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> are called the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Csigma_1,%20%5Csigma_2,%20%5Cldots,%20%5Csigma_r"> (where <img src="https://latex.codecogs.com/png.latex?r"> is the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">), and are arranged in descending order. The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> are called the left and right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, respectively, and are orthonormal vectors.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be a 3 by 2 matrix given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%5C%5C%0A%20%20%20%203%20&amp;%204%5C%5C%0A%20%20%20%205%20&amp;%206%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The SVD of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.23%20&amp;%20-0.53%20&amp;%20-0.81%5C%5C%0A%20%20-0.53%20&amp;%20-0.72%20&amp;%200.45%5C%5C%0A%20%20-0.81%20&amp;%200.45%20&amp;%20-0.38%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%209.53%20&amp;%200%5C%5C%0A%20%200%20&amp;%200.90%5C%5C%0A%20%200%20&amp;%200%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.62%20&amp;%20-0.78%5C%5C%0A%20%20-0.78%20&amp;%200.62%0A%5Cend%7Bbmatrix%7D%5ET%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where the left singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D">, the right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D">, and the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5CSigma%7D">.</p>
<ul>
<li>연립 방정식을 행렬의 곱으로 나타내보기 <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bmatrix%7Dx_1+2y_1=4%5C%5C2x_1+5y_1=9%5Cend%7Bmatrix%7D%20%5Cquad%20%5Cquad%20%5Cquad%20%5Cbegin%7Bmatrix%7Dx_2+2y_2=3%5C%5C2x_2+5y_2=7%5Cend%7Bmatrix%7D"> <img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20%5C%5C%202%20&amp;%205%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20%5C%5C%20y_1%20&amp;%20y_2%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%204%20&amp;%209%20%5C%5C%203%20&amp;%207%20%5Cend%7Bbmatrix%7D"></li>
<li>중요한 사실(….당연한 사실?)
<ul>
<li>곱셈의 왼쪽 행렬의 열 수와, 오른쪽 행렬의 행 수가 같아야 가능함
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20B_%7Bo%20%5Ctimes%20p%7D"> 에서 <img src="https://latex.codecogs.com/png.latex?n%20=%20o"> 여야 곱셈 성립</li>
</ul></li>
<li>곱셈의 결과 행렬의 크기 = 곱셈의 왼쪽 행렬의 행 수 <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> 곱셈의 오른쪽 행렬의 열 수
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20B_%7Bo%20%5Ctimes%20p%7D%20=%20C_%7Bm%20%5Ctimes%20p%7D"></li>
</ul></li>
<li>교환법칙(Commutative property)이 성립하지 않음
<ul>
<li><img src="https://latex.codecogs.com/png.latex?AB%20%5Cneq%20BA"></li>
</ul></li>
</ul></li>
<li>행렬 곱셈의 여러가지 관점
<ul>
<li>내적으로 바라보기 <img src="https://latex.codecogs.com/png.latex?%20A%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20"> <img src="https://latex.codecogs.com/png.latex?%20AB%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%7D%20&amp;%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_1%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_1%5ET%20b_m%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_2%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_2%5ET%20b_m%7D%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_m%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%5ET%20b_m%7D%20%5Cend%7Bbmatrix%7D"></li>
<li>rank-1 matrix의 합 (또 안가르쳐준 개념 먼저 사용중…..-_-) <img src="https://latex.codecogs.com/png.latex?AB%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%7D%20&amp;%20%5Cmathbf%7Ba_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Bb_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Bb_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7Ba_1%20b_1%5ET%7D%20+%20%5Cmathbf%7Ba_2%20b_2%5ET%7D%20+%20%5Ccdots%20+%20%5Cmathbf%7Ba_m%20b_m%5ET%7D"></li>
<li>column space로 바라보기 <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%7D%20&amp;%20%5Cmathbf%7Ba_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20%5C%5C%20x_2%20%5C%5C%20%5Cvdots%20%5C%5C%20x_m%20%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7Ba_1%7D%20x_1%20+%20%5Cmathbf%7Ba_2%7D%20x_2%20+%20%5Ccdots%20+%20%5Cmathbf%7Ba_m%7D%20x_m%20"> (스칼라배의 합)
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20%5C%5C%200%20&amp;%201%20%5Cend%7Bbmatrix%7D"> 는 2차원 좌표평면의 모든 점을, <img src="https://latex.codecogs.com/png.latex?A=%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%200%20%5C%5C%200%20&amp;%201%20&amp;%200%20%5C%5C%200%20&amp;%200%20&amp;%201%20%5Cend%7Bbmatrix%7D">은 3차원 좌표평면의 모든 점 표현 가능</li>
<li><img src="https://latex.codecogs.com/png.latex?AB%20=%20A%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%7D%20&amp;%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20A%20%5Cmathbf%7Bb_1%7D%20&amp;%20A%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20A%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D"></li>
<li>column space: A의 column vector로 만들 수 있는 부분 공간</li>
</ul></li>
<li>row space로 바라보기 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%5ET%7DA%20=%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20&amp;%20%5Ccdots%20&amp;%20x_m%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20=%20x_1%20%5Cmathbf%7Ba_1%5ET%7D%20+%20x_2%20%5Cmathbf%7Ba_2%5ET%7D%20+%20%5Ccdots%20+%20x_m%20%5Cmathbf%7Ba_m%5ET%7D%20"></li>
</ul></li>
</ul>
</section>
</section>
<section id="열공간column-space" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="열공간column-space"><span class="header-section-number">3</span> 열공간(Column Space)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/g0eaDeVRdZk" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>column space: column vector 들이 span 하는 space
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A">의 column space = <img src="https://latex.codecogs.com/png.latex?C(A)"> 또는 <img src="https://latex.codecogs.com/png.latex?range(A)"></li>
</ul></li>
<li>span: vector들의 linear combination 으로 나타낼 수 있는 모든 vector를 모은 집합
<ul>
<li>vector에 따라, 점일수도 선일수도 평면일 수도 있음</li>
<li>vector space를 이 vector들이 span하는 space → column space는 행렬의 열들이 span하는 space</li>
</ul></li>
<li>vector의 선형 결합(linear combination): vector에 스칼라배를 해서 더하는 것
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D"> 과 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D">의 linear combination으로 2차원 좌표평면 나타내기 <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" class="img-fluid"></li>
</ul></li>
</ul>
</section>
<section id="선형-독립linear-independent" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="선형-독립linear-independent"><span class="header-section-number">4</span> 선형 독립(Linear Independent)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/mOOI4-BfjGQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>…and also see</p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/9F4PZ_1orF0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>선형 독립(linearly independent)인 vectors: (선형 결합을 통해) 더 고차원을 span할 수 있게 해줌</li>
<li>orthogonal 하면 independent
<ul>
<li>but independent해도 항상 orthogonal하지는 않음 (Independent &gt; Orthogonal)</li>
</ul></li>
<li>definition: <img src="https://latex.codecogs.com/png.latex?a_1%20%5Cmathbf%7Bv_1%7D%20+%20a_2%20%5Cmathbf%7Bv_2%7D%20+%20a_3%20%5Cmathbf%7Bv_3%7D%20%5Ccdots%20a_n%20%5Cmathbf%7Bv_n%7D%20=%20%5Cmathbf%7B0%7D"> 를 만족하는 <img src="https://latex.codecogs.com/png.latex?a_1,%20a_2,%20a_3,%20%5Ccdots%20a_n"> 이 <img src="https://latex.codecogs.com/png.latex?a_1%20=%20a_2%20=%20a_3%20=%20%5Ccdots%20=%20a_n%20=%200"> 밖에 없을때
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D">는 모든 elements가 <img src="https://latex.codecogs.com/png.latex?0">인 벡터</li>
<li>예: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%202%20%5Cend%7Bbmatrix%7D"> 는 <img src="https://latex.codecogs.com/png.latex?-2%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D%20+%201%20%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%202%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> 이 되므로, linearly independent 하지 않음</li>
<li>independent한 vector 들의 수 = 표현할 수 있는 차원의 dimension</li>
</ul></li>
</ul>
</section>
<section id="기저basis" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="기저basis"><span class="header-section-number">5</span> 기저(basis)</h2>
<ul>
<li>주어진 vector space를 span하는 linearly independent한 vectors</li>
<li>어떤 공간을 이루는 필수적인 구성요소</li>
<li>orthogonal 하면 orthogonal basis</li>
<li>예: 2차원 좌표평면에 대해
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"> : orthogonal basis</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"> : orthogonal 하지 않은 basis</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> : linearly independent 하지 않으므로 basis 아님</li>
</ul></li>
</ul>
</section>
<section id="항등행렬identity-matrix-역행렬inverse-matrix-대각행렬diagonal-matrix-직교행렬orthogonal-matrix" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="항등행렬identity-matrix-역행렬inverse-matrix-대각행렬diagonal-matrix-직교행렬orthogonal-matrix"><span class="header-section-number">6</span> 항등행렬(identity matrix), 역행렬(inverse matrix), 대각행렬(Diagonal Matrix), 직교행렬(orthogonal matrix)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/XqOvyfMUAwA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="identity-matrix항등행렬" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="identity-matrix항등행렬"><span class="header-section-number">6.1</span> Identity matrix(항등행렬)</h3>
<ul>
<li>항등원: 임의의 원소에 대해 연산하면 자기 자신이 나오게 하는 원소 (by namu.wiki)
<ul>
<li>실수에서 곱셈의 항등원은 1</li>
</ul></li>
<li>행렬의 항등원: 항등행렬(<img src="https://latex.codecogs.com/png.latex?I">) <img src="https://latex.codecogs.com/png.latex?I%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%200%20&amp;%201%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%200%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%201%20%5Cend%7Bbmatrix%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20I_%7Bn%20%5Ctimes%20n%20=%20n%7D%20=%20A_%7Bm%20%5Ctimes%20n%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?I_%7Bm%20%5Ctimes%20m%20=%20m%7D%20%5Ctimes%20A_%7Bm%20%5Ctimes%20n%7D%20=%20A_%7Bm%20%5Ctimes%20n%7D"></li>
</ul></li>
</ul>
</section>
<section id="sec-inv" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="sec-inv"><span class="header-section-number">6.2</span> Inverse matrix(역행렬)</h3>
<ul>
<li>역원: 연산 결과 항등원이 나오게 하는 연소
<ul>
<li>실수에서 곱셈의 역원은 지수의 부호가 반대인 역수 (by namu.wiki): <img src="https://latex.codecogs.com/png.latex?a%20%5Ctimes%20a%5E%7B-1%7D%20=%201"></li>
</ul></li>
<li>행렬의 역원: 역행렬(<img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D">) <img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I%20,%20A%5E%7B-1%7D%20%5Ctimes%20A%20=%20I">
<ul>
<li>존재하지 않는 경우도 있음</li>
<li>존재하면 Invertible(nonsingular, nondegenerate) matrix라고 불림
<ul>
<li>존재하지 않으면 singular, degenerate라고 불림</li>
</ul></li>
<li>square matrix(정사각행렬, <img src="https://latex.codecogs.com/png.latex?m%20=%20n">)은 특수한 경우를 제외하면 역행렬이 항상 존재
<ul>
<li>역행렬이 존재하지 않는특수한 경우: (나중에 배울) determinant가 0인 경우</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?m%20%5Cneq%20n">인 행렬의 경우에는 역행렬이 존재하지 않음
<ul>
<li>다만, 경우에 따라 <img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I"> 를 만족하거나(right inverse), <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D%20%5Ctimes%20A%20=%20I">를 만족하는(left inverse)는 <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D">이 존재함</li>
</ul></li>
<li>연립 방정식을 matrix로 나타냈을 때, 역행렬을 이용해서 해를 찾을 수 있음 <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cmathbf%7Bb%7D%20%5CRightarrow%20A%5E%7B-1%7DA%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D%20%5CRightarrow%20I%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D%20%5CRightarrow%20%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D"></li>
</ul></li>
</ul>
</section>
<section id="diagonal-matrix대각행렬" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="diagonal-matrix대각행렬"><span class="header-section-number">6.3</span> Diagonal Matrix(대각행렬)</h3>
<ul>
<li>diagonal element(대각 원소)외의 모든 elements(off-diagonal elements)가 0인 matrix <img src="https://latex.codecogs.com/png.latex?%20D%20=%20Diag(%5Cmathbf%7Ba%7D)%20=%20%5Cbegin%7Bbmatrix%7D%20a_%7B1,1%7D%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%200%20&amp;%20a_%7B2,2%7D%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%200%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%20a_%7Bn,n%7D%20%5Cend%7Bbmatrix%7D">
<ul>
<li>identity matrix는 diagonal matrix</li>
<li>diagnomal matrix는 symmetric matrix 이기도 함</li>
<li>보통은 square matrix에서 주로 사용됨
<ul>
<li>square matrix가 아니면서 diagonal matrix인 경우: rectangular diagonal matrix</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="orthogonal-matrix직교행렬-orthonomal-matrix" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="orthogonal-matrix직교행렬-orthonomal-matrix"><span class="header-section-number">6.4</span> Orthogonal matrix(직교행렬, orthonomal matrix)</h3>
<ul>
<li>행렬의 각 columns들이 orthonomal vectors (서로 수직하면서 unit vectors) <img src="https://latex.codecogs.com/png.latex?A%20A%5ET%20=%20A%5ET%20A%20=%20I"></li>
<li>identity matrix는 orthogonal matrix</li>
<li>square matrix에서만 정의됨</li>
<li>Orthogonal matrix인 <img src="https://latex.codecogs.com/png.latex?A">이면 <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D%20=%20A%5E%7BT%7D">
<ul>
<li>각 columns에서 자기 자신과의 내적 = 1, 다른 column과의 내적 = 0임</li>
</ul></li>
<li>complex matrix(복소수 행렬)에서는 unitary matrix라고 부름</li>
</ul>
</section>
</section>
<section id="계수rank" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="계수rank"><span class="header-section-number">7</span> 계수(Rank)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/HMST0Yc7EXE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>rank: 행렬이 가지는 independent한 columns의 수 = column space의 dimension = row space의 dimension</li>
<li>independent한 column의 수 = independent한 행의 수: <img src="https://latex.codecogs.com/png.latex?rank(A)%20=%20rank(A%5ET)">
<ul>
<li>proof: <a href="https://en.wikipedia.org/wiki/Rank_%28linear_algebra%29#Proofs_that_column_rank_=_row_rank">Wikipedia</a></li>
</ul></li>
<li>예: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%200%20&amp;%200%20&amp;%200%20%5Cend%7Bbmatrix%7D%20%5CRightarrow%20rank=1"> <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%201%20%5C%5C%200%20&amp;%201%20&amp;%201%20%5Cend%7Bbmatrix%7D%20%5CRightarrow%20rank=2"></li>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D"> 의 최대 랭크는 <img src="https://latex.codecogs.com/png.latex?min%5C%7Bm,n%5C%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?rank(A)%20%3C%20min%5C%7Bm,n%5C%7D"> 면 rank-deficient, <img src="https://latex.codecogs.com/png.latex?rank(A)%20=%20min%5C%7Bm,n%5C%7D">면 full (row/column) rank</li>
</ul></li>
</ul>
</section>
<section id="영공간null-space" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="영공간null-space"><span class="header-section-number">8</span> 영공간(Null space)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/Eizc9TSRYMQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%20%5Cmathbf%7B0%7D"> 을 만족하는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">의 집합
<ul>
<li>column space 관점에서 보기: <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20x_1%20%5Cmathbf%7Ba_1%7D%20+%20x_2%20%5Cmathbf%7Ba_2%7D%20+%20%5Ccdots%20+%20x_n%20%5Cmathbf%7Ba_n%7D%20=%20%5Cmathbf%7B0%7D"></li>
<li>null space에 항상 들어가는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%200%20%5C%5C%20%5Cvdots%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> : trivial solution
<ul>
<li>모든 columns이 다 lienarly independent 하면, null space에는 위의 벡터 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D">하나 밖에 없음</li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D"> 가 아닌 vector가 null space에 있으면, 스칼라배(constant <img src="https://latex.codecogs.com/png.latex?c">에 대해 <img src="https://latex.codecogs.com/png.latex?c%20%5Cmathbf%7Bx%7D">) 역시 null space에 포함됨</li>
<li>혼동 주의! null space는 column space의 일부가 아님
<ul>
<li>row vector의 차원이 null space가 존재하는 공간</li>
</ul></li>
<li>rank와 null space의 dimension의 합은 항상 matrix의 column의 수
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D">에 대해, <img src="https://latex.codecogs.com/png.latex?dim(N(A))%20=%20n%20-%20r">
<ul>
<li>모든 columns이 다 lienarly independent 하면 null space는 0차원(점)</li>
</ul></li>
<li>null space는 row space와 수직한 space
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%20%5Cmathbf%7B0%7D"> : 각각 모든 행과 내적해서 0, → 행들의 linear combination과 내적해도 0</li>
<li>rank는 row space의 dimension → row space의 dimension(<img src="https://latex.codecogs.com/png.latex?dim(R(A))">)과 null space의 dimension(<img src="https://latex.codecogs.com/png.latex?dim(N(A))">)의 합이 <img src="https://latex.codecogs.com/png.latex?n"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%5En%7D"> 공간에 표현: <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_10.PNG" class="img-fluid">
<ul>
<li>겹친 점: 영벡터</li>
</ul></li>
</ul></li>
</ul></li>
<li>left null space: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%5ET%7D%20A%20=%20%5Cmathbf%7B0%5ET%7D"> 인 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">
<ul>
<li>위의 성질을 row에 대해 적용
<ul>
<li>m 차원에 놓인 벡터</li>
<li>dimension: <img src="https://latex.codecogs.com/png.latex?dim(N_L(A))%20=%20m%20-%20r"></li>
<li>column space와 수직: <img src="https://latex.codecogs.com/png.latex?dim(N_L(A))%20+dim(C(A))%20=%20m"></li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?R(A)">에 있는 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_r%7D"> 와 <img src="https://latex.codecogs.com/png.latex?N(A)">에 있는 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 대해:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_r%7D">에 <img src="https://latex.codecogs.com/png.latex?A">를 곱하면 column space로 감</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 <img src="https://latex.codecogs.com/png.latex?A">를 곱하면 $</li>
<li><img src="https://latex.codecogs.com/png.latex?A(%5Cmathbf%7Bx_r%7D%20+%5Cmathbf%7Bx_n%7D)%20=%20A%5Cmathbf%7Bx_r%7D%20+%20A%5Cmathbf%7Bx_n%7D%20=%20A%5Cmathbf%7Bx_r%7D%20=%20%5Cmathbf%7Bb%7D"></li>
</ul></li>
</ul>
</section>
<section id="ax-b의-해의-수" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="ax-b의-해의-수"><span class="header-section-number">9</span> Ax = b의 해의 수</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/nNI2TlD598c" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><p>full column rank 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 있으면 해가 하나</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 없으면 해가 없음 <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_11.PNG" class="img-fluid"></li>
</ul></li>
<li><p>full row rank 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">는 항상 column space 안에 있음: 무한의 해를 가짐</li>
<li>임의의 특정한 해(particular solution) <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_p%7D">와 null space의 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 대해, <img src="https://latex.codecogs.com/png.latex?A(%5Cmathbf%7Bx_p%7D%20+%5Cmathbf%7Bx_n%7D)=%5Cmathbf%7Bb%7D">
<ul>
<li>즉, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_p%7D%20+%5Cmathbf%7Bx_n%7D"> 도 해가 됨: complete solution
<ul>
<li>null space는 무한하므로, 해도 무한함</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>full rank 일때(square matrix): 해가 하나 존재 (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D">$)</p></li>
<li><p>rank-deficient 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 있으면 무한한 해를 가짐</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 없으면 해가 없음</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/05.vector_space.html</guid>
  <pubDate>Thu, 30 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" medium="image"/>
</item>
<item>
  <title>Basics (3) - Special Matrices</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/07.rank.html</link>
  <description><![CDATA[ 



<section id="matrix" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="matrix"><span class="header-section-number">1</span> Matrix</h2>
<p>A matrix is a rectangular array of elements, usually real numbers, arranged in rows and columns. If <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix, it can be represented as: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%20a_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B1n%7D%20%5C%5C%0A%20%20a_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B2n%7D%20%5C%5C%0A%20%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20a_%7Bm1%7D%20&amp;%20a_%7Bm2%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7Bmn%7D%0A%5Cend%7Bbmatrix%7D%0A"> where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of the matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
</section>
<section id="basic-matrix-operations" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="basic-matrix-operations"><span class="header-section-number">2</span> Basic Matrix Operations</h2>
<section id="matrix-addition" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="matrix-addition"><span class="header-section-number">2.1</span> Matrix addition</h3>
<p>The sum of two matrices of the same size is a matrix of the same size obtained by adding corresponding entries.</p>
<p>Given two <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">, their sum <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BA%7D%20+%20%5Cmathbf%7BB%7D"> is defined by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D=a_%7Bi,j%7D+b_%7Bi,j%7D%E2%80%8B%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%201%20&amp;%202%20%5C%5C%0A%20%203%20&amp;%204%20%5C%5C%0A%20%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20+%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-1%20&amp;%200%20%5C%5C%0A%20%202%20&amp;%20-3%20%5C%5C%0A%20%20-5%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%200%20&amp;%202%20%5C%5C%0A%20%205%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%2010%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="scalar-multiplication" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="scalar-multiplication"><span class="header-section-number">2.2</span> Scalar multiplication</h3>
<p>The product of a scalar and a matrix is a matrix obtained by multiplying each entry of the matrix by the scalar.</p>
<p>Given a scalar <img src="https://latex.codecogs.com/png.latex?k"> and an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, their product <img src="https://latex.codecogs.com/png.latex?k%5Cmathbf%7BA%7D"> is defined by: <img src="https://latex.codecogs.com/png.latex?%0A(k%5Cmathbf%7BA%7D)_%7Bi,j%7D%20=%20k(a_%7Bi,j%7D)%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A2%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A2%20&amp;%204%20%5C%5C%0A6%20&amp;%208%20%5C%5C%0A10%20&amp;%2012%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="matrix-multiplication" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="matrix-multiplication"><span class="header-section-number">2.3</span> Matrix multiplication</h3>
<p>The product of two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> is a matrix obtained by multiplying the rows of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> by the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">.</p>
<p>Given two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> with dimensions <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> and <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20p">, respectively, their product <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BAB%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20p"> matrix defined by: <img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D%20=%20%5Csum_%7Bk=1%7D%5En%20a_%7Bi,k%7Db_%7Bk,j%7D%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20p">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%0A-1%20&amp;%200%20&amp;%202%20%5C%5C%0A2%20&amp;%20-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A3%20&amp;%20-6%20&amp;%204%20%5C%5C%0A5%20&amp;%20-12%20&amp;%2010%20%5C%5C%0A7%20&amp;%20-18%20&amp;%2016%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="transpose" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="transpose"><span class="header-section-number">2.4</span> Transpose</h3>
<p>The transpose of an <img src="https://latex.codecogs.com/png.latex?m%20x%20n"> matrix A, denoted by <img src="https://latex.codecogs.com/png.latex?A%5ET">, is the <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix obtained by interchanging the rows and columns of A. Formally, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Ba_%7Bij%7D%5D"> is an m x n matrix, then its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET%20=%20%5Bb_%7Bij%7D%5D"> is an <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix where <img src="https://latex.codecogs.com/png.latex?b_%7Bij%7D"> = <img src="https://latex.codecogs.com/png.latex?a_%7Bji%7D"> for all <img src="https://latex.codecogs.com/png.latex?i"> and <img src="https://latex.codecogs.com/png.latex?j">. In other words, the element in the <img src="https://latex.codecogs.com/png.latex?i"> th row and <img src="https://latex.codecogs.com/png.latex?j"> th column of <img src="https://latex.codecogs.com/png.latex?A%5ET"> is equal to the element in the <img src="https://latex.codecogs.com/png.latex?j"> th row and ith column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>Given an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20m"> matrix defined by: $$ <em>{i,j}^T = </em>{j,i}</p>
<p>$$</p>
<ul>
<li>When <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is transposed, diagnoal entries(<img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D">) do not change but off-diagnoal elements(<img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D%20%5C;%20i%20%5Cneq%20j">) change.</li>
<li>A column vector is tranposed into a row vector, and vice versa.</li>
<li>symmetric matrix: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5ET"></li>
</ul>
<p>Example:</p>
<p>Let A be the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%5C%5C%0A4%20&amp;%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"> The transpose of A, denoted by A^T, is the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5ET%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%204%5C%5C%0A2%20&amp;%205%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="determinant" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="determinant"><span class="header-section-number">2.5</span> Determinant</h3>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> square matrix. The determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C"> or <img src="https://latex.codecogs.com/png.latex?%5Cdet(%5Cmathbf%7BA%7D)">, is a scalar value calculated as the sum of the products of the elements in any row or column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> with their corresponding cofactors, that is,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D=%5Csum_%7Bj=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column, and <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D"> is the cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">. The cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D">, is given by <img src="https://latex.codecogs.com/png.latex?(-1)%5E%7Bi+j%7D"> times the determinant of the <img src="https://latex.codecogs.com/png.latex?(n-1)%20%5Ctimes%20(n-1)"> matrix obtained by deleting the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>The determinant of an <img src="https://latex.codecogs.com/png.latex?n%20x%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is a scalar value denoted as <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C">. It is defined as the sum of all possible products of n elements taken one from each row and one from each column, where the sign of each product alternates according to the position of the element in the matrix. For example, the determinant of a <img src="https://latex.codecogs.com/png.latex?3%20x%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20="> <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%20a_%7B11%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B32%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A-%20a_%7B12%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A+%20a_%7B13%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%0A%5Cend%7Bvmatrix%7D%0A"></p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?3%20%5Ctimes%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%204%20&amp;%205%20&amp;%206%20%5C%5C%207%20&amp;%208%20&amp;%209%20%5Cend%7Bbmatrix%7D">. We can calculate the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> using any row or column. Let’s use the first column:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%201%0A%5Cbegin%7Bvmatrix%7D%0A5%20&amp;%206%20%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A-%204%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%203%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A+%207%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%205%20%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bvmatrix%7D%20=%200%0A"></p>
<p>Therefore, the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is zero.</p>
</section>
<section id="inverse" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="inverse"><span class="header-section-number">2.6</span> Inverse</h3>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?A"> of size <img src="https://latex.codecogs.com/png.latex?n"> is a matrix <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> such that the product of <img src="https://latex.codecogs.com/png.latex?A"> and <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> is the identity matrix <img src="https://latex.codecogs.com/png.latex?I_n">, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I_n">. If such a matrix exists, then <img src="https://latex.codecogs.com/png.latex?A"> is said to be invertible or non-singular.</p>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D"> and is defined as the unique matrix that satisfies the following equation: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BI%7D"> is the identity matrix. Not all matrices have an inverse, and a matrix that has an inverse is called invertible or nonsingular. A matrix that does not have an inverse is called singular.</p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?2%5Ctimes%202"> matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D.%0A"> The inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cfrac%7B1%7D%7B-2%7D%0A%5Cbegin%7Bbmatrix%7D%0A4%20&amp;%20-2%20%5C%5C%0A-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>We can verify that <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BI%7D"> by computing:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%20-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>Let me give another example and A be a <img src="https://latex.codecogs.com/png.latex?3x3"> square matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D">, is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B%5Ctext%7Bdet%7D(%5Cmathbf%7BA%7D)%7D%5Cbegin%7Bbmatrix%7D%0Aa_%7B22%7Da_%7B33%7D-a_%7B23%7Da_%7B32%7D%20&amp;%20a_%7B13%7Da_%7B32%7D-a_%7B12%7Da_%7B33%7D%20&amp;%20a_%7B12%7Da_%7B23%7D-a_%7B13%7Da_%7B22%7D%20%5C%5C%0Aa_%7B23%7Da_%7B31%7D-a_%7B21%7Da_%7B33%7D%20&amp;%20a_%7B11%7Da_%7B33%7D-a_%7B13%7Da_%7B31%7D%20&amp;%20a_%7B13%7Da_%7B21%7D-a_%7B11%7Da_%7B23%7D%20%5C%5C%0Aa_%7B21%7Da_%7B32%7D-a_%7B22%7Da_%7B31%7D%20&amp;%20a_%7B12%7Da_%7B31%7D-a_%7B11%7Da_%7B32%7D%20&amp;%20a_%7B11%7Da_%7B22%7D-a_%7B12%7Da_%7B21%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?det(%5Cmathbf%7BA%7D)"> is the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%20%5C%5C%0A0%20&amp;%201%20&amp;%204%20%5C%5C%0A5%20&amp;%206%20&amp;%200%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, <img src="https://latex.codecogs.com/png.latex?det(A)"> = -57, and the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B-57%7D%5Cbegin%7Bbmatrix%7D%0A-24%20&amp;%2018%20&amp;%205%20%5C%5C%0A20%20&amp;%20-15%20&amp;%20-4%20%5C%5C%0A-3%20&amp;%202%20&amp;%201%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>There are several formulas for finding the inverse of a matrix such as Gauss-Jordan Elimination, Adjoint method, Cramer’s rule, Inverse formula, etc. This topic is going to be handled in the other blogs.</p>
</section>
<section id="rank" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="rank"><span class="header-section-number">2.7</span> Rank</h3>
<p>The rank of a matrix is the dimension of the vector space spanned by its columns (or rows). It is denoted by <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Brank%7D(%5Cmathbf%7BA%7D)">.</p>
<p>For example, consider the following matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%20%20%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%20&amp;%203%5C%5C%0A%20%20%20%204%20&amp;%205%20&amp;%206%20%5C%5C%0A%20%20%20%207%20&amp;%208%20&amp;%209%5C%5C%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are linearly dependent since the third column is equal to the sum of the first two columns. Therefore, the dimension of the vector space spanned by the columns is 2, so the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is 2.</p>
</section>
<section id="trace" class="level3" data-number="2.8">
<h3 data-number="2.8" class="anchored" data-anchor-id="trace"><span class="header-section-number">2.8</span> Trace</h3>
<p>The trace of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)">, is defined as the sum of the diagonal elements of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">. In other words, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> matrix, then its trace is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D"> denotes the <img src="https://latex.codecogs.com/png.latex?i"> th diagonal element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%202%20&amp;%203%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%205%20&amp;%202%20%5C%5C%0A%20%201%20&amp;%201%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>Then, the trace of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)%20=%202%20+%205%20+%204%20=%2011"></p>
</section>
<section id="eigenvalues-and-eigenvectors" class="level3" data-number="2.9">
<h3 data-number="2.9" class="anchored" data-anchor-id="eigenvalues-and-eigenvectors"><span class="header-section-number">2.9</span> Eigenvalues and Eigenvectors</h3>
<p>Let A be an <img src="https://latex.codecogs.com/png.latex?n%20%C3%97%20n"> square matrix. A scalar <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is called an eigenvalue of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> if there exists a non-zero vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> such that <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BAv%7D=%5Clambda%5Cmathbf%7Bv%7D%0A"></p>
<p>Such a vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> is called an eigenvector corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda">.</p>
<p>Example:</p>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> be the matrix</p>
<p>To find the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">, we solve the characteristic equation <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%20=%200">, where I is the n × n identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%0A%20%20&amp;=%0A%20%20%20%20%5Cbegin%7Bvmatrix%7D%0A%20%20%20%203%20-%20%5Clambda%20&amp;%201%20%5C%5C%0A%20%20%20%201%20&amp;%203%20-%20%5Clambda%0A%20%20%20%20%5Cend%7Bvmatrix%7D%20%5C%5C%0A%20%20&amp;=%0A%20%20(3%20-%20%5Clambda)(3%20-%20%5Clambda)%20-%201%20%5C%5C%0A%20%20&amp;=%20%5Clambda%5E2%20-%206%5Clambda%20+%208%20=%200%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this quadratic equation gives us the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">: <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202"> and <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">.</p>
<p>To find the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%20%5Cmathbf%7B0%7D">, where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20I"> is the <img src="https://latex.codecogs.com/png.latex?2%20%5Ctimes%202"> identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%0A%20%20%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%20%201%20&amp;%201%20%5C%5C%0A%20%20%20%20%20%201%20&amp;%201%0A%20%20%20%20%5Cend%7Bbmatrix%7D%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20x%20%5C%5C%0A%20%20%20%20y%0A%20%20%5Cend%7Bbmatrix%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%200%20%5C%5C%0A%20%20%20%200%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this system of equations gives us the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D%20=%20%5Cbegin%7Bbmatrix%7D%20-1%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
<p>Similarly, for <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%204%5Cmathbf%20I)%5Cmathbf%7Bv%7D"> = <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D"> to get the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
</section>
<section id="singular-value-and-singluar-vectors" class="level3" data-number="2.10">
<h3 data-number="2.10" class="anchored" data-anchor-id="singular-value-and-singluar-vectors"><span class="header-section-number">2.10</span> Singular value and Singluar Vectors</h3>
<p>The singular value decomposition (SVD) of a matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> is a factorization of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> into the product of three matrices as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20m"> orthogonal matrix, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> rectangular diagonal matrix with non-negative real numbers on the diagonal, and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> orthogonal matrix.</p>
<p>The diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> are called the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Csigma_1,%20%5Csigma_2,%20%5Cldots,%20%5Csigma_r"> (where <img src="https://latex.codecogs.com/png.latex?r"> is the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">), and are arranged in descending order. The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> are called the left and right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, respectively, and are orthonormal vectors.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be a 3 by 2 matrix given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%5C%5C%0A%20%20%20%203%20&amp;%204%5C%5C%0A%20%20%20%205%20&amp;%206%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The SVD of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.23%20&amp;%20-0.53%20&amp;%20-0.81%5C%5C%0A%20%20-0.53%20&amp;%20-0.72%20&amp;%200.45%5C%5C%0A%20%20-0.81%20&amp;%200.45%20&amp;%20-0.38%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%209.53%20&amp;%200%5C%5C%0A%20%200%20&amp;%200.90%5C%5C%0A%20%200%20&amp;%200%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.62%20&amp;%20-0.78%5C%5C%0A%20%20-0.78%20&amp;%200.62%0A%5Cend%7Bbmatrix%7D%5ET%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where the left singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D">, the right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D">, and the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5CSigma%7D">.</p>
<ul>
<li>연립 방정식을 행렬의 곱으로 나타내보기 <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bmatrix%7Dx_1+2y_1=4%5C%5C2x_1+5y_1=9%5Cend%7Bmatrix%7D%20%5Cquad%20%5Cquad%20%5Cquad%20%5Cbegin%7Bmatrix%7Dx_2+2y_2=3%5C%5C2x_2+5y_2=7%5Cend%7Bmatrix%7D"> <img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20%5C%5C%202%20&amp;%205%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20%5C%5C%20y_1%20&amp;%20y_2%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%204%20&amp;%209%20%5C%5C%203%20&amp;%207%20%5Cend%7Bbmatrix%7D"></li>
<li>중요한 사실(….당연한 사실?)
<ul>
<li>곱셈의 왼쪽 행렬의 열 수와, 오른쪽 행렬의 행 수가 같아야 가능함
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20B_%7Bo%20%5Ctimes%20p%7D"> 에서 <img src="https://latex.codecogs.com/png.latex?n%20=%20o"> 여야 곱셈 성립</li>
</ul></li>
<li>곱셈의 결과 행렬의 크기 = 곱셈의 왼쪽 행렬의 행 수 <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> 곱셈의 오른쪽 행렬의 열 수
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20B_%7Bo%20%5Ctimes%20p%7D%20=%20C_%7Bm%20%5Ctimes%20p%7D"></li>
</ul></li>
<li>교환법칙(Commutative property)이 성립하지 않음
<ul>
<li><img src="https://latex.codecogs.com/png.latex?AB%20%5Cneq%20BA"></li>
</ul></li>
</ul></li>
<li>행렬 곱셈의 여러가지 관점
<ul>
<li>내적으로 바라보기 <img src="https://latex.codecogs.com/png.latex?%20A%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20"> <img src="https://latex.codecogs.com/png.latex?%20AB%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%7D%20&amp;%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_1%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_1%5ET%20b_m%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_2%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_2%5ET%20b_m%7D%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_m%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%5ET%20b_m%7D%20%5Cend%7Bbmatrix%7D"></li>
<li>rank-1 matrix의 합 (또 안가르쳐준 개념 먼저 사용중…..-_-) <img src="https://latex.codecogs.com/png.latex?AB%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%7D%20&amp;%20%5Cmathbf%7Ba_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Bb_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Bb_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7Ba_1%20b_1%5ET%7D%20+%20%5Cmathbf%7Ba_2%20b_2%5ET%7D%20+%20%5Ccdots%20+%20%5Cmathbf%7Ba_m%20b_m%5ET%7D"></li>
<li>column space로 바라보기 <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%7D%20&amp;%20%5Cmathbf%7Ba_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20%5C%5C%20x_2%20%5C%5C%20%5Cvdots%20%5C%5C%20x_m%20%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7Ba_1%7D%20x_1%20+%20%5Cmathbf%7Ba_2%7D%20x_2%20+%20%5Ccdots%20+%20%5Cmathbf%7Ba_m%7D%20x_m%20"> (스칼라배의 합)
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20%5C%5C%200%20&amp;%201%20%5Cend%7Bbmatrix%7D"> 는 2차원 좌표평면의 모든 점을, <img src="https://latex.codecogs.com/png.latex?A=%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%200%20%5C%5C%200%20&amp;%201%20&amp;%200%20%5C%5C%200%20&amp;%200%20&amp;%201%20%5Cend%7Bbmatrix%7D">은 3차원 좌표평면의 모든 점 표현 가능</li>
<li><img src="https://latex.codecogs.com/png.latex?AB%20=%20A%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%7D%20&amp;%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20A%20%5Cmathbf%7Bb_1%7D%20&amp;%20A%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20A%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D"></li>
<li>column space: A의 column vector로 만들 수 있는 부분 공간</li>
</ul></li>
<li>row space로 바라보기 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%5ET%7DA%20=%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20&amp;%20%5Ccdots%20&amp;%20x_m%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20=%20x_1%20%5Cmathbf%7Ba_1%5ET%7D%20+%20x_2%20%5Cmathbf%7Ba_2%5ET%7D%20+%20%5Ccdots%20+%20x_m%20%5Cmathbf%7Ba_m%5ET%7D%20"></li>
</ul></li>
</ul>
</section>
</section>
<section id="열공간column-space" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="열공간column-space"><span class="header-section-number">3</span> 열공간(Column Space)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/g0eaDeVRdZk" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>column space: column vector 들이 span 하는 space
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A">의 column space = <img src="https://latex.codecogs.com/png.latex?C(A)"> 또는 <img src="https://latex.codecogs.com/png.latex?range(A)"></li>
</ul></li>
<li>span: vector들의 linear combination 으로 나타낼 수 있는 모든 vector를 모은 집합
<ul>
<li>vector에 따라, 점일수도 선일수도 평면일 수도 있음</li>
<li>vector space를 이 vector들이 span하는 space → column space는 행렬의 열들이 span하는 space</li>
</ul></li>
<li>vector의 선형 결합(linear combination): vector에 스칼라배를 해서 더하는 것
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D"> 과 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D">의 linear combination으로 2차원 좌표평면 나타내기 <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" class="img-fluid"></li>
</ul></li>
</ul>
</section>
<section id="선형-독립linear-independent" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="선형-독립linear-independent"><span class="header-section-number">4</span> 선형 독립(Linear Independent)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/mOOI4-BfjGQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>…and also see</p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/9F4PZ_1orF0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>선형 독립(linearly independent)인 vectors: (선형 결합을 통해) 더 고차원을 span할 수 있게 해줌</li>
<li>orthogonal 하면 independent
<ul>
<li>but independent해도 항상 orthogonal하지는 않음 (Independent &gt; Orthogonal)</li>
</ul></li>
<li>definition: <img src="https://latex.codecogs.com/png.latex?a_1%20%5Cmathbf%7Bv_1%7D%20+%20a_2%20%5Cmathbf%7Bv_2%7D%20+%20a_3%20%5Cmathbf%7Bv_3%7D%20%5Ccdots%20a_n%20%5Cmathbf%7Bv_n%7D%20=%20%5Cmathbf%7B0%7D"> 를 만족하는 <img src="https://latex.codecogs.com/png.latex?a_1,%20a_2,%20a_3,%20%5Ccdots%20a_n"> 이 <img src="https://latex.codecogs.com/png.latex?a_1%20=%20a_2%20=%20a_3%20=%20%5Ccdots%20=%20a_n%20=%200"> 밖에 없을때
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D">는 모든 elements가 <img src="https://latex.codecogs.com/png.latex?0">인 벡터</li>
<li>예: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%202%20%5Cend%7Bbmatrix%7D"> 는 <img src="https://latex.codecogs.com/png.latex?-2%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D%20+%201%20%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%202%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> 이 되므로, linearly independent 하지 않음</li>
<li>independent한 vector 들의 수 = 표현할 수 있는 차원의 dimension</li>
</ul></li>
</ul>
</section>
<section id="기저basis" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="기저basis"><span class="header-section-number">5</span> 기저(basis)</h2>
<ul>
<li>주어진 vector space를 span하는 linearly independent한 vectors</li>
<li>어떤 공간을 이루는 필수적인 구성요소</li>
<li>orthogonal 하면 orthogonal basis</li>
<li>예: 2차원 좌표평면에 대해
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"> : orthogonal basis</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"> : orthogonal 하지 않은 basis</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> : linearly independent 하지 않으므로 basis 아님</li>
</ul></li>
</ul>
</section>
<section id="항등행렬identity-matrix-역행렬inverse-matrix-대각행렬diagonal-matrix-직교행렬orthogonal-matrix" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="항등행렬identity-matrix-역행렬inverse-matrix-대각행렬diagonal-matrix-직교행렬orthogonal-matrix"><span class="header-section-number">6</span> 항등행렬(identity matrix), 역행렬(inverse matrix), 대각행렬(Diagonal Matrix), 직교행렬(orthogonal matrix)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/XqOvyfMUAwA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="identity-matrix항등행렬" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="identity-matrix항등행렬"><span class="header-section-number">6.1</span> Identity matrix(항등행렬)</h3>
<ul>
<li>항등원: 임의의 원소에 대해 연산하면 자기 자신이 나오게 하는 원소 (by namu.wiki)
<ul>
<li>실수에서 곱셈의 항등원은 1</li>
</ul></li>
<li>행렬의 항등원: 항등행렬(<img src="https://latex.codecogs.com/png.latex?I">) <img src="https://latex.codecogs.com/png.latex?I%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%200%20&amp;%201%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%200%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%201%20%5Cend%7Bbmatrix%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20I_%7Bn%20%5Ctimes%20n%20=%20n%7D%20=%20A_%7Bm%20%5Ctimes%20n%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?I_%7Bm%20%5Ctimes%20m%20=%20m%7D%20%5Ctimes%20A_%7Bm%20%5Ctimes%20n%7D%20=%20A_%7Bm%20%5Ctimes%20n%7D"></li>
</ul></li>
</ul>
</section>
<section id="sec-inv" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="sec-inv"><span class="header-section-number">6.2</span> Inverse matrix(역행렬)</h3>
<ul>
<li>역원: 연산 결과 항등원이 나오게 하는 연소
<ul>
<li>실수에서 곱셈의 역원은 지수의 부호가 반대인 역수 (by namu.wiki): <img src="https://latex.codecogs.com/png.latex?a%20%5Ctimes%20a%5E%7B-1%7D%20=%201"></li>
</ul></li>
<li>행렬의 역원: 역행렬(<img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D">) <img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I%20,%20A%5E%7B-1%7D%20%5Ctimes%20A%20=%20I">
<ul>
<li>존재하지 않는 경우도 있음</li>
<li>존재하면 Invertible(nonsingular, nondegenerate) matrix라고 불림
<ul>
<li>존재하지 않으면 singular, degenerate라고 불림</li>
</ul></li>
<li>square matrix(정사각행렬, <img src="https://latex.codecogs.com/png.latex?m%20=%20n">)은 특수한 경우를 제외하면 역행렬이 항상 존재
<ul>
<li>역행렬이 존재하지 않는특수한 경우: (나중에 배울) determinant가 0인 경우</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?m%20%5Cneq%20n">인 행렬의 경우에는 역행렬이 존재하지 않음
<ul>
<li>다만, 경우에 따라 <img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I"> 를 만족하거나(right inverse), <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D%20%5Ctimes%20A%20=%20I">를 만족하는(left inverse)는 <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D">이 존재함</li>
</ul></li>
<li>연립 방정식을 matrix로 나타냈을 때, 역행렬을 이용해서 해를 찾을 수 있음 <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cmathbf%7Bb%7D%20%5CRightarrow%20A%5E%7B-1%7DA%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D%20%5CRightarrow%20I%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D%20%5CRightarrow%20%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D"></li>
</ul></li>
</ul>
</section>
<section id="diagonal-matrix대각행렬" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="diagonal-matrix대각행렬"><span class="header-section-number">6.3</span> Diagonal Matrix(대각행렬)</h3>
<ul>
<li>diagonal element(대각 원소)외의 모든 elements(off-diagonal elements)가 0인 matrix <img src="https://latex.codecogs.com/png.latex?%20D%20=%20Diag(%5Cmathbf%7Ba%7D)%20=%20%5Cbegin%7Bbmatrix%7D%20a_%7B1,1%7D%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%200%20&amp;%20a_%7B2,2%7D%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%200%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%20a_%7Bn,n%7D%20%5Cend%7Bbmatrix%7D">
<ul>
<li>identity matrix는 diagonal matrix</li>
<li>diagnomal matrix는 symmetric matrix 이기도 함</li>
<li>보통은 square matrix에서 주로 사용됨
<ul>
<li>square matrix가 아니면서 diagonal matrix인 경우: rectangular diagonal matrix</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="orthogonal-matrix직교행렬-orthonomal-matrix" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="orthogonal-matrix직교행렬-orthonomal-matrix"><span class="header-section-number">6.4</span> Orthogonal matrix(직교행렬, orthonomal matrix)</h3>
<ul>
<li>행렬의 각 columns들이 orthonomal vectors (서로 수직하면서 unit vectors) <img src="https://latex.codecogs.com/png.latex?A%20A%5ET%20=%20A%5ET%20A%20=%20I"></li>
<li>identity matrix는 orthogonal matrix</li>
<li>square matrix에서만 정의됨</li>
<li>Orthogonal matrix인 <img src="https://latex.codecogs.com/png.latex?A">이면 <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D%20=%20A%5E%7BT%7D">
<ul>
<li>각 columns에서 자기 자신과의 내적 = 1, 다른 column과의 내적 = 0임</li>
</ul></li>
<li>complex matrix(복소수 행렬)에서는 unitary matrix라고 부름</li>
</ul>
</section>
</section>
<section id="계수rank" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="계수rank"><span class="header-section-number">7</span> 계수(Rank)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/HMST0Yc7EXE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>rank: 행렬이 가지는 independent한 columns의 수 = column space의 dimension = row space의 dimension</li>
<li>independent한 column의 수 = independent한 행의 수: <img src="https://latex.codecogs.com/png.latex?rank(A)%20=%20rank(A%5ET)">
<ul>
<li>proof: <a href="https://en.wikipedia.org/wiki/Rank_%28linear_algebra%29#Proofs_that_column_rank_=_row_rank">Wikipedia</a></li>
</ul></li>
<li>예: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%200%20&amp;%200%20&amp;%200%20%5Cend%7Bbmatrix%7D%20%5CRightarrow%20rank=1"> <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%201%20%5C%5C%200%20&amp;%201%20&amp;%201%20%5Cend%7Bbmatrix%7D%20%5CRightarrow%20rank=2"></li>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D"> 의 최대 랭크는 <img src="https://latex.codecogs.com/png.latex?min%5C%7Bm,n%5C%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?rank(A)%20%3C%20min%5C%7Bm,n%5C%7D"> 면 rank-deficient, <img src="https://latex.codecogs.com/png.latex?rank(A)%20=%20min%5C%7Bm,n%5C%7D">면 full (row/column) rank</li>
</ul></li>
</ul>
</section>
<section id="영공간null-space" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="영공간null-space"><span class="header-section-number">8</span> 영공간(Null space)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/Eizc9TSRYMQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%20%5Cmathbf%7B0%7D"> 을 만족하는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">의 집합
<ul>
<li>column space 관점에서 보기: <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20x_1%20%5Cmathbf%7Ba_1%7D%20+%20x_2%20%5Cmathbf%7Ba_2%7D%20+%20%5Ccdots%20+%20x_n%20%5Cmathbf%7Ba_n%7D%20=%20%5Cmathbf%7B0%7D"></li>
<li>null space에 항상 들어가는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%200%20%5C%5C%20%5Cvdots%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> : trivial solution
<ul>
<li>모든 columns이 다 lienarly independent 하면, null space에는 위의 벡터 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D">하나 밖에 없음</li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D"> 가 아닌 vector가 null space에 있으면, 스칼라배(constant <img src="https://latex.codecogs.com/png.latex?c">에 대해 <img src="https://latex.codecogs.com/png.latex?c%20%5Cmathbf%7Bx%7D">) 역시 null space에 포함됨</li>
<li>혼동 주의! null space는 column space의 일부가 아님
<ul>
<li>row vector의 차원이 null space가 존재하는 공간</li>
</ul></li>
<li>rank와 null space의 dimension의 합은 항상 matrix의 column의 수
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D">에 대해, <img src="https://latex.codecogs.com/png.latex?dim(N(A))%20=%20n%20-%20r">
<ul>
<li>모든 columns이 다 lienarly independent 하면 null space는 0차원(점)</li>
</ul></li>
<li>null space는 row space와 수직한 space
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%20%5Cmathbf%7B0%7D"> : 각각 모든 행과 내적해서 0, → 행들의 linear combination과 내적해도 0</li>
<li>rank는 row space의 dimension → row space의 dimension(<img src="https://latex.codecogs.com/png.latex?dim(R(A))">)과 null space의 dimension(<img src="https://latex.codecogs.com/png.latex?dim(N(A))">)의 합이 <img src="https://latex.codecogs.com/png.latex?n"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%5En%7D"> 공간에 표현: <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_10.PNG" class="img-fluid">
<ul>
<li>겹친 점: 영벡터</li>
</ul></li>
</ul></li>
</ul></li>
<li>left null space: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%5ET%7D%20A%20=%20%5Cmathbf%7B0%5ET%7D"> 인 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">
<ul>
<li>위의 성질을 row에 대해 적용
<ul>
<li>m 차원에 놓인 벡터</li>
<li>dimension: <img src="https://latex.codecogs.com/png.latex?dim(N_L(A))%20=%20m%20-%20r"></li>
<li>column space와 수직: <img src="https://latex.codecogs.com/png.latex?dim(N_L(A))%20+dim(C(A))%20=%20m"></li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?R(A)">에 있는 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_r%7D"> 와 <img src="https://latex.codecogs.com/png.latex?N(A)">에 있는 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 대해:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_r%7D">에 <img src="https://latex.codecogs.com/png.latex?A">를 곱하면 column space로 감</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 <img src="https://latex.codecogs.com/png.latex?A">를 곱하면 $</li>
<li><img src="https://latex.codecogs.com/png.latex?A(%5Cmathbf%7Bx_r%7D%20+%5Cmathbf%7Bx_n%7D)%20=%20A%5Cmathbf%7Bx_r%7D%20+%20A%5Cmathbf%7Bx_n%7D%20=%20A%5Cmathbf%7Bx_r%7D%20=%20%5Cmathbf%7Bb%7D"></li>
</ul></li>
</ul>
</section>
<section id="ax-b의-해의-수" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="ax-b의-해의-수"><span class="header-section-number">9</span> Ax = b의 해의 수</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/nNI2TlD598c" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><p>full column rank 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 있으면 해가 하나</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 없으면 해가 없음 <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_11.PNG" class="img-fluid"></li>
</ul></li>
<li><p>full row rank 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">는 항상 column space 안에 있음: 무한의 해를 가짐</li>
<li>임의의 특정한 해(particular solution) <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_p%7D">와 null space의 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 대해, <img src="https://latex.codecogs.com/png.latex?A(%5Cmathbf%7Bx_p%7D%20+%5Cmathbf%7Bx_n%7D)=%5Cmathbf%7Bb%7D">
<ul>
<li>즉, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_p%7D%20+%5Cmathbf%7Bx_n%7D"> 도 해가 됨: complete solution
<ul>
<li>null space는 무한하므로, 해도 무한함</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>full rank 일때(square matrix): 해가 하나 존재 (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D">$)</p></li>
<li><p>rank-deficient 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 있으면 무한한 해를 가짐</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 없으면 해가 없음</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/07.rank.html</guid>
  <pubDate>Thu, 30 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" medium="image"/>
</item>
<item>
  <title>Basics (3) - Special Matrices</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/08.orthogonal_matrix.html</link>
  <description><![CDATA[ 



<section id="matrix" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="matrix"><span class="header-section-number">1</span> Matrix</h2>
<p>A matrix is a rectangular array of elements, usually real numbers, arranged in rows and columns. If <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix, it can be represented as: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%20a_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B1n%7D%20%5C%5C%0A%20%20a_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7B2n%7D%20%5C%5C%0A%20%20%5Cvdots%20&amp;%20%5Cvdots%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%0A%20%20a_%7Bm1%7D%20&amp;%20a_%7Bm2%7D%20&amp;%20%5Ccdots%20&amp;%20a_%7Bmn%7D%0A%5Cend%7Bbmatrix%7D%0A"> where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of the matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
</section>
<section id="basic-matrix-operations" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="basic-matrix-operations"><span class="header-section-number">2</span> Basic Matrix Operations</h2>
<section id="matrix-addition" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="matrix-addition"><span class="header-section-number">2.1</span> Matrix addition</h3>
<p>The sum of two matrices of the same size is a matrix of the same size obtained by adding corresponding entries.</p>
<p>Given two <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">, their sum <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BA%7D%20+%20%5Cmathbf%7BB%7D"> is defined by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D=a_%7Bi,j%7D+b_%7Bi,j%7D%E2%80%8B%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%201%20&amp;%202%20%5C%5C%0A%20%203%20&amp;%204%20%5C%5C%0A%20%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20+%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-1%20&amp;%200%20%5C%5C%0A%20%202%20&amp;%20-3%20%5C%5C%0A%20%20-5%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%200%20&amp;%202%20%5C%5C%0A%20%205%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%2010%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="scalar-multiplication" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="scalar-multiplication"><span class="header-section-number">2.2</span> Scalar multiplication</h3>
<p>The product of a scalar and a matrix is a matrix obtained by multiplying each entry of the matrix by the scalar.</p>
<p>Given a scalar <img src="https://latex.codecogs.com/png.latex?k"> and an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, their product <img src="https://latex.codecogs.com/png.latex?k%5Cmathbf%7BA%7D"> is defined by: <img src="https://latex.codecogs.com/png.latex?%0A(k%5Cmathbf%7BA%7D)_%7Bi,j%7D%20=%20k(a_%7Bi,j%7D)%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20n">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A2%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A2%20&amp;%204%20%5C%5C%0A6%20&amp;%208%20%5C%5C%0A10%20&amp;%2012%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="matrix-multiplication" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="matrix-multiplication"><span class="header-section-number">2.3</span> Matrix multiplication</h3>
<p>The product of two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> is a matrix obtained by multiplying the rows of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> by the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D">.</p>
<p>Given two matrices <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BB%7D"> with dimensions <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> and <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20p">, respectively, their product <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BC%7D%20=%20%5Cmathbf%7BAB%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20p"> matrix defined by: <img src="https://latex.codecogs.com/png.latex?%0Ac_%7Bi,j%7D%20=%20%5Csum_%7Bk=1%7D%5En%20a_%7Bi,k%7Db_%7Bk,j%7D%0A"> for <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20i%20%5Cleq%20m"> and <img src="https://latex.codecogs.com/png.latex?1%20%5Cleq%20j%20%5Cleq%20p">.</p>
<p>Example: <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%20%5C%5C%0A5%20&amp;%206%0A%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%0A-1%20&amp;%200%20&amp;%202%20%5C%5C%0A2%20&amp;%20-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A3%20&amp;%20-6%20&amp;%204%20%5C%5C%0A5%20&amp;%20-12%20&amp;%2010%20%5C%5C%0A7%20&amp;%20-18%20&amp;%2016%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="transpose" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="transpose"><span class="header-section-number">2.4</span> Transpose</h3>
<p>The transpose of an <img src="https://latex.codecogs.com/png.latex?m%20x%20n"> matrix A, denoted by <img src="https://latex.codecogs.com/png.latex?A%5ET">, is the <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix obtained by interchanging the rows and columns of A. Formally, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Ba_%7Bij%7D%5D"> is an m x n matrix, then its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET%20=%20%5Bb_%7Bij%7D%5D"> is an <img src="https://latex.codecogs.com/png.latex?n%20x%20m"> matrix where <img src="https://latex.codecogs.com/png.latex?b_%7Bij%7D"> = <img src="https://latex.codecogs.com/png.latex?a_%7Bji%7D"> for all <img src="https://latex.codecogs.com/png.latex?i"> and <img src="https://latex.codecogs.com/png.latex?j">. In other words, the element in the <img src="https://latex.codecogs.com/png.latex?i"> th row and <img src="https://latex.codecogs.com/png.latex?j"> th column of <img src="https://latex.codecogs.com/png.latex?A%5ET"> is equal to the element in the <img src="https://latex.codecogs.com/png.latex?j"> th row and ith column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>Given an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, its transpose <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5ET"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20m"> matrix defined by: $$ <em>{i,j}^T = </em>{j,i}</p>
<p>$$</p>
<ul>
<li>When <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is transposed, diagnoal entries(<img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D">) do not change but off-diagnoal elements(<img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D%20%5C;%20i%20%5Cneq%20j">) change.</li>
<li>A column vector is tranposed into a row vector, and vice versa.</li>
<li>symmetric matrix: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5ET"></li>
</ul>
<p>Example:</p>
<p>Let A be the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%5C%5C%0A4%20&amp;%205%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"> The transpose of A, denoted by A^T, is the matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5ET%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%204%5C%5C%0A2%20&amp;%205%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bbmatrix%7D%0A"></p>
</section>
<section id="determinant" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="determinant"><span class="header-section-number">2.5</span> Determinant</h3>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> square matrix. The determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C"> or <img src="https://latex.codecogs.com/png.latex?%5Cdet(%5Cmathbf%7BA%7D)">, is a scalar value calculated as the sum of the products of the elements in any row or column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> with their corresponding cofactors, that is,</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D=%5Csum_%7Bj=1%7D%5E%7Bn%7Da_%7Bij%7DC_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D"> is the element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> in the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column, and <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D"> is the cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">. The cofactor of <img src="https://latex.codecogs.com/png.latex?a_%7Bij%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?C_%7Bij%7D">, is given by <img src="https://latex.codecogs.com/png.latex?(-1)%5E%7Bi+j%7D"> times the determinant of the <img src="https://latex.codecogs.com/png.latex?(n-1)%20%5Ctimes%20(n-1)"> matrix obtained by deleting the <img src="https://latex.codecogs.com/png.latex?i">-th row and <img src="https://latex.codecogs.com/png.latex?j">-th column of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>The determinant of an <img src="https://latex.codecogs.com/png.latex?n%20x%20n"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is a scalar value denoted as <img src="https://latex.codecogs.com/png.latex?%7C%5Cmathbf%7BA%7D%7C">. It is defined as the sum of all possible products of n elements taken one from each row and one from each column, where the sign of each product alternates according to the position of the element in the matrix. For example, the determinant of a <img src="https://latex.codecogs.com/png.latex?3%20x%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20="> <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%20a_%7B11%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B32%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A-%20a_%7B12%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B33%7D%0A%5Cend%7Bvmatrix%7D%0A+%20a_%7B13%7D%0A%5Cbegin%7Bvmatrix%7D%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%0A%5Cend%7Bvmatrix%7D%0A"></p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?3%20%5Ctimes%203"> matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%204%20&amp;%205%20&amp;%206%20%5C%5C%207%20&amp;%208%20&amp;%209%20%5Cend%7Bbmatrix%7D">. We can calculate the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> using any row or column. Let’s use the first column:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbf%7BA%7D%7C%20=%201%0A%5Cbegin%7Bvmatrix%7D%0A5%20&amp;%206%20%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A-%204%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%203%5C%5C%0A8%20&amp;%209%0A%5Cend%7Bvmatrix%7D%0A+%207%0A%5Cbegin%7Bvmatrix%7D%0A2%20&amp;%205%20%5C%5C%0A3%20&amp;%206%0A%5Cend%7Bvmatrix%7D%20=%200%0A"></p>
<p>Therefore, the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is zero.</p>
</section>
<section id="inverse" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="inverse"><span class="header-section-number">2.6</span> Inverse</h3>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?A"> of size <img src="https://latex.codecogs.com/png.latex?n"> is a matrix <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> such that the product of <img src="https://latex.codecogs.com/png.latex?A"> and <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D"> is the identity matrix <img src="https://latex.codecogs.com/png.latex?I_n">, i.e.&nbsp;<img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I_n">. If such a matrix exists, then <img src="https://latex.codecogs.com/png.latex?A"> is said to be invertible or non-singular.</p>
<p>The inverse of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D"> and is defined as the unique matrix that satisfies the following equation: <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BI%7D"> is the identity matrix. Not all matrices have an inverse, and a matrix that has an inverse is called invertible or nonsingular. A matrix that does not have an inverse is called singular.</p>
<p>For example, consider the <img src="https://latex.codecogs.com/png.latex?2%5Ctimes%202"> matrix <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D.%0A"> The inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cfrac%7B1%7D%7B-2%7D%0A%5Cbegin%7Bbmatrix%7D%0A4%20&amp;%20-2%20%5C%5C%0A-3%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>We can verify that <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BI%7D"> by computing:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%5Cmathbf%7BA%7D%20=%0A%5Cbegin%7Bbmatrix%7D%20-2%20&amp;%201%20%5C%5C%0A%5Cfrac%7B3%7D%7B2%7D%20&amp;%20-%5Cfrac%7B1%7D%7B2%7D%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20%5C%5C%0A3%20&amp;%204%0A%5Cend%7Bbmatrix%7D%20=%0A%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%200%20%5C%5C%0A0%20&amp;%201%0A%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7BI%7D%0A"></p>
<p>Let me give another example and A be a <img src="https://latex.codecogs.com/png.latex?3x3"> square matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0Aa_%7B11%7D%20&amp;%20a_%7B12%7D%20&amp;%20a_%7B13%7D%20%5C%5C%0Aa_%7B21%7D%20&amp;%20a_%7B22%7D%20&amp;%20a_%7B23%7D%20%5C%5C%0Aa_%7B31%7D%20&amp;%20a_%7B32%7D%20&amp;%20a_%7B33%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D%5E%7B-1%7D">, is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B%5Ctext%7Bdet%7D(%5Cmathbf%7BA%7D)%7D%5Cbegin%7Bbmatrix%7D%0Aa_%7B22%7Da_%7B33%7D-a_%7B23%7Da_%7B32%7D%20&amp;%20a_%7B13%7Da_%7B32%7D-a_%7B12%7Da_%7B33%7D%20&amp;%20a_%7B12%7Da_%7B23%7D-a_%7B13%7Da_%7B22%7D%20%5C%5C%0Aa_%7B23%7Da_%7B31%7D-a_%7B21%7Da_%7B33%7D%20&amp;%20a_%7B11%7Da_%7B33%7D-a_%7B13%7Da_%7B31%7D%20&amp;%20a_%7B13%7Da_%7B21%7D-a_%7B11%7Da_%7B23%7D%20%5C%5C%0Aa_%7B21%7Da_%7B32%7D-a_%7B22%7Da_%7B31%7D%20&amp;%20a_%7B12%7Da_%7B31%7D-a_%7B11%7Da_%7B32%7D%20&amp;%20a_%7B11%7Da_%7B22%7D-a_%7B12%7Da_%7B21%7D%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?det(%5Cmathbf%7BA%7D)"> is the determinant of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A1%20&amp;%202%20&amp;%203%20%5C%5C%0A0%20&amp;%201%20&amp;%204%20%5C%5C%0A5%20&amp;%206%20&amp;%200%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"> Then, <img src="https://latex.codecogs.com/png.latex?det(A)"> = -57, and the inverse of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%5E%7B-1%7D%20=%20%5Cfrac%7B1%7D%7B-57%7D%5Cbegin%7Bbmatrix%7D%0A-24%20&amp;%2018%20&amp;%205%20%5C%5C%0A20%20&amp;%20-15%20&amp;%20-4%20%5C%5C%0A-3%20&amp;%202%20&amp;%201%20%5C%5C%0A%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>There are several formulas for finding the inverse of a matrix such as Gauss-Jordan Elimination, Adjoint method, Cramer’s rule, Inverse formula, etc. This topic is going to be handled in the other blogs.</p>
</section>
<section id="rank" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="rank"><span class="header-section-number">2.7</span> Rank</h3>
<p>The rank of a matrix is the dimension of the vector space spanned by its columns (or rows). It is denoted by <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Brank%7D(%5Cmathbf%7BA%7D)">.</p>
<p>For example, consider the following matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%20%20%5Cmathbf%7BA%7D%20=%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%20&amp;%203%5C%5C%0A%20%20%20%204%20&amp;%205%20&amp;%206%20%5C%5C%0A%20%20%20%207%20&amp;%208%20&amp;%209%5C%5C%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are linearly dependent since the third column is equal to the sum of the first two columns. Therefore, the dimension of the vector space spanned by the columns is 2, so the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is 2.</p>
</section>
<section id="trace" class="level3" data-number="2.8">
<h3 data-number="2.8" class="anchored" data-anchor-id="trace"><span class="header-section-number">2.8</span> Trace</h3>
<p>The trace of a square matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted by <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)">, is defined as the sum of the diagonal elements of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">. In other words, if <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> matrix, then its trace is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)=%5Csum_%7Bi=1%7D%5E%7Bn%7Da_%7Bij%7D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?a_%7Bii%7D"> denotes the <img src="https://latex.codecogs.com/png.latex?i"> th diagonal element of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bbmatrix%7D%0A%20%202%20&amp;%203%20&amp;%201%20%5C%5C%0A%20%200%20&amp;%205%20&amp;%202%20%5C%5C%0A%20%201%20&amp;%201%20&amp;%204%0A%5Cend%7Bbmatrix%7D%0A"></p>
<p>Then, the trace of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is <img src="https://latex.codecogs.com/png.latex?%5Cmathrm%7Btr%7D(%5Cmathbf%7BA%7D)%20=%202%20+%205%20+%204%20=%2011"></p>
</section>
<section id="eigenvalues-and-eigenvectors" class="level3" data-number="2.9">
<h3 data-number="2.9" class="anchored" data-anchor-id="eigenvalues-and-eigenvectors"><span class="header-section-number">2.9</span> Eigenvalues and Eigenvectors</h3>
<p>Let A be an <img src="https://latex.codecogs.com/png.latex?n%20%C3%97%20n"> square matrix. A scalar <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is called an eigenvalue of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> if there exists a non-zero vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> such that <img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BAv%7D=%5Clambda%5Cmathbf%7Bv%7D%0A"></p>
<p>Such a vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv%7D"> is called an eigenvector corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda">.</p>
<p>Example:</p>
<p>Let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> be the matrix</p>
<p>To find the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">, we solve the characteristic equation <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%20=%200">, where I is the n × n identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20%5Ctext%7Bdet%7D(%5Cmathbf%20A%20-%20%5Clambda%20%5Cmathbf%20I%20)%0A%20%20&amp;=%0A%20%20%20%20%5Cbegin%7Bvmatrix%7D%0A%20%20%20%203%20-%20%5Clambda%20&amp;%201%20%5C%5C%0A%20%20%20%201%20&amp;%203%20-%20%5Clambda%0A%20%20%20%20%5Cend%7Bvmatrix%7D%20%5C%5C%0A%20%20&amp;=%0A%20%20(3%20-%20%5Clambda)(3%20-%20%5Clambda)%20-%201%20%5C%5C%0A%20%20&amp;=%20%5Clambda%5E2%20-%206%5Clambda%20+%208%20=%200%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this quadratic equation gives us the eigenvalues of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">: <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202"> and <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">.</p>
<p>To find the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%20%5Cmathbf%7B0%7D">, where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20I"> is the <img src="https://latex.codecogs.com/png.latex?2%20%5Ctimes%202"> identity matrix.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign*%7D%0A%20%20(%5Cmathbf%20A%20-%202%20%5Cmathbf%20I)%5Cmathbf%7Bv%7D%20=%0A%20%20%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20%20%201%20&amp;%201%20%5C%5C%0A%20%20%20%20%20%201%20&amp;%201%0A%20%20%20%20%5Cend%7Bbmatrix%7D%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%20x%20%5C%5C%0A%20%20%20%20y%0A%20%20%5Cend%7Bbmatrix%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%200%20%5C%5C%0A%20%20%20%200%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Balign*%7D%0A"></p>
<p>Solving this system of equations gives us the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_1%20=%202">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D%20=%20%5Cbegin%7Bbmatrix%7D%20-1%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
<p>Similarly, for <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">, we solve the equation <img src="https://latex.codecogs.com/png.latex?(%5Cmathbf%20A%20-%204%5Cmathbf%20I)%5Cmathbf%7Bv%7D"> = <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D"> to get the eigenvectors corresponding to <img src="https://latex.codecogs.com/png.latex?%5Clambda_2%20=%204">: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D%20=%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"></p>
</section>
<section id="singular-value-and-singluar-vectors" class="level3" data-number="2.10">
<h3 data-number="2.10" class="anchored" data-anchor-id="singular-value-and-singluar-vectors"><span class="header-section-number">2.10</span> Singular value and Singluar Vectors</h3>
<p>The singular value decomposition (SVD) of a matrix <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> is a factorization of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> into the product of three matrices as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%0A"> where <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20m"> orthogonal matrix, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> is an <img src="https://latex.codecogs.com/png.latex?m%20%5Ctimes%20n"> rectangular diagonal matrix with non-negative real numbers on the diagonal, and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> is an <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20n"> orthogonal matrix.</p>
<p>The diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B%5CSigma%7D"> are called the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, denoted as <img src="https://latex.codecogs.com/png.latex?%5Csigma_1,%20%5Csigma_2,%20%5Cldots,%20%5Csigma_r"> (where <img src="https://latex.codecogs.com/png.latex?r"> is the rank of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">), and are arranged in descending order. The columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D"> are called the left and right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D">, respectively, and are orthonormal vectors.</p>
<p>For example, let <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> be a 3 by 2 matrix given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%0A%20%20%5Cbegin%7Bbmatrix%7D%0A%20%20%20%201%20&amp;%202%5C%5C%0A%20%20%20%203%20&amp;%204%5C%5C%0A%20%20%20%205%20&amp;%206%0A%20%20%5Cend%7Bbmatrix%7D%0A%5Cend%7Bequation*%7D%0A"></p>
<p>The SVD of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Bequation*%7D%0A%5Cmathbf%7BA%7D%20=%20%5Cmathbf%7BU%7D%20%5Cmathbf%7B%5CSigma%7D%20%5Cmathbf%7BV%7D%5ET%20=%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.23%20&amp;%20-0.53%20&amp;%20-0.81%5C%5C%0A%20%20-0.53%20&amp;%20-0.72%20&amp;%200.45%5C%5C%0A%20%20-0.81%20&amp;%200.45%20&amp;%20-0.38%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%209.53%20&amp;%200%5C%5C%0A%20%200%20&amp;%200.90%5C%5C%0A%20%200%20&amp;%200%0A%5Cend%7Bbmatrix%7D%0A%5Cbegin%7Bbmatrix%7D%0A%20%20-0.62%20&amp;%20-0.78%5C%5C%0A%20%20-0.78%20&amp;%200.62%0A%5Cend%7Bbmatrix%7D%5ET%0A%5Cend%7Bequation*%7D%0A"></p>
<p>where the left singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BU%7D">, the right singular vectors of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the columns of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BV%7D">, and the singular values of <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7BA%7D"> are the diagonal entries of <img src="https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5CSigma%7D">.</p>
<ul>
<li>연립 방정식을 행렬의 곱으로 나타내보기 <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bmatrix%7Dx_1+2y_1=4%5C%5C2x_1+5y_1=9%5Cend%7Bmatrix%7D%20%5Cquad%20%5Cquad%20%5Cquad%20%5Cbegin%7Bmatrix%7Dx_2+2y_2=3%5C%5C2x_2+5y_2=7%5Cend%7Bmatrix%7D"> <img src="https://latex.codecogs.com/png.latex?%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20%5C%5C%202%20&amp;%205%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20%5C%5C%20y_1%20&amp;%20y_2%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%204%20&amp;%209%20%5C%5C%203%20&amp;%207%20%5Cend%7Bbmatrix%7D"></li>
<li>중요한 사실(….당연한 사실?)
<ul>
<li>곱셈의 왼쪽 행렬의 열 수와, 오른쪽 행렬의 행 수가 같아야 가능함
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20B_%7Bo%20%5Ctimes%20p%7D"> 에서 <img src="https://latex.codecogs.com/png.latex?n%20=%20o"> 여야 곱셈 성립</li>
</ul></li>
<li>곱셈의 결과 행렬의 크기 = 곱셈의 왼쪽 행렬의 행 수 <img src="https://latex.codecogs.com/png.latex?%5Ctimes"> 곱셈의 오른쪽 행렬의 열 수
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20B_%7Bo%20%5Ctimes%20p%7D%20=%20C_%7Bm%20%5Ctimes%20p%7D"></li>
</ul></li>
<li>교환법칙(Commutative property)이 성립하지 않음
<ul>
<li><img src="https://latex.codecogs.com/png.latex?AB%20%5Cneq%20BA"></li>
</ul></li>
</ul></li>
<li>행렬 곱셈의 여러가지 관점
<ul>
<li>내적으로 바라보기 <img src="https://latex.codecogs.com/png.latex?%20A%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20"> <img src="https://latex.codecogs.com/png.latex?%20AB%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%7D%20&amp;%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_1%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_1%5ET%20b_m%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_2%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_2%5ET%20b_m%7D%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%20b_1%7D%20&amp;%20%5Cmathbf%7Ba_m%5ET%20b_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%5ET%20b_m%7D%20%5Cend%7Bbmatrix%7D"></li>
<li>rank-1 matrix의 합 (또 안가르쳐준 개념 먼저 사용중…..-_-) <img src="https://latex.codecogs.com/png.latex?AB%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%7D%20&amp;%20%5Cmathbf%7Ba_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Bb_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Bb_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7Ba_1%20b_1%5ET%7D%20+%20%5Cmathbf%7Ba_2%20b_2%5ET%7D%20+%20%5Ccdots%20+%20%5Cmathbf%7Ba_m%20b_m%5ET%7D"></li>
<li>column space로 바라보기 <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%7D%20&amp;%20%5Cmathbf%7Ba_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Ba_m%7D%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20x_1%20%5C%5C%20x_2%20%5C%5C%20%5Cvdots%20%5C%5C%20x_m%20%5Cend%7Bbmatrix%7D%20=%20%5Cmathbf%7Ba_1%7D%20x_1%20+%20%5Cmathbf%7Ba_2%7D%20x_2%20+%20%5Ccdots%20+%20%5Cmathbf%7Ba_m%7D%20x_m%20"> (스칼라배의 합)
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20%5C%5C%200%20&amp;%201%20%5Cend%7Bbmatrix%7D"> 는 2차원 좌표평면의 모든 점을, <img src="https://latex.codecogs.com/png.latex?A=%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%200%20%5C%5C%200%20&amp;%201%20&amp;%200%20%5C%5C%200%20&amp;%200%20&amp;%201%20%5Cend%7Bbmatrix%7D">은 3차원 좌표평면의 모든 점 표현 가능</li>
<li><img src="https://latex.codecogs.com/png.latex?AB%20=%20A%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Bb_1%7D%20&amp;%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%20A%20%5Cmathbf%7Bb_1%7D%20&amp;%20A%20%5Cmathbf%7Bb_2%7D%20&amp;%20%5Ccdots%20&amp;%20A%20%5Cmathbf%7Bb_m%7D%20%5Cend%7Bbmatrix%7D"></li>
<li>column space: A의 column vector로 만들 수 있는 부분 공간</li>
</ul></li>
<li>row space로 바라보기 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%5ET%7DA%20=%20%5Cbegin%7Bbmatrix%7D%20x_1%20&amp;%20x_2%20&amp;%20%5Ccdots%20&amp;%20x_m%20%5Cend%7Bbmatrix%7D%20%5Cbegin%7Bbmatrix%7D%20%5Cmathbf%7Ba_1%5ET%7D%20%5C%5C%20%5Cmathbf%7Ba_2%5ET%7D%20%5C%5C%20%5Cvdots%20%5C%5C%20%5Cmathbf%7Ba_m%5ET%7D%20%5Cend%7Bbmatrix%7D%20=%20x_1%20%5Cmathbf%7Ba_1%5ET%7D%20+%20x_2%20%5Cmathbf%7Ba_2%5ET%7D%20+%20%5Ccdots%20+%20x_m%20%5Cmathbf%7Ba_m%5ET%7D%20"></li>
</ul></li>
</ul>
</section>
</section>
<section id="열공간column-space" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="열공간column-space"><span class="header-section-number">3</span> 열공간(Column Space)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/g0eaDeVRdZk" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>column space: column vector 들이 span 하는 space
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A">의 column space = <img src="https://latex.codecogs.com/png.latex?C(A)"> 또는 <img src="https://latex.codecogs.com/png.latex?range(A)"></li>
</ul></li>
<li>span: vector들의 linear combination 으로 나타낼 수 있는 모든 vector를 모은 집합
<ul>
<li>vector에 따라, 점일수도 선일수도 평면일 수도 있음</li>
<li>vector space를 이 vector들이 span하는 space → column space는 행렬의 열들이 span하는 space</li>
</ul></li>
<li>vector의 선형 결합(linear combination): vector에 스칼라배를 해서 더하는 것
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_1%7D"> 과 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bv_2%7D">의 linear combination으로 2차원 좌표평면 나타내기 <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" class="img-fluid"></li>
</ul></li>
</ul>
</section>
<section id="선형-독립linear-independent" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="선형-독립linear-independent"><span class="header-section-number">4</span> 선형 독립(Linear Independent)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/mOOI4-BfjGQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>…and also see</p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/9F4PZ_1orF0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>선형 독립(linearly independent)인 vectors: (선형 결합을 통해) 더 고차원을 span할 수 있게 해줌</li>
<li>orthogonal 하면 independent
<ul>
<li>but independent해도 항상 orthogonal하지는 않음 (Independent &gt; Orthogonal)</li>
</ul></li>
<li>definition: <img src="https://latex.codecogs.com/png.latex?a_1%20%5Cmathbf%7Bv_1%7D%20+%20a_2%20%5Cmathbf%7Bv_2%7D%20+%20a_3%20%5Cmathbf%7Bv_3%7D%20%5Ccdots%20a_n%20%5Cmathbf%7Bv_n%7D%20=%20%5Cmathbf%7B0%7D"> 를 만족하는 <img src="https://latex.codecogs.com/png.latex?a_1,%20a_2,%20a_3,%20%5Ccdots%20a_n"> 이 <img src="https://latex.codecogs.com/png.latex?a_1%20=%20a_2%20=%20a_3%20=%20%5Ccdots%20=%20a_n%20=%200"> 밖에 없을때
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7B0%7D">는 모든 elements가 <img src="https://latex.codecogs.com/png.latex?0">인 벡터</li>
<li>예: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%202%20%5Cend%7Bbmatrix%7D"> 는 <img src="https://latex.codecogs.com/png.latex?-2%20%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D%20+%201%20%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%202%20%5Cend%7Bbmatrix%7D%20=%20%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> 이 되므로, linearly independent 하지 않음</li>
<li>independent한 vector 들의 수 = 표현할 수 있는 차원의 dimension</li>
</ul></li>
</ul>
</section>
<section id="기저basis" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="기저basis"><span class="header-section-number">5</span> 기저(basis)</h2>
<ul>
<li>주어진 vector space를 span하는 linearly independent한 vectors</li>
<li>어떤 공간을 이루는 필수적인 구성요소</li>
<li>orthogonal 하면 orthogonal basis</li>
<li>예: 2차원 좌표평면에 대해
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"> : orthogonal basis</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%201%20%5Cend%7Bbmatrix%7D"> : orthogonal 하지 않은 basis</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20%5C%5C%200%20%5Cend%7Bbmatrix%7D">, <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%202%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> : linearly independent 하지 않으므로 basis 아님</li>
</ul></li>
</ul>
</section>
<section id="항등행렬identity-matrix-역행렬inverse-matrix-대각행렬diagonal-matrix-직교행렬orthogonal-matrix" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="항등행렬identity-matrix-역행렬inverse-matrix-대각행렬diagonal-matrix-직교행렬orthogonal-matrix"><span class="header-section-number">6</span> 항등행렬(identity matrix), 역행렬(inverse matrix), 대각행렬(Diagonal Matrix), 직교행렬(orthogonal matrix)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/XqOvyfMUAwA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="identity-matrix항등행렬" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="identity-matrix항등행렬"><span class="header-section-number">6.1</span> Identity matrix(항등행렬)</h3>
<ul>
<li>항등원: 임의의 원소에 대해 연산하면 자기 자신이 나오게 하는 원소 (by namu.wiki)
<ul>
<li>실수에서 곱셈의 항등원은 1</li>
</ul></li>
<li>행렬의 항등원: 항등행렬(<img src="https://latex.codecogs.com/png.latex?I">) <img src="https://latex.codecogs.com/png.latex?I%20=%20%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%200%20&amp;%201%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%200%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%201%20%5Cend%7Bbmatrix%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D%20%5Ctimes%20I_%7Bn%20%5Ctimes%20n%20=%20n%7D%20=%20A_%7Bm%20%5Ctimes%20n%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?I_%7Bm%20%5Ctimes%20m%20=%20m%7D%20%5Ctimes%20A_%7Bm%20%5Ctimes%20n%7D%20=%20A_%7Bm%20%5Ctimes%20n%7D"></li>
</ul></li>
</ul>
</section>
<section id="sec-inv" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="sec-inv"><span class="header-section-number">6.2</span> Inverse matrix(역행렬)</h3>
<ul>
<li>역원: 연산 결과 항등원이 나오게 하는 연소
<ul>
<li>실수에서 곱셈의 역원은 지수의 부호가 반대인 역수 (by namu.wiki): <img src="https://latex.codecogs.com/png.latex?a%20%5Ctimes%20a%5E%7B-1%7D%20=%201"></li>
</ul></li>
<li>행렬의 역원: 역행렬(<img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D">) <img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I%20,%20A%5E%7B-1%7D%20%5Ctimes%20A%20=%20I">
<ul>
<li>존재하지 않는 경우도 있음</li>
<li>존재하면 Invertible(nonsingular, nondegenerate) matrix라고 불림
<ul>
<li>존재하지 않으면 singular, degenerate라고 불림</li>
</ul></li>
<li>square matrix(정사각행렬, <img src="https://latex.codecogs.com/png.latex?m%20=%20n">)은 특수한 경우를 제외하면 역행렬이 항상 존재
<ul>
<li>역행렬이 존재하지 않는특수한 경우: (나중에 배울) determinant가 0인 경우</li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?m%20%5Cneq%20n">인 행렬의 경우에는 역행렬이 존재하지 않음
<ul>
<li>다만, 경우에 따라 <img src="https://latex.codecogs.com/png.latex?A%20%5Ctimes%20A%5E%7B-1%7D%20=%20I"> 를 만족하거나(right inverse), <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D%20%5Ctimes%20A%20=%20I">를 만족하는(left inverse)는 <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D">이 존재함</li>
</ul></li>
<li>연립 방정식을 matrix로 나타냈을 때, 역행렬을 이용해서 해를 찾을 수 있음 <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20%5Cmathbf%7Bb%7D%20%5CRightarrow%20A%5E%7B-1%7DA%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D%20%5CRightarrow%20I%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D%20%5CRightarrow%20%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D%5Cmathbf%7Bb%7D"></li>
</ul></li>
</ul>
</section>
<section id="diagonal-matrix대각행렬" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="diagonal-matrix대각행렬"><span class="header-section-number">6.3</span> Diagonal Matrix(대각행렬)</h3>
<ul>
<li>diagonal element(대각 원소)외의 모든 elements(off-diagonal elements)가 0인 matrix <img src="https://latex.codecogs.com/png.latex?%20D%20=%20Diag(%5Cmathbf%7Ba%7D)%20=%20%5Cbegin%7Bbmatrix%7D%20a_%7B1,1%7D%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%200%20&amp;%20a_%7B2,2%7D%20&amp;%20%5Ccdots%20&amp;%200%20%5C%5C%20%5Cvdots%20%20&amp;%20%5Cvdots%20%20&amp;%20%5Cddots%20&amp;%20%5Cvdots%20%5C%5C%200%20&amp;%200%20&amp;%20%5Ccdots%20&amp;%20a_%7Bn,n%7D%20%5Cend%7Bbmatrix%7D">
<ul>
<li>identity matrix는 diagonal matrix</li>
<li>diagnomal matrix는 symmetric matrix 이기도 함</li>
<li>보통은 square matrix에서 주로 사용됨
<ul>
<li>square matrix가 아니면서 diagonal matrix인 경우: rectangular diagonal matrix</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="orthogonal-matrix직교행렬-orthonomal-matrix" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="orthogonal-matrix직교행렬-orthonomal-matrix"><span class="header-section-number">6.4</span> Orthogonal matrix(직교행렬, orthonomal matrix)</h3>
<ul>
<li>행렬의 각 columns들이 orthonomal vectors (서로 수직하면서 unit vectors) <img src="https://latex.codecogs.com/png.latex?A%20A%5ET%20=%20A%5ET%20A%20=%20I"></li>
<li>identity matrix는 orthogonal matrix</li>
<li>square matrix에서만 정의됨</li>
<li>Orthogonal matrix인 <img src="https://latex.codecogs.com/png.latex?A">이면 <img src="https://latex.codecogs.com/png.latex?A%5E%7B-1%7D%20=%20A%5E%7BT%7D">
<ul>
<li>각 columns에서 자기 자신과의 내적 = 1, 다른 column과의 내적 = 0임</li>
</ul></li>
<li>complex matrix(복소수 행렬)에서는 unitary matrix라고 부름</li>
</ul>
</section>
</section>
<section id="계수rank" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="계수rank"><span class="header-section-number">7</span> 계수(Rank)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/HMST0Yc7EXE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>rank: 행렬이 가지는 independent한 columns의 수 = column space의 dimension = row space의 dimension</li>
<li>independent한 column의 수 = independent한 행의 수: <img src="https://latex.codecogs.com/png.latex?rank(A)%20=%20rank(A%5ET)">
<ul>
<li>proof: <a href="https://en.wikipedia.org/wiki/Rank_%28linear_algebra%29#Proofs_that_column_rank_=_row_rank">Wikipedia</a></li>
</ul></li>
<li>예: <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20&amp;%202%20&amp;%203%20%5C%5C%200%20&amp;%200%20&amp;%200%20%5Cend%7Bbmatrix%7D%20%5CRightarrow%20rank=1"> <img src="https://latex.codecogs.com/png.latex?%5Cbegin%7Bbmatrix%7D%201%20&amp;%200%20&amp;%201%20%5C%5C%200%20&amp;%201%20&amp;%201%20%5Cend%7Bbmatrix%7D%20%5CRightarrow%20rank=2"></li>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D"> 의 최대 랭크는 <img src="https://latex.codecogs.com/png.latex?min%5C%7Bm,n%5C%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?rank(A)%20%3C%20min%5C%7Bm,n%5C%7D"> 면 rank-deficient, <img src="https://latex.codecogs.com/png.latex?rank(A)%20=%20min%5C%7Bm,n%5C%7D">면 full (row/column) rank</li>
</ul></li>
</ul>
</section>
<section id="영공간null-space" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="영공간null-space"><span class="header-section-number">8</span> 영공간(Null space)</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/Eizc9TSRYMQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%20%5Cmathbf%7B0%7D"> 을 만족하는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">의 집합
<ul>
<li>column space 관점에서 보기: <img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D%20=%20x_1%20%5Cmathbf%7Ba_1%7D%20+%20x_2%20%5Cmathbf%7Ba_2%7D%20+%20%5Ccdots%20+%20x_n%20%5Cmathbf%7Ba_n%7D%20=%20%5Cmathbf%7B0%7D"></li>
<li>null space에 항상 들어가는 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20%5Cbegin%7Bbmatrix%7D%200%20%5C%5C%200%20%5C%5C%20%5Cvdots%20%5C%5C%200%20%5Cend%7Bbmatrix%7D"> : trivial solution
<ul>
<li>모든 columns이 다 lienarly independent 하면, null space에는 위의 벡터 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D">하나 밖에 없음</li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D=%5Cmathbf%7B0%7D"> 가 아닌 vector가 null space에 있으면, 스칼라배(constant <img src="https://latex.codecogs.com/png.latex?c">에 대해 <img src="https://latex.codecogs.com/png.latex?c%20%5Cmathbf%7Bx%7D">) 역시 null space에 포함됨</li>
<li>혼동 주의! null space는 column space의 일부가 아님
<ul>
<li>row vector의 차원이 null space가 존재하는 공간</li>
</ul></li>
<li>rank와 null space의 dimension의 합은 항상 matrix의 column의 수
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A_%7Bm%20%5Ctimes%20n%7D">에 대해, <img src="https://latex.codecogs.com/png.latex?dim(N(A))%20=%20n%20-%20r">
<ul>
<li>모든 columns이 다 lienarly independent 하면 null space는 0차원(점)</li>
</ul></li>
<li>null space는 row space와 수직한 space
<ul>
<li><img src="https://latex.codecogs.com/png.latex?A%5Cmathbf%7Bx%7D=%20%5Cmathbf%7B0%7D"> : 각각 모든 행과 내적해서 0, → 행들의 linear combination과 내적해도 0</li>
<li>rank는 row space의 dimension → row space의 dimension(<img src="https://latex.codecogs.com/png.latex?dim(R(A))">)과 null space의 dimension(<img src="https://latex.codecogs.com/png.latex?dim(N(A))">)의 합이 <img src="https://latex.codecogs.com/png.latex?n"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%5En%7D"> 공간에 표현: <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_10.PNG" class="img-fluid">
<ul>
<li>겹친 점: 영벡터</li>
</ul></li>
</ul></li>
</ul></li>
<li>left null space: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%5ET%7D%20A%20=%20%5Cmathbf%7B0%5ET%7D"> 인 <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D">
<ul>
<li>위의 성질을 row에 대해 적용
<ul>
<li>m 차원에 놓인 벡터</li>
<li>dimension: <img src="https://latex.codecogs.com/png.latex?dim(N_L(A))%20=%20m%20-%20r"></li>
<li>column space와 수직: <img src="https://latex.codecogs.com/png.latex?dim(N_L(A))%20+dim(C(A))%20=%20m"></li>
</ul></li>
</ul></li>
<li><img src="https://latex.codecogs.com/png.latex?R(A)">에 있는 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_r%7D"> 와 <img src="https://latex.codecogs.com/png.latex?N(A)">에 있는 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 대해:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_r%7D">에 <img src="https://latex.codecogs.com/png.latex?A">를 곱하면 column space로 감</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 <img src="https://latex.codecogs.com/png.latex?A">를 곱하면 $</li>
<li><img src="https://latex.codecogs.com/png.latex?A(%5Cmathbf%7Bx_r%7D%20+%5Cmathbf%7Bx_n%7D)%20=%20A%5Cmathbf%7Bx_r%7D%20+%20A%5Cmathbf%7Bx_n%7D%20=%20A%5Cmathbf%7Bx_r%7D%20=%20%5Cmathbf%7Bb%7D"></li>
</ul></li>
</ul>
</section>
<section id="ax-b의-해의-수" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="ax-b의-해의-수"><span class="header-section-number">9</span> Ax = b의 해의 수</h2>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/nNI2TlD598c" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><p>full column rank 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 있으면 해가 하나</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 없으면 해가 없음 <img src="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_11.PNG" class="img-fluid"></li>
</ul></li>
<li><p>full row rank 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">는 항상 column space 안에 있음: 무한의 해를 가짐</li>
<li>임의의 특정한 해(particular solution) <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_p%7D">와 null space의 vector <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_n%7D">에 대해, <img src="https://latex.codecogs.com/png.latex?A(%5Cmathbf%7Bx_p%7D%20+%5Cmathbf%7Bx_n%7D)=%5Cmathbf%7Bb%7D">
<ul>
<li>즉, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx_p%7D%20+%5Cmathbf%7Bx_n%7D"> 도 해가 됨: complete solution
<ul>
<li>null space는 무한하므로, 해도 무한함</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>full rank 일때(square matrix): 해가 하나 존재 (<img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bx%7D%20=%20A%5E%7B-1%7D">$)</p></li>
<li><p>rank-deficient 일때</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 있으면 무한한 해를 가짐</li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bb%7D">가 column space(<img src="https://latex.codecogs.com/png.latex?C(A)">)안에 없으면 해가 없음</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>Mathematics</category>
  <guid>kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/08.orthogonal_matrix.html</guid>
  <pubDate>Thu, 30 Mar 2023 15:00:00 GMT</pubDate>
  <media:content url="kmink3225.netlify.app/docs/blog/posts/Mathmatics/linear_algebra/images/chap02_09.PNG" medium="image"/>
</item>
</channel>
</rss>
