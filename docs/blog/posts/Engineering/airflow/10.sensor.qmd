---
title: "Template Variabler"
subtitle: DAG Creation, Bash Operator, Task Performance Subject, 
description: |
  template
categories:
  - Engineering
author: Kwangmin Kim
date: 05/01/2023
format: 
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
comments: 
  utterances: 
    repo: ./docs/comments
draft: False
---

<ul class="nav nav-pills" id="language-tab" role="tablist">
  <li class="nav-item" role="presentation">
    <button class="nav-link active" id="Korean-tab" data-bs-toggle="tab" data-bs-target="#Korean" type="button" role="tab" aria-controls="Korean" aria-selected="true">Korean</button>
  </li>
  <li class="nav-item" role="presentation">
    <button class="nav-link" id="English-tab" data-bs-toggle="tab" data-bs-target="#English" type="button" role="tab" aria-controls="knitr" aria-selected="false">English</button>
  </li>

<div class="tab-content" id="language-tabcontent">

<div class="tab-pane fade  show active" id="Korean" role="tabpanel" aria-labelledby="Korean-tab">

# 센서

## 센서의 개념

* 일종의 특화된 오퍼레이터
* 특정 조건이 만족되기를 기다리고 만족되면 True를 반환하는 Task
* 모든 센서는 BaseSensorOperator를 상속하여 구현되며
(BaseSensorOperator는 BaseOperator를 상속함)
상속시에는 __init()__ 함수와 poke(context) 함수 재정의 필요
* 센싱하는 로직은 poke 함수에 정의

## BaseSensor 오퍼레이터 명세 확인

[airflow](https://airflow.apache.org/docs/apache-airflow/stable/_api/airflow/sensors/base/index.html#airflow.sensors.base.BaseSensorOperator)

* parameter
    * soft_fail (bool) – Set to true to mark the task as SKIPPED on failure
    * poke_interval (float) – Time in seconds that the job should wait in between each try
    * timeout (float) – Time, in seconds before the task times out and fails.
    * mode (str) – How the sensor operates. Options are: { poke | reschedule }, default is poke. When set to poke the sensor is taking up a worker slot for its whole execution time and sleeps between pokes. Use this mode if the expected runtime of the sensor is short or if a short poke interval is required. Note that the sensor will hold onto a worker slot and a pool slot for the duration of the sensor’s runtime in this mode. When set to reschedule the sensor task frees the worker slot when the criteria is not yet met and it’s rescheduled at a later time. Use this mode if the time before the criteria is met is expected to be quite long. The poke interval should be more than one minute to prevent too much load on the scheduler.
    * exponential_backoff (bool) – allow progressive longer waits between pokes by using exponential backoff algorithm
    * max_wait (datetime.timedelta | float | None) – maximum wait interval between pokes, can be timedelta or float seconds
    * silent_fail (bool) – If true, and poke method raises an exception different from AirflowSensorTimeout, AirflowTaskTimeout, AirflowSkipException and AirflowFailException, the sensor will log the error and continue its execution. Otherwise, the sensor task fails, and it can be retried based on the provided retries parameter.
* BaseSensor 오퍼레이터 Mode 유형
    * mode 유형

  | Comparison          | Poke Mode    | Reschedule Mode   |
  |---------------------|-----------------|:------------------------|
  | 원리                | DAG이 수행되는 내내 Running Slot을 차지. 다만 Slot 안에서 Sleep, active 를 반복   | 센서가 동작하는 시기에만 Slot을 차지. 그 외에는 Slot을 점유하지 않음 |
  | Wait에서의 Task 상태 | running            | up_for_reschedule  |
  | 유리한 적용 시점 |  짧은 센싱 간격 (interval, 초 단위)    | 긴 센싱 간격, 주로 분 단위 Reschedule될 때 스케줄러의
부하 발생 |

## BaseSensor 오퍼레이터 Mode 유형

* Pool
    * 모든 Task는 특정 Pool에서 수행되며 Pool은 Slot이라는 것을 가지고 있음.
    * 기본적으로 Task 1개당 Slot 1개를 점유하며 Pool을 지정하지 않으면 default_pool에서 수행
    ![Poke Mode vs Reschedule Mode](../../../../../images/airflow/poke.PNG)

# Bash Sensor

## Bash 센서 명세 확인

* 쉘 스크립트에서 return True를 주는 방법
    - 파이썬에서의 return True와 같은 의미로 쉘 스크립트에서는 exit 0 를 사용
* 모든 쉘은 수행을 마친 후 EXIT_STATUS를 가지고 있으며 0~255 사이의 값을 가짐.
    * EXIT 0 만 정상이며 나머지는 모두 비정상의 의미를 가짐
    * 마지막 명령 수행의 EXIT_STATUS를 확인하려면 echo $? 로 확인

# File Sensor

## File 센서 명세 확인

* [airflow.sensors.filesystem](https://airflow.apache.org/docs/apache-airflow/stable/_api/airflow/sensors/filesystem/index.html#airflow.sensors.filesystem.FileSensor)

![File Sensor Sequential Diagram](../../../../../images/airflow/File_sensor_diagram.PNG)

* Connection 작성

  | Connection_id   | conn_file_opt_airflow_files   |
  |-----------------|:------------------------------|
  | Connection_type | File (path)                   |
  | Host            |                               |
  | Schema          |                               |
  | Login           |                               |
  | Password        |                               |
  | Port            |                               |
  | Extra           | {"path":"/opt/airflow/files"} |

* Dag 작성

```markdown
from airflow import DAG
from airflow.sensors.filesystem import FileSensor
import pendulum

with DAG(
    dag_id='dags_file_sensor',
    start_date=pendulum.datetime(2023,4,1, tz='Asia/Seoul'),
    schedule='0 7 * * *',
    catchup=False
) as dag:
    tvCorona19VaccinestatNew_sensor = FileSensor(
        task_id='tvCorona19VaccinestatNew_sensor',
        fs_conn_id='conn_file_opt_airflow_files',
        filepath='tvCorona19VaccinestatNew/{{data_interval_end.in_timezone("Asia/Seoul") | ds_nodash }}/tvCorona19VaccinestatNew.csv',
        recursive=False,
        poke_interval=60,
        timeout=60*60*24, # 1일
        mode='reschedule'
    )

```

# Python Sensor
 
* [airflow.sensors.python](https://airflow.apache.org/docs/apache-airflow/stable/_api/airflow/sensors/python/index.html)

```markdown

classairflow.sensors.python.PythonSensor(*, python_callable, op_args=None, op_kwargs=None, templates_dict=None, **kwargs)[source]
Bases: airflow.sensors.base.BaseSensorOperator

Waits for a Python callable to return True.

User could put input argument in templates_dict e.g templates_dict = {'start_ds': 1970} and access the argument by calling kwargs['templates_dict']['start_ds'] in the callable

Parameters
* python_callable (Callable) – A reference to an object that is callable
* op_kwargs (Mapping[str, Any] | None) – a dictionary of keyword arguments that will get unpacked in your function
* op_args (list | None) – a list of positional arguments that will get unpacked when calling your callable
* templates_dict (dict | None) – a dictionary where the values are templates that will get templated by the Airflow engine sometime between __init__ and execute takes place and are made available in your callable’s context after the template has been applied.
```

## Python 센서 DAG 작성

* 무엇을 센싱할 것인가
    * 서울시 공공데이터에서 당일 날짜로 데이터가 생성되었는지 센싱하기(날짜 컬럼이 있는 경우)

# ExternalTask 센서

## DAG 간 의존관계 설정

* DAG 의존관계 설정 방법
    * TriggerDagRun 오퍼레이터
    
    ```{dot}

    digraph G {
      compound=true;
      rankdir=LR;
      subgraph cluster0 {
        rankdir=TB;
        task1 [shape=box];
        task2_1 [shape=box];
        task2_2 [shape=box];
        task2_3 [shape=box];

        label= "Task Flow";
      }

      task1 -> task2_1;
      task1 -> task2_2;
      task1 -> task2_3;
    
    }
    ```

    * ExternalTask 센서
    ```{dot}
    digraph G {
      compound=true;
      rankdir=LR;
      subgraph cluster0 {
        rankdir=TB;
        task1 [shape=box];
        task2 [shape=box];
        task3 [shape=box];
        task4 [shape=box];
        
        label= "Task Flow";
      }
    
      task1 -> task4;
      task2 -> task4;
      task3 -> task4; 
    }
    ```

## ExternalTask 센서 명세 확인

* [airflow.sensors.external_task](https://airflow.apache.org/docs/apache-airflow/stable/_api/airflow/sensors/external_task/index.html#module-airflow.sensors.external_task)
* 
| Parameter   | 필수여부   | 설명                  |
|-----------------|-----------------|:------------------------------|
| external_dag_id | O | 센싱할 dag 명  | 
| external_task_id | X (셋 중 하나만 입력 가능 없으면 dag만 센싱) | 센싱할 task_id 명 (string) |
| external_task_ids |  X (셋 중 하나만 입력 가능 없으면 dag만 센싱) | 센싱할 1 개 이상의 task_id 명 (list) |
| external_task_group_id |  X (셋 중 하나만 입력 가능 없으면 dag만 센싱) | 센싱할 task_group_id명 |
| allowed_status | X (같은 상태가 입력되면 안됨)  | 센서가 Success 되기 위한 센싱 대상의 상태      |
| skipped_status | X (같은 상태가 입력되면 안됨)  | 센서가 Skipped 되기 위한 센싱 대상의 상태      |
| failed_states  | X (같은 상태가 입력되면 안됨)  | 센서가 Fail 되기 위한 센싱 대상의 상태         |
| execution_delta | Login           | 현재 dag과 센싱할 dag의 data_interval_start의 차이를 입력  |
| execution_date_fn | Password      | 센싱할 dag의 data_interval_start를 구하기 위한 함수        |
| check_existence | Password        | 해당 dag_id 또는 task_id 가 있는지 확인                    |

* states: State.SKIPPED, State.SUCCESS, State.FAILED, State.QUEUED, State.SCHEDULED, State.UP_FOR_RESCHEDULE 등
(from airflow.utils.state import State 필요)

# Custom Sensor

## Custom Sensor 만들기

* 어떤 센서를 만들 것인가?
    * Python 센서에서 만들었던 로직을 Custom Sensor화 하기
    (서울시 공공데이터에서 날짜 컬럼이 있는 경우 날짜 기준 update되었는지 센싱)
* 재활용성이 높아 다른 DAG에서 활용될 가능성이 높다면 가급적이면 Custom 오퍼레이터화 해놓는 것이 좋다.
    (협업 환경에서 코드 중복 구현의 방지, 로직의 일원화 등)


</div>

<div class="tab-pane fade" id="English" role="tabpanel" aria-labelledby="English-tab">


</div>

