---
title: p-values
subtitle: Statistical Hypothesis Test 
description: |
  p-value is one of the most commonly used statistcal index to show significance level of a hypothesis testing result of your experiment.
categories:
  - statistics
author: Kwangmin Kim
date: 12/15/2022
image: coding.jpg
image-alt: "test"
draft: False
---

### Significance

It is said to be statistically significant if a result of your experiment is more extreme than one that is produced by chance. (Try thinking that your result could have come from a different distribution from the one under the null hypothesis.)

### p-value

p of 'p-value' stands for 'probability'. The p-value is the summation of the probabilities of obtaining results as extreme as the observed results from your experiments could occur under the null hypothesis. In other words, p-value is the probability that the result of your experiment is obtained by chance.

### Alpha

The probability threshold of the extreme or rarer results that chance results must be beyond actual results of your experiments in order to be said to be statistically significant.

### Type 1 error

concluding $H_o$ or the null hypothesis is true by mistake.

### Type 2 error

concluding $H_a$ or the alternative hypothesis is true by mistake.

## p-value: Good vs Bad?

### Goodness

p-value is an efficient and effective statistical index when to measure thesignificance of your test result. Let's make an assumption that you have conducted a regression analysis. Then, you can get beta coefficients and their standard errors as results of your regression model.

|              | high Standard Error    |     low Standard Error |
|--------------|:-----------------------|-----------------------:|
| high $\beta$ | Unclear Interpretation |                     OK |
| low $\beta$  | OK                     | Unclear Interpretation |

: Number of Cases of How You Interpret Regresssion Result

The above table shows the number of cases you can interprete the results of your regression model. There are 4 cases for each coefficient $\beta$.

1.  high $\beta$ and high Standard Error mean that the corresponding variable has a strong effect but its effect may be fluctuated, so the $\beta$ coefficient resulted from your regression model is likely to be not significant. We are not sure that its effect is statistically significant.
2.  high $\beta$ and low Standard Error mean that the corresponding variable has a strong effect, and its variation is small, so the $\beta$ coefficient resulted from your regression model is likely to be significant.
3.  low $\beta$ and high Standard Error mean that the corresponding variable has a weak effect on your reponse variable, its effect has a high variation. So, we can clearly interprete the variable with the $\beta$ as a variable that is not significantly associated with your response variable.
4.  low $\beta$ and high Standard Error mean that the corresponding variable has a weak effect on your reponse variable, but its effect has a low variation. So, it is difficult to conclude that the variable is significant.

The p-value could be used to provide a clearer interpretation of the unclear situation (i.e. (high $\beta$, high Standard Error), (low $\beta$, high Standard Error) ) by looking at the ratio of the estimated value of a parameter(= $\beta$) to its standard error on the distribution under the null hypothesis. By general convention, the cut-off of p-value indicating statistical signficance is 0.05.

### Badness

Despite the goodness of p-value, it is controversial to make a decision based solely on the p-value. As mentioned above, p-value is the probability that the result of your experiment is due to chance. In addition, looking into $\frac{\beta}{\frac{s.e}{\sqrt{n}}}$, the p-value gets smaller as the sample size becomes larger and larger. It should be avoided that something is *proved* just because a low p-value is calucated.

Even if a result is statistically significant, that does not necessarily mean it has real significance. A small difference that has no practical meaning can be statistically significant if the sample size is large enough. It is because large samples ensure that meaningless effects can become big enough to possibly exclude chance due to simple math.

The American Statistical Association (ASA) has released a statement of six principles for researchers and journal editors on p-values:\
[Source: ASA Statement on Statistical Significance and p-values](https://www.amstat.org/asa/files/pdfs/p-valuestatement.pdf)

1.  P-values can indicate how incompatible the data are with a specified statistical model.
2.  P-values do not measure the probability that the studied hypothesis is true, or the probability that the data produced by random chance alone.
3.  Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.
4.  Proper inference requires full reporting and transparency.
5.  A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.
6.  By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.

## How to use p-vlaues?

Personally, I make use of p-values as a tool in data science to just check whether a model result or a set of variables that appears interesting and useful is in the range of normal variability by chance in the exploratory data analysis(EDA) or data mining step.

If you want to get a statistical significance level through p-values, other methodologies could help increase the accuracy of real significance such as permuted p-values, q-values, and penalization on multiple comparison tests
